[32m[0906 13-39-13 @logger.py:99][0m Log file set to /app/logs/dats-delay-10/zinc-coating-v0_0/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-13 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00001, current rewards: 0.86234, mean: 0.08623
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00001, current rewards: -81.99213, mean: -1.36654
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00001, current rewards: -155.03500, mean: -1.40941
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00001, current rewards: -233.62039, mean: -1.46013
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00001, current rewards: -310.84099, mean: -1.48020
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00001, current rewards: -393.59528, mean: -1.51383
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00001, current rewards: -476.23974, mean: -1.53626
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00001, current rewards: -552.05312, mean: -1.53348
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00001, current rewards: -630.24237, mean: -1.53718
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00001, current rewards: -693.11491, mean: -1.50677
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00001, current rewards: -745.46591, mean: -1.46170
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00001, current rewards: -812.76992, mean: -1.45137
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00001, current rewards: -870.21401, mean: -1.42658
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00001, current rewards: -924.20315, mean: -1.40031
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00001, current rewards: -982.28325, mean: -1.38350
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00001, current rewards: -1039.32560, mean: -1.36753
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00001, current rewards: -1099.47612, mean: -1.35738
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00001, current rewards: -1156.64203, mean: -1.34493
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00001, current rewards: -1216.12005, mean: -1.33640
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00001, current rewards: -1286.99725, mean: -1.34062
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00001, current rewards: -1344.20488, mean: -1.33090
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00001, current rewards: -1407.80157, mean: -1.32811
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00001, current rewards: -1464.03109, mean: -1.31895
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00001, current rewards: -1514.08617, mean: -1.30525
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00001, current rewards: -1575.60606, mean: -1.30215
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00001, current rewards: -1613.84185, mean: -1.28083
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00001, current rewards: -1663.05707, mean: -1.26951
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00001, current rewards: -1715.11144, mean: -1.26111
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00001, current rewards: -1765.59770, mean: -1.25220
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00001, current rewards: -1818.92182, mean: -1.24584
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00001, current rewards: -1875.07499, mean: -1.24177
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00001, current rewards: -1930.40911, mean: -1.23744
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00001, current rewards: -1976.56700, mean: -1.22768
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00001, current rewards: -2029.09112, mean: -1.22234
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00001, current rewards: -2080.17962, mean: -1.21648
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00001, current rewards: -2129.34440, mean: -1.20985
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00001, current rewards: -2182.64317, mean: -1.20588
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00001, current rewards: -2222.13587, mean: -1.19470
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00001, current rewards: -2265.12474, mean: -1.18593
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00001, current rewards: -2322.86949, mean: -1.18514
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00001, current rewards: -2377.75009, mean: -1.18296
[32m[0906 13-39-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00001, current rewards: -2437.13055, mean: -1.18307
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00001, current rewards: -2483.81742, mean: -1.17716
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00001, current rewards: -2534.47004, mean: -1.17337
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00001, current rewards: -2594.74081, mean: -1.17409
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00001, current rewards: -2652.82666, mean: -1.17382
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00001, current rewards: -2714.22195, mean: -1.17499
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00001, current rewards: -2783.79918, mean: -1.17958
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00001, current rewards: -2833.11064, mean: -1.17556
[32m[0906 13-39-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00001, current rewards: -2888.15023, mean: -1.17404
[32m[0906 13-39-14 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-39-15 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-15 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.10991, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-39-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.10178, current rewards: -52.32078, mean: -0.87201
[32m[0906 13-39-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.10120, current rewards: -102.72138, mean: -0.93383
[32m[0906 13-39-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.10112, current rewards: -155.31021, mean: -0.97069
[32m[0906 13-39-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.10101, current rewards: -203.56105, mean: -0.96934
[32m[0906 13-39-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.10091, current rewards: -256.13507, mean: -0.98513
[32m[0906 13-39-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.10089, current rewards: -306.55305, mean: -0.98888
[32m[0906 13-39-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.10123, current rewards: -356.95552, mean: -0.99154
[32m[0906 13-39-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.10266, current rewards: -409.53590, mean: -0.99887
[32m[0906 13-40-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.10515, current rewards: -452.91209, mean: -0.98459
[32m[0906 13-40-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.10725, current rewards: -498.84102, mean: -0.97812
[32m[0906 13-40-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.11014, current rewards: -535.10810, mean: -0.95555
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.11320, current rewards: -577.15275, mean: -0.94615
[32m[0906 13-40-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.11595, current rewards: -612.46262, mean: -0.92797
[32m[0906 13-40-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.11925, current rewards: -656.73767, mean: -0.92498
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.12253, current rewards: -689.85024, mean: -0.90770
[32m[0906 13-40-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.12542, current rewards: -734.08826, mean: -0.90628
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.12802, current rewards: -768.92186, mean: -0.89410
[32m[0906 13-41-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.13027, current rewards: -763.12255, mean: -0.83860
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.13243, current rewards: -758.44493, mean: -0.79005
[32m[0906 13-41-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.13505, current rewards: -753.96392, mean: -0.74650
[32m[0906 13-41-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.13765, current rewards: -749.91113, mean: -0.70746
[32m[0906 13-41-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.13988, current rewards: -746.64533, mean: -0.67265
[32m[0906 13-42-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.14197, current rewards: -743.34074, mean: -0.64081
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.14385, current rewards: -740.04860, mean: -0.61161
[32m[0906 13-42-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.14561, current rewards: -736.75695, mean: -0.58473
[32m[0906 13-42-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.14718, current rewards: -733.46463, mean: -0.55990
[32m[0906 13-42-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.14867, current rewards: -730.17192, mean: -0.53689
[32m[0906 13-42-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.15004, current rewards: -726.87905, mean: -0.51552
[32m[0906 13-42-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.15130, current rewards: -723.58570, mean: -0.49561
[32m[0906 13-43-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.15249, current rewards: -720.29412, mean: -0.47702
[32m[0906 13-43-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.15361, current rewards: -716.99972, mean: -0.45962
[32m[0906 13-43-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.15464, current rewards: -713.70954, mean: -0.44330
[32m[0906 13-43-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.15562, current rewards: -710.41544, mean: -0.42796
[32m[0906 13-43-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.15658, current rewards: -765.45602, mean: -0.44764
[32m[0906 13-43-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.15747, current rewards: -827.00629, mean: -0.46989
[32m[0906 13-44-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.15825, current rewards: -891.13553, mean: -0.49234
[32m[0906 13-44-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.15902, current rewards: -954.98638, mean: -0.51343
[32m[0906 13-44-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.15976, current rewards: -1016.13881, mean: -0.53201
[32m[0906 13-44-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.16046, current rewards: -1079.99748, mean: -0.55102
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.16112, current rewards: -1141.15976, mean: -0.56774
[32m[0906 13-44-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.16174, current rewards: -1204.97884, mean: -0.58494
[32m[0906 13-44-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.16233, current rewards: -1257.17632, mean: -0.59582
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.16290, current rewards: -1317.52383, mean: -0.60996
[32m[0906 13-45-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.16347, current rewards: -1377.54194, mean: -0.62332
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.16399, current rewards: -1437.61262, mean: -0.63611
[32m[0906 13-45-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.16449, current rewards: -1497.67885, mean: -0.64835
[32m[0906 13-45-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.16498, current rewards: -1524.42803, mean: -0.64594
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.16544, current rewards: -1509.54657, mean: -0.62637
[32m[0906 13-46-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.16586, current rewards: -1495.60237, mean: -0.60797
[32m[0906 13-46-11 @Agent.py:117][0m Average action selection time: 0.1662
[32m[0906 13-46-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-46-11 @MBExp.py:227][0m Rewards obtained: [-1497.4406694365312], Lows: [863], Highs: [21], Total time: 416.114262
[32m[0906 13-46-16 @MBExp.py:144][0m ####################################################################
[32m[0906 13-46-16 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-46-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18537, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-46-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18633, current rewards: -1.15908, mean: -0.01932
[32m[0906 13-46-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18611, current rewards: 7.08175, mean: 0.06438
[32m[0906 13-46-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18624, current rewards: 15.30897, mean: 0.09568
[32m[0906 13-46-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18612, current rewards: 23.54589, mean: 0.11212
[32m[0906 13-47-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18608, current rewards: 31.77149, mean: 0.12220
[32m[0906 13-47-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18604, current rewards: 39.98609, mean: 0.12899
[32m[0906 13-47-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18600, current rewards: 48.21818, mean: 0.13394
[32m[0906 13-47-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18567, current rewards: 56.46087, mean: 0.13771
[32m[0906 13-47-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18564, current rewards: 67.79081, mean: 0.14737
[32m[0906 13-47-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18573, current rewards: 79.11629, mean: 0.15513
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18557, current rewards: 90.43184, mean: 0.16149
[32m[0906 13-48-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18562, current rewards: 101.77302, mean: 0.16684
[32m[0906 13-48-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18562, current rewards: 113.12635, mean: 0.17140
[32m[0906 13-48-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18546, current rewards: 108.87175, mean: 0.15334
[32m[0906 13-48-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18551, current rewards: 114.88526, mean: 0.15116
[32m[0906 13-48-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18552, current rewards: 131.73723, mean: 0.16264
[32m[0906 13-48-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18547, current rewards: 72.12372, mean: 0.08386
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18547, current rewards: -27.87628, mean: -0.03063
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18549, current rewards: -127.87628, mean: -0.13320
[32m[0906 13-49-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18539, current rewards: -227.87628, mean: -0.22562
[32m[0906 13-49-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18542, current rewards: -327.87628, mean: -0.30932
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18543, current rewards: -427.87628, mean: -0.38547
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18544, current rewards: -527.87628, mean: -0.45507
[32m[0906 13-50-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18550, current rewards: -591.41925, mean: -0.48878
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18551, current rewards: -691.41925, mean: -0.54875
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18555, current rewards: -791.41925, mean: -0.60414
[32m[0906 13-50-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18553, current rewards: -891.41925, mean: -0.65546
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18551, current rewards: -991.41925, mean: -0.70313
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18550, current rewards: -1091.41925, mean: -0.74755
[32m[0906 13-50-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18546, current rewards: -1191.41925, mean: -0.78902
[32m[0906 13-51-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18543, current rewards: -1291.41925, mean: -0.82783
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18543, current rewards: -1364.83821, mean: -0.84773
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18542, current rewards: -1401.86577, mean: -0.84450
[32m[0906 13-51-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18541, current rewards: -1386.15929, mean: -0.81062
[32m[0906 13-51-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18540, current rewards: -1367.26125, mean: -0.77685
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18538, current rewards: -1348.40417, mean: -0.74497
[32m[0906 13-52-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18535, current rewards: -1329.51487, mean: -0.71479
[32m[0906 13-52-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18538, current rewards: -1310.60680, mean: -0.68618
[32m[0906 13-52-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18535, current rewards: -1291.68983, mean: -0.65903
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18532, current rewards: -1272.88860, mean: -0.63328
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18531, current rewards: -1253.98885, mean: -0.60873
[32m[0906 13-52-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18530, current rewards: -1292.15353, mean: -0.61240
[32m[0906 13-52-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18527, current rewards: -1332.98661, mean: -0.61712
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18526, current rewards: -1314.84255, mean: -0.59495
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18523, current rewards: -1293.09969, mean: -0.57217
[32m[0906 13-53-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18521, current rewards: -1271.29895, mean: -0.55035
[32m[0906 13-53-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18520, current rewards: -1249.65868, mean: -0.52952
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18522, current rewards: -1281.44497, mean: -0.53172
[32m[0906 13-53-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18521, current rewards: -1381.44497, mean: -0.56156
[32m[0906 13-53-59 @Agent.py:117][0m Average action selection time: 0.1852
[32m[0906 13-53-59 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-53-59 @MBExp.py:227][0m Rewards obtained: [-1444.3949530064867], Lows: [935], Highs: [31], Total time: 879.714837
[32m[0906 13-54-06 @MBExp.py:144][0m ####################################################################
[32m[0906 13-54-06 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-54-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18484, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-54-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18582, current rewards: -8.23060, mean: -0.13718
[32m[0906 13-54-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18534, current rewards: -5.46872, mean: -0.04972
[32m[0906 13-54-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18452, current rewards: -2.70793, mean: -0.01692
[32m[0906 13-54-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18446, current rewards: 0.05345, mean: 0.00025
[32m[0906 13-54-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18440, current rewards: 2.81485, mean: 0.01083
[32m[0906 13-55-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18430, current rewards: 5.57704, mean: 0.01799
[32m[0906 13-55-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18415, current rewards: 8.33827, mean: 0.02316
[32m[0906 13-55-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18414, current rewards: 11.10064, mean: 0.02707
[32m[0906 13-55-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18418, current rewards: 10.97373, mean: 0.02386
[32m[0906 13-55-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18434, current rewards: 7.20533, mean: 0.01413
[32m[0906 13-55-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18413, current rewards: 11.06989, mean: 0.01977
[32m[0906 13-55-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18429, current rewards: 14.93194, mean: 0.02448
[32m[0906 13-56-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18447, current rewards: 18.79699, mean: 0.02848
[32m[0906 13-56-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18438, current rewards: 22.66410, mean: 0.03192
[32m[0906 13-56-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18455, current rewards: 26.52690, mean: 0.03490
[32m[0906 13-56-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18459, current rewards: 30.39477, mean: 0.03752
[32m[0906 13-56-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18465, current rewards: 13.45748, mean: 0.01565
[32m[0906 13-56-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18469, current rewards: 17.07403, mean: 0.01876
[32m[0906 13-57-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18473, current rewards: 20.68677, mean: 0.02155
[32m[0906 13-57-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18460, current rewards: 24.30087, mean: 0.02406
[32m[0906 13-57-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18467, current rewards: 25.84336, mean: 0.02438
[32m[0906 13-57-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18479, current rewards: 11.96334, mean: 0.01078
[32m[0906 13-57-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18484, current rewards: 16.92055, mean: 0.01459
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18485, current rewards: 21.87776, mean: 0.01808
[32m[0906 13-57-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18486, current rewards: 7.60617, mean: 0.00604
[32m[0906 13-58-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18490, current rewards: -42.39383, mean: -0.03236
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18495, current rewards: -92.39383, mean: -0.06794
[32m[0906 13-58-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18495, current rewards: -142.39383, mean: -0.10099
[32m[0906 13-58-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18495, current rewards: -192.39383, mean: -0.13178
[32m[0906 13-58-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18499, current rewards: -242.39383, mean: -0.16053
[32m[0906 13-58-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18499, current rewards: -292.39383, mean: -0.18743
[32m[0906 13-59-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18500, current rewards: -342.39383, mean: -0.21267
[32m[0906 13-59-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18498, current rewards: -377.67463, mean: -0.22751
[32m[0906 13-59-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18498, current rewards: -407.69149, mean: -0.23842
[32m[0906 13-59-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18497, current rewards: -457.69149, mean: -0.26005
[32m[0906 13-59-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18497, current rewards: -507.69149, mean: -0.28049
[32m[0906 13-59-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18497, current rewards: -557.69149, mean: -0.29983
[32m[0906 13-59-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18498, current rewards: -607.69149, mean: -0.31816
[32m[0906 14-00-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18499, current rewards: -657.69149, mean: -0.33556
[32m[0906 14-00-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18500, current rewards: -707.69149, mean: -0.35209
[32m[0906 14-00-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18504, current rewards: -757.69149, mean: -0.36781
[32m[0906 14-00-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18506, current rewards: -807.69149, mean: -0.38279
[32m[0906 14-00-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18505, current rewards: -857.69149, mean: -0.39708
[32m[0906 14-00-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18504, current rewards: -907.69149, mean: -0.41072
[32m[0906 14-01-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18503, current rewards: -957.69149, mean: -0.42376
[32m[0906 14-01-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18503, current rewards: -1007.69149, mean: -0.43623
[32m[0906 14-01-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18503, current rewards: -1057.69149, mean: -0.44817
[32m[0906 14-01-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18503, current rewards: -1107.69149, mean: -0.45962
[32m[0906 14-01-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18502, current rewards: -1157.69149, mean: -0.47061
[32m[0906 14-01-49 @Agent.py:117][0m Average action selection time: 0.1850
[32m[0906 14-01-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-01-49 @MBExp.py:227][0m Rewards obtained: [-1197.6914894494244], Lows: [20], Highs: [1245], Total time: 1342.885634
[32m[0906 14-01-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-01-57 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-01-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18650, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-02-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18657, current rewards: -2.38241, mean: -0.03971
[32m[0906 14-02-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18547, current rewards: 8.63348, mean: 0.07849
[32m[0906 14-02-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18512, current rewards: 19.62750, mean: 0.12267
[32m[0906 14-02-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18530, current rewards: 30.64239, mean: 0.14592
[32m[0906 14-02-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18533, current rewards: 41.66207, mean: 0.16024
[32m[0906 14-02-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18520, current rewards: 52.68756, mean: 0.16996
[32m[0906 14-03-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18468, current rewards: 63.68909, mean: 0.17691
[32m[0906 14-03-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18476, current rewards: 73.10311, mean: 0.17830
[32m[0906 14-03-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18488, current rewards: 80.03958, mean: 0.17400
[32m[0906 14-03-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18494, current rewards: 87.24916, mean: 0.17108
[32m[0906 14-03-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18457, current rewards: 73.09740, mean: 0.13053
[32m[0906 14-03-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18464, current rewards: 82.88756, mean: 0.13588
[32m[0906 14-03-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18467, current rewards: 92.68410, mean: 0.14043
[32m[0906 14-04-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18443, current rewards: 102.46619, mean: 0.14432
[32m[0906 14-04-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18452, current rewards: 112.24910, mean: 0.14770
[32m[0906 14-04-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18458, current rewards: 122.03704, mean: 0.15066
[32m[0906 14-04-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18466, current rewards: 131.81892, mean: 0.15328
[32m[0906 14-04-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18471, current rewards: 141.59782, mean: 0.15560
[32m[0906 14-04-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18471, current rewards: 151.38368, mean: 0.15769
[32m[0906 14-05-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18456, current rewards: 161.16566, mean: 0.15957
[32m[0906 14-05-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18462, current rewards: 170.95222, mean: 0.16128
[32m[0906 14-05-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18465, current rewards: 180.72444, mean: 0.16281
[32m[0906 14-05-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18466, current rewards: 190.51467, mean: 0.16424
[32m[0906 14-05-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18469, current rewards: 200.29140, mean: 0.16553
[32m[0906 14-05-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18469, current rewards: 207.37982, mean: 0.16459
[32m[0906 14-06-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18468, current rewards: 223.40259, mean: 0.17054
[32m[0906 14-06-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18468, current rewards: 239.38165, mean: 0.17602
[32m[0906 14-06-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18468, current rewards: 255.40764, mean: 0.18114
[32m[0906 14-06-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18466, current rewards: 271.32034, mean: 0.18584
[32m[0906 14-06-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18465, current rewards: 287.34182, mean: 0.19029
[32m[0906 14-06-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18469, current rewards: 303.30951, mean: 0.19443
[32m[0906 14-06-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18467, current rewards: 319.29853, mean: 0.19832
[32m[0906 14-07-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18468, current rewards: 332.10494, mean: 0.20006
[32m[0906 14-07-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18466, current rewards: 345.18222, mean: 0.20186
[32m[0906 14-07-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18466, current rewards: 358.28167, mean: 0.20357
[32m[0906 14-07-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18464, current rewards: 371.41043, mean: 0.20520
[32m[0906 14-07-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18466, current rewards: 357.39236, mean: 0.19215
[32m[0906 14-07-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18468, current rewards: 364.58157, mean: 0.19088
[32m[0906 14-08-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18469, current rewards: 371.75617, mean: 0.18967
[32m[0906 14-08-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18469, current rewards: 378.93760, mean: 0.18853
[32m[0906 14-08-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18469, current rewards: 388.35340, mean: 0.18852
[32m[0906 14-08-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18468, current rewards: 396.98609, mean: 0.18815
[32m[0906 14-08-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18467, current rewards: 409.18882, mean: 0.18944
[32m[0906 14-08-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18467, current rewards: 439.48682, mean: 0.19886
[32m[0906 14-08-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18470, current rewards: 470.02642, mean: 0.20798
[32m[0906 14-09-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18470, current rewards: 500.62629, mean: 0.21672
[32m[0906 14-09-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18470, current rewards: 531.11457, mean: 0.22505
[32m[0906 14-09-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18468, current rewards: 561.53386, mean: 0.23300
[32m[0906 14-09-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18469, current rewards: 561.41748, mean: 0.22822
[32m[0906 14-09-40 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0906 14-09-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-09-40 @MBExp.py:227][0m Rewards obtained: [564.2636006285115], Lows: [37], Highs: [12], Total time: 1805.2446909999999
[32m[0906 14-09-50 @MBExp.py:144][0m ####################################################################
[32m[0906 14-09-50 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18673, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-10-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18542, current rewards: -93.91894, mean: -1.56532
[32m[0906 14-10-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18493, current rewards: -160.25215, mean: -1.45684
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18471, current rewards: -224.43118, mean: -1.40269
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18468, current rewards: -258.27245, mean: -1.22987
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18465, current rewards: -264.73036, mean: -1.01819
[32m[0906 14-10-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18427, current rewards: -268.89760, mean: -0.86741
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18404, current rewards: -298.63837, mean: -0.82955
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18424, current rewards: -398.63837, mean: -0.97229
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18435, current rewards: -498.63837, mean: -1.08400
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18431, current rewards: -598.63837, mean: -1.17380
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18404, current rewards: -696.53684, mean: -1.24382
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18416, current rewards: -794.00649, mean: -1.30165
[32m[0906 14-11-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18423, current rewards: -894.00649, mean: -1.35456
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18391, current rewards: -994.00649, mean: -1.40001
[32m[0906 14-12-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18407, current rewards: -1049.04019, mean: -1.38032
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18419, current rewards: -1079.49745, mean: -1.33271
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18430, current rewards: -1179.49745, mean: -1.37151
[32m[0906 14-12-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18438, current rewards: -1279.49745, mean: -1.40604
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18432, current rewards: -1379.49745, mean: -1.43698
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18422, current rewards: -1479.49745, mean: -1.46485
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18435, current rewards: -1579.49745, mean: -1.49009
[32m[0906 14-13-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18438, current rewards: -1679.49745, mean: -1.51306
[32m[0906 14-13-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18442, current rewards: -1779.49745, mean: -1.53405
[32m[0906 14-13-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18446, current rewards: -1872.24261, mean: -1.54731
[32m[0906 14-13-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18449, current rewards: -1926.79307, mean: -1.52920
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18452, current rewards: -1981.30489, mean: -1.51245
[32m[0906 14-14-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18454, current rewards: -2038.69655, mean: -1.49904
[32m[0906 14-14-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18458, current rewards: -2093.27257, mean: -1.48459
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18461, current rewards: -2150.75931, mean: -1.47312
[32m[0906 14-14-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18462, current rewards: -2202.69970, mean: -1.45874
[32m[0906 14-14-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18465, current rewards: -2262.75600, mean: -1.45048
[32m[0906 14-14-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18466, current rewards: -2309.63528, mean: -1.43456
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18468, current rewards: -2362.51142, mean: -1.42320
[32m[0906 14-15-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18470, current rewards: -2462.51142, mean: -1.44007
[32m[0906 14-15-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18474, current rewards: -2562.51142, mean: -1.45597
[32m[0906 14-15-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18473, current rewards: -2662.51142, mean: -1.47100
[32m[0906 14-15-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18474, current rewards: -2762.51142, mean: -1.48522
[32m[0906 14-15-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18474, current rewards: -2862.51142, mean: -1.49870
[32m[0906 14-15-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18474, current rewards: -2962.51142, mean: -1.51149
[32m[0906 14-16-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18473, current rewards: -3062.51142, mean: -1.52364
[32m[0906 14-16-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18473, current rewards: -3162.51142, mean: -1.53520
[32m[0906 14-16-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18473, current rewards: -3262.51142, mean: -1.54621
[32m[0906 14-16-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18474, current rewards: -3362.51142, mean: -1.55672
[32m[0906 14-16-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18475, current rewards: -3462.51142, mean: -1.56675
[32m[0906 14-16-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18476, current rewards: -3560.30358, mean: -1.57536
[32m[0906 14-16-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18475, current rewards: -3660.30358, mean: -1.58455
[32m[0906 14-17-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18476, current rewards: -3760.30358, mean: -1.59335
[32m[0906 14-17-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18479, current rewards: -3860.30358, mean: -1.60179
[32m[0906 14-17-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18481, current rewards: -3945.57930, mean: -1.60389
[32m[0906 14-17-33 @Agent.py:117][0m Average action selection time: 0.1848
[32m[0906 14-17-33 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-17-33 @MBExp.py:227][0m Rewards obtained: [-3979.50546766608], Lows: [2092], Highs: [18], Total time: 2267.886424
[32m[0906 14-17-46 @MBExp.py:144][0m ####################################################################
[32m[0906 14-17-46 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-17-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18459, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-17-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18547, current rewards: -39.97485, mean: -0.66625
[32m[0906 14-18-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18541, current rewards: -46.21880, mean: -0.42017
[32m[0906 14-18-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18518, current rewards: -50.79618, mean: -0.31748
[32m[0906 14-18-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18500, current rewards: -66.50943, mean: -0.31671
[32m[0906 14-18-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18499, current rewards: -71.94045, mean: -0.27669
[32m[0906 14-18-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18446, current rewards: -75.96823, mean: -0.24506
[32m[0906 14-18-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18427, current rewards: -80.15145, mean: -0.22264
[32m[0906 14-19-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18447, current rewards: -92.53399, mean: -0.22569
[32m[0906 14-19-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18460, current rewards: -98.30804, mean: -0.21371
[32m[0906 14-19-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18461, current rewards: -94.75807, mean: -0.18580
[32m[0906 14-19-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18427, current rewards: -91.22544, mean: -0.16290
[32m[0906 14-19-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18438, current rewards: -87.68918, mean: -0.14375
[32m[0906 14-19-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18430, current rewards: -84.15261, mean: -0.12750
[32m[0906 14-19-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18399, current rewards: -80.61737, mean: -0.11355
[32m[0906 14-20-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18411, current rewards: -77.08206, mean: -0.10142
[32m[0906 14-20-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18425, current rewards: -73.40067, mean: -0.09062
[32m[0906 14-20-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18434, current rewards: -69.86074, mean: -0.08123
[32m[0906 14-20-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18439, current rewards: -66.94908, mean: -0.07357
[32m[0906 14-20-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18430, current rewards: -84.58599, mean: -0.08811
[32m[0906 14-20-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18418, current rewards: -80.40470, mean: -0.07961
[32m[0906 14-21-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18429, current rewards: -77.45524, mean: -0.07307
[32m[0906 14-21-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18435, current rewards: -74.50715, mean: -0.06712
[32m[0906 14-21-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18441, current rewards: -89.77936, mean: -0.07740
[32m[0906 14-21-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18449, current rewards: -91.96226, mean: -0.07600
[32m[0906 14-21-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18453, current rewards: -87.83284, mean: -0.06971
[32m[0906 14-21-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18452, current rewards: -83.42351, mean: -0.06368
[32m[0906 14-21-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18453, current rewards: -79.01894, mean: -0.05810
[32m[0906 14-22-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18455, current rewards: -74.60463, mean: -0.05291
[32m[0906 14-22-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18457, current rewards: -70.19561, mean: -0.04808
[32m[0906 14-22-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18458, current rewards: -65.79337, mean: -0.04357
[32m[0906 14-22-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18458, current rewards: -61.38801, mean: -0.03935
[32m[0906 14-22-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18460, current rewards: -69.50880, mean: -0.04317
[32m[0906 14-22-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18465, current rewards: -89.66070, mean: -0.05401
[32m[0906 14-23-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18469, current rewards: -84.37131, mean: -0.04934
[32m[0906 14-23-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18471, current rewards: -79.08895, mean: -0.04494
[32m[0906 14-23-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18473, current rewards: -73.81571, mean: -0.04078
[32m[0906 14-23-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18478, current rewards: -89.56956, mean: -0.04816
[32m[0906 14-23-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18479, current rewards: -85.58560, mean: -0.04481
[32m[0906 14-23-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18479, current rewards: -81.60707, mean: -0.04164
[32m[0906 14-23-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18480, current rewards: -77.62854, mean: -0.03862
[32m[0906 14-24-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18479, current rewards: -72.57366, mean: -0.03523
[32m[0906 14-24-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18482, current rewards: -66.77843, mean: -0.03165
[32m[0906 14-24-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18482, current rewards: -60.98320, mean: -0.02823
[32m[0906 14-24-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18485, current rewards: -68.57883, mean: -0.03103
[32m[0906 14-24-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18485, current rewards: -118.57883, mean: -0.05247
[32m[0906 14-24-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18486, current rewards: -168.57883, mean: -0.07298
[32m[0906 14-25-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18486, current rewards: -218.57883, mean: -0.09262
[32m[0906 14-25-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18486, current rewards: -268.57883, mean: -0.11144
[32m[0906 14-25-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18486, current rewards: -318.57883, mean: -0.12950
[32m[0906 14-25-29 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0906 14-25-29 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-25-29 @MBExp.py:227][0m Rewards obtained: [-358.57882841128554], Lows: [67], Highs: [413], Total time: 2730.675668
[32m[0906 14-25-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-25-43 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-25-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18525, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-25-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18549, current rewards: -8.24124, mean: -0.13735
[32m[0906 14-26-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18534, current rewards: -3.83982, mean: -0.03491
[32m[0906 14-26-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18530, current rewards: 0.56433, mean: 0.00353
[32m[0906 14-26-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18522, current rewards: 4.96488, mean: 0.02364
[32m[0906 14-26-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18479, current rewards: 9.36929, mean: 0.03604
[32m[0906 14-26-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18415, current rewards: 13.77466, mean: 0.04443
[32m[0906 14-26-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18422, current rewards: 18.17312, mean: 0.05048
[32m[0906 14-26-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18437, current rewards: 22.55118, mean: 0.05500
[32m[0906 14-27-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18456, current rewards: 26.96639, mean: 0.05862
[32m[0906 14-27-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18431, current rewards: 31.38035, mean: 0.06153
[32m[0906 14-27-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18395, current rewards: 14.93521, mean: 0.02667
[32m[0906 14-27-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18409, current rewards: 19.89165, mean: 0.03261
[32m[0906 14-27-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18403, current rewards: 24.84948, mean: 0.03765
[32m[0906 14-27-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18381, current rewards: 29.80749, mean: 0.04198
[32m[0906 14-28-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18393, current rewards: 35.12338, mean: 0.04621
[32m[0906 14-28-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18403, current rewards: 40.86939, mean: 0.05046
[32m[0906 14-28-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18411, current rewards: 46.05085, mean: 0.05355
[32m[0906 14-28-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18417, current rewards: 51.23265, mean: 0.05630
[32m[0906 14-28-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18403, current rewards: 56.41864, mean: 0.05877
[32m[0906 14-28-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18397, current rewards: 61.60190, mean: 0.06099
[32m[0906 14-28-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18404, current rewards: 66.78017, mean: 0.06300
[32m[0906 14-29-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18409, current rewards: 51.32374, mean: 0.04624
[32m[0906 14-29-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18416, current rewards: 56.94435, mean: 0.04909
[32m[0906 14-29-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18423, current rewards: 61.52904, mean: 0.05085
[32m[0906 14-29-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18425, current rewards: 67.22594, mean: 0.05335
[32m[0906 14-29-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18426, current rewards: 72.92481, mean: 0.05567
[32m[0906 14-29-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18431, current rewards: 78.62274, mean: 0.05781
[32m[0906 14-30-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18433, current rewards: 84.32161, mean: 0.05980
[32m[0906 14-30-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18435, current rewards: 79.06670, mean: 0.05416
[32m[0906 14-30-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18435, current rewards: 86.76359, mean: 0.05746
[32m[0906 14-30-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18438, current rewards: 94.46896, mean: 0.06056
[32m[0906 14-30-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18439, current rewards: 101.40550, mean: 0.06298
[32m[0906 14-30-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18442, current rewards: 109.71615, mean: 0.06609
[32m[0906 14-30-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18442, current rewards: 118.02271, mean: 0.06902
[32m[0906 14-31-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18444, current rewards: 126.33364, mean: 0.07178
[32m[0906 14-31-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18447, current rewards: 134.64469, mean: 0.07439
[32m[0906 14-31-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18449, current rewards: 142.95908, mean: 0.07686
[32m[0906 14-31-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18450, current rewards: 151.29331, mean: 0.07921
[32m[0906 14-31-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18450, current rewards: 159.60627, mean: 0.08143
[32m[0906 14-31-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18455, current rewards: 167.77946, mean: 0.08347
[32m[0906 14-32-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18457, current rewards: 176.16331, mean: 0.08552
[32m[0906 14-32-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18458, current rewards: 184.52879, mean: 0.08745
[32m[0906 14-32-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18459, current rewards: 192.90165, mean: 0.08931
[32m[0906 14-32-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18457, current rewards: 179.44972, mean: 0.08120
[32m[0906 14-32-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18456, current rewards: 185.43057, mean: 0.08205
[32m[0906 14-32-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18457, current rewards: 191.77319, mean: 0.08302
[32m[0906 14-33-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18458, current rewards: 198.11400, mean: 0.08395
[32m[0906 14-33-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18459, current rewards: 206.59812, mean: 0.08573
[32m[0906 14-33-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18460, current rewards: 223.32071, mean: 0.09078
[32m[0906 14-33-26 @Agent.py:117][0m Average action selection time: 0.1846
[32m[0906 14-33-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-33-26 @MBExp.py:227][0m Rewards obtained: [227.92663440937193], Lows: [30], Highs: [23], Total time: 3192.78811
[32m[0906 14-33-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-33-43 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-33-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18656, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-33-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18586, current rewards: -6.56863, mean: -0.10948
[32m[0906 14-34-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18593, current rewards: -2.41034, mean: -0.02191
[32m[0906 14-34-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18583, current rewards: 1.74250, mean: 0.01089
[32m[0906 14-34-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18557, current rewards: 5.89823, mean: 0.02809
[32m[0906 14-34-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18471, current rewards: 10.05141, mean: 0.03866
[32m[0906 14-34-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18405, current rewards: 14.20798, mean: 0.04583
[32m[0906 14-34-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18432, current rewards: 19.08397, mean: 0.05301
[32m[0906 14-34-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18442, current rewards: 23.17908, mean: 0.05653
[32m[0906 14-35-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18450, current rewards: 16.81502, mean: 0.03655
[32m[0906 14-35-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18419, current rewards: 19.95541, mean: 0.03913
[32m[0906 14-35-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18386, current rewards: 23.09132, mean: 0.04123
[32m[0906 14-35-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18405, current rewards: 26.22873, mean: 0.04300
[32m[0906 14-35-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18388, current rewards: 29.36686, mean: 0.04450
[32m[0906 14-35-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18366, current rewards: 11.98285, mean: 0.01688
[32m[0906 14-36-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18387, current rewards: 14.92182, mean: 0.01963
[32m[0906 14-36-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18439, current rewards: 17.84913, mean: 0.02204
[32m[0906 14-36-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18465, current rewards: 20.77354, mean: 0.02416
[32m[0906 14-36-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18463, current rewards: 3.84911, mean: 0.00423
[32m[0906 14-36-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18443, current rewards: 8.76532, mean: 0.00913
[32m[0906 14-36-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18432, current rewards: 13.68430, mean: 0.01355
[32m[0906 14-36-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18439, current rewards: 18.60293, mean: 0.01755
[32m[0906 14-37-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18440, current rewards: 23.51968, mean: 0.02119
[32m[0906 14-37-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18440, current rewards: 28.11808, mean: 0.02424
[32m[0906 14-37-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18441, current rewards: 32.50198, mean: 0.02686
[32m[0906 14-37-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18441, current rewards: 37.19330, mean: 0.02952
[32m[0906 14-37-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18446, current rewards: 41.87912, mean: 0.03197
[32m[0906 14-37-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18446, current rewards: 46.56579, mean: 0.03424
[32m[0906 14-38-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18447, current rewards: 51.25459, mean: 0.03635
[32m[0906 14-38-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18452, current rewards: 48.28683, mean: 0.03307
[32m[0906 14-38-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18455, current rewards: 51.41669, mean: 0.03405
[32m[0906 14-38-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18456, current rewards: 56.55538, mean: 0.03625
[32m[0906 14-38-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18457, current rewards: 61.27623, mean: 0.03806
[32m[0906 14-38-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18456, current rewards: 66.41941, mean: 0.04001
[32m[0906 14-38-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18457, current rewards: 71.56183, mean: 0.04185
[32m[0906 14-39-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18460, current rewards: 76.70365, mean: 0.04358
[32m[0906 14-39-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18459, current rewards: 81.84442, mean: 0.04522
[32m[0906 14-39-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18460, current rewards: 86.98718, mean: 0.04677
[32m[0906 14-39-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18463, current rewards: 92.13317, mean: 0.04824
[32m[0906 14-39-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18464, current rewards: 97.27492, mean: 0.04963
[32m[0906 14-39-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18463, current rewards: 103.15450, mean: 0.05132
[32m[0906 14-40-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18464, current rewards: 108.30156, mean: 0.05257
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18467, current rewards: 113.43710, mean: 0.05376
[32m[0906 14-40-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18468, current rewards: 118.57831, mean: 0.05490
[32m[0906 14-40-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18470, current rewards: 123.71636, mean: 0.05598
[32m[0906 14-40-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18471, current rewards: 128.85530, mean: 0.05702
[32m[0906 14-40-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18470, current rewards: 112.97015, mean: 0.04890
[32m[0906 14-40-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18470, current rewards: 117.70521, mean: 0.04988
[32m[0906 14-41-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18473, current rewards: 122.21552, mean: 0.05071
[32m[0906 14-41-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18472, current rewards: 126.81337, mean: 0.05155
[32m[0906 14-41-25 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0906 14-41-25 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-41-25 @MBExp.py:227][0m Rewards obtained: [130.4913151740924], Lows: [30], Highs: [31], Total time: 3655.262413
[32m[0906 14-41-44 @MBExp.py:144][0m ####################################################################
[32m[0906 14-41-44 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-41-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18506, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-41-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18611, current rewards: -4.16520, mean: -0.06942
[32m[0906 14-42-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18607, current rewards: 0.57195, mean: 0.00520
[32m[0906 14-42-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18579, current rewards: 5.30866, mean: 0.03318
[32m[0906 14-42-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18551, current rewards: -2.04903, mean: -0.00976
[32m[0906 14-42-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18463, current rewards: 2.88486, mean: 0.01110
[32m[0906 14-42-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18416, current rewards: 7.79609, mean: 0.02515
[32m[0906 14-42-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18429, current rewards: 11.76219, mean: 0.03267
[32m[0906 14-43-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18451, current rewards: 16.39897, mean: 0.04000
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18455, current rewards: 21.03752, mean: 0.04573
[32m[0906 14-43-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18418, current rewards: 25.67482, mean: 0.05034
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18385, current rewards: 30.30676, mean: 0.05412
[32m[0906 14-43-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18398, current rewards: 9.58603, mean: 0.01571
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18379, current rewards: 13.66147, mean: 0.02070
[32m[0906 14-43-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18359, current rewards: 17.74144, mean: 0.02499
[32m[0906 14-44-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18371, current rewards: 21.78159, mean: 0.02866
[32m[0906 14-44-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18382, current rewards: 25.84564, mean: 0.03191
[32m[0906 14-44-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18387, current rewards: 29.90995, mean: 0.03478
[32m[0906 14-44-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18389, current rewards: 33.97545, mean: 0.03734
[32m[0906 14-44-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18378, current rewards: 38.03887, mean: 0.03962
[32m[0906 14-44-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18372, current rewards: 42.10317, mean: 0.04169
[32m[0906 14-44-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18381, current rewards: 33.56398, mean: 0.03166
[32m[0906 14-45-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18388, current rewards: 36.60076, mean: 0.03297
[32m[0906 14-45-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18397, current rewards: 40.28581, mean: 0.03473
[32m[0906 14-45-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18400, current rewards: 43.64197, mean: 0.03607
[32m[0906 14-45-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18405, current rewards: 46.88127, mean: 0.03721
[32m[0906 14-45-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18408, current rewards: 50.11661, mean: 0.03826
[32m[0906 14-45-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18412, current rewards: 54.20396, mean: 0.03986
[32m[0906 14-46-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18418, current rewards: 57.70230, mean: 0.04092
[32m[0906 14-46-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18422, current rewards: 61.20328, mean: 0.04192
[32m[0906 14-46-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18425, current rewards: 64.70240, mean: 0.04285
[32m[0906 14-46-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18428, current rewards: 47.87972, mean: 0.03069
[32m[0906 14-46-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18434, current rewards: 50.97499, mean: 0.03166
[32m[0906 14-46-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18437, current rewards: 54.44541, mean: 0.03280
[32m[0906 14-47-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18439, current rewards: 57.91852, mean: 0.03387
[32m[0906 14-47-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18445, current rewards: 61.38846, mean: 0.03488
[32m[0906 14-47-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18450, current rewards: 64.85802, mean: 0.03583
[32m[0906 14-47-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18454, current rewards: 68.32802, mean: 0.03674
[32m[0906 14-47-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18455, current rewards: 71.80055, mean: 0.03759
[32m[0906 14-47-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18457, current rewards: 75.27154, mean: 0.03840
[32m[0906 14-47-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18456, current rewards: 77.64396, mean: 0.03863
[32m[0906 14-48-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18455, current rewards: 72.22217, mean: 0.03506
[32m[0906 14-48-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18459, current rewards: 76.85789, mean: 0.03643
[32m[0906 14-48-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18461, current rewards: 81.49422, mean: 0.03773
[32m[0906 14-48-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18462, current rewards: 86.13067, mean: 0.03897
[32m[0906 14-48-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18464, current rewards: 90.76533, mean: 0.04016
[32m[0906 14-48-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18466, current rewards: 95.40229, mean: 0.04130
[32m[0906 14-49-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18467, current rewards: 100.03942, mean: 0.04239
[32m[0906 14-49-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18467, current rewards: 104.77964, mean: 0.04348
[32m[0906 14-49-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18468, current rewards: 97.60998, mean: 0.03968
[32m[0906 14-49-26 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0906 14-49-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-49-26 @MBExp.py:227][0m Rewards obtained: [100.05740790625127], Lows: [20], Highs: [56], Total time: 4117.576027
[32m[0906 14-49-47 @MBExp.py:144][0m ####################################################################
[32m[0906 14-49-47 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-49-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18508, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-49-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18507, current rewards: -5.66903, mean: -0.09448
[32m[0906 14-50-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18522, current rewards: -1.01665, mean: -0.00924
[32m[0906 14-50-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18514, current rewards: 3.64207, mean: 0.02276
[32m[0906 14-50-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18419, current rewards: 8.29878, mean: 0.03952
[32m[0906 14-50-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18336, current rewards: 12.95416, mean: 0.04982
[32m[0906 14-50-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18351, current rewards: 17.36712, mean: 0.05602
[32m[0906 14-50-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18392, current rewards: 21.75126, mean: 0.06042
[32m[0906 14-51-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18398, current rewards: 26.35288, mean: 0.06428
[32m[0906 14-51-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18396, current rewards: 30.95217, mean: 0.06729
[32m[0906 14-51-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18359, current rewards: 27.18328, mean: 0.05330
[32m[0906 14-51-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18329, current rewards: 16.93080, mean: 0.03023
[32m[0906 14-51-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18337, current rewards: 21.37092, mean: 0.03503
[32m[0906 14-51-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18320, current rewards: 25.80866, mean: 0.03910
[32m[0906 14-51-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18299, current rewards: 30.25321, mean: 0.04261
[32m[0906 14-52-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18311, current rewards: 34.87551, mean: 0.04589
[32m[0906 14-52-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18328, current rewards: 39.35313, mean: 0.04858
[32m[0906 14-52-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18340, current rewards: 43.83013, mean: 0.05097
[32m[0906 14-52-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18331, current rewards: 48.30777, mean: 0.05309
[32m[0906 14-52-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18316, current rewards: 52.78560, mean: 0.05499
[32m[0906 14-52-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18319, current rewards: 57.26217, mean: 0.05670
[32m[0906 14-53-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18336, current rewards: 61.73855, mean: 0.05824
[32m[0906 14-53-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18345, current rewards: 66.21636, mean: 0.05965
[32m[0906 14-53-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18356, current rewards: 54.27825, mean: 0.04679
[32m[0906 14-53-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18366, current rewards: 58.50631, mean: 0.04835
[32m[0906 14-53-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18371, current rewards: 62.73434, mean: 0.04979
[32m[0906 14-53-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18377, current rewards: 66.96702, mean: 0.05112
[32m[0906 14-53-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18383, current rewards: 48.31226, mean: 0.03552
[32m[0906 14-54-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18388, current rewards: 52.93857, mean: 0.03755
[32m[0906 14-54-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18392, current rewards: 57.55689, mean: 0.03942
[32m[0906 14-54-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18396, current rewards: 62.17520, mean: 0.04118
[32m[0906 14-54-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18399, current rewards: 46.09358, mean: 0.02955
[32m[0906 14-54-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18403, current rewards: 51.35170, mean: 0.03190
[32m[0906 14-54-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18407, current rewards: 56.80094, mean: 0.03422
[32m[0906 14-55-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18411, current rewards: 62.25235, mean: 0.03640
[32m[0906 14-55-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18414, current rewards: 67.70262, mean: 0.03847
[32m[0906 14-55-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18416, current rewards: 73.15415, mean: 0.04042
[32m[0906 14-55-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18419, current rewards: 78.60519, mean: 0.04226
[32m[0906 14-55-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18422, current rewards: 72.79432, mean: 0.03811
[32m[0906 14-55-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18424, current rewards: 76.40182, mean: 0.03898
[32m[0906 14-55-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18424, current rewards: 80.50198, mean: 0.04005
[32m[0906 14-56-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18425, current rewards: 84.57859, mean: 0.04106
[32m[0906 14-56-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18426, current rewards: 88.64948, mean: 0.04201
[32m[0906 14-56-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18426, current rewards: 92.72057, mean: 0.04293
[32m[0906 14-56-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18427, current rewards: 96.79293, mean: 0.04380
[32m[0906 14-56-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18428, current rewards: 100.86517, mean: 0.04463
[32m[0906 14-56-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18426, current rewards: 104.93853, mean: 0.04543
[32m[0906 14-57-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18430, current rewards: 109.22009, mean: 0.04628
[32m[0906 14-57-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18432, current rewards: 113.98311, mean: 0.04730
[32m[0906 14-57-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18433, current rewards: 118.25673, mean: 0.04807
[32m[0906 14-57-29 @Agent.py:117][0m Average action selection time: 0.1843
[32m[0906 14-57-29 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-57-29 @MBExp.py:227][0m Rewards obtained: [121.67638647661259], Lows: [32], Highs: [35], Total time: 4579.048375
[32m[0906 14-57-52 @MBExp.py:144][0m ####################################################################
[32m[0906 14-57-52 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-57-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18498, current rewards: 1.15596, mean: 0.11560
[32m[0906 14-58-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18584, current rewards: 7.12626, mean: 0.11877
[32m[0906 14-58-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18574, current rewards: 12.88897, mean: 0.11717
[32m[0906 14-58-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18488, current rewards: 18.65477, mean: 0.11659
[32m[0906 14-58-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18371, current rewards: 24.42070, mean: 0.11629
[32m[0906 14-58-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18313, current rewards: 17.13742, mean: 0.06591
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18337, current rewards: 22.02217, mean: 0.07104
[32m[0906 14-58-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18365, current rewards: 26.95114, mean: 0.07486
[32m[0906 14-59-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18400, current rewards: 31.88194, mean: 0.07776
[32m[0906 14-59-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18406, current rewards: 36.80730, mean: 0.08002
[32m[0906 14-59-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18372, current rewards: 41.73927, mean: 0.08184
[32m[0906 14-59-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18342, current rewards: 46.66408, mean: 0.08333
[32m[0906 14-59-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18337, current rewards: 51.59537, mean: 0.08458
[32m[0906 14-59-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18316, current rewards: 35.89141, mean: 0.05438
[32m[0906 15-00-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18297, current rewards: 42.25698, mean: 0.05952
[32m[0906 15-00-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18302, current rewards: 47.56665, mean: 0.06259
[32m[0906 15-00-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18326, current rewards: 52.87225, mean: 0.06527
[32m[0906 15-00-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18336, current rewards: 58.17867, mean: 0.06765
[32m[0906 15-00-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18323, current rewards: 63.48600, mean: 0.06976
[32m[0906 15-00-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18313, current rewards: 68.79559, mean: 0.07166
[32m[0906 15-00-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18312, current rewards: 74.10397, mean: 0.07337
[32m[0906 15-01-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18321, current rewards: 79.41195, mean: 0.07492
[32m[0906 15-01-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18336, current rewards: 73.56019, mean: 0.06627
[32m[0906 15-01-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18345, current rewards: 78.66541, mean: 0.06782
[32m[0906 15-01-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18356, current rewards: 83.77028, mean: 0.06923
[32m[0906 15-01-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18364, current rewards: 88.87279, mean: 0.07053
[32m[0906 15-01-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18369, current rewards: 74.79282, mean: 0.05709
[32m[0906 15-02-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18375, current rewards: 81.54643, mean: 0.05996
[32m[0906 15-02-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18382, current rewards: 88.29774, mean: 0.06262
[32m[0906 15-02-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18387, current rewards: 95.05259, mean: 0.06510
[32m[0906 15-02-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18394, current rewards: 101.05827, mean: 0.06693
[32m[0906 15-02-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18399, current rewards: 106.94777, mean: 0.06856
[32m[0906 15-02-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18403, current rewards: 113.21470, mean: 0.07032
[32m[0906 15-02-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18407, current rewards: 119.48162, mean: 0.07198
[32m[0906 15-03-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18411, current rewards: 125.75046, mean: 0.07354
[32m[0906 15-03-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18415, current rewards: 132.02181, mean: 0.07501
[32m[0906 15-03-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18418, current rewards: 124.55347, mean: 0.06881
[32m[0906 15-03-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18421, current rewards: 129.60470, mean: 0.06968
[32m[0906 15-03-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18420, current rewards: 134.68065, mean: 0.07051
[32m[0906 15-03-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18423, current rewards: 139.62658, mean: 0.07124
[32m[0906 15-04-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18426, current rewards: 144.67627, mean: 0.07198
[32m[0906 15-04-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18429, current rewards: 149.72878, mean: 0.07268
[32m[0906 15-04-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18433, current rewards: 154.78134, mean: 0.07336
[32m[0906 15-04-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18434, current rewards: 159.83513, mean: 0.07400
[32m[0906 15-04-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18435, current rewards: 164.88679, mean: 0.07461
[32m[0906 15-04-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18437, current rewards: 169.94108, mean: 0.07520
[32m[0906 15-04-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18438, current rewards: 154.41221, mean: 0.06685
[32m[0906 15-05-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18438, current rewards: 160.32616, mean: 0.06793
[32m[0906 15-05-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18439, current rewards: 166.33898, mean: 0.06902
[32m[0906 15-05-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18441, current rewards: 172.34813, mean: 0.07006
[32m[0906 15-05-34 @Agent.py:117][0m Average action selection time: 0.1844
[32m[0906 15-05-34 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-05-34 @MBExp.py:227][0m Rewards obtained: [177.15528428495526], Lows: [31], Highs: [31], Total time: 5040.782612
[32m[0906 15-05-59 @MBExp.py:144][0m ####################################################################
[32m[0906 15-05-59 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 15-06-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18760, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-06-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18631, current rewards: -6.08231, mean: -0.10137
[32m[0906 15-06-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18581, current rewards: -0.92771, mean: -0.00843
[32m[0906 15-06-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18454, current rewards: 4.22519, mean: 0.02641
[32m[0906 15-06-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18360, current rewards: 9.38483, mean: 0.04469
[32m[0906 15-06-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18303, current rewards: 14.38072, mean: 0.05531
[32m[0906 15-06-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18355, current rewards: 19.57288, mean: 0.06314
[32m[0906 15-07-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18377, current rewards: 24.76393, mean: 0.06879
[32m[0906 15-07-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18390, current rewards: 29.95324, mean: 0.07306
[32m[0906 15-07-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18379, current rewards: 35.14401, mean: 0.07640
[32m[0906 15-07-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18363, current rewards: 40.33152, mean: 0.07908
[32m[0906 15-07-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18340, current rewards: 45.52464, mean: 0.08129
[32m[0906 15-07-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18327, current rewards: 50.71087, mean: 0.08313
[32m[0906 15-08-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18311, current rewards: 56.54631, mean: 0.08568
[32m[0906 15-08-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18298, current rewards: 61.64574, mean: 0.08682
[32m[0906 15-08-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18309, current rewards: 66.74859, mean: 0.08783
[32m[0906 15-08-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18333, current rewards: 71.85996, mean: 0.08872
[32m[0906 15-08-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18339, current rewards: 85.57413, mean: 0.09950
[32m[0906 15-08-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18324, current rewards: 90.10784, mean: 0.09902
[32m[0906 15-08-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18314, current rewards: 94.64361, mean: 0.09859
[32m[0906 15-09-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18315, current rewards: 99.18060, mean: 0.09820
[32m[0906 15-09-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18328, current rewards: 104.50713, mean: 0.09859
[32m[0906 15-09-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18337, current rewards: 108.85317, mean: 0.09807
[32m[0906 15-09-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18345, current rewards: 90.29838, mean: 0.07784
[32m[0906 15-09-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18358, current rewards: 96.08591, mean: 0.07941
[32m[0906 15-09-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18367, current rewards: 101.72813, mean: 0.08074
[32m[0906 15-10-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18375, current rewards: 107.36851, mean: 0.08196
[32m[0906 15-10-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18382, current rewards: 113.01063, mean: 0.08310
[32m[0906 15-10-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18387, current rewards: 118.65115, mean: 0.08415
[32m[0906 15-10-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18391, current rewards: 103.05492, mean: 0.07059
[32m[0906 15-10-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18395, current rewards: 108.07637, mean: 0.07157
[32m[0906 15-10-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18399, current rewards: 113.13837, mean: 0.07252
[32m[0906 15-10-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18403, current rewards: 118.20556, mean: 0.07342
[32m[0906 15-11-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18406, current rewards: 123.27456, mean: 0.07426
[32m[0906 15-11-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18413, current rewards: 128.34142, mean: 0.07505
[32m[0906 15-11-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18416, current rewards: 133.40773, mean: 0.07580
[32m[0906 15-11-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18422, current rewards: 138.47726, mean: 0.07651
[32m[0906 15-11-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18425, current rewards: 143.48451, mean: 0.07714
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18431, current rewards: 148.49691, mean: 0.07775
[32m[0906 15-12-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18435, current rewards: 153.56721, mean: 0.07835
[32m[0906 15-12-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18437, current rewards: 146.67188, mean: 0.07297
[32m[0906 15-12-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18441, current rewards: 151.96307, mean: 0.07377
[32m[0906 15-12-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18442, current rewards: 157.25894, mean: 0.07453
[32m[0906 15-12-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18443, current rewards: 162.55482, mean: 0.07526
[32m[0906 15-12-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18445, current rewards: 167.85240, mean: 0.07595
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18444, current rewards: 173.10199, mean: 0.07659
[32m[0906 15-13-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18446, current rewards: 178.27948, mean: 0.07718
[32m[0906 15-13-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18447, current rewards: 183.87354, mean: 0.07791
[32m[0906 15-13-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18449, current rewards: 189.47158, mean: 0.07862
[32m[0906 15-13-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18449, current rewards: 195.06640, mean: 0.07930
[32m[0906 15-13-41 @Agent.py:117][0m Average action selection time: 0.1845
[32m[0906 15-13-41 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-13-41 @MBExp.py:227][0m Rewards obtained: [199.54088018066142], Lows: [21], Highs: [22], Total time: 5502.674153
[32m[0906 15-14-08 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-08 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 15-14-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18646, current rewards: 0.91689, mean: 0.09169
[32m[0906 15-14-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18555, current rewards: 0.29602, mean: 0.00493
[32m[0906 15-14-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18483, current rewards: 4.33029, mean: 0.03937
[32m[0906 15-14-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18350, current rewards: 8.36607, mean: 0.05229
[32m[0906 15-14-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18271, current rewards: 13.45477, mean: 0.06407
[32m[0906 15-14-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18251, current rewards: 20.53353, mean: 0.07898
[32m[0906 15-15-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18301, current rewards: 27.63008, mean: 0.08913
[32m[0906 15-15-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18321, current rewards: 34.72663, mean: 0.09646
[32m[0906 15-15-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18335, current rewards: 41.82318, mean: 0.10201
[32m[0906 15-15-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18318, current rewards: 12.37794, mean: 0.02691
[32m[0906 15-15-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18291, current rewards: -37.62206, mean: -0.07377
[32m[0906 15-15-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18273, current rewards: -87.62206, mean: -0.15647
[32m[0906 15-16-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18263, current rewards: -137.62206, mean: -0.22561
[32m[0906 15-16-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18250, current rewards: -187.62206, mean: -0.28428
[32m[0906 15-16-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18235, current rewards: -237.62206, mean: -0.33468
[32m[0906 15-16-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18241, current rewards: -287.62206, mean: -0.37845
[32m[0906 15-16-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18261, current rewards: -337.62206, mean: -0.41682
[32m[0906 15-16-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18264, current rewards: -387.62206, mean: -0.45072
[32m[0906 15-16-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18253, current rewards: -437.62206, mean: -0.48090
[32m[0906 15-17-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18242, current rewards: -487.62206, mean: -0.50794
[32m[0906 15-17-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18241, current rewards: -537.62206, mean: -0.53230
[32m[0906 15-17-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18257, current rewards: -587.62206, mean: -0.55436
[32m[0906 15-17-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18272, current rewards: -637.62206, mean: -0.57443
[32m[0906 15-17-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18287, current rewards: -687.62206, mean: -0.59278
[32m[0906 15-17-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18299, current rewards: -737.62206, mean: -0.60961
[32m[0906 15-17-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18310, current rewards: -787.62206, mean: -0.62510
[32m[0906 15-18-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18323, current rewards: -837.62206, mean: -0.63941
[32m[0906 15-18-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18329, current rewards: -887.62206, mean: -0.65266
[32m[0906 15-18-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18339, current rewards: -937.62206, mean: -0.66498
[32m[0906 15-18-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18346, current rewards: -987.62206, mean: -0.67645
[32m[0906 15-18-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18356, current rewards: -1037.62206, mean: -0.68717
[32m[0906 15-18-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18361, current rewards: -1087.62206, mean: -0.69719
[32m[0906 15-19-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18367, current rewards: -1137.62206, mean: -0.70660
[32m[0906 15-19-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18372, current rewards: -1187.62206, mean: -0.71543
[32m[0906 15-19-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18375, current rewards: -1237.62206, mean: -0.72376
[32m[0906 15-19-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18379, current rewards: -1287.62206, mean: -0.73160
[32m[0906 15-19-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18384, current rewards: -1337.62206, mean: -0.73902
[32m[0906 15-19-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18388, current rewards: -1387.62206, mean: -0.74603
[32m[0906 15-20-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18389, current rewards: -1437.62206, mean: -0.75268
[32m[0906 15-20-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18395, current rewards: -1487.62206, mean: -0.75899
[32m[0906 15-20-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18399, current rewards: -1537.62206, mean: -0.76499
[32m[0906 15-20-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18403, current rewards: -1587.62206, mean: -0.77069
[32m[0906 15-20-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18404, current rewards: -1637.62206, mean: -0.77612
[32m[0906 15-20-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18405, current rewards: -1687.62206, mean: -0.78131
[32m[0906 15-20-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18405, current rewards: -1737.62206, mean: -0.78625
[32m[0906 15-21-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18406, current rewards: -1787.62206, mean: -0.79098
[32m[0906 15-21-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18409, current rewards: -1837.62206, mean: -0.79551
[32m[0906 15-21-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18410, current rewards: -1887.62206, mean: -0.79984
[32m[0906 15-21-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18411, current rewards: -1937.62206, mean: -0.80399
[32m[0906 15-21-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18412, current rewards: -1987.62206, mean: -0.80798
[32m[0906 15-21-49 @Agent.py:117][0m Average action selection time: 0.1841
[32m[0906 15-21-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-21-49 @MBExp.py:227][0m Rewards obtained: [-2027.622058734065], Lows: [0], Highs: [2076], Total time: 5963.653085
[32m[0906 15-22-19 @MBExp.py:144][0m ####################################################################
[32m[0906 15-22-19 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 15-22-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18654, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-22-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18582, current rewards: -6.59606, mean: -0.10993
[32m[0906 15-22-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18346, current rewards: -2.23192, mean: -0.02029
[32m[0906 15-22-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18247, current rewards: 2.12730, mean: 0.01330
[32m[0906 15-22-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18199, current rewards: 7.95153, mean: 0.03786
[32m[0906 15-23-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18229, current rewards: 12.98249, mean: 0.04993
[32m[0906 15-23-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18286, current rewards: 17.40140, mean: 0.05613
[32m[0906 15-23-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18305, current rewards: 21.81740, mean: 0.06060
[32m[0906 15-23-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18339, current rewards: 26.23579, mean: 0.06399
[32m[0906 15-23-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18315, current rewards: 30.65217, mean: 0.06664
[32m[0906 15-23-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18291, current rewards: 18.36057, mean: 0.03600
[32m[0906 15-24-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18267, current rewards: 10.32963, mean: 0.01845
[32m[0906 15-24-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18239, current rewards: 16.32651, mean: 0.02676
[32m[0906 15-24-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18237, current rewards: 22.04239, mean: 0.03340
[32m[0906 15-24-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18226, current rewards: 28.21104, mean: 0.03973
[32m[0906 15-24-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18234, current rewards: 34.39271, mean: 0.04525
[32m[0906 15-24-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18257, current rewards: 40.56434, mean: 0.05008
[32m[0906 15-24-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18255, current rewards: 46.73650, mean: 0.05434
[32m[0906 15-25-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18248, current rewards: 31.67559, mean: 0.03481
[32m[0906 15-25-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18241, current rewards: 36.95941, mean: 0.03850
[32m[0906 15-25-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18241, current rewards: 42.22746, mean: 0.04181
[32m[0906 15-25-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18256, current rewards: 47.85229, mean: 0.04514
[32m[0906 15-25-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18268, current rewards: 53.05469, mean: 0.04780
[32m[0906 15-25-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18284, current rewards: 58.25840, mean: 0.05022
[32m[0906 15-26-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18296, current rewards: 63.46112, mean: 0.05245
[32m[0906 15-26-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18303, current rewards: 68.66535, mean: 0.05450
[32m[0906 15-26-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18311, current rewards: 61.71584, mean: 0.04711
[32m[0906 15-26-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18321, current rewards: 66.63331, mean: 0.04900
[32m[0906 15-26-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18326, current rewards: 71.55232, mean: 0.05075
[32m[0906 15-26-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18332, current rewards: 76.09101, mean: 0.05212
[32m[0906 15-26-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18337, current rewards: 80.74525, mean: 0.05347
[32m[0906 15-27-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18342, current rewards: 83.86891, mean: 0.05376
[32m[0906 15-27-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18346, current rewards: 86.97718, mean: 0.05402
[32m[0906 15-27-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18351, current rewards: 90.08448, mean: 0.05427
[32m[0906 15-27-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18356, current rewards: 93.18956, mean: 0.05450
[32m[0906 15-27-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18360, current rewards: 96.29676, mean: 0.05471
[32m[0906 15-27-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18364, current rewards: 78.78046, mean: 0.04353
[32m[0906 15-28-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18368, current rewards: 84.25987, mean: 0.04530
[32m[0906 15-28-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18371, current rewards: 89.69751, mean: 0.04696
[32m[0906 15-28-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18375, current rewards: 95.12840, mean: 0.04853
[32m[0906 15-28-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18378, current rewards: 100.57064, mean: 0.05004
[32m[0906 15-28-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18382, current rewards: 106.00712, mean: 0.05146
[32m[0906 15-28-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18384, current rewards: 111.44310, mean: 0.05282
[32m[0906 15-28-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18385, current rewards: 116.87438, mean: 0.05411
[32m[0906 15-29-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18387, current rewards: 122.31211, mean: 0.05534
[32m[0906 15-29-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18390, current rewards: 81.69410, mean: 0.03615
[32m[0906 15-29-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18392, current rewards: 80.82026, mean: 0.03499
[32m[0906 15-29-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18393, current rewards: 86.61360, mean: 0.03670
[32m[0906 15-29-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18395, current rewards: 92.40703, mean: 0.03834
[32m[0906 15-29-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18396, current rewards: 98.19966, mean: 0.03992
[32m[0906 15-30-00 @Agent.py:117][0m Average action selection time: 0.1840
[32m[0906 15-30-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-30-00 @MBExp.py:227][0m Rewards obtained: [102.83278799625869], Lows: [61], Highs: [22], Total time: 6424.243562
[32m[0906 15-30-31 @MBExp.py:144][0m ####################################################################
[32m[0906 15-30-31 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 15-30-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18752, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-30-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18568, current rewards: -0.58164, mean: -0.00969
[32m[0906 15-30-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18343, current rewards: 5.82847, mean: 0.05299
[32m[0906 15-31-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18248, current rewards: 12.23675, mean: 0.07648
[32m[0906 15-31-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18215, current rewards: 18.63716, mean: 0.08875
[32m[0906 15-31-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18261, current rewards: 25.04022, mean: 0.09631
[32m[0906 15-31-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18305, current rewards: 31.44649, mean: 0.10144
[32m[0906 15-31-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18333, current rewards: 37.84797, mean: 0.10513
[32m[0906 15-31-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18353, current rewards: 44.24711, mean: 0.10792
[32m[0906 15-31-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18319, current rewards: 42.75687, mean: 0.09295
[32m[0906 15-32-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18300, current rewards: 44.84338, mean: 0.08793
[32m[0906 15-32-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18283, current rewards: 50.43458, mean: 0.09006
[32m[0906 15-32-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18240, current rewards: 55.76687, mean: 0.09142
[32m[0906 15-32-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18224, current rewards: 60.42922, mean: 0.09156
[32m[0906 15-32-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18218, current rewards: 65.60962, mean: 0.09241
[32m[0906 15-32-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18229, current rewards: 70.80255, mean: 0.09316
[32m[0906 15-32-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18254, current rewards: 75.97994, mean: 0.09380
[32m[0906 15-33-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18249, current rewards: 81.16985, mean: 0.09438
[32m[0906 15-33-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18238, current rewards: 86.35752, mean: 0.09490
[32m[0906 15-33-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18229, current rewards: 93.86518, mean: 0.09778
[32m[0906 15-33-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18228, current rewards: 101.85034, mean: 0.10084
[32m[0906 15-33-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18245, current rewards: 111.02243, mean: 0.10474
[32m[0906 15-33-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18258, current rewards: 117.08726, mean: 0.10548
[32m[0906 15-34-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18273, current rewards: 123.13245, mean: 0.10615
[32m[0906 15-34-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18284, current rewards: 129.18237, mean: 0.10676
[32m[0906 15-34-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18296, current rewards: 135.23143, mean: 0.10733
[32m[0906 15-34-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18306, current rewards: 141.28242, mean: 0.10785
[32m[0906 15-34-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18314, current rewards: 125.96721, mean: 0.09262
[32m[0906 15-34-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18327, current rewards: 131.80993, mean: 0.09348
[32m[0906 15-34-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18337, current rewards: 137.52418, mean: 0.09419
[32m[0906 15-35-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18343, current rewards: 122.50084, mean: 0.08113
[32m[0906 15-35-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18348, current rewards: 129.11368, mean: 0.08277
[32m[0906 15-35-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18354, current rewards: 135.72192, mean: 0.08430
[32m[0906 15-35-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18362, current rewards: 142.33017, mean: 0.08574
[32m[0906 15-35-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18364, current rewards: 148.93842, mean: 0.08710
[32m[0906 15-35-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18367, current rewards: 155.54667, mean: 0.08838
[32m[0906 15-36-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18370, current rewards: 162.15493, mean: 0.08959
[32m[0906 15-36-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18370, current rewards: 152.91287, mean: 0.08221
[32m[0906 15-36-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18374, current rewards: 153.00805, mean: 0.08011
[32m[0906 15-36-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18376, current rewards: 158.36767, mean: 0.08080
[32m[0906 15-36-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18376, current rewards: 163.73011, mean: 0.08146
[32m[0906 15-36-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18379, current rewards: 169.09364, mean: 0.08208
[32m[0906 15-36-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18383, current rewards: 174.45393, mean: 0.08268
[32m[0906 15-37-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18385, current rewards: 179.80851, mean: 0.08324
[32m[0906 15-37-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18386, current rewards: 185.16934, mean: 0.08379
[32m[0906 15-37-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18387, current rewards: 190.52842, mean: 0.08430
[32m[0906 15-37-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18389, current rewards: 197.93119, mean: 0.08568
[32m[0906 15-37-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18391, current rewards: 203.45681, mean: 0.08621
[32m[0906 15-37-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18393, current rewards: 208.95810, mean: 0.08670
[32m[0906 15-38-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18394, current rewards: 214.46386, mean: 0.08718
[32m[0906 15-38-12 @Agent.py:117][0m Average action selection time: 0.1840
[32m[0906 15-38-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-38-12 @MBExp.py:227][0m Rewards obtained: [218.8699638968975], Lows: [20], Highs: [39], Total time: 6884.794703
[32m[0906 15-38-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-38-45 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18495, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-38-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18243, current rewards: -5.06645, mean: -0.08444
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18177, current rewards: -0.10375, mean: -0.00094
[32m[0906 15-39-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18150, current rewards: 4.85685, mean: 0.03036
[32m[0906 15-39-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18121, current rewards: 9.82167, mean: 0.04677
[32m[0906 15-39-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18211, current rewards: 14.60944, mean: 0.05619
[32m[0906 15-39-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18257, current rewards: 19.62202, mean: 0.06330
[32m[0906 15-39-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18281, current rewards: 24.63527, mean: 0.06843
[32m[0906 15-40-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18284, current rewards: 29.65341, mean: 0.07233
[32m[0906 15-40-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18260, current rewards: 34.66799, mean: 0.07537
[32m[0906 15-40-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18237, current rewards: 39.68286, mean: 0.07781
[32m[0906 15-40-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18212, current rewards: 21.59624, mean: 0.03856
[32m[0906 15-40-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18177, current rewards: 26.24606, mean: 0.04303
[32m[0906 15-40-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18168, current rewards: 32.86406, mean: 0.04979
[32m[0906 15-40-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18163, current rewards: 39.17948, mean: 0.05518
[32m[0906 15-41-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18176, current rewards: 45.49491, mean: 0.05986
[32m[0906 15-41-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18200, current rewards: 51.81033, mean: 0.06396
[32m[0906 15-41-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18192, current rewards: 58.12575, mean: 0.06759
[32m[0906 15-41-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18185, current rewards: 64.44118, mean: 0.07081
[32m[0906 15-41-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18181, current rewards: 70.75660, mean: 0.07370
[32m[0906 15-41-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18184, current rewards: 77.07203, mean: 0.07631
[32m[0906 15-41-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18203, current rewards: 75.87804, mean: 0.07158
[32m[0906 15-42-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18224, current rewards: 25.87804, mean: 0.02331
[32m[0906 15-42-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18238, current rewards: -24.12196, mean: -0.02079
[32m[0906 15-42-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18250, current rewards: -74.12196, mean: -0.06126
[32m[0906 15-42-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18258, current rewards: -124.12196, mean: -0.09851
[32m[0906 15-42-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18269, current rewards: -174.12196, mean: -0.13292
[32m[0906 15-42-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18277, current rewards: -224.12196, mean: -0.16480
[32m[0906 15-43-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18284, current rewards: -274.12196, mean: -0.19441
[32m[0906 15-43-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18297, current rewards: -324.12196, mean: -0.22200
[32m[0906 15-43-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18305, current rewards: -374.12196, mean: -0.24776
[32m[0906 15-43-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18308, current rewards: -424.12196, mean: -0.27187
[32m[0906 15-43-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18315, current rewards: -474.12196, mean: -0.29449
[32m[0906 15-43-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18319, current rewards: -524.12196, mean: -0.31574
[32m[0906 15-43-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18322, current rewards: -574.12196, mean: -0.33574
[32m[0906 15-44-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18328, current rewards: -624.12196, mean: -0.35461
[32m[0906 15-44-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18334, current rewards: -674.12196, mean: -0.37244
[32m[0906 15-44-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18336, current rewards: -724.12196, mean: -0.38931
[32m[0906 15-44-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18339, current rewards: -774.12196, mean: -0.40530
[32m[0906 15-44-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18344, current rewards: -824.12196, mean: -0.42047
[32m[0906 15-44-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18345, current rewards: -874.12196, mean: -0.43489
[32m[0906 15-45-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18348, current rewards: -924.12196, mean: -0.44860
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18350, current rewards: -974.12196, mean: -0.46167
[32m[0906 15-45-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18354, current rewards: -1024.12196, mean: -0.47413
[32m[0906 15-45-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18357, current rewards: -1074.12196, mean: -0.48603
[32m[0906 15-45-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18357, current rewards: -1124.12196, mean: -0.49740
[32m[0906 15-45-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18358, current rewards: -1174.12196, mean: -0.50828
[32m[0906 15-45-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18359, current rewards: -1224.12196, mean: -0.51870
[32m[0906 15-46-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18361, current rewards: -1274.12196, mean: -0.52868
[32m[0906 15-46-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18362, current rewards: -1324.12196, mean: -0.53826
[32m[0906 15-46-25 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 15-46-25 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-46-25 @MBExp.py:227][0m Rewards obtained: [-1364.1219604288563], Lows: [11], Highs: [1456], Total time: 7344.538611999999
[32m[0906 15-47-01 @MBExp.py:144][0m ####################################################################
[32m[0906 15-47-01 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 15-47-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17992, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-47-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18000, current rewards: -5.54928, mean: -0.09249
[32m[0906 15-47-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18084, current rewards: -1.39491, mean: -0.01268
[32m[0906 15-47-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18076, current rewards: 2.75861, mean: 0.01724
[32m[0906 15-47-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18099, current rewards: 6.70205, mean: 0.03191
[32m[0906 15-47-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18175, current rewards: 10.82699, mean: 0.04164
[32m[0906 15-47-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18226, current rewards: 14.95284, mean: 0.04823
[32m[0906 15-48-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18258, current rewards: -1.36936, mean: -0.00380
[32m[0906 15-48-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18266, current rewards: 3.42466, mean: 0.00835
[32m[0906 15-48-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18240, current rewards: 8.21452, mean: 0.01786
[32m[0906 15-48-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18217, current rewards: 13.00747, mean: 0.02550
[32m[0906 15-48-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18183, current rewards: 17.79971, mean: 0.03179
[32m[0906 15-48-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18148, current rewards: 23.71757, mean: 0.03888
[32m[0906 15-49-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18140, current rewards: 17.16065, mean: 0.02600
[32m[0906 15-49-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18133, current rewards: 21.36165, mean: 0.03009
[32m[0906 15-49-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18137, current rewards: 25.55972, mean: 0.03363
[32m[0906 15-49-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18161, current rewards: 29.75840, mean: 0.03674
[32m[0906 15-49-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18159, current rewards: 33.95713, mean: 0.03949
[32m[0906 15-49-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18155, current rewards: 38.15673, mean: 0.04193
[32m[0906 15-49-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18152, current rewards: 22.59420, mean: 0.02354
[32m[0906 15-50-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18159, current rewards: 28.93483, mean: 0.02865
[32m[0906 15-50-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18177, current rewards: 5.97927, mean: 0.00564
[32m[0906 15-50-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18190, current rewards: 10.49978, mean: 0.00946
[32m[0906 15-50-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18202, current rewards: 15.02469, mean: 0.01295
[32m[0906 15-50-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18216, current rewards: 19.54759, mean: 0.01616
[32m[0906 15-50-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18226, current rewards: 13.31644, mean: 0.01057
[32m[0906 15-51-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18237, current rewards: 17.42112, mean: 0.01330
[32m[0906 15-51-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18246, current rewards: 21.55171, mean: 0.01585
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18259, current rewards: 25.68185, mean: 0.01821
[32m[0906 15-51-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18271, current rewards: 31.02872, mean: 0.02125
[32m[0906 15-51-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18283, current rewards: 35.32748, mean: 0.02340
[32m[0906 15-51-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18288, current rewards: 39.62850, mean: 0.02540
[32m[0906 15-51-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18294, current rewards: 23.50620, mean: 0.01460
[32m[0906 15-52-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18303, current rewards: 27.99319, mean: 0.01686
[32m[0906 15-52-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18309, current rewards: 32.47908, mean: 0.01899
[32m[0906 15-52-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18315, current rewards: 36.96259, mean: 0.02100
[32m[0906 15-52-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18322, current rewards: 41.44877, mean: 0.02290
[32m[0906 15-52-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18327, current rewards: 46.36070, mean: 0.02493
[32m[0906 15-52-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18333, current rewards: 50.83034, mean: 0.02661
[32m[0906 15-53-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18336, current rewards: 55.29659, mean: 0.02821
[32m[0906 15-53-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18340, current rewards: 59.76350, mean: 0.02973
[32m[0906 15-53-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18345, current rewards: 64.23261, mean: 0.03118
[32m[0906 15-53-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18347, current rewards: 57.86992, mean: 0.02743
[32m[0906 15-53-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18350, current rewards: 62.22728, mean: 0.02881
[32m[0906 15-53-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18356, current rewards: 66.58714, mean: 0.03013
[32m[0906 15-53-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18359, current rewards: 70.88368, mean: 0.03136
[32m[0906 15-54-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18361, current rewards: 74.40119, mean: 0.03221
[32m[0906 15-54-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18364, current rewards: 78.53111, mean: 0.03328
[32m[0906 15-54-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18368, current rewards: 82.66302, mean: 0.03430
[32m[0906 15-54-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18370, current rewards: 86.79371, mean: 0.03528
[32m[0906 15-54-41 @Agent.py:117][0m Average action selection time: 0.1837
[32m[0906 15-54-41 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-54-41 @MBExp.py:227][0m Rewards obtained: [90.09713156762089], Lows: [30], Highs: [66], Total time: 7804.495392999999
[32m[0906 15-55-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-55-18 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-55-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18087, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-55-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18007, current rewards: -3.22408, mean: -0.05373
[32m[0906 15-55-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18009, current rewards: 2.05589, mean: 0.01869
[32m[0906 15-55-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18066, current rewards: 7.34164, mean: 0.04589
[32m[0906 15-55-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18119, current rewards: 12.72669, mean: 0.06060
[32m[0906 15-56-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18215, current rewards: 18.10387, mean: 0.06963
[32m[0906 15-56-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18258, current rewards: 23.32130, mean: 0.07523
[32m[0906 15-56-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18290, current rewards: 28.55237, mean: 0.07931
[32m[0906 15-56-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18275, current rewards: 13.75626, mean: 0.03355
[32m[0906 15-56-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18249, current rewards: 19.58756, mean: 0.04258
[32m[0906 15-56-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18228, current rewards: 25.41934, mean: 0.04984
[32m[0906 15-57-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18187, current rewards: 31.25538, mean: 0.05581
[32m[0906 15-57-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18151, current rewards: 37.06848, mean: 0.06077
[32m[0906 15-57-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18141, current rewards: 42.70328, mean: 0.06470
[32m[0906 15-57-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18136, current rewards: 48.55088, mean: 0.06838
[32m[0906 15-57-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18140, current rewards: 54.39843, mean: 0.07158
[32m[0906 15-57-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18147, current rewards: 40.40921, mean: 0.04989
[32m[0906 15-57-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18146, current rewards: 46.91255, mean: 0.05455
[32m[0906 15-58-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18143, current rewards: 53.41269, mean: 0.05870
[32m[0906 15-58-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18137, current rewards: 59.91533, mean: 0.06241
[32m[0906 15-58-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18149, current rewards: 66.41305, mean: 0.06576
[32m[0906 15-58-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18166, current rewards: 73.60751, mean: 0.06944
[32m[0906 15-58-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18186, current rewards: 80.15872, mean: 0.07222
[32m[0906 15-58-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18204, current rewards: 86.71025, mean: 0.07475
[32m[0906 15-58-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18217, current rewards: 80.47874, mean: 0.06651
[32m[0906 15-59-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18230, current rewards: 86.24090, mean: 0.06845
[32m[0906 15-59-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18240, current rewards: 92.02295, mean: 0.07025
[32m[0906 15-59-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18253, current rewards: 97.80122, mean: 0.07191
[32m[0906 15-59-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18264, current rewards: 103.57913, mean: 0.07346
[32m[0906 15-59-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18272, current rewards: 108.98520, mean: 0.07465
[32m[0906 15-59-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18281, current rewards: 115.13621, mean: 0.07625
[32m[0906 16-00-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18291, current rewards: 100.19285, mean: 0.06423
[32m[0906 16-00-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18301, current rewards: 105.95356, mean: 0.06581
[32m[0906 16-00-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18307, current rewards: 111.69508, mean: 0.06729
[32m[0906 16-00-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18316, current rewards: 117.43824, mean: 0.06868
[32m[0906 16-00-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18323, current rewards: 123.19045, mean: 0.06999
[32m[0906 16-00-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18328, current rewards: 128.95105, mean: 0.07124
[32m[0906 16-01-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18333, current rewards: 117.17019, mean: 0.06299
[32m[0906 16-01-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18338, current rewards: 123.27897, mean: 0.06454
[32m[0906 16-01-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18340, current rewards: 129.39107, mean: 0.06602
[32m[0906 16-01-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18343, current rewards: 135.50313, mean: 0.06741
[32m[0906 16-01-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18350, current rewards: 141.61560, mean: 0.06875
[32m[0906 16-01-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18351, current rewards: 147.72379, mean: 0.07001
[32m[0906 16-01-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18355, current rewards: 133.38738, mean: 0.06175
[32m[0906 16-02-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18362, current rewards: 140.03000, mean: 0.06336
[32m[0906 16-02-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18365, current rewards: 146.34529, mean: 0.06475
[32m[0906 16-02-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18367, current rewards: 152.91638, mean: 0.06620
[32m[0906 16-02-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18370, current rewards: 146.98446, mean: 0.06228
[32m[0906 16-02-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18371, current rewards: 152.60098, mean: 0.06332
[32m[0906 16-02-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18373, current rewards: 157.97850, mean: 0.06422
[32m[0906 16-02-58 @Agent.py:117][0m Average action selection time: 0.1837
[32m[0906 16-02-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-02-58 @MBExp.py:227][0m Rewards obtained: [162.280715652842], Lows: [50], Highs: [33], Total time: 8264.514822
[32m[0906 16-03-38 @MBExp.py:144][0m ####################################################################
[32m[0906 16-03-38 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 16-03-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18120, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-03-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18020, current rewards: -45.60888, mean: -0.76015
[32m[0906 16-03-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18022, current rewards: -75.24679, mean: -0.68406
[32m[0906 16-04-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18036, current rewards: -99.71152, mean: -0.62320
[32m[0906 16-04-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18143, current rewards: -126.40754, mean: -0.60194
[32m[0906 16-04-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18207, current rewards: -164.37911, mean: -0.63223
[32m[0906 16-04-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18266, current rewards: -198.80253, mean: -0.64130
[32m[0906 16-04-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18301, current rewards: -226.28289, mean: -0.62856
[32m[0906 16-04-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18284, current rewards: -258.01632, mean: -0.62931
[32m[0906 16-05-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18254, current rewards: -288.25347, mean: -0.62664
[32m[0906 16-05-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18234, current rewards: -303.23872, mean: -0.59459
[32m[0906 16-05-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18185, current rewards: -296.45201, mean: -0.52938
[32m[0906 16-05-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18141, current rewards: -289.79548, mean: -0.47507
[32m[0906 16-05-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18134, current rewards: -283.16260, mean: -0.42903
[32m[0906 16-05-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18129, current rewards: -276.53140, mean: -0.38948
[32m[0906 16-05-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18131, current rewards: -268.18831, mean: -0.35288
[32m[0906 16-06-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18129, current rewards: -260.54342, mean: -0.32166
[32m[0906 16-06-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18128, current rewards: -252.90369, mean: -0.29407
[32m[0906 16-06-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18123, current rewards: -245.26504, mean: -0.26952
[32m[0906 16-06-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18119, current rewards: -237.16578, mean: -0.24705
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18129, current rewards: -225.69914, mean: -0.22346
[32m[0906 16-06-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18156, current rewards: -217.52406, mean: -0.20521
[32m[0906 16-07-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18172, current rewards: -209.35415, mean: -0.18861
[32m[0906 16-07-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18186, current rewards: -224.16703, mean: -0.19325
[32m[0906 16-07-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18199, current rewards: -217.12879, mean: -0.17945
[32m[0906 16-07-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18210, current rewards: -210.07390, mean: -0.16673
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18225, current rewards: -203.01717, mean: -0.15497
[32m[0906 16-07-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18234, current rewards: -195.95965, mean: -0.14409
[32m[0906 16-07-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18245, current rewards: -190.17215, mean: -0.13487
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18254, current rewards: -182.96486, mean: -0.12532
[32m[0906 16-08-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18262, current rewards: -175.76191, mean: -0.11640
[32m[0906 16-08-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18272, current rewards: -168.55857, mean: -0.10805
[32m[0906 16-08-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18279, current rewards: -161.35740, mean: -0.10022
[32m[0906 16-08-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18284, current rewards: -154.14844, mean: -0.09286
[32m[0906 16-08-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18289, current rewards: -168.34935, mean: -0.09845
[32m[0906 16-09-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18296, current rewards: -162.28249, mean: -0.09221
[32m[0906 16-09-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18302, current rewards: -154.21512, mean: -0.08520
[32m[0906 16-09-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18308, current rewards: -147.02302, mean: -0.07904
[32m[0906 16-09-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18314, current rewards: -140.28137, mean: -0.07345
[32m[0906 16-09-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18319, current rewards: -145.35628, mean: -0.07416
[32m[0906 16-09-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18322, current rewards: -132.26446, mean: -0.06580
[32m[0906 16-09-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18327, current rewards: -119.42578, mean: -0.05797
[32m[0906 16-10-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18331, current rewards: -106.60597, mean: -0.05052
[32m[0906 16-10-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18336, current rewards: -117.22671, mean: -0.05427
[32m[0906 16-10-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18339, current rewards: -110.57344, mean: -0.05003
[32m[0906 16-10-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18346, current rewards: -104.50794, mean: -0.04624
[32m[0906 16-10-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18349, current rewards: -97.87984, mean: -0.04237
[32m[0906 16-10-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18352, current rewards: -91.25546, mean: -0.03867
[32m[0906 16-11-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18354, current rewards: -84.63094, mean: -0.03512
[32m[0906 16-11-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18356, current rewards: -78.00210, mean: -0.03171
[32m[0906 16-11-17 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 16-11-17 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-11-17 @MBExp.py:227][0m Rewards obtained: [-72.69610321060551], Lows: [219], Highs: [22], Total time: 8724.111975
[32m[0906 16-11-59 @MBExp.py:144][0m ####################################################################
[32m[0906 16-11-59 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 16-12-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18022, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-12-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18062, current rewards: -3.86038, mean: -0.06434
[32m[0906 16-12-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18059, current rewards: 1.21993, mean: 0.01109
[32m[0906 16-12-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18052, current rewards: 6.26450, mean: 0.03915
[32m[0906 16-12-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18200, current rewards: 11.30117, mean: 0.05382
[32m[0906 16-12-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18254, current rewards: 16.40225, mean: 0.06309
[32m[0906 16-12-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18298, current rewards: 21.50345, mean: 0.06937
[32m[0906 16-13-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18331, current rewards: 26.60482, mean: 0.07390
[32m[0906 16-13-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18301, current rewards: 31.70252, mean: 0.07732
[32m[0906 16-13-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18275, current rewards: 25.81331, mean: 0.05612
[32m[0906 16-13-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18254, current rewards: 30.65502, mean: 0.06011
[32m[0906 16-13-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18196, current rewards: 35.50859, mean: 0.06341
[32m[0906 16-13-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18146, current rewards: 40.48338, mean: 0.06637
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18138, current rewards: 45.30563, mean: 0.06864
[32m[0906 16-14-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18137, current rewards: 50.12813, mean: 0.07060
[32m[0906 16-14-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18130, current rewards: 54.95363, mean: 0.07231
[32m[0906 16-14-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18124, current rewards: 59.77927, mean: 0.07380
[32m[0906 16-14-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18122, current rewards: 65.70357, mean: 0.07640
[32m[0906 16-14-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18124, current rewards: 75.08615, mean: 0.08251
[32m[0906 16-14-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18119, current rewards: 79.88959, mean: 0.08322
[32m[0906 16-15-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18129, current rewards: 84.24799, mean: 0.08341
[32m[0906 16-15-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18152, current rewards: 80.59615, mean: 0.07603
[32m[0906 16-15-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18171, current rewards: 73.03261, mean: 0.06580
[32m[0906 16-15-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18185, current rewards: 77.89509, mean: 0.06715
[32m[0906 16-15-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18198, current rewards: 82.75633, mean: 0.06839
[32m[0906 16-15-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18213, current rewards: 87.61400, mean: 0.06953
[32m[0906 16-15-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18224, current rewards: 92.47361, mean: 0.07059
[32m[0906 16-16-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18233, current rewards: 97.33932, mean: 0.07157
[32m[0906 16-16-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18246, current rewards: 101.48121, mean: 0.07197
[32m[0906 16-16-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18253, current rewards: 106.31561, mean: 0.07282
[32m[0906 16-16-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18260, current rewards: 100.49832, mean: 0.06656
[32m[0906 16-16-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18271, current rewards: 105.27258, mean: 0.06748
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18278, current rewards: 110.05244, mean: 0.06836
[32m[0906 16-17-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18286, current rewards: 114.82972, mean: 0.06917
[32m[0906 16-17-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18292, current rewards: 119.60887, mean: 0.06995
[32m[0906 16-17-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18296, current rewards: 124.38537, mean: 0.07067
[32m[0906 16-17-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18301, current rewards: 129.95960, mean: 0.07180
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18308, current rewards: 135.12497, mean: 0.07265
[32m[0906 16-17-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18311, current rewards: 140.03843, mean: 0.07332
[32m[0906 16-17-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18316, current rewards: 144.95353, mean: 0.07396
[32m[0906 16-18-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18322, current rewards: 149.87133, mean: 0.07456
[32m[0906 16-18-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18326, current rewards: 154.78385, mean: 0.07514
[32m[0906 16-18-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18329, current rewards: 159.70072, mean: 0.07569
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18334, current rewards: 156.21583, mean: 0.07232
[32m[0906 16-18-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18338, current rewards: 146.49086, mean: 0.06629
[32m[0906 16-18-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18343, current rewards: 150.63145, mean: 0.06665
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18347, current rewards: 155.20627, mean: 0.06719
[32m[0906 16-19-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18348, current rewards: 159.78011, mean: 0.06770
[32m[0906 16-19-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18350, current rewards: 164.35542, mean: 0.06820
[32m[0906 16-19-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18353, current rewards: 168.93261, mean: 0.06867
[32m[0906 16-19-38 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 16-19-38 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-19-39 @MBExp.py:227][0m Rewards obtained: [172.59598650795604], Lows: [21], Highs: [31], Total time: 9183.645618
[32m[0906 16-20-22 @MBExp.py:144][0m ####################################################################
[32m[0906 16-20-22 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 16-20-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18072, current rewards: -8.95116, mean: -0.89512
[32m[0906 16-20-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18054, current rewards: -2.89000, mean: -0.04817
[32m[0906 16-20-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18046, current rewards: 2.79490, mean: 0.02541
[32m[0906 16-20-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18104, current rewards: 9.01198, mean: 0.05632
[32m[0906 16-21-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18228, current rewards: 14.85777, mean: 0.07075
[32m[0906 16-21-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18278, current rewards: 20.70173, mean: 0.07962
[32m[0906 16-21-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18320, current rewards: 26.54425, mean: 0.08563
[32m[0906 16-21-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18334, current rewards: 32.38636, mean: 0.08996
[32m[0906 16-21-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18295, current rewards: 38.22982, mean: 0.09324
[32m[0906 16-21-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18265, current rewards: 32.90353, mean: 0.07153
[32m[0906 16-21-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18243, current rewards: 36.19908, mean: 0.07098
[32m[0906 16-22-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18177, current rewards: 41.31759, mean: 0.07378
[32m[0906 16-22-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18127, current rewards: 46.74097, mean: 0.07662
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18124, current rewards: 52.18374, mean: 0.07907
[32m[0906 16-22-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18122, current rewards: 57.62794, mean: 0.08117
[32m[0906 16-22-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18099, current rewards: 63.06807, mean: 0.08298
[32m[0906 16-22-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18100, current rewards: 68.51432, mean: 0.08459
[32m[0906 16-22-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18100, current rewards: 73.95796, mean: 0.08600
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18099, current rewards: 68.74456, mean: 0.07554
[32m[0906 16-23-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18095, current rewards: 73.97025, mean: 0.07705
[32m[0906 16-23-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18107, current rewards: 79.66405, mean: 0.07888
[32m[0906 16-23-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18130, current rewards: 84.87649, mean: 0.08007
[32m[0906 16-23-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18148, current rewards: 90.07971, mean: 0.08115
[32m[0906 16-23-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18165, current rewards: 94.18181, mean: 0.08119
[32m[0906 16-24-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18183, current rewards: 90.06455, mean: 0.07443
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18193, current rewards: 95.13899, mean: 0.07551
[32m[0906 16-24-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18205, current rewards: 100.21882, mean: 0.07650
[32m[0906 16-24-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18215, current rewards: 105.29620, mean: 0.07742
[32m[0906 16-24-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18226, current rewards: 111.78194, mean: 0.07928
[32m[0906 16-24-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18236, current rewards: 116.65427, mean: 0.07990
[32m[0906 16-24-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18248, current rewards: 121.52121, mean: 0.08048
[32m[0906 16-25-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18260, current rewards: 126.39145, mean: 0.08102
[32m[0906 16-25-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18269, current rewards: 134.86931, mean: 0.08377
[32m[0906 16-25-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18274, current rewards: 139.72621, mean: 0.08417
[32m[0906 16-25-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18281, current rewards: 144.58097, mean: 0.08455
[32m[0906 16-25-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18286, current rewards: 149.43586, mean: 0.08491
[32m[0906 16-25-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18290, current rewards: 153.66282, mean: 0.08490
[32m[0906 16-26-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18293, current rewards: 158.45672, mean: 0.08519
[32m[0906 16-26-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18297, current rewards: 163.34680, mean: 0.08552
[32m[0906 16-26-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18304, current rewards: 168.23488, mean: 0.08583
[32m[0906 16-26-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18308, current rewards: 173.12617, mean: 0.08613
[32m[0906 16-26-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18312, current rewards: 169.62448, mean: 0.08234
[32m[0906 16-26-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18314, current rewards: 162.20259, mean: 0.07687
[32m[0906 16-26-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18317, current rewards: 167.40936, mean: 0.07750
[32m[0906 16-27-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18322, current rewards: 172.61615, mean: 0.07811
[32m[0906 16-27-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18328, current rewards: 180.81027, mean: 0.08000
[32m[0906 16-27-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18331, current rewards: 186.34969, mean: 0.08067
[32m[0906 16-27-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18333, current rewards: 191.89197, mean: 0.08131
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18337, current rewards: 197.43035, mean: 0.08192
[32m[0906 16-27-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18341, current rewards: 202.43534, mean: 0.08229
[32m[0906 16-28-01 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0906 16-28-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-28-01 @MBExp.py:227][0m Rewards obtained: [206.7372555945825], Lows: [11], Highs: [39], Total time: 9642.877579
[32m[0906 16-28-47 @MBExp.py:144][0m ####################################################################
[32m[0906 16-28-47 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 16-28-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18053, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-28-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18036, current rewards: -5.77483, mean: -0.09625
[32m[0906 16-29-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18027, current rewards: -1.53764, mean: -0.01398
[32m[0906 16-29-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18139, current rewards: 2.67605, mean: 0.01673
[32m[0906 16-29-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18260, current rewards: 6.89309, mean: 0.03282
[32m[0906 16-29-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18325, current rewards: 11.10949, mean: 0.04273
[32m[0906 16-29-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18347, current rewards: 15.32966, mean: 0.04945
[32m[0906 16-29-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18351, current rewards: 19.54671, mean: 0.05430
[32m[0906 16-30-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18317, current rewards: 23.76434, mean: 0.05796
[32m[0906 16-30-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18288, current rewards: 27.98044, mean: 0.06083
[32m[0906 16-30-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18262, current rewards: 32.19684, mean: 0.06313
[32m[0906 16-30-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18196, current rewards: 36.76394, mean: 0.06565
[32m[0906 16-30-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18142, current rewards: 42.59392, mean: 0.06983
[32m[0906 16-30-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18133, current rewards: 36.94094, mean: 0.05597
[32m[0906 16-30-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18134, current rewards: 42.73435, mean: 0.06019
[32m[0906 16-31-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18102, current rewards: 48.52928, mean: 0.06385
[32m[0906 16-31-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18098, current rewards: 54.32009, mean: 0.06706
[32m[0906 16-31-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18100, current rewards: 60.11811, mean: 0.06990
[32m[0906 16-31-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18097, current rewards: 65.91049, mean: 0.07243
[32m[0906 16-31-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18095, current rewards: 48.31364, mean: 0.05033
[32m[0906 16-31-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18108, current rewards: 55.06627, mean: 0.05452
[32m[0906 16-31-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18130, current rewards: 62.75901, mean: 0.05921
[32m[0906 16-32-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18151, current rewards: 70.43740, mean: 0.06346
[32m[0906 16-32-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18163, current rewards: 78.10479, mean: 0.06733
[32m[0906 16-32-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18174, current rewards: 85.78256, mean: 0.07089
[32m[0906 16-32-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18188, current rewards: 93.45411, mean: 0.07417
[32m[0906 16-32-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18196, current rewards: 101.12569, mean: 0.07720
[32m[0906 16-32-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18204, current rewards: 108.79887, mean: 0.08000
[32m[0906 16-33-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18216, current rewards: 117.37530, mean: 0.08324
[32m[0906 16-33-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18223, current rewards: 125.55864, mean: 0.08600
[32m[0906 16-33-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18233, current rewards: 133.75452, mean: 0.08858
[32m[0906 16-33-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18247, current rewards: 141.96510, mean: 0.09100
[32m[0906 16-33-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18256, current rewards: 150.16008, mean: 0.09327
[32m[0906 16-33-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18262, current rewards: 158.37539, mean: 0.09541
[32m[0906 16-34-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18269, current rewards: 154.93379, mean: 0.09060
[32m[0906 16-34-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18278, current rewards: 160.16665, mean: 0.09100
[32m[0906 16-34-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18283, current rewards: 166.42169, mean: 0.09195
[32m[0906 16-34-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18291, current rewards: 173.03124, mean: 0.09303
[32m[0906 16-34-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18296, current rewards: 178.42170, mean: 0.09341
[32m[0906 16-34-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18302, current rewards: 183.81339, mean: 0.09378
[32m[0906 16-34-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18306, current rewards: 188.56237, mean: 0.09381
[32m[0906 16-35-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18311, current rewards: 193.81755, mean: 0.09409
[32m[0906 16-35-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18314, current rewards: 199.07337, mean: 0.09435
[32m[0906 16-35-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18317, current rewards: 204.32885, mean: 0.09460
[32m[0906 16-35-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18323, current rewards: 209.58553, mean: 0.09484
[32m[0906 16-35-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18328, current rewards: 213.69115, mean: 0.09455
[32m[0906 16-35-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18331, current rewards: 218.75188, mean: 0.09470
[32m[0906 16-36-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18335, current rewards: 223.68655, mean: 0.09478
[32m[0906 16-36-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18338, current rewards: 196.45607, mean: 0.08152
[32m[0906 16-36-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18340, current rewards: 154.96612, mean: 0.06299
[32m[0906 16-36-26 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0906 16-36-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-36-26 @MBExp.py:227][0m Rewards obtained: [133.41944709010164], Lows: [56], Highs: [44], Total time: 10102.12316
[32m[0906 16-37-14 @MBExp.py:144][0m ####################################################################
[32m[0906 16-37-14 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 16-37-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18134, current rewards: 0.69976, mean: 0.06998
[32m[0906 16-37-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18043, current rewards: 7.35624, mean: 0.12260
[32m[0906 16-37-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18060, current rewards: 13.67167, mean: 0.12429
[32m[0906 16-37-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18203, current rewards: 19.98709, mean: 0.12492
[32m[0906 16-37-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18305, current rewards: 24.64884, mean: 0.11738
[32m[0906 16-38-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18352, current rewards: 28.50629, mean: 0.10964
[32m[0906 16-38-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18375, current rewards: 32.36374, mean: 0.10440
[32m[0906 16-38-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18361, current rewards: -4.71048, mean: -0.01308
[32m[0906 16-38-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18319, current rewards: -54.71048, mean: -0.13344
[32m[0906 16-38-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18288, current rewards: -104.71048, mean: -0.22763
[32m[0906 16-38-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18249, current rewards: -154.71048, mean: -0.30335
[32m[0906 16-38-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18182, current rewards: -204.71048, mean: -0.36555
[32m[0906 16-39-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18133, current rewards: -254.71048, mean: -0.41756
[32m[0906 16-39-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18128, current rewards: -304.71048, mean: -0.46168
[32m[0906 16-39-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18122, current rewards: -354.71048, mean: -0.49959
[32m[0906 16-39-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18085, current rewards: -404.71048, mean: -0.53251
[32m[0906 16-39-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18081, current rewards: -454.71048, mean: -0.56137
[32m[0906 16-39-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18091, current rewards: -504.71048, mean: -0.58687
[32m[0906 16-39-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18089, current rewards: -554.71048, mean: -0.60957
[32m[0906 16-40-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18093, current rewards: -604.71048, mean: -0.62991
[32m[0906 16-40-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18110, current rewards: -654.71048, mean: -0.64823
[32m[0906 16-40-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18134, current rewards: -704.71048, mean: -0.66482
[32m[0906 16-40-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18149, current rewards: -754.71048, mean: -0.67992
[32m[0906 16-40-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18169, current rewards: -804.71048, mean: -0.69372
[32m[0906 16-40-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18186, current rewards: -854.71048, mean: -0.70637
[32m[0906 16-41-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18200, current rewards: -904.71048, mean: -0.71802
[32m[0906 16-41-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18216, current rewards: -954.71048, mean: -0.72879
[32m[0906 16-41-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18230, current rewards: -1004.71048, mean: -0.73876
[32m[0906 16-41-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18242, current rewards: -1054.71048, mean: -0.74802
[32m[0906 16-41-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18253, current rewards: -1104.71048, mean: -0.75665
[32m[0906 16-41-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18261, current rewards: -1154.71048, mean: -0.76471
[32m[0906 16-41-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18273, current rewards: -1204.71048, mean: -0.77225
[32m[0906 16-42-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18279, current rewards: -1254.71048, mean: -0.77932
[32m[0906 16-42-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18284, current rewards: -1304.71048, mean: -0.78597
[32m[0906 16-42-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18292, current rewards: -1354.71048, mean: -0.79223
[32m[0906 16-42-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18297, current rewards: -1404.71048, mean: -0.79813
[32m[0906 16-42-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18304, current rewards: -1454.71048, mean: -0.80371
[32m[0906 16-42-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18309, current rewards: -1504.71048, mean: -0.80898
[32m[0906 16-43-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18313, current rewards: -1554.71048, mean: -0.81398
[32m[0906 16-43-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18315, current rewards: -1604.71048, mean: -0.81873
[32m[0906 16-43-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18317, current rewards: -1654.71048, mean: -0.82324
[32m[0906 16-43-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18322, current rewards: -1704.71048, mean: -0.82753
[32m[0906 16-43-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18324, current rewards: -1754.71048, mean: -0.83162
[32m[0906 16-43-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18327, current rewards: -1804.71048, mean: -0.83551
[32m[0906 16-43-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18332, current rewards: -1854.71048, mean: -0.83924
[32m[0906 16-44-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18336, current rewards: -1904.71048, mean: -0.84279
[32m[0906 16-44-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18337, current rewards: -1954.71048, mean: -0.84620
[32m[0906 16-44-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18340, current rewards: -2004.71048, mean: -0.84945
[32m[0906 16-44-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18344, current rewards: -2054.71048, mean: -0.85258
[32m[0906 16-44-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18347, current rewards: -2104.71048, mean: -0.85557
[32m[0906 16-44-53 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 16-44-53 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-44-53 @MBExp.py:227][0m Rewards obtained: [-2144.7104764689966], Lows: [0], Highs: [2178], Total time: 10561.53323
[32m[0906 16-45-43 @MBExp.py:144][0m ####################################################################
[32m[0906 16-45-43 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 16-45-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18025, current rewards: -4.74379, mean: -0.47438
[32m[0906 16-45-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18048, current rewards: 5.63422, mean: 0.09390
[32m[0906 16-46-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18085, current rewards: 12.11897, mean: 0.11017
[32m[0906 16-46-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18262, current rewards: 17.68440, mean: 0.11053
[32m[0906 16-46-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18336, current rewards: 23.95408, mean: 0.11407
[32m[0906 16-46-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18375, current rewards: 30.22162, mean: 0.11624
[32m[0906 16-46-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18389, current rewards: 36.48808, mean: 0.11770
[32m[0906 16-46-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18362, current rewards: 32.63194, mean: 0.09064
[32m[0906 16-46-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18320, current rewards: 39.02230, mean: 0.09518
[32m[0906 16-47-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18290, current rewards: 45.57353, mean: 0.09907
[32m[0906 16-47-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18240, current rewards: 52.12920, mean: 0.10221
[32m[0906 16-47-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18176, current rewards: 58.68769, mean: 0.10480
[32m[0906 16-47-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18118, current rewards: 65.23376, mean: 0.10694
[32m[0906 16-47-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18115, current rewards: 71.79198, mean: 0.10878
[32m[0906 16-47-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18097, current rewards: 78.34673, mean: 0.11035
[32m[0906 16-48-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18058, current rewards: 84.90057, mean: 0.11171
[32m[0906 16-48-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18057, current rewards: 91.44273, mean: 0.11289
[32m[0906 16-48-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18062, current rewards: 98.00472, mean: 0.11396
[32m[0906 16-48-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18059, current rewards: 104.54939, mean: 0.11489
[32m[0906 16-48-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18058, current rewards: 89.88486, mean: 0.09363
[32m[0906 16-48-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18076, current rewards: 95.84660, mean: 0.09490
[32m[0906 16-48-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18096, current rewards: 101.80030, mean: 0.09604
[32m[0906 16-49-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18112, current rewards: 107.75998, mean: 0.09708
[32m[0906 16-49-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18126, current rewards: 113.71679, mean: 0.09803
[32m[0906 16-49-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18150, current rewards: 119.67404, mean: 0.09890
[32m[0906 16-49-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18164, current rewards: 125.63506, mean: 0.09971
[32m[0906 16-49-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18177, current rewards: 131.59237, mean: 0.10045
[32m[0906 16-49-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18191, current rewards: 137.54608, mean: 0.10114
[32m[0906 16-50-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18201, current rewards: 143.50510, mean: 0.10178
[32m[0906 16-50-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18214, current rewards: 149.45996, mean: 0.10237
[32m[0906 16-50-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18227, current rewards: 145.16802, mean: 0.09614
[32m[0906 16-50-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18234, current rewards: 151.87016, mean: 0.09735
[32m[0906 16-50-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18242, current rewards: 158.53818, mean: 0.09847
[32m[0906 16-50-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18248, current rewards: 165.20910, mean: 0.09952
[32m[0906 16-50-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18254, current rewards: 171.86726, mean: 0.10051
[32m[0906 16-51-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18261, current rewards: 177.84563, mean: 0.10105
[32m[0906 16-51-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18267, current rewards: 184.53523, mean: 0.10195
[32m[0906 16-51-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18273, current rewards: 191.12137, mean: 0.10275
[32m[0906 16-51-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18280, current rewards: 197.71684, mean: 0.10352
[32m[0906 16-51-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18286, current rewards: 204.31062, mean: 0.10424
[32m[0906 16-51-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18292, current rewards: 189.31443, mean: 0.09419
[32m[0906 16-52-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18296, current rewards: 194.68248, mean: 0.09451
[32m[0906 16-52-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18300, current rewards: 200.33585, mean: 0.09495
[32m[0906 16-52-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18306, current rewards: 205.98877, mean: 0.09537
[32m[0906 16-52-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18311, current rewards: 211.64174, mean: 0.09577
[32m[0906 16-52-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18315, current rewards: 217.29010, mean: 0.09615
[32m[0906 16-52-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18319, current rewards: 222.94790, mean: 0.09651
[32m[0906 16-52-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18321, current rewards: 228.60081, mean: 0.09686
[32m[0906 16-53-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18323, current rewards: 234.25757, mean: 0.09720
[32m[0906 16-53-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18327, current rewards: 239.91052, mean: 0.09752
[32m[0906 16-53-22 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0906 16-53-22 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-53-22 @MBExp.py:227][0m Rewards obtained: [244.43785944386883], Lows: [20], Highs: [26], Total time: 11020.422072
[32m[0906 16-54-13 @MBExp.py:144][0m ####################################################################
[32m[0906 16-54-13 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 16-54-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17949, current rewards: -5.79398, mean: -0.57940
[32m[0906 16-54-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18062, current rewards: -0.90650, mean: -0.01511
[32m[0906 16-54-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18152, current rewards: 8.03151, mean: 0.07301
[32m[0906 16-54-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18267, current rewards: 14.70255, mean: 0.09189
[32m[0906 16-54-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18337, current rewards: 21.37166, mean: 0.10177
[32m[0906 16-55-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18357, current rewards: 28.04458, mean: 0.10786
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18396, current rewards: 34.71633, mean: 0.11199
[32m[0906 16-55-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18341, current rewards: 41.39107, mean: 0.11498
[32m[0906 16-55-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18307, current rewards: 48.06495, mean: 0.11723
[32m[0906 16-55-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18279, current rewards: 54.74313, mean: 0.11901
[32m[0906 16-55-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18219, current rewards: 61.41513, mean: 0.12042
[32m[0906 16-55-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18153, current rewards: 68.08949, mean: 0.12159
[32m[0906 16-56-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18103, current rewards: 74.76266, mean: 0.12256
[32m[0906 16-56-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18102, current rewards: 81.43157, mean: 0.12338
[32m[0906 16-56-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18079, current rewards: 81.30816, mean: 0.11452
[32m[0906 16-56-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18045, current rewards: 83.09379, mean: 0.10933
[32m[0906 16-56-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18046, current rewards: 90.45474, mean: 0.11167
[32m[0906 16-56-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18047, current rewards: 97.81716, mean: 0.11374
[32m[0906 16-56-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18053, current rewards: 105.26676, mean: 0.11568
[32m[0906 16-57-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18057, current rewards: 112.61752, mean: 0.11731
[32m[0906 16-57-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18076, current rewards: 119.98170, mean: 0.11879
[32m[0906 16-57-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18101, current rewards: 127.33229, mean: 0.12012
[32m[0906 16-57-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18116, current rewards: 134.69399, mean: 0.12135
[32m[0906 16-57-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18133, current rewards: 142.05186, mean: 0.12246
[32m[0906 16-57-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18145, current rewards: 149.42288, mean: 0.12349
[32m[0906 16-58-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18159, current rewards: 156.79102, mean: 0.12444
[32m[0906 16-58-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18173, current rewards: 167.18985, mean: 0.12763
[32m[0906 16-58-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18185, current rewards: 152.28514, mean: 0.11197
[32m[0906 16-58-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18195, current rewards: 158.35958, mean: 0.11231
[32m[0906 16-58-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18206, current rewards: 164.44238, mean: 0.11263
[32m[0906 16-58-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18215, current rewards: 170.51858, mean: 0.11293
[32m[0906 16-58-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18222, current rewards: 176.59482, mean: 0.11320
[32m[0906 16-59-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18229, current rewards: 182.67000, mean: 0.11346
[32m[0906 16-59-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18236, current rewards: 188.75202, mean: 0.11371
[32m[0906 16-59-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18245, current rewards: 194.40858, mean: 0.11369
[32m[0906 16-59-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18250, current rewards: 200.13877, mean: 0.11372
[32m[0906 16-59-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18257, current rewards: 205.70951, mean: 0.11365
[32m[0906 16-59-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18261, current rewards: 211.63345, mean: 0.11378
[32m[0906 17-00-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18267, current rewards: 217.51278, mean: 0.11388
[32m[0906 17-00-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18274, current rewards: 223.38947, mean: 0.11397
[32m[0906 17-00-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18281, current rewards: 229.26587, mean: 0.11406
[32m[0906 17-00-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18286, current rewards: 235.13785, mean: 0.11414
[32m[0906 17-00-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18291, current rewards: 241.01442, mean: 0.11422
[32m[0906 17-00-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18300, current rewards: 247.67839, mean: 0.11467
[32m[0906 17-00-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18305, current rewards: 253.52681, mean: 0.11472
[32m[0906 17-01-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18309, current rewards: 239.20508, mean: 0.10584
[32m[0906 17-01-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18313, current rewards: 246.01941, mean: 0.10650
[32m[0906 17-01-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18315, current rewards: 252.82250, mean: 0.10713
[32m[0906 17-01-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18318, current rewards: 259.63045, mean: 0.10773
[32m[0906 17-01-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18321, current rewards: 266.44244, mean: 0.10831
[32m[0906 17-01-52 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 17-01-52 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-01-52 @MBExp.py:227][0m Rewards obtained: [271.88158572016624], Lows: [20], Highs: [18], Total time: 11479.189021999999
[32m[0906 17-02-45 @MBExp.py:144][0m ####################################################################
[32m[0906 17-02-45 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 17-02-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17986, current rewards: 0.49339, mean: 0.04934
[32m[0906 17-02-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18091, current rewards: 4.73260, mean: 0.07888
[32m[0906 17-03-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18177, current rewards: 9.23944, mean: 0.08399
[32m[0906 17-03-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18285, current rewards: 13.74772, mean: 0.08592
[32m[0906 17-03-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18344, current rewards: 18.25822, mean: 0.08694
[32m[0906 17-03-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18376, current rewards: 22.76540, mean: 0.08756
[32m[0906 17-03-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18397, current rewards: 27.27318, mean: 0.08798
[32m[0906 17-03-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18357, current rewards: 31.78090, mean: 0.08828
[32m[0906 17-04-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18315, current rewards: 36.28860, mean: 0.08851
[32m[0906 17-04-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18287, current rewards: 40.47487, mean: 0.08799
[32m[0906 17-04-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18210, current rewards: 44.92959, mean: 0.08810
[32m[0906 17-04-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18147, current rewards: 49.38191, mean: 0.08818
[32m[0906 17-04-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18090, current rewards: 53.83296, mean: 0.08825
[32m[0906 17-04-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18082, current rewards: 58.28507, mean: 0.08831
[32m[0906 17-04-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18050, current rewards: 62.73955, mean: 0.08837
[32m[0906 17-05-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18018, current rewards: 67.19147, mean: 0.08841
[32m[0906 17-05-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18013, current rewards: 71.64378, mean: 0.08845
[32m[0906 17-05-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18017, current rewards: 69.08141, mean: 0.08033
[32m[0906 17-05-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18019, current rewards: 74.61806, mean: 0.08200
[32m[0906 17-05-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18023, current rewards: 80.18761, mean: 0.08353
[32m[0906 17-05-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18044, current rewards: 85.75738, mean: 0.08491
[32m[0906 17-05-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18069, current rewards: 91.32590, mean: 0.08616
[32m[0906 17-06-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18087, current rewards: 96.89919, mean: 0.08730
[32m[0906 17-06-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18107, current rewards: 102.46983, mean: 0.08834
[32m[0906 17-06-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18122, current rewards: 86.75412, mean: 0.07170
[32m[0906 17-06-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18140, current rewards: 93.17046, mean: 0.07394
[32m[0906 17-06-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18151, current rewards: 99.39269, mean: 0.07587
[32m[0906 17-06-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18164, current rewards: 104.91087, mean: 0.07714
[32m[0906 17-07-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18179, current rewards: 89.53992, mean: 0.06350
[32m[0906 17-07-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18192, current rewards: 95.38847, mean: 0.06533
[32m[0906 17-07-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18204, current rewards: 101.18739, mean: 0.06701
[32m[0906 17-07-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18213, current rewards: 106.98614, mean: 0.06858
[32m[0906 17-07-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18223, current rewards: 112.78505, mean: 0.07005
[32m[0906 17-07-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18231, current rewards: 113.00568, mean: 0.06808
[32m[0906 17-07-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18241, current rewards: 112.06672, mean: 0.06554
[32m[0906 17-08-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18252, current rewards: 117.15377, mean: 0.06656
[32m[0906 17-08-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18258, current rewards: 122.23882, mean: 0.06754
[32m[0906 17-08-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18264, current rewards: 127.32460, mean: 0.06845
[32m[0906 17-08-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18272, current rewards: 132.40841, mean: 0.06932
[32m[0906 17-08-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18278, current rewards: 137.49187, mean: 0.07015
[32m[0906 17-08-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18282, current rewards: 142.57129, mean: 0.07093
[32m[0906 17-09-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18288, current rewards: 147.65421, mean: 0.07168
[32m[0906 17-09-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18295, current rewards: 154.26732, mean: 0.07311
[32m[0906 17-09-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18300, current rewards: 159.39500, mean: 0.07379
[32m[0906 17-09-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18304, current rewards: 164.60723, mean: 0.07448
[32m[0906 17-09-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18311, current rewards: 169.81575, mean: 0.07514
[32m[0906 17-09-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18314, current rewards: 175.02746, mean: 0.07577
[32m[0906 17-09-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18317, current rewards: 180.24725, mean: 0.07638
[32m[0906 17-10-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18320, current rewards: 185.46181, mean: 0.07696
[32m[0906 17-10-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18322, current rewards: 190.67114, mean: 0.07751
[32m[0906 17-10-24 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 17-10-24 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-10-24 @MBExp.py:227][0m Rewards obtained: [194.84349666821643], Lows: [20], Highs: [20], Total time: 11937.967819999998
[32m[0906 17-11-19 @MBExp.py:144][0m ####################################################################
[32m[0906 17-11-19 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 17-11-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18010, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-11-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18003, current rewards: -3.47440, mean: -0.05791
[32m[0906 17-11-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18148, current rewards: 2.35173, mean: 0.02138
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18256, current rewards: 8.17531, mean: 0.05110
[32m[0906 17-11-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18324, current rewards: 13.99960, mean: 0.06666
[32m[0906 17-12-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18365, current rewards: 19.82130, mean: 0.07624
[32m[0906 17-12-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18362, current rewards: 25.64872, mean: 0.08274
[32m[0906 17-12-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18317, current rewards: 31.47255, mean: 0.08742
[32m[0906 17-12-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18279, current rewards: 37.29737, mean: 0.09097
[32m[0906 17-12-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18255, current rewards: 42.66905, mean: 0.09276
[32m[0906 17-12-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18184, current rewards: 37.95002, mean: 0.07441
[32m[0906 17-13-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18122, current rewards: 43.38792, mean: 0.07748
[32m[0906 17-13-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18066, current rewards: 48.56078, mean: 0.07961
[32m[0906 17-13-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18058, current rewards: 53.73079, mean: 0.08141
[32m[0906 17-13-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18020, current rewards: 58.90797, mean: 0.08297
[32m[0906 17-13-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17984, current rewards: 64.07639, mean: 0.08431
[32m[0906 17-13-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17975, current rewards: 46.16321, mean: 0.05699
[32m[0906 17-13-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17980, current rewards: 53.23092, mean: 0.06190
[32m[0906 17-14-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17987, current rewards: 60.27806, mean: 0.06624
[32m[0906 17-14-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17989, current rewards: 67.32404, mean: 0.07013
[32m[0906 17-14-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18015, current rewards: 74.37203, mean: 0.07364
[32m[0906 17-14-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18042, current rewards: 81.41976, mean: 0.07681
[32m[0906 17-14-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18060, current rewards: 88.46664, mean: 0.07970
[32m[0906 17-14-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18084, current rewards: 95.51117, mean: 0.08234
[32m[0906 17-14-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18102, current rewards: 102.56112, mean: 0.08476
[32m[0906 17-15-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18118, current rewards: 110.03645, mean: 0.08733
[32m[0906 17-15-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18130, current rewards: 117.06165, mean: 0.08936
[32m[0906 17-15-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18150, current rewards: 124.04801, mean: 0.09121
[32m[0906 17-15-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18163, current rewards: 131.03713, mean: 0.09293
[32m[0906 17-15-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18172, current rewards: 125.36890, mean: 0.08587
[32m[0906 17-15-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18183, current rewards: 130.35980, mean: 0.08633
[32m[0906 17-16-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18191, current rewards: 135.35193, mean: 0.08676
[32m[0906 17-16-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18200, current rewards: 140.34060, mean: 0.08717
[32m[0906 17-16-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18207, current rewards: 146.37773, mean: 0.08818
[32m[0906 17-16-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18214, current rewards: 151.52466, mean: 0.08861
[32m[0906 17-16-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18220, current rewards: 156.31543, mean: 0.08882
[32m[0906 17-16-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18230, current rewards: 161.10549, mean: 0.08901
[32m[0906 17-16-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18236, current rewards: 165.89273, mean: 0.08919
[32m[0906 17-17-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18243, current rewards: 170.68158, mean: 0.08936
[32m[0906 17-17-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18249, current rewards: 165.02142, mean: 0.08419
[32m[0906 17-17-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18256, current rewards: 170.08136, mean: 0.08462
[32m[0906 17-17-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18264, current rewards: 175.13743, mean: 0.08502
[32m[0906 17-17-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18270, current rewards: 159.29296, mean: 0.07549
[32m[0906 17-17-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18277, current rewards: 164.81865, mean: 0.07630
[32m[0906 17-18-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18280, current rewards: 170.34033, mean: 0.07708
[32m[0906 17-18-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18286, current rewards: 175.86404, mean: 0.07782
[32m[0906 17-18-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18290, current rewards: 181.38599, mean: 0.07852
[32m[0906 17-18-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18294, current rewards: 186.90993, mean: 0.07920
[32m[0906 17-18-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18297, current rewards: 192.43532, mean: 0.07985
[32m[0906 17-18-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18302, current rewards: 197.95918, mean: 0.08047
[32m[0906 17-18-58 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 17-18-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-18-58 @MBExp.py:227][0m Rewards obtained: [202.27111289724232], Lows: [21], Highs: [41], Total time: 12396.219897999998
[32m[0906 17-19-55 @MBExp.py:144][0m ####################################################################
[32m[0906 17-19-55 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 17-19-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17932, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-20-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18053, current rewards: -5.79018, mean: -0.09650
[32m[0906 17-20-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18241, current rewards: -0.15177, mean: -0.00138
[32m[0906 17-20-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18314, current rewards: 5.48272, mean: 0.03427
[32m[0906 17-20-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18362, current rewards: 11.11953, mean: 0.05295
[32m[0906 17-20-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18392, current rewards: -4.09829, mean: -0.01576
[32m[0906 17-20-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18381, current rewards: 1.42846, mean: 0.00461
[32m[0906 17-21-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18328, current rewards: 6.95945, mean: 0.01933
[32m[0906 17-21-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18302, current rewards: 12.48787, mean: 0.03046
[32m[0906 17-21-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18269, current rewards: 18.01389, mean: 0.03916
[32m[0906 17-21-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18192, current rewards: 23.53864, mean: 0.04615
[32m[0906 17-21-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18127, current rewards: 29.06542, mean: 0.05190
[32m[0906 17-21-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18082, current rewards: 34.59047, mean: 0.05671
[32m[0906 17-21-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18059, current rewards: 34.56078, mean: 0.05236
[32m[0906 17-22-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18021, current rewards: 33.15230, mean: 0.04669
[32m[0906 17-22-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17986, current rewards: 38.89184, mean: 0.05117
[32m[0906 17-22-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17978, current rewards: 45.69630, mean: 0.05642
[32m[0906 17-22-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17985, current rewards: 51.28508, mean: 0.05963
[32m[0906 17-22-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17991, current rewards: 56.89005, mean: 0.06252
[32m[0906 17-22-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17997, current rewards: 62.48871, mean: 0.06509
[32m[0906 17-22-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18022, current rewards: 68.08789, mean: 0.06741
[32m[0906 17-23-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18049, current rewards: 73.68694, mean: 0.06952
[32m[0906 17-23-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18070, current rewards: 36.31900, mean: 0.03272
[32m[0906 17-23-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18089, current rewards: 44.85692, mean: 0.03867
[32m[0906 17-23-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18108, current rewards: 52.59881, mean: 0.04347
[32m[0906 17-23-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18125, current rewards: 57.53384, mean: 0.04566
[32m[0906 17-23-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18145, current rewards: 63.88640, mean: 0.04877
[32m[0906 17-24-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18157, current rewards: 57.80595, mean: 0.04250
[32m[0906 17-24-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18172, current rewards: 62.97517, mean: 0.04466
[32m[0906 17-24-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18182, current rewards: 68.18083, mean: 0.04670
[32m[0906 17-24-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18193, current rewards: 73.38707, mean: 0.04860
[32m[0906 17-24-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18205, current rewards: 78.59706, mean: 0.05038
[32m[0906 17-24-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18214, current rewards: 83.80614, mean: 0.05205
[32m[0906 17-24-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18224, current rewards: 89.00609, mean: 0.05362
[32m[0906 17-25-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18232, current rewards: 73.56726, mean: 0.04302
[32m[0906 17-25-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18239, current rewards: 79.54273, mean: 0.04519
[32m[0906 17-25-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18247, current rewards: 85.38585, mean: 0.04717
[32m[0906 17-25-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18255, current rewards: 91.22655, mean: 0.04905
[32m[0906 17-25-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18260, current rewards: 97.07547, mean: 0.05082
[32m[0906 17-25-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18269, current rewards: 102.91406, mean: 0.05251
[32m[0906 17-26-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18277, current rewards: 108.75912, mean: 0.05411
[32m[0906 17-26-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18282, current rewards: 114.22360, mean: 0.05545
[32m[0906 17-26-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18288, current rewards: 120.14599, mean: 0.05694
[32m[0906 17-26-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18293, current rewards: 107.00197, mean: 0.04954
[32m[0906 17-26-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18298, current rewards: 111.88063, mean: 0.05062
[32m[0906 17-26-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18304, current rewards: 118.30400, mean: 0.05235
[32m[0906 17-26-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18307, current rewards: 124.73242, mean: 0.05400
[32m[0906 17-27-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18311, current rewards: 131.15566, mean: 0.05557
[32m[0906 17-27-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18316, current rewards: 137.58151, mean: 0.05709
[32m[0906 17-27-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18318, current rewards: 147.77620, mean: 0.06007
[32m[0906 17-27-34 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 17-27-34 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-27-34 @MBExp.py:227][0m Rewards obtained: [152.89868379396606], Lows: [52], Highs: [32], Total time: 12854.968726999998
[32m[0906 17-28-33 @MBExp.py:144][0m ####################################################################
[32m[0906 17-28-33 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 17-28-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17990, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-28-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18073, current rewards: -52.16235, mean: -0.86937
[32m[0906 17-28-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18301, current rewards: -106.25623, mean: -0.96597
[32m[0906 17-29-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18348, current rewards: -148.81514, mean: -0.93009
[32m[0906 17-29-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18382, current rewards: -200.51835, mean: -0.95485
[32m[0906 17-29-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18405, current rewards: -245.43255, mean: -0.94397
[32m[0906 17-29-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18372, current rewards: -294.88218, mean: -0.95123
[32m[0906 17-29-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18332, current rewards: -342.40077, mean: -0.95111
[32m[0906 17-29-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18295, current rewards: -389.73651, mean: -0.95058
[32m[0906 17-29-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18242, current rewards: -439.36339, mean: -0.95514
[32m[0906 17-30-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18175, current rewards: -484.40499, mean: -0.94981
[32m[0906 17-30-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18112, current rewards: -536.30266, mean: -0.95768
[32m[0906 17-30-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18060, current rewards: -567.57293, mean: -0.93045
[32m[0906 17-30-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18020, current rewards: -563.88570, mean: -0.85437
[32m[0906 17-30-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17983, current rewards: -560.19786, mean: -0.78901
[32m[0906 17-30-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17951, current rewards: -555.87815, mean: -0.73142
[32m[0906 17-30-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17942, current rewards: -550.50775, mean: -0.67964
[32m[0906 17-31-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17950, current rewards: -545.26306, mean: -0.63403
[32m[0906 17-31-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17956, current rewards: -540.01837, mean: -0.59343
[32m[0906 17-31-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17960, current rewards: -534.77368, mean: -0.55706
[32m[0906 17-31-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17987, current rewards: -529.52900, mean: -0.52429
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18015, current rewards: -558.53602, mean: -0.52692
[32m[0906 17-31-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18037, current rewards: -608.53602, mean: -0.54823
[32m[0906 17-32-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18061, current rewards: -658.53602, mean: -0.56770
[32m[0906 17-32-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18088, current rewards: -708.53602, mean: -0.58557
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18107, current rewards: -758.53602, mean: -0.60201
[32m[0906 17-32-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18124, current rewards: -808.53602, mean: -0.61720
[32m[0906 17-32-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18140, current rewards: -858.53602, mean: -0.63128
[32m[0906 17-32-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18152, current rewards: -908.53602, mean: -0.64435
[32m[0906 17-32-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18166, current rewards: -958.53602, mean: -0.65653
[32m[0906 17-33-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18176, current rewards: -1008.53602, mean: -0.66790
[32m[0906 17-33-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18186, current rewards: -1058.53602, mean: -0.67855
[32m[0906 17-33-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18197, current rewards: -1108.53602, mean: -0.68853
[32m[0906 17-33-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18206, current rewards: -1158.53602, mean: -0.69791
[32m[0906 17-33-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18213, current rewards: -1208.53602, mean: -0.70675
[32m[0906 17-33-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18222, current rewards: -1258.53602, mean: -0.71508
[32m[0906 17-34-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18229, current rewards: -1308.53602, mean: -0.72295
[32m[0906 17-34-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18239, current rewards: -1358.53602, mean: -0.73040
[32m[0906 17-34-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18248, current rewards: -1408.53602, mean: -0.73745
[32m[0906 17-34-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18255, current rewards: -1458.53602, mean: -0.74415
[32m[0906 17-34-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18257, current rewards: -1508.53602, mean: -0.75052
[32m[0906 17-34-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18264, current rewards: -1558.53602, mean: -0.75657
[32m[0906 17-34-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18270, current rewards: -1608.53602, mean: -0.76234
[32m[0906 17-35-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18278, current rewards: -1658.53602, mean: -0.76784
[32m[0906 17-35-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18282, current rewards: -1708.53602, mean: -0.77309
[32m[0906 17-35-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18286, current rewards: -1758.53602, mean: -0.77811
[32m[0906 17-35-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18291, current rewards: -1808.53602, mean: -0.78292
[32m[0906 17-35-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18293, current rewards: -1858.53602, mean: -0.78752
[32m[0906 17-35-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18298, current rewards: -1908.53602, mean: -0.79192
[32m[0906 17-36-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18302, current rewards: -1958.53602, mean: -0.79615
[32m[0906 17-36-12 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 17-36-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-36-12 @MBExp.py:227][0m Rewards obtained: [-1998.536015701623], Lows: [317], Highs: [1482], Total time: 13313.248753999998
[32m[0906 17-37-13 @MBExp.py:144][0m ####################################################################
[32m[0906 17-37-13 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 17-37-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17987, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-37-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18171, current rewards: -5.17102, mean: -0.08618
[32m[0906 17-37-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18350, current rewards: 0.67883, mean: 0.00617
[32m[0906 17-37-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18390, current rewards: 6.53216, mean: 0.04083
[32m[0906 17-37-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18417, current rewards: 12.38205, mean: 0.05896
[32m[0906 17-38-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18442, current rewards: 18.23638, mean: 0.07014
[32m[0906 17-38-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18394, current rewards: 24.08901, mean: 0.07771
[32m[0906 17-38-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18342, current rewards: 28.43370, mean: 0.07898
[32m[0906 17-38-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18313, current rewards: 34.23977, mean: 0.08351
[32m[0906 17-38-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18254, current rewards: 40.03071, mean: 0.08702
[32m[0906 17-38-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18176, current rewards: 45.81246, mean: 0.08983
[32m[0906 17-38-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18116, current rewards: 51.60201, mean: 0.09215
[32m[0906 17-39-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18068, current rewards: 57.39183, mean: 0.09408
[32m[0906 17-39-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18018, current rewards: 63.18076, mean: 0.09573
[32m[0906 17-39-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17981, current rewards: 47.40888, mean: 0.06677
[32m[0906 17-39-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17950, current rewards: 55.05315, mean: 0.07244
[32m[0906 17-39-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17939, current rewards: 65.37524, mean: 0.08071
[32m[0906 17-39-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17943, current rewards: 71.83407, mean: 0.08353
[32m[0906 17-39-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17949, current rewards: 78.29289, mean: 0.08604
[32m[0906 17-40-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17954, current rewards: 84.75171, mean: 0.08828
[32m[0906 17-40-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17985, current rewards: 79.91877, mean: 0.07913
[32m[0906 17-40-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18011, current rewards: 29.91877, mean: 0.02823
[32m[0906 17-40-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18035, current rewards: -20.08123, mean: -0.01809
[32m[0906 17-40-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18054, current rewards: -70.08123, mean: -0.06041
[32m[0906 17-40-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18076, current rewards: -120.08123, mean: -0.09924
[32m[0906 17-41-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18092, current rewards: -170.08123, mean: -0.13499
[32m[0906 17-41-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18108, current rewards: -220.08123, mean: -0.16800
[32m[0906 17-41-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18123, current rewards: -270.08123, mean: -0.19859
[32m[0906 17-41-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18133, current rewards: -320.08123, mean: -0.22701
[32m[0906 17-41-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18146, current rewards: -370.08123, mean: -0.25348
[32m[0906 17-41-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18153, current rewards: -420.08123, mean: -0.27820
[32m[0906 17-41-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18164, current rewards: -470.08123, mean: -0.30133
[32m[0906 17-42-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18172, current rewards: -520.08123, mean: -0.32303
[32m[0906 17-42-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18180, current rewards: -570.08123, mean: -0.34342
[32m[0906 17-42-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18189, current rewards: -620.08123, mean: -0.36262
[32m[0906 17-42-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18198, current rewards: -670.08123, mean: -0.38073
[32m[0906 17-42-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18206, current rewards: -720.08123, mean: -0.39783
[32m[0906 17-42-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18213, current rewards: -770.08123, mean: -0.41402
[32m[0906 17-43-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18220, current rewards: -820.08123, mean: -0.42936
[32m[0906 17-43-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18225, current rewards: -870.08123, mean: -0.44392
[32m[0906 17-43-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18229, current rewards: -920.08123, mean: -0.45775
[32m[0906 17-43-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18234, current rewards: -970.08123, mean: -0.47091
[32m[0906 17-43-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18238, current rewards: -1020.08123, mean: -0.48345
[32m[0906 17-43-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18242, current rewards: -1070.08123, mean: -0.49541
[32m[0906 17-43-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18248, current rewards: -1120.08123, mean: -0.50682
[32m[0906 17-44-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18253, current rewards: -1170.08123, mean: -0.51774
[32m[0906 17-44-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18258, current rewards: -1220.08123, mean: -0.52817
[32m[0906 17-44-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18261, current rewards: -1270.08123, mean: -0.53817
[32m[0906 17-44-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18265, current rewards: -1320.08123, mean: -0.54775
[32m[0906 17-44-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18269, current rewards: -1370.08123, mean: -0.55694
[32m[0906 17-44-50 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 17-44-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-44-50 @MBExp.py:227][0m Rewards obtained: [-1410.0812276876163], Lows: [11], Highs: [1510], Total time: 13770.750356999999
[32m[0906 17-45-54 @MBExp.py:144][0m ####################################################################
[32m[0906 17-45-54 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 17-45-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18115, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-46-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18291, current rewards: -4.74298, mean: -0.07905
[32m[0906 17-46-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18414, current rewards: 0.79916, mean: 0.00727
[32m[0906 17-46-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18423, current rewards: 6.34508, mean: 0.03966
[32m[0906 17-46-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18442, current rewards: 11.89390, mean: 0.05664
[32m[0906 17-46-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18456, current rewards: 17.43359, mean: 0.06705
[32m[0906 17-46-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18396, current rewards: 22.97992, mean: 0.07413
[32m[0906 17-47-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18349, current rewards: 31.92734, mean: 0.08869
[32m[0906 17-47-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18305, current rewards: 37.66770, mean: 0.09187
[32m[0906 17-47-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18227, current rewards: 32.83625, mean: 0.07138
[32m[0906 17-47-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18156, current rewards: 29.53021, mean: 0.05790
[32m[0906 17-47-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18094, current rewards: 36.80442, mean: 0.06572
[32m[0906 17-47-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18039, current rewards: 44.07863, mean: 0.07226
[32m[0906 17-47-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17984, current rewards: 34.17058, mean: 0.05177
[32m[0906 17-48-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17947, current rewards: -15.82942, mean: -0.02229
[32m[0906 17-48-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17913, current rewards: -65.82942, mean: -0.08662
[32m[0906 17-48-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17903, current rewards: -115.82942, mean: -0.14300
[32m[0906 17-48-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17912, current rewards: -165.82942, mean: -0.19282
[32m[0906 17-48-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17921, current rewards: -215.82942, mean: -0.23718
[32m[0906 17-48-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17926, current rewards: -265.82942, mean: -0.27691
[32m[0906 17-48-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17960, current rewards: -315.82942, mean: -0.31270
[32m[0906 17-49-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17988, current rewards: -365.82942, mean: -0.34512
[32m[0906 17-49-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18010, current rewards: -415.82942, mean: -0.37462
[32m[0906 17-49-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18028, current rewards: -465.82942, mean: -0.40158
[32m[0906 17-49-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18044, current rewards: -515.82942, mean: -0.42631
[32m[0906 17-49-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18058, current rewards: -565.82942, mean: -0.44907
[32m[0906 17-49-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18076, current rewards: -615.82942, mean: -0.47010
[32m[0906 17-50-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18090, current rewards: -665.82942, mean: -0.48958
[32m[0906 17-50-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18105, current rewards: -715.82942, mean: -0.50768
[32m[0906 17-50-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18116, current rewards: -765.82942, mean: -0.52454
[32m[0906 17-50-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18128, current rewards: -815.82942, mean: -0.54028
[32m[0906 17-50-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18141, current rewards: -865.82942, mean: -0.55502
[32m[0906 17-50-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18150, current rewards: -915.82942, mean: -0.56884
[32m[0906 17-50-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18159, current rewards: -965.82942, mean: -0.58182
[32m[0906 17-51-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18173, current rewards: -1015.82942, mean: -0.59405
[32m[0906 17-51-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18184, current rewards: -1065.82942, mean: -0.60558
[32m[0906 17-51-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18194, current rewards: -1115.82942, mean: -0.61648
[32m[0906 17-51-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18201, current rewards: -1165.82942, mean: -0.62679
[32m[0906 17-51-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18206, current rewards: -1215.82942, mean: -0.63656
[32m[0906 17-51-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18214, current rewards: -1265.82942, mean: -0.64583
[32m[0906 17-52-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18220, current rewards: -1315.82942, mean: -0.65464
[32m[0906 17-52-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18228, current rewards: -1365.82942, mean: -0.66302
[32m[0906 17-52-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18236, current rewards: -1415.82942, mean: -0.67101
[32m[0906 17-52-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18240, current rewards: -1465.82942, mean: -0.67862
[32m[0906 17-52-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18243, current rewards: -1515.82942, mean: -0.68590
[32m[0906 17-52-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18249, current rewards: -1565.82942, mean: -0.69284
[32m[0906 17-52-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18251, current rewards: -1615.82942, mean: -0.69949
[32m[0906 17-53-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18256, current rewards: -1665.82942, mean: -0.70586
[32m[0906 17-53-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18264, current rewards: -1715.82942, mean: -0.71196
[32m[0906 17-53-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18268, current rewards: -1765.82942, mean: -0.71782
[32m[0906 17-53-31 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 17-53-31 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-53-31 @MBExp.py:227][0m Rewards obtained: [-1805.8294161017657], Lows: [10], Highs: [1865], Total time: 14228.230119
[32m[0906 17-54-36 @MBExp.py:144][0m ####################################################################
[32m[0906 17-54-36 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 17-54-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18033, current rewards: 0.90712, mean: 0.09071
[32m[0906 17-54-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18392, current rewards: 5.79739, mean: 0.09662
[32m[0906 17-54-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18461, current rewards: 10.68194, mean: 0.09711
[32m[0906 17-55-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18479, current rewards: 15.56632, mean: 0.09729
[32m[0906 17-55-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18487, current rewards: 20.45087, mean: 0.09739
[32m[0906 17-55-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18482, current rewards: 25.33514, mean: 0.09744
[32m[0906 17-55-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18407, current rewards: 29.91145, mean: 0.09649
[32m[0906 17-55-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18359, current rewards: 34.75539, mean: 0.09654
[32m[0906 17-55-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18316, current rewards: 27.40053, mean: 0.06683
[32m[0906 17-56-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18236, current rewards: 32.18861, mean: 0.06998
[32m[0906 17-56-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18164, current rewards: 36.97639, mean: 0.07250
[32m[0906 17-56-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18100, current rewards: 41.76726, mean: 0.07458
[32m[0906 17-56-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18037, current rewards: 46.55548, mean: 0.07632
[32m[0906 17-56-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17979, current rewards: 51.34491, mean: 0.07780
[32m[0906 17-56-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17943, current rewards: 56.37286, mean: 0.07940
[32m[0906 17-56-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17911, current rewards: 61.23634, mean: 0.08057
[32m[0906 17-57-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17896, current rewards: 66.09393, mean: 0.08160
[32m[0906 17-57-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17906, current rewards: 50.19096, mean: 0.05836
[32m[0906 17-57-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17918, current rewards: 55.22598, mean: 0.06069
[32m[0906 17-57-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17928, current rewards: 60.13786, mean: 0.06264
[32m[0906 17-57-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17960, current rewards: 65.04375, mean: 0.06440
[32m[0906 17-57-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17989, current rewards: 69.95064, mean: 0.06599
[32m[0906 17-57-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18014, current rewards: 74.85780, mean: 0.06744
[32m[0906 17-58-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18038, current rewards: 79.76593, mean: 0.06876
[32m[0906 17-58-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18061, current rewards: 84.67061, mean: 0.06998
[32m[0906 17-58-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18083, current rewards: 89.58015, mean: 0.07110
[32m[0906 17-58-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18100, current rewards: 94.48884, mean: 0.07213
[32m[0906 17-58-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18118, current rewards: 78.41605, mean: 0.05766
[32m[0906 17-58-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18134, current rewards: 84.30617, mean: 0.05979
[32m[0906 17-59-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18151, current rewards: 89.47099, mean: 0.06128
[32m[0906 17-59-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18164, current rewards: 94.53663, mean: 0.06261
[32m[0906 17-59-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18178, current rewards: 99.47517, mean: 0.06377
[32m[0906 17-59-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18194, current rewards: 104.60862, mean: 0.06497
[32m[0906 17-59-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18206, current rewards: 109.74363, mean: 0.06611
[32m[0906 17-59-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18219, current rewards: 114.87955, mean: 0.06718
[32m[0906 17-59-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18230, current rewards: 109.29702, mean: 0.06210
[32m[0906 18-00-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18238, current rewards: 113.65146, mean: 0.06279
[32m[0906 18-00-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18246, current rewards: 117.90306, mean: 0.06339
[32m[0906 18-00-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18250, current rewards: 122.15580, mean: 0.06396
[32m[0906 18-00-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18257, current rewards: 126.30067, mean: 0.06444
[32m[0906 18-00-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18263, current rewards: 130.54712, mean: 0.06495
[32m[0906 18-00-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18267, current rewards: 134.79324, mean: 0.06543
[32m[0906 18-01-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18275, current rewards: 119.13272, mean: 0.05646
[32m[0906 18-01-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18280, current rewards: 124.27161, mean: 0.05753
[32m[0906 18-01-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18285, current rewards: 129.45890, mean: 0.05858
[32m[0906 18-01-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18293, current rewards: 134.64053, mean: 0.05958
[32m[0906 18-01-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18301, current rewards: 139.82980, mean: 0.06053
[32m[0906 18-01-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18305, current rewards: 144.61562, mean: 0.06128
[32m[0906 18-01-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18309, current rewards: 149.73440, mean: 0.06213
[32m[0906 18-02-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18312, current rewards: 154.85405, mean: 0.06295
[32m[0906 18-02-15 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 18-02-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-02-15 @MBExp.py:227][0m Rewards obtained: [158.94879332274013], Lows: [30], Highs: [21], Total time: 14686.7992
[32m[0906 18-03-22 @MBExp.py:144][0m ####################################################################
[32m[0906 18-03-22 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 18-03-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17931, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-03-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18467, current rewards: -5.88256, mean: -0.09804
[32m[0906 18-03-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18508, current rewards: -0.39533, mean: -0.00359
[32m[0906 18-03-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18509, current rewards: 5.09871, mean: 0.03187
[32m[0906 18-04-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18496, current rewards: 10.59481, mean: 0.05045
[32m[0906 18-04-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18449, current rewards: 16.23364, mean: 0.06244
[32m[0906 18-04-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18385, current rewards: 21.74466, mean: 0.07014
[32m[0906 18-04-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18336, current rewards: 27.26481, mean: 0.07574
[32m[0906 18-04-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18295, current rewards: 32.78932, mean: 0.07997
[32m[0906 18-04-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18207, current rewards: 38.31126, mean: 0.08329
[32m[0906 18-04-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18136, current rewards: 43.83402, mean: 0.08595
[32m[0906 18-05-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18077, current rewards: 49.34851, mean: 0.08812
[32m[0906 18-05-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18005, current rewards: 54.86259, mean: 0.08994
[32m[0906 18-05-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17946, current rewards: 62.89511, mean: 0.09530
[32m[0906 18-05-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17911, current rewards: 69.63595, mean: 0.09808
[32m[0906 18-05-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17885, current rewards: 62.09350, mean: 0.08170
[32m[0906 18-05-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17874, current rewards: 60.39336, mean: 0.07456
[32m[0906 18-05-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17884, current rewards: 69.44679, mean: 0.08075
[32m[0906 18-06-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17893, current rewards: 78.50022, mean: 0.08626
[32m[0906 18-06-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17900, current rewards: 87.55365, mean: 0.09120
[32m[0906 18-06-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17930, current rewards: 96.60709, mean: 0.09565
[32m[0906 18-06-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17961, current rewards: 74.95273, mean: 0.07071
[32m[0906 18-06-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17985, current rewards: 24.95273, mean: 0.02248
[32m[0906 18-06-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18006, current rewards: -25.04727, mean: -0.02159
[32m[0906 18-07-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18029, current rewards: -75.04727, mean: -0.06202
[32m[0906 18-07-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18051, current rewards: -125.04727, mean: -0.09924
[32m[0906 18-07-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18069, current rewards: -175.04727, mean: -0.13362
[32m[0906 18-07-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18085, current rewards: -225.04727, mean: -0.16548
[32m[0906 18-07-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18100, current rewards: -275.04727, mean: -0.19507
[32m[0906 18-07-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18113, current rewards: -325.04727, mean: -0.22264
[32m[0906 18-07-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18128, current rewards: -375.04727, mean: -0.24838
[32m[0906 18-08-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18143, current rewards: -425.04727, mean: -0.27247
[32m[0906 18-08-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18152, current rewards: -475.04727, mean: -0.29506
[32m[0906 18-08-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18159, current rewards: -525.04727, mean: -0.31629
[32m[0906 18-08-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18170, current rewards: -575.04727, mean: -0.33628
[32m[0906 18-08-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18178, current rewards: -625.04727, mean: -0.35514
[32m[0906 18-08-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18186, current rewards: -675.04727, mean: -0.37295
[32m[0906 18-09-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18197, current rewards: -725.04727, mean: -0.38981
[32m[0906 18-09-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18204, current rewards: -775.04727, mean: -0.40578
[32m[0906 18-09-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18209, current rewards: -825.04727, mean: -0.42094
[32m[0906 18-09-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18217, current rewards: -875.04727, mean: -0.43535
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18222, current rewards: -925.04727, mean: -0.44905
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18230, current rewards: -975.04727, mean: -0.46211
[32m[0906 18-09-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18239, current rewards: -1025.04727, mean: -0.47456
[32m[0906 18-10-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18246, current rewards: -1075.04727, mean: -0.48645
[32m[0906 18-10-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18252, current rewards: -1125.04727, mean: -0.49781
[32m[0906 18-10-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18256, current rewards: -1175.04727, mean: -0.50868
[32m[0906 18-10-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18262, current rewards: -1225.04727, mean: -0.51909
[32m[0906 18-10-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18266, current rewards: -1275.04727, mean: -0.52907
[32m[0906 18-10-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18271, current rewards: -1325.04727, mean: -0.53864
[32m[0906 18-10-59 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 18-10-59 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-11-00 @MBExp.py:227][0m Rewards obtained: [-1365.04726620924], Lows: [11], Highs: [1477], Total time: 15144.279718
[32m[0906 18-12-09 @MBExp.py:144][0m ####################################################################
[32m[0906 18-12-09 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 18-12-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18450, current rewards: -1.55528, mean: -0.15553
[32m[0906 18-12-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18554, current rewards: 2.11918, mean: 0.03532
[32m[0906 18-12-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18548, current rewards: 8.08330, mean: 0.07348
[32m[0906 18-12-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18555, current rewards: 14.04758, mean: 0.08780
[32m[0906 18-12-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18532, current rewards: 20.01298, mean: 0.09530
[32m[0906 18-12-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18479, current rewards: 25.97357, mean: 0.09990
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18408, current rewards: 31.93785, mean: 0.10303
[32m[0906 18-13-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18357, current rewards: 37.89803, mean: 0.10527
[32m[0906 18-13-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18302, current rewards: 32.85452, mean: 0.08013
[32m[0906 18-13-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18212, current rewards: 39.71779, mean: 0.08634
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18146, current rewards: 46.57984, mean: 0.09133
[32m[0906 18-13-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18091, current rewards: 53.42693, mean: 0.09541
[32m[0906 18-13-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18008, current rewards: 60.27950, mean: 0.09882
[32m[0906 18-14-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17951, current rewards: 72.14993, mean: 0.10932
[32m[0906 18-14-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17919, current rewards: 78.16694, mean: 0.11009
[32m[0906 18-14-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17893, current rewards: 84.15010, mean: 0.11072
[32m[0906 18-14-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17875, current rewards: 69.20067, mean: 0.08543
[32m[0906 18-14-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17887, current rewards: 75.71869, mean: 0.08804
[32m[0906 18-14-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17896, current rewards: 82.15664, mean: 0.09028
[32m[0906 18-15-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17904, current rewards: 88.59987, mean: 0.09229
[32m[0906 18-15-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17936, current rewards: 95.04261, mean: 0.09410
[32m[0906 18-15-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17965, current rewards: 100.49043, mean: 0.09480
[32m[0906 18-15-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17996, current rewards: 106.44535, mean: 0.09590
[32m[0906 18-15-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18022, current rewards: 112.81961, mean: 0.09726
[32m[0906 18-15-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18044, current rewards: 119.18094, mean: 0.09850
[32m[0906 18-15-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18062, current rewards: 115.40611, mean: 0.09159
[32m[0906 18-16-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18081, current rewards: 122.77285, mean: 0.09372
[32m[0906 18-16-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18099, current rewards: 129.58837, mean: 0.09529
[32m[0906 18-16-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18116, current rewards: 136.41444, mean: 0.09675
[32m[0906 18-16-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18128, current rewards: 143.22759, mean: 0.09810
[32m[0906 18-16-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18140, current rewards: 152.88363, mean: 0.10125
[32m[0906 18-16-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18152, current rewards: 159.94200, mean: 0.10253
[32m[0906 18-17-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18161, current rewards: 166.99664, mean: 0.10372
[32m[0906 18-17-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18171, current rewards: 174.04625, mean: 0.10485
[32m[0906 18-17-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18181, current rewards: 181.09657, mean: 0.10590
[32m[0906 18-17-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18190, current rewards: 188.15014, mean: 0.10690
[32m[0906 18-17-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18198, current rewards: 173.12494, mean: 0.09565
[32m[0906 18-17-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18204, current rewards: 179.29540, mean: 0.09640
[32m[0906 18-17-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18210, current rewards: 184.38645, mean: 0.09654
[32m[0906 18-18-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18219, current rewards: 190.56513, mean: 0.09723
[32m[0906 18-18-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18226, current rewards: 196.77370, mean: 0.09790
[32m[0906 18-18-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18236, current rewards: 202.98128, mean: 0.09853
[32m[0906 18-18-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18242, current rewards: 209.18561, mean: 0.09914
[32m[0906 18-18-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18247, current rewards: 215.39223, mean: 0.09972
[32m[0906 18-18-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18254, current rewards: 221.59381, mean: 0.10027
[32m[0906 18-19-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18259, current rewards: 227.79883, mean: 0.10080
[32m[0906 18-19-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18264, current rewards: 222.57825, mean: 0.09635
[32m[0906 18-19-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18269, current rewards: 229.20902, mean: 0.09712
[32m[0906 18-19-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18272, current rewards: 235.81462, mean: 0.09785
[32m[0906 18-19-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18277, current rewards: 242.40885, mean: 0.09854
[32m[0906 18-19-46 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 18-19-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-19-46 @MBExp.py:227][0m Rewards obtained: [247.68783436053334], Lows: [22], Highs: [32], Total time: 15601.926026
[32m[0906 18-20-58 @MBExp.py:144][0m ####################################################################
[32m[0906 18-20-58 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 18-21-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18616, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-21-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18613, current rewards: -5.91183, mean: -0.09853
[32m[0906 18-21-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18574, current rewards: -0.58711, mean: -0.00534
[32m[0906 18-21-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18560, current rewards: 4.72852, mean: 0.02955
[32m[0906 18-21-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18559, current rewards: 10.04740, mean: 0.04784
[32m[0906 18-21-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18493, current rewards: 16.74792, mean: 0.06442
[32m[0906 18-21-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18420, current rewards: 21.92633, mean: 0.07073
[32m[0906 18-22-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18373, current rewards: 27.10813, mean: 0.07530
[32m[0906 18-22-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18310, current rewards: 32.29424, mean: 0.07877
[32m[0906 18-22-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18223, current rewards: 37.47221, mean: 0.08146
[32m[0906 18-22-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18154, current rewards: 42.60335, mean: 0.08354
[32m[0906 18-22-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18094, current rewards: 46.91029, mean: 0.08377
[32m[0906 18-22-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17996, current rewards: 51.25404, mean: 0.08402
[32m[0906 18-22-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17939, current rewards: 55.59242, mean: 0.08423
[32m[0906 18-23-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17911, current rewards: 59.93308, mean: 0.08441
[32m[0906 18-23-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17886, current rewards: 64.27705, mean: 0.08458
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17868, current rewards: 49.10116, mean: 0.06062
[32m[0906 18-23-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17880, current rewards: 57.17545, mean: 0.06648
[32m[0906 18-23-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17888, current rewards: 65.24974, mean: 0.07170
[32m[0906 18-23-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17901, current rewards: 73.32402, mean: 0.07638
[32m[0906 18-23-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17934, current rewards: 81.39831, mean: 0.08059
[32m[0906 18-24-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17971, current rewards: 89.80121, mean: 0.08472
[32m[0906 18-24-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17997, current rewards: 98.58987, mean: 0.08882
[32m[0906 18-24-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18020, current rewards: 94.44503, mean: 0.08142
[32m[0906 18-24-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18045, current rewards: 44.44503, mean: 0.03673
[32m[0906 18-24-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18062, current rewards: -5.55497, mean: -0.00441
[32m[0906 18-24-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18076, current rewards: -55.55497, mean: -0.04241
[32m[0906 18-25-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18094, current rewards: -105.55497, mean: -0.07761
[32m[0906 18-25-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18110, current rewards: -148.21561, mean: -0.10512
[32m[0906 18-25-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18123, current rewards: -145.79160, mean: -0.09986
[32m[0906 18-25-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18135, current rewards: -143.36759, mean: -0.09495
[32m[0906 18-25-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18143, current rewards: -140.94358, mean: -0.09035
[32m[0906 18-25-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18155, current rewards: -183.60422, mean: -0.11404
[32m[0906 18-26-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18165, current rewards: -233.60422, mean: -0.14073
[32m[0906 18-26-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18175, current rewards: -283.60422, mean: -0.16585
[32m[0906 18-26-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18187, current rewards: -288.92484, mean: -0.16416
[32m[0906 18-26-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18195, current rewards: -280.13618, mean: -0.15477
[32m[0906 18-26-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18201, current rewards: -271.66184, mean: -0.14605
[32m[0906 18-26-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18212, current rewards: -263.58755, mean: -0.13800
[32m[0906 18-26-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18219, current rewards: -255.51327, mean: -0.13036
[32m[0906 18-27-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18225, current rewards: -247.43898, mean: -0.12310
[32m[0906 18-27-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18231, current rewards: -283.50115, mean: -0.13762
[32m[0906 18-27-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18236, current rewards: -333.50115, mean: -0.15806
[32m[0906 18-27-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18243, current rewards: -383.50115, mean: -0.17755
[32m[0906 18-27-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18249, current rewards: -433.50115, mean: -0.19615
[32m[0906 18-27-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18254, current rewards: -483.50115, mean: -0.21394
[32m[0906 18-28-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18258, current rewards: -533.50115, mean: -0.23095
[32m[0906 18-28-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18263, current rewards: -583.50115, mean: -0.24725
[32m[0906 18-28-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18268, current rewards: -633.50115, mean: -0.26286
[32m[0906 18-28-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18272, current rewards: -683.50115, mean: -0.27785
[32m[0906 18-28-35 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 18-28-35 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-28-35 @MBExp.py:227][0m Rewards obtained: [-723.5011535794981], Lows: [11], Highs: [898], Total time: 16059.364907
[32m[0906 18-29-49 @MBExp.py:144][0m ####################################################################
[32m[0906 18-29-49 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 18-29-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18454, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-30-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18457, current rewards: -2.87015, mean: -0.04784
[32m[0906 18-30-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18473, current rewards: 3.63706, mean: 0.03306
[32m[0906 18-30-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18463, current rewards: 10.57776, mean: 0.06611
[32m[0906 18-30-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18485, current rewards: 17.02237, mean: 0.08106
[32m[0906 18-30-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18416, current rewards: 23.46656, mean: 0.09026
[32m[0906 18-30-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18353, current rewards: 29.91283, mean: 0.09649
[32m[0906 18-30-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18332, current rewards: 36.35607, mean: 0.10099
[32m[0906 18-31-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18266, current rewards: 42.80842, mean: 0.10441
[32m[0906 18-31-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18182, current rewards: 27.96006, mean: 0.06078
[32m[0906 18-31-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18117, current rewards: 35.02655, mean: 0.06868
[32m[0906 18-31-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18043, current rewards: 41.22020, mean: 0.07361
[32m[0906 18-31-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17952, current rewards: 47.86263, mean: 0.07846
[32m[0906 18-31-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17887, current rewards: 54.46294, mean: 0.08252
[32m[0906 18-31-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17858, current rewards: 56.79580, mean: 0.07999
[32m[0906 18-32-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17832, current rewards: 46.05834, mean: 0.06060
[32m[0906 18-32-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17811, current rewards: 52.25283, mean: 0.06451
[32m[0906 18-32-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17826, current rewards: 58.44913, mean: 0.06796
[32m[0906 18-32-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17840, current rewards: 64.64170, mean: 0.07103
[32m[0906 18-32-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17852, current rewards: 71.18088, mean: 0.07415
[32m[0906 18-32-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17884, current rewards: 80.50818, mean: 0.07971
[32m[0906 18-32-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17924, current rewards: 86.93454, mean: 0.08201
[32m[0906 18-33-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17964, current rewards: 93.36515, mean: 0.08411
[32m[0906 18-33-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17991, current rewards: 99.79721, mean: 0.08603
[32m[0906 18-33-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18015, current rewards: 95.19526, mean: 0.07867
[32m[0906 18-33-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18037, current rewards: 101.87024, mean: 0.08085
[32m[0906 18-33-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18055, current rewards: 108.53489, mean: 0.08285
[32m[0906 18-33-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18069, current rewards: 115.19991, mean: 0.08471
[32m[0906 18-34-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18085, current rewards: 122.37228, mean: 0.08679
[32m[0906 18-34-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18099, current rewards: 129.02992, mean: 0.08838
[32m[0906 18-34-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18113, current rewards: 135.69308, mean: 0.08986
[32m[0906 18-34-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18127, current rewards: 142.36422, mean: 0.09126
[32m[0906 18-34-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18141, current rewards: 126.68382, mean: 0.07869
[32m[0906 18-34-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18153, current rewards: 137.15902, mean: 0.08263
[32m[0906 18-35-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18164, current rewards: 147.64063, mean: 0.08634
[32m[0906 18-35-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18175, current rewards: 158.11466, mean: 0.08984
[32m[0906 18-35-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18185, current rewards: 167.18327, mean: 0.09237
[32m[0906 18-35-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18194, current rewards: 177.47637, mean: 0.09542
[32m[0906 18-35-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18200, current rewards: 187.80167, mean: 0.09833
[32m[0906 18-35-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18206, current rewards: 198.13062, mean: 0.10109
[32m[0906 18-35-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18212, current rewards: 208.44304, mean: 0.10370
[32m[0906 18-36-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18217, current rewards: 218.76639, mean: 0.10620
[32m[0906 18-36-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18223, current rewards: 206.86581, mean: 0.09804
[32m[0906 18-36-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18230, current rewards: 214.00508, mean: 0.09908
[32m[0906 18-36-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18236, current rewards: 221.06122, mean: 0.10003
[32m[0906 18-36-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18243, current rewards: 227.97685, mean: 0.10087
[32m[0906 18-36-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18250, current rewards: 234.89285, mean: 0.10169
[32m[0906 18-37-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18254, current rewards: 241.80851, mean: 0.10246
[32m[0906 18-37-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18260, current rewards: 248.72275, mean: 0.10320
[32m[0906 18-37-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18264, current rewards: 255.63917, mean: 0.10392
[32m[0906 18-37-26 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 18-37-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-37-26 @MBExp.py:227][0m Rewards obtained: [261.1736611791794], Lows: [41], Highs: [20], Total time: 16516.591712999998
[32m[0906 18-38-42 @MBExp.py:144][0m ####################################################################
[32m[0906 18-38-42 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 18-38-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18518, current rewards: 1.15596, mean: 0.11560
[32m[0906 18-38-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18579, current rewards: 9.24656, mean: 0.15411
[32m[0906 18-39-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18581, current rewards: 16.45694, mean: 0.14961
[32m[0906 18-39-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18553, current rewards: 20.10049, mean: 0.12563
[32m[0906 18-39-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18571, current rewards: 23.73382, mean: 0.11302
[32m[0906 18-39-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18468, current rewards: 27.36715, mean: 0.10526
[32m[0906 18-39-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18396, current rewards: 31.00048, mean: 0.10000
[32m[0906 18-39-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18343, current rewards: 14.25315, mean: 0.03959
[32m[0906 18-39-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18262, current rewards: -35.74685, mean: -0.08719
[32m[0906 18-40-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18176, current rewards: -85.74685, mean: -0.18641
[32m[0906 18-40-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18108, current rewards: -135.74685, mean: -0.26617
[32m[0906 18-40-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18019, current rewards: -185.74685, mean: -0.33169
[32m[0906 18-40-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17932, current rewards: -235.74685, mean: -0.38647
[32m[0906 18-40-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17867, current rewards: -285.74685, mean: -0.43295
[32m[0906 18-40-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17843, current rewards: -335.74685, mean: -0.47288
[32m[0906 18-40-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17820, current rewards: -385.74685, mean: -0.50756
[32m[0906 18-41-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17801, current rewards: -421.06150, mean: -0.51983
[32m[0906 18-41-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17815, current rewards: -418.61379, mean: -0.48676
[32m[0906 18-41-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17834, current rewards: -416.16609, mean: -0.45733
[32m[0906 18-41-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17847, current rewards: -447.28492, mean: -0.46592
[32m[0906 18-41-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17883, current rewards: -497.28492, mean: -0.49236
[32m[0906 18-41-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17916, current rewards: -547.28492, mean: -0.51631
[32m[0906 18-42-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17945, current rewards: -597.28492, mean: -0.53809
[32m[0906 18-42-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17972, current rewards: -647.28492, mean: -0.55800
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17995, current rewards: -697.28492, mean: -0.57627
[32m[0906 18-42-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18013, current rewards: -747.28492, mean: -0.59308
[32m[0906 18-42-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18034, current rewards: -797.28492, mean: -0.60861
[32m[0906 18-42-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18054, current rewards: -847.28492, mean: -0.62300
[32m[0906 18-42-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18074, current rewards: -897.28492, mean: -0.63637
[32m[0906 18-43-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18090, current rewards: -947.28492, mean: -0.64883
[32m[0906 18-43-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18108, current rewards: -997.28492, mean: -0.66045
[32m[0906 18-43-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18124, current rewards: -1047.28492, mean: -0.67134
[32m[0906 18-43-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18138, current rewards: -1097.28492, mean: -0.68154
[32m[0906 18-43-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18148, current rewards: -1147.28492, mean: -0.69114
[32m[0906 18-43-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18161, current rewards: -1197.28492, mean: -0.70017
[32m[0906 18-44-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18167, current rewards: -1247.28492, mean: -0.70868
[32m[0906 18-44-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18175, current rewards: -1297.28492, mean: -0.71673
[32m[0906 18-44-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18184, current rewards: -1347.28492, mean: -0.72435
[32m[0906 18-44-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18192, current rewards: -1397.28492, mean: -0.73156
[32m[0906 18-44-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18201, current rewards: -1447.28492, mean: -0.73841
[32m[0906 18-44-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18208, current rewards: -1497.28492, mean: -0.74492
[32m[0906 18-44-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18215, current rewards: -1547.28492, mean: -0.75111
[32m[0906 18-45-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18221, current rewards: -1597.28492, mean: -0.75701
[32m[0906 18-45-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18226, current rewards: -1647.28492, mean: -0.76263
[32m[0906 18-45-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18231, current rewards: -1697.28492, mean: -0.76800
[32m[0906 18-45-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18236, current rewards: -1747.28492, mean: -0.77313
[32m[0906 18-45-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18242, current rewards: -1797.28492, mean: -0.77805
[32m[0906 18-45-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18248, current rewards: -1847.28492, mean: -0.78275
[32m[0906 18-46-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18253, current rewards: -1897.28492, mean: -0.78726
[32m[0906 18-46-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18254, current rewards: -1947.28492, mean: -0.79158
[32m[0906 18-46-19 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 18-46-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-46-19 @MBExp.py:227][0m Rewards obtained: [-1987.284917869289], Lows: [0], Highs: [2027], Total time: 16973.53271
[32m[0906 18-47-36 @MBExp.py:144][0m ####################################################################
[32m[0906 18-47-36 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 18-47-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18752, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-47-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18671, current rewards: -5.76977, mean: -0.09616
[32m[0906 18-47-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18635, current rewards: 0.05902, mean: 0.00054
[32m[0906 18-48-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18592, current rewards: 5.88122, mean: 0.03676
[32m[0906 18-48-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18559, current rewards: 11.70306, mean: 0.05573
[32m[0906 18-48-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18457, current rewards: 17.52104, mean: 0.06739
[32m[0906 18-48-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18384, current rewards: 23.34107, mean: 0.07529
[32m[0906 18-48-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18342, current rewards: 8.16183, mean: 0.02267
[32m[0906 18-48-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18258, current rewards: 14.07690, mean: 0.03433
[32m[0906 18-49-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18176, current rewards: 20.01079, mean: 0.04350
[32m[0906 18-49-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18104, current rewards: 25.94362, mean: 0.05087
[32m[0906 18-49-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18007, current rewards: 20.12954, mean: 0.03595
[32m[0906 18-49-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17922, current rewards: 26.92652, mean: 0.04414
[32m[0906 18-49-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17856, current rewards: 33.73311, mean: 0.05111
[32m[0906 18-49-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17831, current rewards: 40.53954, mean: 0.05710
[32m[0906 18-49-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17814, current rewards: 47.35160, mean: 0.06230
[32m[0906 18-50-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17794, current rewards: 31.72333, mean: 0.03916
[32m[0906 18-50-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17806, current rewards: 37.56055, mean: 0.04368
[32m[0906 18-50-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17821, current rewards: 43.39508, mean: 0.04769
[32m[0906 18-50-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17831, current rewards: 49.23343, mean: 0.05128
[32m[0906 18-50-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17867, current rewards: 55.06330, mean: 0.05452
[32m[0906 18-50-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17902, current rewards: 60.89402, mean: 0.05745
[32m[0906 18-50-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17931, current rewards: 66.72957, mean: 0.06012
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17959, current rewards: 61.88417, mean: 0.05335
[32m[0906 18-51-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17983, current rewards: 61.99151, mean: 0.05123
[32m[0906 18-51-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18010, current rewards: 67.62210, mean: 0.05367
[32m[0906 18-51-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18031, current rewards: 73.24470, mean: 0.05591
[32m[0906 18-51-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18050, current rewards: 78.55475, mean: 0.05776
[32m[0906 18-51-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18072, current rewards: 84.44879, mean: 0.05989
[32m[0906 18-52-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18088, current rewards: 90.32840, mean: 0.06187
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18104, current rewards: 96.20302, mean: 0.06371
[32m[0906 18-52-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18119, current rewards: 78.22192, mean: 0.05014
[32m[0906 18-52-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18131, current rewards: 83.75083, mean: 0.05202
[32m[0906 18-52-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18144, current rewards: 89.27930, mean: 0.05378
[32m[0906 18-52-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18155, current rewards: 94.80710, mean: 0.05544
[32m[0906 18-52-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18162, current rewards: 101.43732, mean: 0.05763
[32m[0906 18-53-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18172, current rewards: 107.33035, mean: 0.05930
[32m[0906 18-53-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18181, current rewards: 112.75785, mean: 0.06062
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18189, current rewards: 118.18223, mean: 0.06188
[32m[0906 18-53-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18197, current rewards: 110.53884, mean: 0.05640
[32m[0906 18-53-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18205, current rewards: 115.93545, mean: 0.05768
[32m[0906 18-53-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18215, current rewards: 121.33872, mean: 0.05890
[32m[0906 18-54-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18225, current rewards: 126.74010, mean: 0.06007
[32m[0906 18-54-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18232, current rewards: 132.13915, mean: 0.06118
[32m[0906 18-54-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18237, current rewards: 137.40825, mean: 0.06218
[32m[0906 18-54-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18242, current rewards: 119.42932, mean: 0.05284
[32m[0906 18-54-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18247, current rewards: 124.93432, mean: 0.05408
[32m[0906 18-54-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18252, current rewards: 130.44786, mean: 0.05527
[32m[0906 18-54-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18255, current rewards: 135.95883, mean: 0.05641
[32m[0906 18-55-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18257, current rewards: 141.47076, mean: 0.05751
[32m[0906 18-55-13 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 18-55-13 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-55-13 @MBExp.py:227][0m Rewards obtained: [145.8823193804432], Lows: [47], Highs: [41], Total time: 17430.56024
[32m[0906 18-56-33 @MBExp.py:144][0m ####################################################################
[32m[0906 18-56-33 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 18-56-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18395, current rewards: 1.23428, mean: 0.12343
[32m[0906 18-56-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18531, current rewards: -31.72294, mean: -0.52872
[32m[0906 18-56-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18469, current rewards: -29.87328, mean: -0.27158
[32m[0906 18-57-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18482, current rewards: -24.52115, mean: -0.15326
[32m[0906 18-57-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18440, current rewards: -19.16424, mean: -0.09126
[32m[0906 18-57-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18372, current rewards: -13.81052, mean: -0.05312
[32m[0906 18-57-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18314, current rewards: -8.45674, mean: -0.02728
[32m[0906 18-57-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18283, current rewards: -14.25768, mean: -0.03960
[32m[0906 18-57-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18191, current rewards: -8.78818, mean: -0.02143
[32m[0906 18-57-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18117, current rewards: -3.31441, mean: -0.00721
[32m[0906 18-58-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18060, current rewards: 2.40956, mean: 0.00472
[32m[0906 18-58-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17967, current rewards: 8.11480, mean: 0.01449
[32m[0906 18-58-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17886, current rewards: 13.69343, mean: 0.02245
[32m[0906 18-58-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17818, current rewards: 19.26301, mean: 0.02919
[32m[0906 18-58-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17798, current rewards: 24.84141, mean: 0.03499
[32m[0906 18-58-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17782, current rewards: 9.59708, mean: 0.01263
[32m[0906 18-58-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17764, current rewards: 14.04404, mean: 0.01734
[32m[0906 18-59-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17775, current rewards: 17.97650, mean: 0.02090
[32m[0906 18-59-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17792, current rewards: 21.88920, mean: 0.02405
[32m[0906 18-59-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17807, current rewards: 25.70874, mean: 0.02678
[32m[0906 18-59-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17844, current rewards: 29.59841, mean: 0.02931
[32m[0906 18-59-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17884, current rewards: 33.48875, mean: 0.03159
[32m[0906 18-59-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17920, current rewards: 37.38048, mean: 0.03368
[32m[0906 19-00-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17944, current rewards: 41.26984, mean: 0.03558
[32m[0906 19-00-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17969, current rewards: 45.15925, mean: 0.03732
[32m[0906 19-00-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17992, current rewards: 49.04977, mean: 0.03893
[32m[0906 19-00-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18012, current rewards: 52.94004, mean: 0.04041
[32m[0906 19-00-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18031, current rewards: 56.83189, mean: 0.04179
[32m[0906 19-00-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18050, current rewards: 60.71925, mean: 0.04306
[32m[0906 19-00-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18067, current rewards: 64.61026, mean: 0.04425
[32m[0906 19-01-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18080, current rewards: 68.50236, mean: 0.04537
[32m[0906 19-01-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18093, current rewards: 41.01251, mean: 0.02629
[32m[0906 19-01-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18109, current rewards: 46.44040, mean: 0.02884
[32m[0906 19-01-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18120, current rewards: 51.56020, mean: 0.03106
[32m[0906 19-01-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18134, current rewards: 56.69509, mean: 0.03316
[32m[0906 19-01-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18142, current rewards: 62.54654, mean: 0.03554
[32m[0906 19-02-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18152, current rewards: 67.97218, mean: 0.03755
[32m[0906 19-02-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18165, current rewards: 73.38336, mean: 0.03945
[32m[0906 19-02-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18176, current rewards: 57.35871, mean: 0.03003
[32m[0906 19-02-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18186, current rewards: 61.16571, mean: 0.03121
[32m[0906 19-02-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18194, current rewards: 64.96641, mean: 0.03232
[32m[0906 19-02-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18200, current rewards: 68.76255, mean: 0.03338
[32m[0906 19-02-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18207, current rewards: 72.56061, mean: 0.03439
[32m[0906 19-03-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18213, current rewards: 76.56964, mean: 0.03545
[32m[0906 19-03-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18220, current rewards: 80.50196, mean: 0.03643
[32m[0906 19-03-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18225, current rewards: 84.43689, mean: 0.03736
[32m[0906 19-03-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18230, current rewards: 88.36969, mean: 0.03826
[32m[0906 19-03-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18237, current rewards: 92.30306, mean: 0.03911
[32m[0906 19-03-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18243, current rewards: 96.24054, mean: 0.03993
[32m[0906 19-04-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18241, current rewards: 100.17411, mean: 0.04072
[32m[0906 19-04-10 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 19-04-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-04-10 @MBExp.py:227][0m Rewards obtained: [92.61247716022916], Lows: [30], Highs: [67], Total time: 17887.222302
[32m[0906 19-05-32 @MBExp.py:144][0m ####################################################################
[32m[0906 19-05-32 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 19-05-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18638, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-05-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18599, current rewards: -1.96668, mean: -0.03278
[32m[0906 19-05-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18583, current rewards: 3.93072, mean: 0.03573
[32m[0906 19-06-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18553, current rewards: 9.83264, mean: 0.06145
[32m[0906 19-06-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18496, current rewards: 15.73231, mean: 0.07492
[32m[0906 19-06-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18412, current rewards: 21.63517, mean: 0.08321
[32m[0906 19-06-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18366, current rewards: 27.53740, mean: 0.08883
[32m[0906 19-06-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18324, current rewards: 33.43926, mean: 0.09289
[32m[0906 19-06-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18216, current rewards: 39.34414, mean: 0.09596
[32m[0906 19-06-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18141, current rewards: 46.29789, mean: 0.10065
[32m[0906 19-07-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18062, current rewards: 52.24231, mean: 0.10244
[32m[0906 19-07-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17962, current rewards: 45.51674, mean: 0.08128
[32m[0906 19-07-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17881, current rewards: 51.81666, mean: 0.08495
[32m[0906 19-07-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17812, current rewards: 58.12254, mean: 0.08806
[32m[0906 19-07-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17793, current rewards: 64.41752, mean: 0.09073
[32m[0906 19-07-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17774, current rewards: 70.71366, mean: 0.09304
[32m[0906 19-07-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17761, current rewards: 77.00378, mean: 0.09507
[32m[0906 19-08-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17770, current rewards: 83.62446, mean: 0.09724
[32m[0906 19-08-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17792, current rewards: 68.82835, mean: 0.07564
[32m[0906 19-08-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17804, current rewards: 74.43850, mean: 0.07754
[32m[0906 19-08-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17843, current rewards: 80.22138, mean: 0.07943
[32m[0906 19-08-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17883, current rewards: 85.99938, mean: 0.08113
[32m[0906 19-08-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17914, current rewards: 91.77939, mean: 0.08268
[32m[0906 19-09-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17942, current rewards: 97.55544, mean: 0.08410
[32m[0906 19-09-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17967, current rewards: 103.32707, mean: 0.08539
[32m[0906 19-09-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17993, current rewards: 109.08268, mean: 0.08657
[32m[0906 19-09-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18013, current rewards: 114.27619, mean: 0.08723
[32m[0906 19-09-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18032, current rewards: 109.26633, mean: 0.08034
[32m[0906 19-09-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18053, current rewards: 116.17913, mean: 0.08240
[32m[0906 19-09-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18069, current rewards: 123.10309, mean: 0.08432
[32m[0906 19-10-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18087, current rewards: 130.03449, mean: 0.08612
[32m[0906 19-10-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18102, current rewards: 136.95193, mean: 0.08779
[32m[0906 19-10-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18117, current rewards: 143.87612, mean: 0.08936
[32m[0906 19-10-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18130, current rewards: 150.79984, mean: 0.09084
[32m[0906 19-10-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18144, current rewards: 157.61268, mean: 0.09217
[32m[0906 19-10-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18157, current rewards: 164.57912, mean: 0.09351
[32m[0906 19-11-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18166, current rewards: 171.54884, mean: 0.09478
[32m[0906 19-11-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18176, current rewards: 178.51264, mean: 0.09597
[32m[0906 19-11-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18184, current rewards: 163.31349, mean: 0.08550
[32m[0906 19-11-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18191, current rewards: 168.93142, mean: 0.08619
[32m[0906 19-11-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18199, current rewards: 174.56006, mean: 0.08685
[32m[0906 19-11-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18207, current rewards: 180.18963, mean: 0.08747
[32m[0906 19-11-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18213, current rewards: 185.96220, mean: 0.08813
[32m[0906 19-12-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18219, current rewards: 180.30775, mean: 0.08348
[32m[0906 19-12-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18225, current rewards: 185.90949, mean: 0.08412
[32m[0906 19-12-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18232, current rewards: 191.50231, mean: 0.08474
[32m[0906 19-12-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18238, current rewards: 197.10501, mean: 0.08533
[32m[0906 19-12-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18243, current rewards: 202.70404, mean: 0.08589
[32m[0906 19-12-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18251, current rewards: 208.30142, mean: 0.08643
[32m[0906 19-13-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18249, current rewards: 213.89282, mean: 0.08695
[32m[0906 19-13-08 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 19-13-08 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-13-09 @MBExp.py:227][0m Rewards obtained: [218.36866363972027], Lows: [20], Highs: [42], Total time: 18344.052657999997
[32m[0906 19-14-33 @MBExp.py:144][0m ####################################################################
[32m[0906 19-14-33 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 19-14-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18474, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-14-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18584, current rewards: -5.04350, mean: -0.08406
[32m[0906 19-14-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18567, current rewards: 2.54870, mean: 0.02317
[32m[0906 19-15-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18607, current rewards: 10.15329, mean: 0.06346
[32m[0906 19-15-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18516, current rewards: 17.75574, mean: 0.08455
[32m[0906 19-15-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18429, current rewards: 25.34946, mean: 0.09750
[32m[0906 19-15-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18367, current rewards: 32.94980, mean: 0.10629
[32m[0906 19-15-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18316, current rewards: 18.88870, mean: 0.05247
[32m[0906 19-15-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18215, current rewards: 23.53654, mean: 0.05741
[32m[0906 19-15-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18140, current rewards: 28.40279, mean: 0.06175
[32m[0906 19-16-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18049, current rewards: 33.26775, mean: 0.06523
[32m[0906 19-16-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17952, current rewards: 38.13369, mean: 0.06810
[32m[0906 19-16-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17872, current rewards: 43.00141, mean: 0.07049
[32m[0906 19-16-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17804, current rewards: 41.57332, mean: 0.06299
[32m[0906 19-16-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17783, current rewards: 32.37599, mean: 0.04560
[32m[0906 19-16-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17766, current rewards: 37.12425, mean: 0.04885
[32m[0906 19-16-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17754, current rewards: 43.17481, mean: 0.05330
[32m[0906 19-17-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17766, current rewards: 48.00276, mean: 0.05582
[32m[0906 19-17-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17782, current rewards: 52.84500, mean: 0.05807
[32m[0906 19-17-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17800, current rewards: 57.68694, mean: 0.06009
[32m[0906 19-17-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17837, current rewards: 62.52882, mean: 0.06191
[32m[0906 19-17-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17871, current rewards: 67.37193, mean: 0.06356
[32m[0906 19-17-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17899, current rewards: 72.21498, mean: 0.06506
[32m[0906 19-18-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17927, current rewards: 65.15900, mean: 0.05617
[32m[0906 19-18-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17953, current rewards: 70.89162, mean: 0.05859
[32m[0906 19-18-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17978, current rewards: 76.50195, mean: 0.06072
[32m[0906 19-18-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17999, current rewards: 82.12549, mean: 0.06269
[32m[0906 19-18-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18017, current rewards: 87.78015, mean: 0.06454
[32m[0906 19-18-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18034, current rewards: 93.42671, mean: 0.06626
[32m[0906 19-18-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18050, current rewards: 99.09007, mean: 0.06787
[32m[0906 19-19-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18069, current rewards: 104.75946, mean: 0.06938
[32m[0906 19-19-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18084, current rewards: 110.43072, mean: 0.07079
[32m[0906 19-19-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18099, current rewards: 112.66941, mean: 0.06998
[32m[0906 19-19-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18111, current rewards: 107.81236, mean: 0.06495
[32m[0906 19-19-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18125, current rewards: 113.29546, mean: 0.06625
[32m[0906 19-19-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18136, current rewards: 118.79864, mean: 0.06750
[32m[0906 19-20-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18148, current rewards: 124.31170, mean: 0.06868
[32m[0906 19-20-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18159, current rewards: 129.80888, mean: 0.06979
[32m[0906 19-20-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18167, current rewards: 135.30752, mean: 0.07084
[32m[0906 19-20-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18176, current rewards: 140.81695, mean: 0.07185
[32m[0906 19-20-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18184, current rewards: 146.32938, mean: 0.07280
[32m[0906 19-20-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18191, current rewards: 163.32696, mean: 0.07928
[32m[0906 19-20-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18197, current rewards: 174.25051, mean: 0.08258
[32m[0906 19-21-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18202, current rewards: 162.26939, mean: 0.07512
[32m[0906 19-21-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18212, current rewards: 166.96046, mean: 0.07555
[32m[0906 19-21-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18218, current rewards: 170.81692, mean: 0.07558
[32m[0906 19-21-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18223, current rewards: 174.67357, mean: 0.07562
[32m[0906 19-21-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18228, current rewards: 178.52845, mean: 0.07565
[32m[0906 19-21-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18231, current rewards: 182.38110, mean: 0.07568
[32m[0906 19-22-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18227, current rewards: 186.08250, mean: 0.07564
[32m[0906 19-22-09 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 19-22-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-22-09 @MBExp.py:227][0m Rewards obtained: [189.02935921006377], Lows: [30], Highs: [34], Total time: 18800.369633999995
[32m[0906 19-23-35 @MBExp.py:144][0m ####################################################################
[32m[0906 19-23-35 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 19-23-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18539, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-23-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18594, current rewards: -9.70046, mean: -0.16167
[32m[0906 19-23-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18555, current rewards: -4.54786, mean: -0.04134
[32m[0906 19-24-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18531, current rewards: 0.60153, mean: 0.00376
[32m[0906 19-24-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18441, current rewards: 0.24394, mean: 0.00116
[32m[0906 19-24-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18358, current rewards: 1.27528, mean: 0.00490
[32m[0906 19-24-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18317, current rewards: 7.89064, mean: 0.02545
[32m[0906 19-24-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18244, current rewards: 14.51902, mean: 0.04033
[32m[0906 19-24-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18158, current rewards: 20.68926, mean: 0.05046
[32m[0906 19-24-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18087, current rewards: 27.32920, mean: 0.05941
[32m[0906 19-25-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17987, current rewards: 33.95233, mean: 0.06657
[32m[0906 19-25-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17892, current rewards: 40.57762, mean: 0.07246
[32m[0906 19-25-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17820, current rewards: 25.71235, mean: 0.04215
[32m[0906 19-25-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17757, current rewards: 32.73142, mean: 0.04959
[32m[0906 19-25-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17731, current rewards: 39.74926, mean: 0.05598
[32m[0906 19-25-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17716, current rewards: 46.76240, mean: 0.06153
[32m[0906 19-25-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17701, current rewards: 53.27539, mean: 0.06577
[32m[0906 19-26-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17707, current rewards: 60.25938, mean: 0.07007
[32m[0906 19-26-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17725, current rewards: 67.20628, mean: 0.07385
[32m[0906 19-26-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17744, current rewards: 74.14710, mean: 0.07724
[32m[0906 19-26-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17785, current rewards: 81.08554, mean: 0.08028
[32m[0906 19-26-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17820, current rewards: 88.02167, mean: 0.08304
[32m[0906 19-26-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17854, current rewards: 94.96886, mean: 0.08556
[32m[0906 19-27-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17886, current rewards: 87.26463, mean: 0.07523
[32m[0906 19-27-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17912, current rewards: 91.95276, mean: 0.07599
[32m[0906 19-27-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17935, current rewards: 96.62111, mean: 0.07668
[32m[0906 19-27-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17964, current rewards: 101.19138, mean: 0.07725
[32m[0906 19-27-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17989, current rewards: 105.76990, mean: 0.07777
[32m[0906 19-27-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18006, current rewards: 110.34072, mean: 0.07826
[32m[0906 19-27-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18024, current rewards: 92.59948, mean: 0.06342
[32m[0906 19-28-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18041, current rewards: 98.91224, mean: 0.06550
[32m[0906 19-28-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18056, current rewards: 105.23981, mean: 0.06746
[32m[0906 19-28-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18071, current rewards: 111.69388, mean: 0.06938
[32m[0906 19-28-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18084, current rewards: 118.62161, mean: 0.07146
[32m[0906 19-28-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18096, current rewards: 124.91889, mean: 0.07305
[32m[0906 19-28-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18107, current rewards: 131.21080, mean: 0.07455
[32m[0906 19-29-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18117, current rewards: 137.50067, mean: 0.07597
[32m[0906 19-29-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18127, current rewards: 143.78917, mean: 0.07731
[32m[0906 19-29-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18136, current rewards: 150.07817, mean: 0.07857
[32m[0906 19-29-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18147, current rewards: 156.36380, mean: 0.07978
[32m[0906 19-29-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18158, current rewards: 158.15044, mean: 0.07868
[32m[0906 19-29-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18166, current rewards: 157.56456, mean: 0.07649
[32m[0906 19-29-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18173, current rewards: 164.86924, mean: 0.07814
[32m[0906 19-30-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18181, current rewards: 172.15727, mean: 0.07970
[32m[0906 19-30-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18187, current rewards: 179.46288, mean: 0.08120
[32m[0906 19-30-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18195, current rewards: 186.76827, mean: 0.08264
[32m[0906 19-30-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18200, current rewards: 194.06555, mean: 0.08401
[32m[0906 19-30-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18206, current rewards: 201.36276, mean: 0.08532
[32m[0906 19-30-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18207, current rewards: 208.65577, mean: 0.08658
[32m[0906 19-31-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18204, current rewards: 223.46495, mean: 0.09084
[32m[0906 19-31-11 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0906 19-31-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-31-11 @MBExp.py:227][0m Rewards obtained: [229.4441177745554], Lows: [24], Highs: [41], Total time: 19256.102185999996
[32m[0906 19-32-39 @MBExp.py:144][0m ####################################################################
[32m[0906 19-32-39 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 19-32-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18574, current rewards: 1.26308, mean: 0.12631
[32m[0906 19-32-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18602, current rewards: 9.31681, mean: 0.15528
[32m[0906 19-33-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18544, current rewards: 15.63224, mean: 0.14211
[32m[0906 19-33-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18524, current rewards: 21.94766, mean: 0.13717
[32m[0906 19-33-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18424, current rewards: 28.26309, mean: 0.13459
[32m[0906 19-33-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18363, current rewards: 34.57851, mean: 0.13299
[32m[0906 19-33-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18311, current rewards: -9.78994, mean: -0.03158
[32m[0906 19-33-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18237, current rewards: -59.78994, mean: -0.16608
[32m[0906 19-33-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18151, current rewards: -109.78994, mean: -0.26778
[32m[0906 19-34-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18087, current rewards: -159.78994, mean: -0.34737
[32m[0906 19-34-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17977, current rewards: -209.78994, mean: -0.41135
[32m[0906 19-34-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17881, current rewards: -259.78994, mean: -0.46391
[32m[0906 19-34-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17806, current rewards: -309.78994, mean: -0.50785
[32m[0906 19-34-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17741, current rewards: -359.78994, mean: -0.54514
[32m[0906 19-34-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17720, current rewards: -409.78994, mean: -0.57717
[32m[0906 19-34-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17707, current rewards: -459.78994, mean: -0.60499
[32m[0906 19-35-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17694, current rewards: -509.78994, mean: -0.62937
[32m[0906 19-35-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17698, current rewards: -559.78994, mean: -0.65092
[32m[0906 19-35-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17722, current rewards: -609.78994, mean: -0.67010
[32m[0906 19-35-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17743, current rewards: -659.78994, mean: -0.68728
[32m[0906 19-35-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17784, current rewards: -709.78994, mean: -0.70276
[32m[0906 19-35-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17825, current rewards: -759.78994, mean: -0.71678
[32m[0906 19-35-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17863, current rewards: -809.78994, mean: -0.72954
[32m[0906 19-36-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17893, current rewards: -859.78994, mean: -0.74120
[32m[0906 19-36-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17924, current rewards: -909.78994, mean: -0.75189
[32m[0906 19-36-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17947, current rewards: -959.78994, mean: -0.76174
[32m[0906 19-36-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17971, current rewards: -1009.78994, mean: -0.77083
[32m[0906 19-36-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17993, current rewards: -1059.78994, mean: -0.77926
[32m[0906 19-36-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18008, current rewards: -1109.78994, mean: -0.78709
[32m[0906 19-37-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18025, current rewards: -1159.78994, mean: -0.79438
[32m[0906 19-37-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18040, current rewards: -1209.78994, mean: -0.80119
[32m[0906 19-37-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18057, current rewards: -1259.78994, mean: -0.80756
[32m[0906 19-37-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18070, current rewards: -1309.78994, mean: -0.81353
[32m[0906 19-37-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18084, current rewards: -1359.78994, mean: -0.81915
[32m[0906 19-37-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18098, current rewards: -1409.78994, mean: -0.82444
[32m[0906 19-37-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18111, current rewards: -1459.78994, mean: -0.82943
[32m[0906 19-38-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18123, current rewards: -1509.78994, mean: -0.83414
[32m[0906 19-38-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18134, current rewards: -1559.78994, mean: -0.83860
[32m[0906 19-38-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18145, current rewards: -1609.78994, mean: -0.84282
[32m[0906 19-38-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18152, current rewards: -1659.78994, mean: -0.84683
[32m[0906 19-38-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18162, current rewards: -1709.78994, mean: -0.85064
[32m[0906 19-38-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18172, current rewards: -1759.78994, mean: -0.85427
[32m[0906 19-39-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18179, current rewards: -1809.78994, mean: -0.85772
[32m[0906 19-39-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18188, current rewards: -1859.78994, mean: -0.86101
[32m[0906 19-39-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18195, current rewards: -1909.78994, mean: -0.86416
[32m[0906 19-39-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18202, current rewards: -1959.78994, mean: -0.86716
[32m[0906 19-39-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18209, current rewards: -2009.78994, mean: -0.87004
[32m[0906 19-39-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18215, current rewards: -2059.78994, mean: -0.87279
[32m[0906 19-39-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18214, current rewards: -2109.78994, mean: -0.87543
[32m[0906 19-40-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18215, current rewards: -2159.78994, mean: -0.87796
[32m[0906 19-40-15 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 19-40-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-40-15 @MBExp.py:227][0m Rewards obtained: [-2199.789943539207], Lows: [0], Highs: [2235], Total time: 19712.126523999996
[32m[0906 19-41-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-41-46 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 19-41-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18448, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-41-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18609, current rewards: -4.91636, mean: -0.08194
[32m[0906 19-42-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18608, current rewards: 0.33419, mean: 0.00304
[32m[0906 19-42-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18628, current rewards: 5.58509, mean: 0.03491
[32m[0906 19-42-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18490, current rewards: 10.83521, mean: 0.05160
[32m[0906 19-42-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18405, current rewards: 16.08288, mean: 0.06186
[32m[0906 19-42-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18346, current rewards: 0.36688, mean: 0.00118
[32m[0906 19-42-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18251, current rewards: 5.38624, mean: 0.01496
[32m[0906 19-43-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18161, current rewards: 10.67591, mean: 0.02604
[32m[0906 19-43-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18073, current rewards: 15.97033, mean: 0.03472
[32m[0906 19-43-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17953, current rewards: 21.26484, mean: 0.04170
[32m[0906 19-43-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17861, current rewards: 26.55519, mean: 0.04742
[32m[0906 19-43-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17782, current rewards: 31.84956, mean: 0.05221
[32m[0906 19-43-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17718, current rewards: 37.14424, mean: 0.05628
[32m[0906 19-43-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17691, current rewards: 32.43304, mean: 0.04568
[32m[0906 19-44-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17679, current rewards: 40.07258, mean: 0.05273
[32m[0906 19-44-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17667, current rewards: 48.24862, mean: 0.05957
[32m[0906 19-44-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17676, current rewards: 56.68433, mean: 0.06591
[32m[0906 19-44-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17700, current rewards: 65.13371, mean: 0.07158
[32m[0906 19-44-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17718, current rewards: 73.58842, mean: 0.07665
[32m[0906 19-44-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17758, current rewards: 59.11218, mean: 0.05853
[32m[0906 19-44-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17794, current rewards: 64.44804, mean: 0.06080
[32m[0906 19-45-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17831, current rewards: 70.31190, mean: 0.06334
[32m[0906 19-45-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17862, current rewards: 76.16801, mean: 0.06566
[32m[0906 19-45-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17890, current rewards: 83.83765, mean: 0.06929
[32m[0906 19-45-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17919, current rewards: 89.35640, mean: 0.07092
[32m[0906 19-45-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17942, current rewards: 94.87392, mean: 0.07242
[32m[0906 19-45-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17965, current rewards: 100.39262, mean: 0.07382
[32m[0906 19-46-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17985, current rewards: 95.57752, mean: 0.06779
[32m[0906 19-46-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18003, current rewards: 102.85382, mean: 0.07045
[32m[0906 19-46-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18019, current rewards: 110.11568, mean: 0.07292
[32m[0906 19-46-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18040, current rewards: 117.39916, mean: 0.07526
[32m[0906 19-46-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18056, current rewards: 124.34685, mean: 0.07723
[32m[0906 19-46-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18071, current rewards: 132.41902, mean: 0.07977
[32m[0906 19-46-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18084, current rewards: 140.49283, mean: 0.08216
[32m[0906 19-47-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18097, current rewards: 148.59212, mean: 0.08443
[32m[0906 19-47-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18111, current rewards: 156.66524, mean: 0.08656
[32m[0906 19-47-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18123, current rewards: 164.76419, mean: 0.08858
[32m[0906 19-47-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18132, current rewards: 172.84413, mean: 0.09049
[32m[0906 19-47-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18141, current rewards: 180.92822, mean: 0.09231
[32m[0906 19-47-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18150, current rewards: 172.86908, mean: 0.08600
[32m[0906 19-48-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18160, current rewards: 178.67385, mean: 0.08673
[32m[0906 19-48-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18167, current rewards: 183.80658, mean: 0.08711
[32m[0906 19-48-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18174, current rewards: 188.94080, mean: 0.08747
[32m[0906 19-48-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18183, current rewards: 194.07446, mean: 0.08782
[32m[0906 19-48-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18192, current rewards: 199.20719, mean: 0.08814
[32m[0906 19-48-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18198, current rewards: 204.34067, mean: 0.08846
[32m[0906 19-48-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18203, current rewards: 209.47339, mean: 0.08876
[32m[0906 19-49-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18200, current rewards: 214.39600, mean: 0.08896
[32m[0906 19-49-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18198, current rewards: 219.58463, mean: 0.08926
[32m[0906 19-49-21 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0906 19-49-21 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-49-21 @MBExp.py:227][0m Rewards obtained: [223.72307155280723], Lows: [30], Highs: [31], Total time: 20167.743781999994
[32m[0906 19-50-54 @MBExp.py:144][0m ####################################################################
[32m[0906 19-50-54 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 19-50-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18547, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-51-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18577, current rewards: -3.08745, mean: -0.05146
[32m[0906 19-51-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18536, current rewards: 3.22377, mean: 0.02931
[32m[0906 19-51-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18521, current rewards: 9.53437, mean: 0.05959
[32m[0906 19-51-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18432, current rewards: 15.84334, mean: 0.07544
[32m[0906 19-51-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18359, current rewards: 10.93770, mean: 0.04207
[32m[0906 19-51-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18307, current rewards: 17.40281, mean: 0.05614
[32m[0906 19-52-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18209, current rewards: 23.10310, mean: 0.06418
[32m[0906 19-52-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18123, current rewards: 29.68635, mean: 0.07241
[32m[0906 19-52-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18027, current rewards: 36.26387, mean: 0.07883
[32m[0906 19-52-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17921, current rewards: 42.85231, mean: 0.08402
[32m[0906 19-52-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17835, current rewards: -15.16609, mean: -0.02708
[32m[0906 19-52-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17767, current rewards: -115.16609, mean: -0.18880
[32m[0906 19-52-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17705, current rewards: -215.16609, mean: -0.32601
[32m[0906 19-53-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17670, current rewards: -315.16609, mean: -0.44390
[32m[0906 19-53-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17661, current rewards: -415.16609, mean: -0.54627
[32m[0906 19-53-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17654, current rewards: -515.16609, mean: -0.63601
[32m[0906 19-53-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17650, current rewards: -615.16609, mean: -0.71531
[32m[0906 19-53-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17673, current rewards: -715.16609, mean: -0.78590
[32m[0906 19-53-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17693, current rewards: -815.16609, mean: -0.84913
[32m[0906 19-53-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17731, current rewards: -915.16609, mean: -0.90611
[32m[0906 19-54-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17771, current rewards: -1015.16609, mean: -0.95770
[32m[0906 19-54-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17804, current rewards: -1115.16609, mean: -1.00465
[32m[0906 19-54-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17838, current rewards: -1215.16609, mean: -1.04756
[32m[0906 19-54-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17870, current rewards: -1247.02251, mean: -1.03060
[32m[0906 19-54-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17900, current rewards: -1240.48219, mean: -0.98451
[32m[0906 19-54-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17929, current rewards: -1233.95599, mean: -0.94195
[32m[0906 19-54-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17953, current rewards: -1227.43027, mean: -0.90252
[32m[0906 19-55-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17973, current rewards: -1220.91352, mean: -0.86590
[32m[0906 19-55-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17991, current rewards: -1214.38966, mean: -0.83177
[32m[0906 19-55-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18009, current rewards: -1207.86589, mean: -0.79991
[32m[0906 19-55-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18026, current rewards: -1200.62121, mean: -0.76963
[32m[0906 19-55-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18046, current rewards: -1190.40571, mean: -0.73938
[32m[0906 19-55-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18061, current rewards: -1184.44147, mean: -0.71352
[32m[0906 19-56-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18074, current rewards: -1181.83900, mean: -0.69113
[32m[0906 19-56-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18084, current rewards: -1196.04268, mean: -0.67957
[32m[0906 19-56-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18098, current rewards: -1189.18602, mean: -0.65701
[32m[0906 19-56-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18108, current rewards: -1182.32800, mean: -0.63566
[32m[0906 19-56-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18120, current rewards: -1175.46468, mean: -0.61543
[32m[0906 19-56-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18131, current rewards: -1189.45746, mean: -0.60687
[32m[0906 19-56-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18142, current rewards: -1189.53725, mean: -0.59181
[32m[0906 19-57-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18151, current rewards: -1188.56149, mean: -0.57697
[32m[0906 19-57-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18158, current rewards: -1182.74948, mean: -0.56054
[32m[0906 19-57-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18166, current rewards: -1176.93279, mean: -0.54488
[32m[0906 19-57-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18174, current rewards: -1171.11872, mean: -0.52992
[32m[0906 19-57-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18180, current rewards: -1182.45697, mean: -0.52321
[32m[0906 19-57-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18188, current rewards: -1189.77938, mean: -0.51506
[32m[0906 19-58-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18192, current rewards: -1182.73807, mean: -0.50116
[32m[0906 19-58-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18190, current rewards: -1175.62588, mean: -0.48781
[32m[0906 19-58-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18189, current rewards: -1165.90447, mean: -0.47394
[32m[0906 19-58-29 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 19-58-29 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-58-29 @MBExp.py:227][0m Rewards obtained: [-1160.387047193017], Lows: [670], Highs: [60], Total time: 20623.157833999994
[32m[0906 20-00-04 @MBExp.py:144][0m ####################################################################
[32m[0906 20-00-04 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 20-00-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18443, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-00-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18568, current rewards: -4.74941, mean: -0.07916
[32m[0906 20-00-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18617, current rewards: 0.72262, mean: 0.00657
[32m[0906 20-00-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18589, current rewards: 6.20541, mean: 0.03878
[32m[0906 20-00-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18448, current rewards: 11.68230, mean: 0.05563
[32m[0906 20-00-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18365, current rewards: 17.16202, mean: 0.06601
[32m[0906 20-01-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18325, current rewards: 22.63635, mean: 0.07302
[32m[0906 20-01-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18237, current rewards: 28.82176, mean: 0.08006
[32m[0906 20-01-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18151, current rewards: 34.31708, mean: 0.08370
[32m[0906 20-01-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18047, current rewards: 39.81154, mean: 0.08655
[32m[0906 20-01-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17942, current rewards: 45.30714, mean: 0.08884
[32m[0906 20-01-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17858, current rewards: 50.80243, mean: 0.09072
[32m[0906 20-01-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17789, current rewards: 56.29620, mean: 0.09229
[32m[0906 20-02-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17725, current rewards: 61.78808, mean: 0.09362
[32m[0906 20-02-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17684, current rewards: 67.28469, mean: 0.09477
[32m[0906 20-02-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17672, current rewards: 63.02509, mean: 0.08293
[32m[0906 20-02-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17662, current rewards: 70.61916, mean: 0.08718
[32m[0906 20-02-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17651, current rewards: 78.22450, mean: 0.09096
[32m[0906 20-02-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17675, current rewards: 85.84161, mean: 0.09433
[32m[0906 20-02-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17696, current rewards: 93.42456, mean: 0.09732
[32m[0906 20-03-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17736, current rewards: 101.03338, mean: 0.10003
[32m[0906 20-03-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17781, current rewards: 108.61351, mean: 0.10247
[32m[0906 20-03-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17815, current rewards: 94.39039, mean: 0.08504
[32m[0906 20-03-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17845, current rewards: 80.21096, mean: 0.06915
[32m[0906 20-03-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17872, current rewards: 93.99666, mean: 0.07768
[32m[0906 20-03-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17899, current rewards: 117.61154, mean: 0.09334
[32m[0906 20-03-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17924, current rewards: 144.95356, mean: 0.11065
[32m[0906 20-04-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17945, current rewards: 173.12533, mean: 0.12730
[32m[0906 20-04-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17966, current rewards: 201.30562, mean: 0.14277
[32m[0906 20-04-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17986, current rewards: 229.63232, mean: 0.15728
[32m[0906 20-04-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18001, current rewards: 258.10002, mean: 0.17093
[32m[0906 20-04-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18017, current rewards: 284.42611, mean: 0.18232
[32m[0906 20-04-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18034, current rewards: 301.10154, mean: 0.18702
[32m[0906 20-05-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18048, current rewards: 292.49496, mean: 0.17620
[32m[0906 20-05-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18063, current rewards: 298.35442, mean: 0.17448
[32m[0906 20-05-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18080, current rewards: 304.21330, mean: 0.17285
[32m[0906 20-05-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18095, current rewards: 310.07121, mean: 0.17131
[32m[0906 20-05-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18106, current rewards: 315.92744, mean: 0.16985
[32m[0906 20-05-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18118, current rewards: 321.78605, mean: 0.16847
[32m[0906 20-06-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18127, current rewards: 327.64513, mean: 0.16717
[32m[0906 20-06-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18139, current rewards: 333.50337, mean: 0.16592
[32m[0906 20-06-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18150, current rewards: 339.36246, mean: 0.16474
[32m[0906 20-06-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18159, current rewards: 345.22090, mean: 0.16361
[32m[0906 20-06-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18168, current rewards: 351.07928, mean: 0.16254
[32m[0906 20-06-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18178, current rewards: 344.36247, mean: 0.15582
[32m[0906 20-06-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18186, current rewards: 349.25991, mean: 0.15454
[32m[0906 20-07-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18191, current rewards: 354.15069, mean: 0.15331
[32m[0906 20-07-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18194, current rewards: 358.68379, mean: 0.15198
[32m[0906 20-07-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18193, current rewards: 363.47726, mean: 0.15082
[32m[0906 20-07-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18191, current rewards: 368.33310, mean: 0.14973
[32m[0906 20-07-39 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 20-07-39 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-07-39 @MBExp.py:227][0m Rewards obtained: [372.21600107136123], Lows: [32], Highs: [31], Total time: 21078.565293999993
[32m[0906 20-09-16 @MBExp.py:144][0m ####################################################################
[32m[0906 20-09-16 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 20-09-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19046, current rewards: -8.95116, mean: -0.89512
[32m[0906 20-09-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18673, current rewards: -3.82215, mean: -0.06370
[32m[0906 20-09-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18579, current rewards: 1.94013, mean: 0.01764
[32m[0906 20-09-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18510, current rewards: 7.70149, mean: 0.04813
[32m[0906 20-09-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18403, current rewards: 13.45873, mean: 0.06409
[32m[0906 20-10-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18338, current rewards: 19.21886, mean: 0.07392
[32m[0906 20-10-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18286, current rewards: 26.83078, mean: 0.08655
[32m[0906 20-10-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18183, current rewards: 32.57035, mean: 0.09047
[32m[0906 20-10-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18099, current rewards: 13.77272, mean: 0.03359
[32m[0906 20-10-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17992, current rewards: -19.93337, mean: -0.04333
[32m[0906 20-10-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17887, current rewards: -31.03645, mean: -0.06086
[32m[0906 20-10-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17802, current rewards: -31.28544, mean: -0.05587
[32m[0906 20-11-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17734, current rewards: -32.53838, mean: -0.05334
[32m[0906 20-11-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17671, current rewards: -32.71953, mean: -0.04958
[32m[0906 20-11-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17620, current rewards: -33.95752, mean: -0.04783
[32m[0906 20-11-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17618, current rewards: -34.14354, mean: -0.04493
[32m[0906 20-11-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17616, current rewards: -35.38131, mean: -0.04368
[32m[0906 20-11-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17607, current rewards: -36.65198, mean: -0.04262
[32m[0906 20-11-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17625, current rewards: -36.80654, mean: -0.04045
[32m[0906 20-12-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17649, current rewards: -38.05445, mean: -0.03964
[32m[0906 20-12-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17683, current rewards: -47.97586, mean: -0.04750
[32m[0906 20-12-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17727, current rewards: -41.95128, mean: -0.03958
[32m[0906 20-12-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17769, current rewards: -30.95109, mean: -0.02788
[32m[0906 20-12-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17802, current rewards: -24.75374, mean: -0.02134
[32m[0906 20-12-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17832, current rewards: -18.71453, mean: -0.01547
[32m[0906 20-13-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17862, current rewards: -12.68019, mean: -0.01006
[32m[0906 20-13-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17888, current rewards: -6.63893, mean: -0.00507
[32m[0906 20-13-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17910, current rewards: -0.61102, mean: -0.00045
[32m[0906 20-13-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17931, current rewards: 5.42643, mean: 0.00385
[32m[0906 20-13-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17956, current rewards: 11.46812, mean: 0.00785
[32m[0906 20-13-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17978, current rewards: 21.46017, mean: 0.01421
[32m[0906 20-13-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17995, current rewards: 41.12362, mean: 0.02636
[32m[0906 20-14-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18011, current rewards: 68.90688, mean: 0.04280
[32m[0906 20-14-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18025, current rewards: 96.48816, mean: 0.05813
[32m[0906 20-14-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18039, current rewards: 124.05759, mean: 0.07255
[32m[0906 20-14-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18052, current rewards: 151.37529, mean: 0.08601
[32m[0906 20-14-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18065, current rewards: 138.20154, mean: 0.07635
[32m[0906 20-14-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18076, current rewards: 143.84120, mean: 0.07733
[32m[0906 20-15-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18087, current rewards: 149.48418, mean: 0.07826
[32m[0906 20-15-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18098, current rewards: 155.00800, mean: 0.07909
[32m[0906 20-15-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18107, current rewards: 160.63194, mean: 0.07992
[32m[0906 20-15-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18116, current rewards: 166.25967, mean: 0.08071
[32m[0906 20-15-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18125, current rewards: 162.28403, mean: 0.07691
[32m[0906 20-15-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18135, current rewards: 170.99051, mean: 0.07916
[32m[0906 20-15-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18142, current rewards: 179.66334, mean: 0.08130
[32m[0906 20-16-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18149, current rewards: 188.41280, mean: 0.08337
[32m[0906 20-16-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18157, current rewards: 197.15760, mean: 0.08535
[32m[0906 20-16-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18157, current rewards: 205.81105, mean: 0.08721
[32m[0906 20-16-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18155, current rewards: 214.68593, mean: 0.08908
[32m[0906 20-16-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18153, current rewards: 200.35635, mean: 0.08145
[32m[0906 20-16-51 @Agent.py:117][0m Average action selection time: 0.1815
[32m[0906 20-16-51 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-16-51 @MBExp.py:227][0m Rewards obtained: [204.85583278765628], Lows: [20], Highs: [144], Total time: 21533.071891999993
[32m[0906 20-18-30 @MBExp.py:144][0m ####################################################################
[32m[0906 20-18-30 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 20-18-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18690, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-18-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18607, current rewards: -5.37925, mean: -0.08965
[32m[0906 20-18-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18605, current rewards: 0.32298, mean: 0.00294
[32m[0906 20-18-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18563, current rewards: 6.02839, mean: 0.03768
[32m[0906 20-19-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18434, current rewards: 11.74155, mean: 0.05591
[32m[0906 20-19-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18352, current rewards: 17.92753, mean: 0.06895
[32m[0906 20-19-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18307, current rewards: 23.72046, mean: 0.07652
[32m[0906 20-19-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18197, current rewards: 9.88901, mean: 0.02747
[32m[0906 20-19-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18118, current rewards: 15.90614, mean: 0.03880
[32m[0906 20-19-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18003, current rewards: 20.50499, mean: 0.04458
[32m[0906 20-20-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17906, current rewards: 25.10030, mean: 0.04922
[32m[0906 20-20-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17821, current rewards: 29.69989, mean: 0.05304
[32m[0906 20-20-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17747, current rewards: 34.29798, mean: 0.05623
[32m[0906 20-20-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17684, current rewards: 38.67315, mean: 0.05860
[32m[0906 20-20-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17629, current rewards: 43.25652, mean: 0.06092
[32m[0906 20-20-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17616, current rewards: 28.10965, mean: 0.03699
[32m[0906 20-20-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17606, current rewards: 34.10513, mean: 0.04211
[32m[0906 20-21-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17599, current rewards: 40.02540, mean: 0.04654
[32m[0906 20-21-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17613, current rewards: 45.94882, mean: 0.05049
[32m[0906 20-21-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17636, current rewards: 51.87008, mean: 0.05403
[32m[0906 20-21-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17670, current rewards: 57.79545, mean: 0.05722
[32m[0906 20-21-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17716, current rewards: 66.45233, mean: 0.06269
[32m[0906 20-21-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17755, current rewards: 73.21637, mean: 0.06596
[32m[0906 20-21-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17789, current rewards: 79.98041, mean: 0.06895
[32m[0906 20-22-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17826, current rewards: 86.74445, mean: 0.07169
[32m[0906 20-22-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17853, current rewards: 71.93815, mean: 0.05709
[32m[0906 20-22-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17879, current rewards: 21.93815, mean: 0.01675
[32m[0906 20-22-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17903, current rewards: -28.06185, mean: -0.02063
[32m[0906 20-22-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17922, current rewards: -78.06185, mean: -0.05536
[32m[0906 20-22-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17941, current rewards: -128.06185, mean: -0.08771
[32m[0906 20-23-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17960, current rewards: -178.06185, mean: -0.11792
[32m[0906 20-23-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17977, current rewards: -228.06185, mean: -0.14619
[32m[0906 20-23-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17995, current rewards: -278.06185, mean: -0.17271
[32m[0906 20-23-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18009, current rewards: -328.06185, mean: -0.19763
[32m[0906 20-23-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18022, current rewards: -378.06185, mean: -0.22109
[32m[0906 20-23-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18035, current rewards: -428.06185, mean: -0.24322
[32m[0906 20-23-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18047, current rewards: -478.06185, mean: -0.26412
[32m[0906 20-24-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18060, current rewards: -528.06185, mean: -0.28390
[32m[0906 20-24-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18072, current rewards: -578.06185, mean: -0.30265
[32m[0906 20-24-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18083, current rewards: -628.06185, mean: -0.32044
[32m[0906 20-24-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18094, current rewards: -678.06185, mean: -0.33734
[32m[0906 20-24-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18103, current rewards: -728.06185, mean: -0.35343
[32m[0906 20-24-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18110, current rewards: -778.06185, mean: -0.36875
[32m[0906 20-25-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18118, current rewards: -828.06185, mean: -0.38336
[32m[0906 20-25-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18126, current rewards: -878.06185, mean: -0.39731
[32m[0906 20-25-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18135, current rewards: -928.06185, mean: -0.41065
[32m[0906 20-25-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18141, current rewards: -978.06185, mean: -0.42340
[32m[0906 20-25-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18140, current rewards: -1028.06185, mean: -0.43562
[32m[0906 20-25-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18138, current rewards: -1078.06185, mean: -0.44733
[32m[0906 20-25-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18136, current rewards: -1128.06185, mean: -0.45856
[32m[0906 20-26-04 @Agent.py:117][0m Average action selection time: 0.1814
[32m[0906 20-26-04 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-26-04 @MBExp.py:227][0m Rewards obtained: [-1168.0618499166765], Lows: [14], Highs: [1280], Total time: 21987.184989999994
[32m[0906 20-27-45 @MBExp.py:144][0m ####################################################################
[32m[0906 20-27-45 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 20-27-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18600, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-27-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18598, current rewards: -5.42401, mean: -0.09040
[32m[0906 20-28-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18597, current rewards: -0.50512, mean: -0.00459
[32m[0906 20-28-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18532, current rewards: 4.41334, mean: 0.02758
[32m[0906 20-28-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18432, current rewards: 9.32996, mean: 0.04443
[32m[0906 20-28-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18354, current rewards: 13.95739, mean: 0.05368
[32m[0906 20-28-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18301, current rewards: 18.87669, mean: 0.06089
[32m[0906 20-28-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18184, current rewards: 23.79642, mean: 0.06610
[32m[0906 20-28-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18098, current rewards: 28.72301, mean: 0.07006
[32m[0906 20-29-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17983, current rewards: 33.64133, mean: 0.07313
[32m[0906 20-29-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17880, current rewards: 38.56216, mean: 0.07561
[32m[0906 20-29-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17797, current rewards: 22.06657, mean: 0.03940
[32m[0906 20-29-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17730, current rewards: 26.64312, mean: 0.04368
[32m[0906 20-29-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17667, current rewards: 31.64748, mean: 0.04795
[32m[0906 20-29-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17614, current rewards: 36.25623, mean: 0.05107
[32m[0906 20-29-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17595, current rewards: 40.86427, mean: 0.05377
[32m[0906 20-30-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17591, current rewards: 34.35706, mean: 0.04242
[32m[0906 20-30-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17586, current rewards: 38.45530, mean: 0.04472
[32m[0906 20-30-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17599, current rewards: 42.65529, mean: 0.04687
[32m[0906 20-30-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17626, current rewards: 46.85491, mean: 0.04881
[32m[0906 20-30-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17660, current rewards: 51.05328, mean: 0.05055
[32m[0906 20-30-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17701, current rewards: 56.50686, mean: 0.05331
[32m[0906 20-31-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17744, current rewards: 60.90045, mean: 0.05487
[32m[0906 20-31-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17780, current rewards: 53.26456, mean: 0.04592
[32m[0906 20-31-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17811, current rewards: 56.96095, mean: 0.04708
[32m[0906 20-31-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17839, current rewards: 60.65742, mean: 0.04814
[32m[0906 20-31-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17867, current rewards: 64.35639, mean: 0.04913
[32m[0906 20-31-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17892, current rewards: 68.04888, mean: 0.05004
[32m[0906 20-31-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17916, current rewards: 71.74581, mean: 0.05088
[32m[0906 20-32-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17939, current rewards: 75.26302, mean: 0.05155
[32m[0906 20-32-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17959, current rewards: 58.37321, mean: 0.03866
[32m[0906 20-32-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17980, current rewards: 62.88601, mean: 0.04031
[32m[0906 20-32-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17997, current rewards: 67.39166, mean: 0.04186
[32m[0906 20-32-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18014, current rewards: 71.89574, mean: 0.04331
[32m[0906 20-32-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18029, current rewards: 76.40228, mean: 0.04468
[32m[0906 20-33-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18044, current rewards: 80.90591, mean: 0.04597
[32m[0906 20-33-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18057, current rewards: 85.40994, mean: 0.04719
[32m[0906 20-33-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18067, current rewards: 89.90890, mean: 0.04834
[32m[0906 20-33-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18078, current rewards: 94.28479, mean: 0.04936
[32m[0906 20-33-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18087, current rewards: 98.74944, mean: 0.05038
[32m[0906 20-33-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18098, current rewards: 93.70035, mean: 0.04662
[32m[0906 20-33-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18107, current rewards: 97.75646, mean: 0.04745
[32m[0906 20-34-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18119, current rewards: 101.65238, mean: 0.04818
[32m[0906 20-34-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18128, current rewards: 105.54451, mean: 0.04886
[32m[0906 20-34-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18136, current rewards: 109.43842, mean: 0.04952
[32m[0906 20-34-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18145, current rewards: 113.33067, mean: 0.05015
[32m[0906 20-34-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18151, current rewards: 117.07837, mean: 0.05068
[32m[0906 20-34-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18149, current rewards: 121.02563, mean: 0.05128
[32m[0906 20-35-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18149, current rewards: 124.97290, mean: 0.05186
[32m[0906 20-35-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18147, current rewards: 128.91876, mean: 0.05241
[32m[0906 20-35-19 @Agent.py:117][0m Average action selection time: 0.1815
[32m[0906 20-35-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-35-19 @MBExp.py:227][0m Rewards obtained: [132.0767923591538], Lows: [20], Highs: [41], Total time: 22441.554628999995
[32m[0906 20-37-03 @MBExp.py:144][0m ####################################################################
[32m[0906 20-37-03 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 20-37-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18600, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-37-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18579, current rewards: -12.23466, mean: -0.20391
[32m[0906 20-37-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18556, current rewards: -8.59092, mean: -0.07810
[32m[0906 20-37-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18483, current rewards: -4.94517, mean: -0.03091
[32m[0906 20-37-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18376, current rewards: -1.14700, mean: -0.00546
[32m[0906 20-37-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18320, current rewards: 2.51411, mean: 0.00967
[32m[0906 20-37-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18269, current rewards: 6.17374, mean: 0.01992
[32m[0906 20-38-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18162, current rewards: 9.83579, mean: 0.02732
[32m[0906 20-38-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18085, current rewards: 13.49720, mean: 0.03292
[32m[0906 20-38-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17957, current rewards: 18.55085, mean: 0.04033
[32m[0906 20-38-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17855, current rewards: 23.06092, mean: 0.04522
[32m[0906 20-38-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17771, current rewards: 27.58763, mean: 0.04926
[32m[0906 20-38-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17708, current rewards: 32.10383, mean: 0.05263
[32m[0906 20-38-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17649, current rewards: 36.62217, mean: 0.05549
[32m[0906 20-39-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17597, current rewards: 41.13948, mean: 0.05794
[32m[0906 20-39-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17570, current rewards: 45.65403, mean: 0.06007
[32m[0906 20-39-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17567, current rewards: 50.17280, mean: 0.06194
[32m[0906 20-39-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17565, current rewards: 54.68879, mean: 0.06359
[32m[0906 20-39-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17572, current rewards: 59.21067, mean: 0.06507
[32m[0906 20-39-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17599, current rewards: 63.72402, mean: 0.06638
[32m[0906 20-40-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17628, current rewards: 68.17249, mean: 0.06750
[32m[0906 20-40-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17676, current rewards: 72.69775, mean: 0.06858
[32m[0906 20-40-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17716, current rewards: 77.22978, mean: 0.06958
[32m[0906 20-40-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17752, current rewards: 81.76851, mean: 0.07049
[32m[0906 20-40-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17786, current rewards: 86.30138, mean: 0.07132
[32m[0906 20-40-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17818, current rewards: 69.93233, mean: 0.05550
[32m[0906 20-40-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17849, current rewards: 74.91199, mean: 0.05718
[32m[0906 20-41-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17876, current rewards: 79.88446, mean: 0.05874
[32m[0906 20-41-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17898, current rewards: 84.57266, mean: 0.05998
[32m[0906 20-41-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17922, current rewards: 89.56103, mean: 0.06134
[32m[0906 20-41-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17944, current rewards: 94.54034, mean: 0.06261
[32m[0906 20-41-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17963, current rewards: 98.41959, mean: 0.06309
[32m[0906 20-41-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17979, current rewards: 93.47904, mean: 0.05806
[32m[0906 20-42-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17995, current rewards: 98.48384, mean: 0.05933
[32m[0906 20-42-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18103, current rewards: 103.49025, mean: 0.06052
[32m[0906 20-42-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18118, current rewards: 108.49641, mean: 0.06165
[32m[0906 20-42-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18130, current rewards: 114.64172, mean: 0.06334
[32m[0906 20-42-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18138, current rewards: 119.74485, mean: 0.06438
[32m[0906 20-42-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18147, current rewards: 124.74216, mean: 0.06531
[32m[0906 20-42-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18154, current rewards: 129.74584, mean: 0.06620
[32m[0906 20-43-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18163, current rewards: 134.74215, mean: 0.06704
[32m[0906 20-43-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18172, current rewards: 139.73916, mean: 0.06783
[32m[0906 20-43-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18179, current rewards: 144.73718, mean: 0.06860
[32m[0906 20-43-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18185, current rewards: 149.73607, mean: 0.06932
[32m[0906 20-43-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18195, current rewards: 154.77190, mean: 0.07003
[32m[0906 20-43-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18201, current rewards: 162.03846, mean: 0.07170
[32m[0906 20-44-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18203, current rewards: 156.11454, mean: 0.06758
[32m[0906 20-44-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18199, current rewards: 161.12232, mean: 0.06827
[32m[0906 20-44-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18196, current rewards: 166.12716, mean: 0.06893
[32m[0906 20-44-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18192, current rewards: 171.13268, mean: 0.06957
[32m[0906 20-44-38 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 20-44-38 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-44-38 @MBExp.py:227][0m Rewards obtained: [175.1355056040168], Lows: [11], Highs: [34], Total time: 22897.030252999994
[32m[0906 20-46-23 @MBExp.py:144][0m ####################################################################
[32m[0906 20-46-23 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 20-46-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18517, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-46-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18579, current rewards: -23.12572, mean: -0.38543
[32m[0906 20-46-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18530, current rewards: -2.65788, mean: -0.02416
[32m[0906 20-46-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18457, current rewards: -19.91387, mean: -0.12446
[32m[0906 20-47-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18362, current rewards: -19.34993, mean: -0.09214
[32m[0906 20-47-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18291, current rewards: 5.34776, mean: 0.02057
[32m[0906 20-47-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18236, current rewards: 35.54443, mean: 0.11466
[32m[0906 20-47-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18131, current rewards: 67.13454, mean: 0.18648
[32m[0906 20-47-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18042, current rewards: 98.87769, mean: 0.24117
[32m[0906 20-47-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17918, current rewards: 84.21316, mean: 0.18307
[32m[0906 20-47-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17823, current rewards: 89.81314, mean: 0.17610
[32m[0906 20-48-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17746, current rewards: 95.40018, mean: 0.17036
[32m[0906 20-48-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17676, current rewards: 100.99030, mean: 0.16556
[32m[0906 20-48-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17618, current rewards: 106.58099, mean: 0.16149
[32m[0906 20-48-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17570, current rewards: 112.17007, mean: 0.15799
[32m[0906 20-48-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17538, current rewards: 117.75717, mean: 0.15494
[32m[0906 20-48-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17536, current rewards: 123.34761, mean: 0.15228
[32m[0906 20-48-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17531, current rewards: 128.93236, mean: 0.14992
[32m[0906 20-49-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17531, current rewards: 123.34612, mean: 0.13555
[32m[0906 20-49-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17560, current rewards: 129.07665, mean: 0.13445
[32m[0906 20-49-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17589, current rewards: 134.03210, mean: 0.13271
[32m[0906 20-49-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17641, current rewards: 139.65510, mean: 0.13175
[32m[0906 20-49-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17682, current rewards: 145.26967, mean: 0.13087
[32m[0906 20-49-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17719, current rewards: 151.29185, mean: 0.13042
[32m[0906 20-49-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17755, current rewards: 157.65471, mean: 0.13029
[32m[0906 20-50-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17786, current rewards: 164.04802, mean: 0.13020
[32m[0906 20-50-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17810, current rewards: 170.42176, mean: 0.13009
[32m[0906 20-50-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17839, current rewards: 168.29876, mean: 0.12375
[32m[0906 20-50-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17861, current rewards: 164.42676, mean: 0.11661
[32m[0906 20-50-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17884, current rewards: 173.48020, mean: 0.11882
[32m[0906 20-50-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17901, current rewards: 182.53363, mean: 0.12088
[32m[0906 20-51-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17920, current rewards: 191.58706, mean: 0.12281
[32m[0906 20-51-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17936, current rewards: 200.64049, mean: 0.12462
[32m[0906 20-51-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17950, current rewards: 209.69393, mean: 0.12632
[32m[0906 20-51-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17962, current rewards: 218.74736, mean: 0.12792
[32m[0906 20-51-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17977, current rewards: 206.54156, mean: 0.11735
[32m[0906 20-51-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17994, current rewards: 156.54156, mean: 0.08649
[32m[0906 20-51-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18007, current rewards: 106.54156, mean: 0.05728
[32m[0906 20-52-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18023, current rewards: 56.54156, mean: 0.02960
[32m[0906 20-52-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18034, current rewards: 6.54156, mean: 0.00334
[32m[0906 20-52-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18044, current rewards: -43.45844, mean: -0.02162
[32m[0906 20-52-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18053, current rewards: -45.39744, mean: -0.02204
[32m[0906 20-52-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18063, current rewards: -40.78267, mean: -0.01933
[32m[0906 20-52-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18072, current rewards: -36.16790, mean: -0.01674
[32m[0906 20-53-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18080, current rewards: -31.69177, mean: -0.01434
[32m[0906 20-53-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18087, current rewards: -29.18129, mean: -0.01291
[32m[0906 20-53-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18089, current rewards: -26.71121, mean: -0.01156
[32m[0906 20-53-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18087, current rewards: -24.24114, mean: -0.01027
[32m[0906 20-53-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18086, current rewards: -21.77106, mean: -0.00903
[32m[0906 20-53-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18084, current rewards: -19.30099, mean: -0.00785
[32m[0906 20-53-56 @Agent.py:117][0m Average action selection time: 0.1808
[32m[0906 20-53-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-53-56 @MBExp.py:227][0m Rewards obtained: [-17.324925326597594], Lows: [58], Highs: [295], Total time: 23349.802121999994
[32m[0906 20-55-43 @MBExp.py:144][0m ####################################################################
[32m[0906 20-55-43 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 20-55-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18601, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-55-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18547, current rewards: -11.46830, mean: -0.19114
[32m[0906 20-56-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18458, current rewards: -5.61265, mean: -0.05102
[32m[0906 20-56-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18438, current rewards: -0.26984, mean: -0.00169
[32m[0906 20-56-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18361, current rewards: 5.27187, mean: 0.02510
[32m[0906 20-56-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18292, current rewards: 10.87848, mean: 0.04184
[32m[0906 20-56-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18231, current rewards: -5.22690, mean: -0.01686
[32m[0906 20-56-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18122, current rewards: 0.04367, mean: 0.00012
[32m[0906 20-56-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18029, current rewards: 5.31438, mean: 0.01296
[32m[0906 20-57-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17905, current rewards: 10.58846, mean: 0.02302
[32m[0906 20-57-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17805, current rewards: 15.86052, mean: 0.03110
[32m[0906 20-57-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17722, current rewards: 22.27929, mean: 0.03978
[32m[0906 20-57-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17652, current rewards: 27.98612, mean: 0.04588
[32m[0906 20-57-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17600, current rewards: 33.27784, mean: 0.05042
[32m[0906 20-57-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17553, current rewards: 38.56992, mean: 0.05432
[32m[0906 20-57-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17512, current rewards: 32.55857, mean: 0.04284
[32m[0906 20-58-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17504, current rewards: 37.39059, mean: 0.04616
[32m[0906 20-58-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17504, current rewards: 42.22891, mean: 0.04910
[32m[0906 20-58-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17508, current rewards: 47.06942, mean: 0.05172
[32m[0906 20-58-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17534, current rewards: 51.57712, mean: 0.05373
[32m[0906 20-58-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17560, current rewards: 53.48856, mean: 0.05296
[32m[0906 20-58-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17605, current rewards: 58.51300, mean: 0.05520
[32m[0906 20-58-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17647, current rewards: 63.54226, mean: 0.05725
[32m[0906 20-59-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17686, current rewards: 68.56871, mean: 0.05911
[32m[0906 20-59-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17719, current rewards: 73.60042, mean: 0.06083
[32m[0906 20-59-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17749, current rewards: 78.62768, mean: 0.06240
[32m[0906 20-59-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17776, current rewards: 83.65272, mean: 0.06386
[32m[0906 20-59-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17801, current rewards: 88.68631, mean: 0.06521
[32m[0906 20-59-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17828, current rewards: 93.82562, mean: 0.06654
[32m[0906 21-00-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17851, current rewards: 98.87137, mean: 0.06772
[32m[0906 21-00-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17870, current rewards: 103.91309, mean: 0.06882
[32m[0906 21-00-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17893, current rewards: 108.95687, mean: 0.06984
[32m[0906 21-00-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17917, current rewards: 81.67958, mean: 0.05073
[32m[0906 21-00-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17935, current rewards: 87.67392, mean: 0.05282
[32m[0906 21-00-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17949, current rewards: 93.95687, mean: 0.05495
[32m[0906 21-00-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17962, current rewards: 100.24172, mean: 0.05696
[32m[0906 21-01-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17977, current rewards: 106.77343, mean: 0.05899
[32m[0906 21-01-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17990, current rewards: 113.03132, mean: 0.06077
[32m[0906 21-01-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18002, current rewards: 119.29482, mean: 0.06246
[32m[0906 21-01-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18013, current rewards: 113.86512, mean: 0.05809
[32m[0906 21-01-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18025, current rewards: 119.79224, mean: 0.05960
[32m[0906 21-01-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18035, current rewards: 125.71787, mean: 0.06103
[32m[0906 21-02-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18045, current rewards: 131.64742, mean: 0.06239
[32m[0906 21-02-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18056, current rewards: 137.57907, mean: 0.06369
[32m[0906 21-02-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18066, current rewards: 143.51044, mean: 0.06494
[32m[0906 21-02-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18076, current rewards: 149.44235, mean: 0.06612
[32m[0906 21-02-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18078, current rewards: 155.37743, mean: 0.06726
[32m[0906 21-02-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18077, current rewards: 161.29958, mean: 0.06835
[32m[0906 21-02-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18076, current rewards: 167.22572, mean: 0.06939
[32m[0906 21-03-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18075, current rewards: 173.15125, mean: 0.07039
[32m[0906 21-03-15 @Agent.py:117][0m Average action selection time: 0.1807
[32m[0906 21-03-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-03-15 @MBExp.py:227][0m Rewards obtained: [177.89195688009562], Lows: [24], Highs: [42], Total time: 23802.365066999995
[32m[0906 21-05-05 @MBExp.py:144][0m ####################################################################
[32m[0906 21-05-05 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 21-05-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18515, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-05-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18509, current rewards: -9.01726, mean: -0.15029
[32m[0906 21-05-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18499, current rewards: -3.37185, mean: -0.03065
[32m[0906 21-05-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18434, current rewards: 4.42541, mean: 0.02766
[32m[0906 21-05-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18329, current rewards: 10.09539, mean: 0.04807
[32m[0906 21-05-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18256, current rewards: -5.36421, mean: -0.02063
[32m[0906 21-06-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18205, current rewards: 0.50713, mean: 0.00164
[32m[0906 21-06-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18090, current rewards: 6.22178, mean: 0.01728
[32m[0906 21-06-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17985, current rewards: 11.93615, mean: 0.02911
[32m[0906 21-06-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17867, current rewards: 17.64975, mean: 0.03837
[32m[0906 21-06-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17771, current rewards: 23.36210, mean: 0.04581
[32m[0906 21-06-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17697, current rewards: 28.78770, mean: 0.05141
[32m[0906 21-06-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17634, current rewards: 23.07502, mean: 0.03783
[32m[0906 21-07-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17576, current rewards: 28.28860, mean: 0.04286
[32m[0906 21-07-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17530, current rewards: 33.50646, mean: 0.04719
[32m[0906 21-07-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17487, current rewards: 38.72252, mean: 0.05095
[32m[0906 21-07-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17469, current rewards: 43.94042, mean: 0.05425
[32m[0906 21-07-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17469, current rewards: 49.15827, mean: 0.05716
[32m[0906 21-07-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17469, current rewards: 54.37680, mean: 0.05975
[32m[0906 21-07-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17486, current rewards: 60.93959, mean: 0.06348
[32m[0906 21-08-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17513, current rewards: 66.30177, mean: 0.06565
[32m[0906 21-08-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17557, current rewards: 71.66479, mean: 0.06761
[32m[0906 21-08-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17604, current rewards: 65.44835, mean: 0.05896
[32m[0906 21-08-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17643, current rewards: 70.17161, mean: 0.06049
[32m[0906 21-08-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17679, current rewards: 74.88593, mean: 0.06189
[32m[0906 21-08-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17714, current rewards: 79.60139, mean: 0.06318
[32m[0906 21-08-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17749, current rewards: 84.31718, mean: 0.06436
[32m[0906 21-09-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17779, current rewards: 88.94371, mean: 0.06540
[32m[0906 21-09-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17805, current rewards: 93.91783, mean: 0.06661
[32m[0906 21-09-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17829, current rewards: 99.11323, mean: 0.06789
[32m[0906 21-09-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17848, current rewards: 104.30818, mean: 0.06908
[32m[0906 21-09-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17869, current rewards: 109.50213, mean: 0.07019
[32m[0906 21-09-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17889, current rewards: 114.69465, mean: 0.07124
[32m[0906 21-10-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17908, current rewards: 119.88990, mean: 0.07222
[32m[0906 21-10-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17925, current rewards: 125.08803, mean: 0.07315
[32m[0906 21-10-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17941, current rewards: 130.28218, mean: 0.07402
[32m[0906 21-10-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17959, current rewards: 135.47452, mean: 0.07485
[32m[0906 21-10-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17973, current rewards: 140.62212, mean: 0.07560
[32m[0906 21-10-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17987, current rewards: 145.94917, mean: 0.07641
[32m[0906 21-10-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18002, current rewards: 151.26726, mean: 0.07718
[32m[0906 21-11-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18014, current rewards: 156.59256, mean: 0.07791
[32m[0906 21-11-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18024, current rewards: 161.92445, mean: 0.07860
[32m[0906 21-11-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18034, current rewards: 167.24945, mean: 0.07927
[32m[0906 21-11-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18044, current rewards: 168.36749, mean: 0.07795
[32m[0906 21-11-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18052, current rewards: 159.54249, mean: 0.07219
[32m[0906 21-11-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18059, current rewards: 165.21233, mean: 0.07310
[32m[0906 21-12-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18061, current rewards: 170.87266, mean: 0.07397
[32m[0906 21-12-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18060, current rewards: 176.53486, mean: 0.07480
[32m[0906 21-12-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18061, current rewards: 160.52913, mean: 0.06661
[32m[0906 21-12-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18061, current rewards: 165.82314, mean: 0.06741
[32m[0906 21-12-37 @Agent.py:117][0m Average action selection time: 0.1806
[32m[0906 21-12-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-12-37 @MBExp.py:227][0m Rewards obtained: [170.0579763582237], Lows: [30], Highs: [34], Total time: 24254.633522999997
[32m[0906 21-14-28 @MBExp.py:144][0m ####################################################################
[32m[0906 21-14-28 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 21-14-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18529, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-14-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18568, current rewards: -7.57960, mean: -0.12633
[32m[0906 21-14-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18565, current rewards: -2.14705, mean: -0.01952
[32m[0906 21-14-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18508, current rewards: 3.13164, mean: 0.01957
[32m[0906 21-15-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18415, current rewards: 8.41020, mean: 0.04005
[32m[0906 21-15-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18352, current rewards: 13.68176, mean: 0.05262
[32m[0906 21-15-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18285, current rewards: 18.95801, mean: 0.06115
[32m[0906 21-15-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18167, current rewards: 24.23534, mean: 0.06732
[32m[0906 21-15-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18050, current rewards: 29.50790, mean: 0.07197
[32m[0906 21-15-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17929, current rewards: 34.78010, mean: 0.07561
[32m[0906 21-15-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17830, current rewards: 39.49184, mean: 0.07743
[32m[0906 21-16-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17746, current rewards: 15.84226, mean: 0.02829
[32m[0906 21-16-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17673, current rewards: -42.89922, mean: -0.07033
[32m[0906 21-16-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17617, current rewards: -110.67150, mean: -0.16768
[32m[0906 21-16-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17566, current rewards: -163.68079, mean: -0.23054
[32m[0906 21-16-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17526, current rewards: -226.06341, mean: -0.29745
[32m[0906 21-16-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17503, current rewards: -283.94273, mean: -0.35055
[32m[0906 21-16-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17501, current rewards: -350.27326, mean: -0.40729
[32m[0906 21-17-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17503, current rewards: -406.65767, mean: -0.44688
[32m[0906 21-17-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17517, current rewards: -452.45635, mean: -0.47131
[32m[0906 21-17-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17544, current rewards: -447.02735, mean: -0.44260
[32m[0906 21-17-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17582, current rewards: -441.59945, mean: -0.41660
[32m[0906 21-17-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17627, current rewards: -436.17803, mean: -0.39295
[32m[0906 21-17-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17665, current rewards: -430.75216, mean: -0.37134
[32m[0906 21-18-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17701, current rewards: -425.32927, mean: -0.35151
[32m[0906 21-18-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17731, current rewards: -419.90518, mean: -0.33326
[32m[0906 21-18-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17764, current rewards: -414.77658, mean: -0.31662
[32m[0906 21-18-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17789, current rewards: -409.35386, mean: -0.30100
[32m[0906 21-18-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17815, current rewards: -403.97437, mean: -0.28651
[32m[0906 21-18-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17841, current rewards: -398.59998, mean: -0.27301
[32m[0906 21-18-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17862, current rewards: -393.22124, mean: -0.26041
[32m[0906 21-19-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17882, current rewards: -387.85277, mean: -0.24862
[32m[0906 21-19-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17905, current rewards: -403.19820, mean: -0.25043
[32m[0906 21-19-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17927, current rewards: -397.59557, mean: -0.23952
[32m[0906 21-19-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17943, current rewards: -392.28441, mean: -0.22941
[32m[0906 21-19-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17960, current rewards: -386.97494, mean: -0.21987
[32m[0906 21-19-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17974, current rewards: -381.34836, mean: -0.21069
[32m[0906 21-20-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17986, current rewards: -375.72792, mean: -0.20200
[32m[0906 21-20-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18000, current rewards: -370.10324, mean: -0.19377
[32m[0906 21-20-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18011, current rewards: -364.47317, mean: -0.18596
[32m[0906 21-20-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18021, current rewards: -358.83876, mean: -0.17853
[32m[0906 21-20-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18034, current rewards: -353.21312, mean: -0.17146
[32m[0906 21-20-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18045, current rewards: -347.58636, mean: -0.16473
[32m[0906 21-20-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18056, current rewards: -335.59586, mean: -0.15537
[32m[0906 21-21-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18065, current rewards: -329.78642, mean: -0.14922
[32m[0906 21-21-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18074, current rewards: -340.26227, mean: -0.15056
[32m[0906 21-21-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18077, current rewards: -334.96684, mean: -0.14501
[32m[0906 21-21-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18076, current rewards: -329.64814, mean: -0.13968
[32m[0906 21-21-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18076, current rewards: -324.33398, mean: -0.13458
[32m[0906 21-21-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18074, current rewards: -319.02254, mean: -0.12968
[32m[0906 21-22-00 @Agent.py:117][0m Average action selection time: 0.1807
[32m[0906 21-22-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-22-00 @MBExp.py:227][0m Rewards obtained: [-314.7677274966782], Lows: [279], Highs: [36], Total time: 24707.173393999998
[32m[0906 21-23-54 @MBExp.py:144][0m ####################################################################
[32m[0906 21-23-54 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 21-23-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18440, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-24-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18514, current rewards: -5.33630, mean: -0.08894
[32m[0906 21-24-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18496, current rewards: 0.34717, mean: 0.00316
[32m[0906 21-24-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18469, current rewards: 5.86481, mean: 0.03666
[32m[0906 21-24-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18351, current rewards: 11.38185, mean: 0.05420
[32m[0906 21-24-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18282, current rewards: 16.89710, mean: 0.06499
[32m[0906 21-24-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18229, current rewards: 22.41137, mean: 0.07229
[32m[0906 21-24-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18118, current rewards: 11.04387, mean: 0.03068
[32m[0906 21-25-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18010, current rewards: 12.43846, mean: 0.03034
[32m[0906 21-25-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17888, current rewards: 17.88582, mean: 0.03888
[32m[0906 21-25-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17794, current rewards: 22.80626, mean: 0.04472
[32m[0906 21-25-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17712, current rewards: 28.29830, mean: 0.05053
[32m[0906 21-25-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17650, current rewards: 33.78499, mean: 0.05539
[32m[0906 21-25-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17594, current rewards: 39.27361, mean: 0.05951
[32m[0906 21-25-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17543, current rewards: 44.76377, mean: 0.06305
[32m[0906 21-26-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17505, current rewards: 48.03514, mean: 0.06320
[32m[0906 21-26-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17470, current rewards: 47.78015, mean: 0.05899
[32m[0906 21-26-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17466, current rewards: 52.21027, mean: 0.06071
[32m[0906 21-26-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17465, current rewards: 56.67402, mean: 0.06228
[32m[0906 21-26-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17466, current rewards: 61.10778, mean: 0.06365
[32m[0906 21-26-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17495, current rewards: 65.54518, mean: 0.06490
[32m[0906 21-27-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17528, current rewards: 69.98453, mean: 0.06602
[32m[0906 21-27-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17577, current rewards: 74.42142, mean: 0.06705
[32m[0906 21-27-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17624, current rewards: 78.85981, mean: 0.06798
[32m[0906 21-27-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17663, current rewards: 83.29947, mean: 0.06884
[32m[0906 21-27-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17697, current rewards: 89.83786, mean: 0.07130
[32m[0906 21-27-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17732, current rewards: 94.92190, mean: 0.07246
[32m[0906 21-27-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17762, current rewards: 99.84004, mean: 0.07341
[32m[0906 21-28-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17789, current rewards: 104.75649, mean: 0.07430
[32m[0906 21-28-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17817, current rewards: 109.67706, mean: 0.07512
[32m[0906 21-28-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17839, current rewards: 114.59354, mean: 0.07589
[32m[0906 21-28-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17860, current rewards: 119.51380, mean: 0.07661
[32m[0906 21-28-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17881, current rewards: 104.44938, mean: 0.06488
[32m[0906 21-28-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17899, current rewards: 109.88038, mean: 0.06619
[32m[0906 21-29-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17916, current rewards: 117.29918, mean: 0.06860
[32m[0906 21-29-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17931, current rewards: 122.61844, mean: 0.06967
[32m[0906 21-29-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17948, current rewards: 127.92275, mean: 0.07068
[32m[0906 21-29-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17962, current rewards: 133.22702, mean: 0.07163
[32m[0906 21-29-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17974, current rewards: 138.53129, mean: 0.07253
[32m[0906 21-29-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17988, current rewards: 129.14978, mean: 0.06589
[32m[0906 21-29-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18002, current rewards: 134.76587, mean: 0.06705
[32m[0906 21-30-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18013, current rewards: 140.37829, mean: 0.06814
[32m[0906 21-30-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18025, current rewards: 145.99168, mean: 0.06919
[32m[0906 21-30-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18035, current rewards: 151.60787, mean: 0.07019
[32m[0906 21-30-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18045, current rewards: 157.22351, mean: 0.07114
[32m[0906 21-30-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18052, current rewards: 162.83989, mean: 0.07205
[32m[0906 21-30-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18052, current rewards: 168.45638, mean: 0.07292
[32m[0906 21-31-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18052, current rewards: 174.07199, mean: 0.07376
[32m[0906 21-31-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18052, current rewards: 179.68618, mean: 0.07456
[32m[0906 21-31-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18051, current rewards: 185.29996, mean: 0.07533
[32m[0906 21-31-26 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0906 21-31-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-31-26 @MBExp.py:227][0m Rewards obtained: [189.61614166388242], Lows: [20], Highs: [34], Total time: 25159.207591
[32m[0906 21-33-21 @MBExp.py:144][0m ####################################################################
[32m[0906 21-33-21 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 21-33-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18457, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-33-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18547, current rewards: -5.80630, mean: -0.09677
[32m[0906 21-33-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18518, current rewards: -1.56279, mean: -0.01421
[32m[0906 21-33-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18475, current rewards: 2.67596, mean: 0.01672
[32m[0906 21-34-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18386, current rewards: 6.91678, mean: 0.03294
[32m[0906 21-34-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18331, current rewards: 0.95005, mean: 0.00365
[32m[0906 21-34-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18262, current rewards: 7.11857, mean: 0.02296
[32m[0906 21-34-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18148, current rewards: 13.28524, mean: 0.03690
[32m[0906 21-34-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18026, current rewards: 19.46736, mean: 0.04748
[32m[0906 21-34-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17904, current rewards: 25.63514, mean: 0.05573
[32m[0906 21-34-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17805, current rewards: 31.80655, mean: 0.06237
[32m[0906 21-35-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17721, current rewards: 33.49152, mean: 0.05981
[32m[0906 21-35-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17654, current rewards: 30.77987, mean: 0.05046
[32m[0906 21-35-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17597, current rewards: 34.45231, mean: 0.05220
[32m[0906 21-35-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17544, current rewards: 38.12444, mean: 0.05370
[32m[0906 21-35-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17502, current rewards: 41.79497, mean: 0.05499
[32m[0906 21-35-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17462, current rewards: 45.48309, mean: 0.05615
[32m[0906 21-35-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17457, current rewards: 18.38451, mean: 0.02138
[32m[0906 21-36-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17458, current rewards: 5.49598, mean: 0.00604
[32m[0906 21-36-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17462, current rewards: 11.00997, mean: 0.01147
[32m[0906 21-36-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17489, current rewards: 16.62875, mean: 0.01646
[32m[0906 21-36-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17522, current rewards: 22.11535, mean: 0.02086
[32m[0906 21-36-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17568, current rewards: 27.59920, mean: 0.02486
[32m[0906 21-36-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17612, current rewards: 33.08413, mean: 0.02852
[32m[0906 21-36-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17647, current rewards: 38.56897, mean: 0.03188
[32m[0906 21-37-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17683, current rewards: 43.36520, mean: 0.03442
[32m[0906 21-37-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17713, current rewards: 48.69228, mean: 0.03717
[32m[0906 21-37-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17741, current rewards: 54.02052, mean: 0.03972
[32m[0906 21-37-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17765, current rewards: 59.35051, mean: 0.04209
[32m[0906 21-37-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17788, current rewards: 53.63138, mean: 0.03673
[32m[0906 21-37-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17811, current rewards: 58.98037, mean: 0.03906
[32m[0906 21-38-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17831, current rewards: 64.33160, mean: 0.04124
[32m[0906 21-38-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17855, current rewards: 69.67989, mean: 0.04328
[32m[0906 21-38-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17876, current rewards: 74.37591, mean: 0.04480
[32m[0906 21-38-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17894, current rewards: 79.74782, mean: 0.04664
[32m[0906 21-38-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17912, current rewards: 85.12894, mean: 0.04837
[32m[0906 21-38-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17929, current rewards: 90.50732, mean: 0.05000
[32m[0906 21-38-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17944, current rewards: 83.29625, mean: 0.04478
[32m[0906 21-39-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17959, current rewards: 90.14425, mean: 0.04720
[32m[0906 21-39-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17973, current rewards: 97.02999, mean: 0.04951
[32m[0906 21-39-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17987, current rewards: 103.91196, mean: 0.05170
[32m[0906 21-39-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17999, current rewards: 113.05966, mean: 0.05488
[32m[0906 21-39-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18011, current rewards: 119.73635, mean: 0.05675
[32m[0906 21-39-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18022, current rewards: 126.39148, mean: 0.05851
[32m[0906 21-40-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18033, current rewards: 133.05165, mean: 0.06020
[32m[0906 21-40-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18037, current rewards: 139.69292, mean: 0.06181
[32m[0906 21-40-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18040, current rewards: 146.34512, mean: 0.06335
[32m[0906 21-40-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18039, current rewards: 153.00286, mean: 0.06483
[32m[0906 21-40-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18038, current rewards: 159.65312, mean: 0.06625
[32m[0906 21-40-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18037, current rewards: 166.30096, mean: 0.06760
[32m[0906 21-40-53 @Agent.py:117][0m Average action selection time: 0.1804
[32m[0906 21-40-53 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-40-53 @MBExp.py:227][0m Rewards obtained: [149.14265580141742], Lows: [39], Highs: [51], Total time: 25610.855144999998
[32m[0906 21-42-50 @MBExp.py:144][0m ####################################################################
[32m[0906 21-42-50 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 21-42-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18487, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-43-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18520, current rewards: -47.07950, mean: -0.78466
[32m[0906 21-43-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18464, current rewards: -87.36880, mean: -0.79426
[32m[0906 21-43-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18423, current rewards: -137.81176, mean: -0.86132
[32m[0906 21-43-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18402, current rewards: -184.40616, mean: -0.87812
[32m[0906 21-43-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18326, current rewards: -220.50120, mean: -0.84808
[32m[0906 21-43-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18263, current rewards: -264.87461, mean: -0.85443
[32m[0906 21-43-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18149, current rewards: -315.44960, mean: -0.87625
[32m[0906 21-44-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18025, current rewards: -358.93589, mean: -0.87545
[32m[0906 21-44-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17903, current rewards: -376.03605, mean: -0.81747
[32m[0906 21-44-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17804, current rewards: -370.39320, mean: -0.72626
[32m[0906 21-44-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17723, current rewards: -364.74806, mean: -0.65134
[32m[0906 21-44-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17657, current rewards: -361.32691, mean: -0.59234
[32m[0906 21-44-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17599, current rewards: -387.48200, mean: -0.58709
[32m[0906 21-44-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17549, current rewards: -423.97817, mean: -0.59715
[32m[0906 21-45-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17507, current rewards: -462.43701, mean: -0.60847
[32m[0906 21-45-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17471, current rewards: -500.51848, mean: -0.61792
[32m[0906 21-45-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17436, current rewards: -550.37623, mean: -0.63997
[32m[0906 21-45-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17422, current rewards: -544.54621, mean: -0.59840
[32m[0906 21-45-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17422, current rewards: -538.86914, mean: -0.56132
[32m[0906 21-45-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17442, current rewards: -533.19207, mean: -0.52791
[32m[0906 21-45-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17470, current rewards: -527.51501, mean: -0.49766
[32m[0906 21-46-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17521, current rewards: -521.83794, mean: -0.47012
[32m[0906 21-46-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17569, current rewards: -516.16087, mean: -0.44497
[32m[0906 21-46-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17612, current rewards: -510.48381, mean: -0.42189
[32m[0906 21-46-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17655, current rewards: -547.12131, mean: -0.43422
[32m[0906 21-46-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17688, current rewards: -597.12131, mean: -0.45582
[32m[0906 21-46-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17717, current rewards: -647.12131, mean: -0.47582
[32m[0906 21-47-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17744, current rewards: -697.12131, mean: -0.49441
[32m[0906 21-47-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17770, current rewards: -747.12131, mean: -0.51173
[32m[0906 21-47-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17794, current rewards: -797.12131, mean: -0.52789
[32m[0906 21-47-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17813, current rewards: -847.12131, mean: -0.54303
[32m[0906 21-47-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17831, current rewards: -897.12131, mean: -0.55722
[32m[0906 21-47-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17850, current rewards: -947.12131, mean: -0.57056
[32m[0906 21-47-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17869, current rewards: -997.12131, mean: -0.58311
[32m[0906 21-48-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17884, current rewards: -1047.12131, mean: -0.59496
[32m[0906 21-48-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17902, current rewards: -1097.12131, mean: -0.60614
[32m[0906 21-48-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17915, current rewards: -1147.12131, mean: -0.61673
[32m[0906 21-48-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17929, current rewards: -1197.12131, mean: -0.62677
[32m[0906 21-48-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17946, current rewards: -1247.12131, mean: -0.63629
[32m[0906 21-48-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17959, current rewards: -1297.12131, mean: -0.64533
[32m[0906 21-49-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17969, current rewards: -1347.12131, mean: -0.65394
[32m[0906 21-49-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17980, current rewards: -1397.12131, mean: -0.66214
[32m[0906 21-49-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17991, current rewards: -1447.12131, mean: -0.66996
[32m[0906 21-49-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18000, current rewards: -1497.12131, mean: -0.67743
[32m[0906 21-49-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18004, current rewards: -1547.12131, mean: -0.68457
[32m[0906 21-49-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18004, current rewards: -1597.12131, mean: -0.69139
[32m[0906 21-49-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18003, current rewards: -1647.12131, mean: -0.69793
[32m[0906 21-50-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18004, current rewards: -1697.12131, mean: -0.70420
[32m[0906 21-50-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18006, current rewards: -1747.12131, mean: -0.71021
[32m[0906 21-50-20 @Agent.py:117][0m Average action selection time: 0.1801
[32m[0906 21-50-20 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-50-21 @MBExp.py:227][0m Rewards obtained: [-1787.1213105118245], Lows: [315], Highs: [1298], Total time: 26061.753580999997
[32m[0906 21-52-20 @MBExp.py:144][0m ####################################################################
[32m[0906 21-52-20 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 21-52-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18585, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-52-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18539, current rewards: -3.82203, mean: -0.06370
[32m[0906 21-52-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18556, current rewards: 2.77352, mean: 0.02521
[32m[0906 21-52-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18554, current rewards: 9.36136, mean: 0.05851
[32m[0906 21-52-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18540, current rewards: 15.95776, mean: 0.07599
[32m[0906 21-53-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18433, current rewards: 22.56172, mean: 0.08678
[32m[0906 21-53-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18340, current rewards: 9.97066, mean: 0.03216
[32m[0906 21-53-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18218, current rewards: 14.33249, mean: 0.03981
[32m[0906 21-53-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18079, current rewards: 20.88732, mean: 0.05094
[32m[0906 21-53-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17942, current rewards: 27.14000, mean: 0.05900
[32m[0906 21-53-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17838, current rewards: 33.38476, mean: 0.06546
[32m[0906 21-53-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17755, current rewards: 39.63158, mean: 0.07077
[32m[0906 21-54-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17681, current rewards: 45.88098, mean: 0.07521
[32m[0906 21-54-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17622, current rewards: 52.12914, mean: 0.07898
[32m[0906 21-54-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17572, current rewards: 58.37707, mean: 0.08222
[32m[0906 21-54-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17531, current rewards: 51.84964, mean: 0.06822
[32m[0906 21-54-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17488, current rewards: 56.49308, mean: 0.06974
[32m[0906 21-54-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17452, current rewards: 62.01059, mean: 0.07211
[32m[0906 21-54-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17430, current rewards: 67.48050, mean: 0.07415
[32m[0906 21-55-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17434, current rewards: 72.94344, mean: 0.07598
[32m[0906 21-55-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17446, current rewards: 78.41213, mean: 0.07764
[32m[0906 21-55-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17473, current rewards: 83.87176, mean: 0.07912
[32m[0906 21-55-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17517, current rewards: 89.34332, mean: 0.08049
[32m[0906 21-55-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17566, current rewards: 94.80974, mean: 0.08173
[32m[0906 21-55-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17603, current rewards: 100.39793, mean: 0.08297
[32m[0906 21-56-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17636, current rewards: 110.40657, mean: 0.08762
[32m[0906 21-56-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17668, current rewards: 115.92911, mean: 0.08850
[32m[0906 21-56-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17698, current rewards: 121.45380, mean: 0.08930
[32m[0906 21-56-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17725, current rewards: 105.52028, mean: 0.07484
[32m[0906 21-56-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17751, current rewards: 111.35998, mean: 0.07627
[32m[0906 21-56-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17775, current rewards: 117.15814, mean: 0.07759
[32m[0906 21-56-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17798, current rewards: 122.95696, mean: 0.07882
[32m[0906 21-57-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17827, current rewards: 128.75471, mean: 0.07997
[32m[0906 21-57-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17845, current rewards: 134.47825, mean: 0.08101
[32m[0906 21-57-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17863, current rewards: 140.31019, mean: 0.08205
[32m[0906 21-57-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17880, current rewards: 146.14201, mean: 0.08304
[32m[0906 21-57-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17896, current rewards: 141.23289, mean: 0.07803
[32m[0906 21-57-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17913, current rewards: 155.30501, mean: 0.08350
[32m[0906 21-58-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17928, current rewards: 170.32001, mean: 0.08917
[32m[0906 21-58-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17943, current rewards: 185.46399, mean: 0.09462
[32m[0906 21-58-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17958, current rewards: 200.52804, mean: 0.09977
[32m[0906 21-58-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17973, current rewards: 212.68845, mean: 0.10325
[32m[0906 21-58-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17986, current rewards: 201.45810, mean: 0.09548
[32m[0906 21-58-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17998, current rewards: 169.60957, mean: 0.07852
[32m[0906 21-58-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18011, current rewards: 123.19524, mean: 0.05574
[32m[0906 21-59-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18013, current rewards: 90.22088, mean: 0.03992
[32m[0906 21-59-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18015, current rewards: 47.77565, mean: 0.02068
[32m[0906 21-59-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18016, current rewards: 23.41533, mean: 0.00992
[32m[0906 21-59-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18016, current rewards: 29.28984, mean: 0.01215
[32m[0906 21-59-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18017, current rewards: 35.16502, mean: 0.01429
[32m[0906 21-59-51 @Agent.py:117][0m Average action selection time: 0.1802
[32m[0906 21-59-51 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-59-51 @MBExp.py:227][0m Rewards obtained: [40.914703833355986], Lows: [135], Highs: [31], Total time: 26512.909528999997
[32m[0906 22-01-52 @MBExp.py:144][0m ####################################################################
[32m[0906 22-01-52 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 22-01-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18710, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-02-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18603, current rewards: -14.03069, mean: -0.23384
[32m[0906 22-02-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18597, current rewards: -9.36638, mean: -0.08515
[32m[0906 22-02-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18549, current rewards: -4.70216, mean: -0.02939
[32m[0906 22-02-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18514, current rewards: -0.04189, mean: -0.00020
[32m[0906 22-02-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18409, current rewards: 4.61792, mean: 0.01776
[32m[0906 22-02-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18324, current rewards: 9.28072, mean: 0.02994
[32m[0906 22-02-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18203, current rewards: 13.94278, mean: 0.03873
[32m[0906 22-03-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18070, current rewards: 19.18325, mean: 0.04679
[32m[0906 22-03-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17940, current rewards: 24.18163, mean: 0.05257
[32m[0906 22-03-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17838, current rewards: 29.17456, mean: 0.05721
[32m[0906 22-03-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17753, current rewards: 34.16219, mean: 0.06100
[32m[0906 22-03-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17678, current rewards: 39.14735, mean: 0.06418
[32m[0906 22-03-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17614, current rewards: 41.93698, mean: 0.06354
[32m[0906 22-03-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17561, current rewards: 38.41714, mean: 0.05411
[32m[0906 22-04-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17516, current rewards: 43.45958, mean: 0.05718
[32m[0906 22-04-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17476, current rewards: 49.84291, mean: 0.06153
[32m[0906 22-04-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17441, current rewards: 55.09001, mean: 0.06406
[32m[0906 22-04-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17410, current rewards: 60.16087, mean: 0.06611
[32m[0906 22-04-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17411, current rewards: 65.23033, mean: 0.06795
[32m[0906 22-04-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17417, current rewards: 70.30233, mean: 0.06961
[32m[0906 22-04-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17448, current rewards: 75.37501, mean: 0.07111
[32m[0906 22-05-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17487, current rewards: 70.16113, mean: 0.06321
[32m[0906 22-05-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17529, current rewards: 75.02578, mean: 0.06468
[32m[0906 22-05-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17577, current rewards: 79.88721, mean: 0.06602
[32m[0906 22-05-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17613, current rewards: 84.31201, mean: 0.06691
[32m[0906 22-05-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17647, current rewards: 89.57954, mean: 0.06838
[32m[0906 22-05-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17680, current rewards: 94.84401, mean: 0.06974
[32m[0906 22-06-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17711, current rewards: 100.10639, mean: 0.07100
[32m[0906 22-06-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17737, current rewards: 105.37248, mean: 0.07217
[32m[0906 22-06-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17760, current rewards: 110.15212, mean: 0.07295
[32m[0906 22-06-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17781, current rewards: 120.77715, mean: 0.07742
[32m[0906 22-06-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17805, current rewards: 133.21945, mean: 0.08275
[32m[0906 22-06-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17826, current rewards: 121.10175, mean: 0.07295
[32m[0906 22-06-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17845, current rewards: 134.00053, mean: 0.07836
[32m[0906 22-07-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17865, current rewards: 149.10328, mean: 0.08472
[32m[0906 22-07-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17881, current rewards: 131.53731, mean: 0.07267
[32m[0906 22-07-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17896, current rewards: 136.58868, mean: 0.07343
[32m[0906 22-07-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17914, current rewards: 141.63919, mean: 0.07416
[32m[0906 22-07-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17929, current rewards: 146.69244, mean: 0.07484
[32m[0906 22-07-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17942, current rewards: 151.74464, mean: 0.07549
[32m[0906 22-08-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17954, current rewards: 156.66962, mean: 0.07605
[32m[0906 22-08-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17965, current rewards: 161.59761, mean: 0.07659
[32m[0906 22-08-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17978, current rewards: 166.61335, mean: 0.07714
[32m[0906 22-08-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17988, current rewards: 171.62989, mean: 0.07766
[32m[0906 22-08-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18028, current rewards: 136.86893, mean: 0.06056
[32m[0906 22-08-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18030, current rewards: 139.79118, mean: 0.06052
[32m[0906 22-08-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18030, current rewards: 143.55828, mean: 0.06083
[32m[0906 22-09-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18030, current rewards: 147.29903, mean: 0.06112
[32m[0906 22-09-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18030, current rewards: 151.00464, mean: 0.06138
[32m[0906 22-09-24 @Agent.py:117][0m Average action selection time: 0.1803
[32m[0906 22-09-24 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-09-24 @MBExp.py:227][0m Rewards obtained: [154.4766355253234], Lows: [32], Highs: [59], Total time: 26964.383890999998
[32m[0906 22-11-27 @MBExp.py:144][0m ####################################################################
[32m[0906 22-11-27 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 22-11-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18377, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-11-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18557, current rewards: -6.29255, mean: -0.10488
[32m[0906 22-11-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18548, current rewards: -1.16597, mean: -0.01060
[32m[0906 22-11-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18512, current rewards: 3.95890, mean: 0.02474
[32m[0906 22-12-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18493, current rewards: 9.08413, mean: 0.04326
[32m[0906 22-12-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18404, current rewards: 14.20613, mean: 0.05464
[32m[0906 22-12-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18320, current rewards: 19.33131, mean: 0.06236
[32m[0906 22-12-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18202, current rewards: 24.45650, mean: 0.06793
[32m[0906 22-12-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18053, current rewards: 30.10582, mean: 0.07343
[32m[0906 22-12-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17927, current rewards: 35.32956, mean: 0.07680
[32m[0906 22-12-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17833, current rewards: 40.63802, mean: 0.07968
[32m[0906 22-13-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17752, current rewards: 46.92452, mean: 0.08379
[32m[0906 22-13-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17680, current rewards: 53.30378, mean: 0.08738
[32m[0906 22-13-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17623, current rewards: 59.67349, mean: 0.09041
[32m[0906 22-13-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17571, current rewards: 66.05654, mean: 0.09304
[32m[0906 22-13-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17528, current rewards: 72.44423, mean: 0.09532
[32m[0906 22-13-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17493, current rewards: 77.87292, mean: 0.09614
[32m[0906 22-13-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17460, current rewards: 84.21403, mean: 0.09792
[32m[0906 22-14-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17432, current rewards: 90.39166, mean: 0.09933
[32m[0906 22-14-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17426, current rewards: 92.08009, mean: 0.09592
[32m[0906 22-14-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17429, current rewards: 90.56437, mean: 0.08967
[32m[0906 22-14-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17458, current rewards: 95.18485, mean: 0.08980
[32m[0906 22-14-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17498, current rewards: 99.80020, mean: 0.08991
[32m[0906 22-14-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17541, current rewards: 104.42643, mean: 0.09002
[32m[0906 22-15-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17578, current rewards: 109.18536, mean: 0.09024
[32m[0906 22-15-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17612, current rewards: 114.11196, mean: 0.09057
[32m[0906 22-15-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17644, current rewards: 118.88894, mean: 0.09075
[32m[0906 22-15-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17677, current rewards: 123.66612, mean: 0.09093
[32m[0906 22-15-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17707, current rewards: 128.42939, mean: 0.09108
[32m[0906 22-15-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17731, current rewards: 133.21051, mean: 0.09124
[32m[0906 22-15-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17762, current rewards: 137.98014, mean: 0.09138
[32m[0906 22-16-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17785, current rewards: 142.75230, mean: 0.09151
[32m[0906 22-16-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17807, current rewards: 147.52800, mean: 0.09163
[32m[0906 22-16-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17826, current rewards: 152.83128, mean: 0.09207
[32m[0906 22-16-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17844, current rewards: 157.77710, mean: 0.09227
[32m[0906 22-16-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17859, current rewards: 140.01412, mean: 0.07955
[32m[0906 22-16-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17874, current rewards: 145.40251, mean: 0.08033
[32m[0906 22-17-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17887, current rewards: 150.79907, mean: 0.08107
[32m[0906 22-17-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17901, current rewards: 156.19540, mean: 0.08178
[32m[0906 22-17-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17916, current rewards: 161.59343, mean: 0.08245
[32m[0906 22-17-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17931, current rewards: 155.54671, mean: 0.07739
[32m[0906 22-17-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17943, current rewards: 161.98692, mean: 0.07863
[32m[0906 22-17-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17953, current rewards: 167.11770, mean: 0.07920
[32m[0906 22-17-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17968, current rewards: 172.25061, mean: 0.07975
[32m[0906 22-18-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17977, current rewards: 177.38263, mean: 0.08026
[32m[0906 22-18-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17978, current rewards: 182.51615, mean: 0.08076
[32m[0906 22-18-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17979, current rewards: 187.64885, mean: 0.08123
[32m[0906 22-18-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17978, current rewards: 192.78148, mean: 0.08169
[32m[0906 22-18-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17979, current rewards: 187.15711, mean: 0.07766
[32m[0906 22-18-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17978, current rewards: 192.85938, mean: 0.07840
[32m[0906 22-18-58 @Agent.py:117][0m Average action selection time: 0.1798
[32m[0906 22-18-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-18-58 @MBExp.py:227][0m Rewards obtained: [197.38503538079468], Lows: [11], Highs: [42], Total time: 27414.569306999998
[32m[0906 22-21-03 @MBExp.py:144][0m ####################################################################
[32m[0906 22-21-03 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 22-21-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18519, current rewards: 0.90712, mean: 0.09071
[32m[0906 22-21-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18476, current rewards: 6.18034, mean: 0.10301
[32m[0906 22-21-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18459, current rewards: 11.84937, mean: 0.10772
[32m[0906 22-21-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18438, current rewards: 17.51992, mean: 0.10950
[32m[0906 22-21-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18442, current rewards: 23.18974, mean: 0.11043
[32m[0906 22-21-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18365, current rewards: 28.86017, mean: 0.11100
[32m[0906 22-22-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18276, current rewards: 34.52990, mean: 0.11139
[32m[0906 22-22-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18165, current rewards: 28.63445, mean: 0.07954
[32m[0906 22-22-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18032, current rewards: 34.55627, mean: 0.08428
[32m[0906 22-22-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17908, current rewards: 40.29948, mean: 0.08761
[32m[0906 22-22-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17809, current rewards: 46.03685, mean: 0.09027
[32m[0906 22-22-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17719, current rewards: 51.77505, mean: 0.09246
[32m[0906 22-22-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17650, current rewards: 57.51558, mean: 0.09429
[32m[0906 22-22-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17591, current rewards: 63.25684, mean: 0.09584
[32m[0906 22-23-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17540, current rewards: 68.98601, mean: 0.09716
[32m[0906 22-23-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17493, current rewards: 74.74341, mean: 0.09835
[32m[0906 22-23-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17454, current rewards: 80.53412, mean: 0.09942
[32m[0906 22-23-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17420, current rewards: 86.25454, mean: 0.10030
[32m[0906 22-23-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17387, current rewards: 91.97369, mean: 0.10107
[32m[0906 22-23-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17372, current rewards: 97.69063, mean: 0.10176
[32m[0906 22-23-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17377, current rewards: 103.40764, mean: 0.10238
[32m[0906 22-24-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17401, current rewards: 109.12326, mean: 0.10295
[32m[0906 22-24-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17437, current rewards: 114.83683, mean: 0.10346
[32m[0906 22-24-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17490, current rewards: 120.55708, mean: 0.10393
[32m[0906 22-24-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17529, current rewards: 60.70634, mean: 0.05017
[32m[0906 22-24-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17569, current rewards: 32.78182, mean: 0.02602
[32m[0906 22-24-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17603, current rewards: 13.48598, mean: 0.01029
[32m[0906 22-25-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17633, current rewards: -5.87250, mean: -0.00432
[32m[0906 22-25-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17661, current rewards: -23.24134, mean: -0.01648
[32m[0906 22-25-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17686, current rewards: -42.53795, mean: -0.02914
[32m[0906 22-25-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17713, current rewards: -57.55927, mean: -0.03812
[32m[0906 22-25-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17737, current rewards: -59.09042, mean: -0.03788
[32m[0906 22-25-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17759, current rewards: -115.23846, mean: -0.07158
[32m[0906 22-25-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17781, current rewards: -159.16974, mean: -0.09589
[32m[0906 22-26-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17801, current rewards: -195.65945, mean: -0.11442
[32m[0906 22-26-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17819, current rewards: -194.26741, mean: -0.11038
[32m[0906 22-26-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17840, current rewards: -188.34483, mean: -0.10406
[32m[0906 22-26-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17855, current rewards: -182.41993, mean: -0.09808
[32m[0906 22-26-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17872, current rewards: -176.48917, mean: -0.09240
[32m[0906 22-26-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17888, current rewards: -170.56228, mean: -0.08702
[32m[0906 22-27-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17902, current rewards: -164.81858, mean: -0.08200
[32m[0906 22-27-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17915, current rewards: -158.89136, mean: -0.07713
[32m[0906 22-27-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17926, current rewards: -180.32654, mean: -0.08546
[32m[0906 22-27-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17937, current rewards: -247.81887, mean: -0.11473
[32m[0906 22-27-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17941, current rewards: -308.08892, mean: -0.13941
[32m[0906 22-27-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17942, current rewards: -375.85258, mean: -0.16631
[32m[0906 22-27-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17943, current rewards: -394.69280, mean: -0.17086
[32m[0906 22-28-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17943, current rewards: -405.87381, mean: -0.17198
[32m[0906 22-28-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17945, current rewards: -411.64258, mean: -0.17081
[32m[0906 22-28-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17946, current rewards: -406.79692, mean: -0.16536
[32m[0906 22-28-32 @Agent.py:117][0m Average action selection time: 0.1795
[32m[0906 22-28-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-28-32 @MBExp.py:227][0m Rewards obtained: [-402.90940833472456], Lows: [340], Highs: [30], Total time: 27864.050133999997
[32m[0906 22-30-40 @MBExp.py:144][0m ####################################################################
[32m[0906 22-30-40 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 22-30-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18490, current rewards: 1.07681, mean: 0.10768
[32m[0906 22-30-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18463, current rewards: 6.74089, mean: 0.11235
[32m[0906 22-31-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18450, current rewards: 12.43349, mean: 0.11303
[32m[0906 22-31-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18460, current rewards: 18.12607, mean: 0.11329
[32m[0906 22-31-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18447, current rewards: 23.81853, mean: 0.11342
[32m[0906 22-31-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18381, current rewards: 29.51107, mean: 0.11350
[32m[0906 22-31-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18292, current rewards: 34.87472, mean: 0.11250
[32m[0906 22-31-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18170, current rewards: 39.49934, mean: 0.10972
[32m[0906 22-31-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18039, current rewards: 45.02560, mean: 0.10982
[32m[0906 22-32-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17911, current rewards: 50.55224, mean: 0.10990
[32m[0906 22-32-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17809, current rewards: 24.98288, mean: 0.04899
[32m[0906 22-32-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17724, current rewards: 30.60843, mean: 0.05466
[32m[0906 22-32-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17650, current rewards: 35.75055, mean: 0.05861
[32m[0906 22-32-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17587, current rewards: 40.88914, mean: 0.06195
[32m[0906 22-32-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17541, current rewards: 46.03119, mean: 0.06483
[32m[0906 22-32-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17495, current rewards: 52.07285, mean: 0.06852
[32m[0906 22-33-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17454, current rewards: 57.28627, mean: 0.07072
[32m[0906 22-33-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17420, current rewards: 62.49135, mean: 0.07266
[32m[0906 22-33-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17391, current rewards: 67.70322, mean: 0.07440
[32m[0906 22-33-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17364, current rewards: 72.91238, mean: 0.07595
[32m[0906 22-33-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17368, current rewards: 78.12690, mean: 0.07735
[32m[0906 22-33-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17387, current rewards: 83.34218, mean: 0.07862
[32m[0906 22-33-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17414, current rewards: 67.32548, mean: 0.06065
[32m[0906 22-34-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17504, current rewards: 72.79198, mean: 0.06275
[32m[0906 22-34-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17581, current rewards: 79.28057, mean: 0.06552
[32m[0906 22-34-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17666, current rewards: 85.93917, mean: 0.06821
[32m[0906 22-34-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17737, current rewards: 92.81529, mean: 0.07085
[32m[0906 22-34-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17789, current rewards: 99.29315, mean: 0.07301
[32m[0906 22-34-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17886, current rewards: 105.91887, mean: 0.07512
[32m[0906 22-35-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18015, current rewards: 112.13413, mean: 0.07680
[32m[0906 22-35-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18053, current rewards: 105.26963, mean: 0.06971
[32m[0906 22-35-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18066, current rewards: 110.28531, mean: 0.07070
[32m[0906 22-35-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18079, current rewards: 115.30426, mean: 0.07162
[32m[0906 22-35-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18093, current rewards: 120.32349, mean: 0.07248
[32m[0906 22-35-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18103, current rewards: 125.33753, mean: 0.07330
[32m[0906 22-35-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18110, current rewards: 130.35178, mean: 0.07406
[32m[0906 22-36-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18120, current rewards: 136.97061, mean: 0.07567
[32m[0906 22-36-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18128, current rewards: 144.70923, mean: 0.07780
[32m[0906 22-36-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18136, current rewards: 152.36207, mean: 0.07977
[32m[0906 22-36-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18141, current rewards: 160.01727, mean: 0.08164
[32m[0906 22-36-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18148, current rewards: 167.66495, mean: 0.08342
[32m[0906 22-36-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18159, current rewards: 175.31964, mean: 0.08511
[32m[0906 22-37-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18167, current rewards: 182.97416, mean: 0.08672
[32m[0906 22-37-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18168, current rewards: 190.61938, mean: 0.08825
[32m[0906 22-37-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18162, current rewards: 198.26312, mean: 0.08971
[32m[0906 22-37-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18158, current rewards: 205.90816, mean: 0.09111
[32m[0906 22-37-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18154, current rewards: 191.32396, mean: 0.08282
[32m[0906 22-37-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18150, current rewards: 197.22249, mean: 0.08357
[32m[0906 22-37-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18146, current rewards: 202.83733, mean: 0.08416
[32m[0906 22-38-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18143, current rewards: 208.46423, mean: 0.08474
[32m[0906 22-38-14 @Agent.py:117][0m Average action selection time: 0.1814
[32m[0906 22-38-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-38-14 @MBExp.py:227][0m Rewards obtained: [212.96034343490226], Lows: [32], Highs: [20], Total time: 28318.293121
[32m[0906 22-40-24 @MBExp.py:144][0m ####################################################################
[32m[0906 22-40-24 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 22-40-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18430, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-40-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18549, current rewards: -4.22572, mean: -0.07043
[32m[0906 22-40-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18527, current rewards: 1.38856, mean: 0.01262
[32m[0906 22-40-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18482, current rewards: 7.00302, mean: 0.04377
[32m[0906 22-41-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18441, current rewards: 12.61493, mean: 0.06007
[32m[0906 22-41-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18379, current rewards: 18.14653, mean: 0.06979
[32m[0906 22-41-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18252, current rewards: 22.88417, mean: 0.07382
[32m[0906 22-41-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18124, current rewards: 28.42022, mean: 0.07895
[32m[0906 22-41-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17966, current rewards: 13.09432, mean: 0.03194
[32m[0906 22-41-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17847, current rewards: 17.98234, mean: 0.03909
[32m[0906 22-41-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17748, current rewards: 23.46734, mean: 0.04601
[32m[0906 22-42-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17670, current rewards: 28.96228, mean: 0.05172
[32m[0906 22-42-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17604, current rewards: 34.45988, mean: 0.05649
[32m[0906 22-42-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17548, current rewards: 39.94164, mean: 0.06052
[32m[0906 22-42-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17503, current rewards: 45.42292, mean: 0.06398
[32m[0906 22-42-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17461, current rewards: 50.92230, mean: 0.06700
[32m[0906 22-42-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17424, current rewards: 56.39231, mean: 0.06962
[32m[0906 22-42-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17391, current rewards: 61.87444, mean: 0.07195
[32m[0906 22-43-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17372, current rewards: 44.35494, mean: 0.04874
[32m[0906 22-43-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17356, current rewards: 52.68407, mean: 0.05488
[32m[0906 22-43-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17362, current rewards: 61.17164, mean: 0.06057
[32m[0906 22-43-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17391, current rewards: 69.64887, mean: 0.06571
[32m[0906 22-43-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17426, current rewards: 77.98259, mean: 0.07025
[32m[0906 22-43-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17475, current rewards: 86.47738, mean: 0.07455
[32m[0906 22-43-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17513, current rewards: 94.94872, mean: 0.07847
[32m[0906 22-44-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17549, current rewards: 103.43208, mean: 0.08209
[32m[0906 22-44-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17586, current rewards: 111.91205, mean: 0.08543
[32m[0906 22-44-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17620, current rewards: 120.38812, mean: 0.08852
[32m[0906 22-44-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17646, current rewards: 128.87499, mean: 0.09140
[32m[0906 22-44-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17671, current rewards: 114.02479, mean: 0.07810
[32m[0906 22-44-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17696, current rewards: 119.81919, mean: 0.07935
[32m[0906 22-45-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17717, current rewards: 124.94498, mean: 0.08009
[32m[0906 22-45-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17738, current rewards: 130.07545, mean: 0.08079
[32m[0906 22-45-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17763, current rewards: 135.20244, mean: 0.08145
[32m[0906 22-45-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17782, current rewards: 140.33291, mean: 0.08207
[32m[0906 22-45-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17803, current rewards: 145.46283, mean: 0.08265
[32m[0906 22-45-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17816, current rewards: 146.38845, mean: 0.08088
[32m[0906 22-45-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17831, current rewards: 135.88474, mean: 0.07306
[32m[0906 22-46-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17847, current rewards: 141.24461, mean: 0.07395
[32m[0906 22-46-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17863, current rewards: 146.88774, mean: 0.07494
[32m[0906 22-46-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17878, current rewards: 152.53276, mean: 0.07589
[32m[0906 22-46-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17891, current rewards: 158.17700, mean: 0.07678
[32m[0906 22-46-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17904, current rewards: 163.82775, mean: 0.07764
[32m[0906 22-46-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17912, current rewards: 169.47540, mean: 0.07846
[32m[0906 22-47-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17914, current rewards: 175.12312, mean: 0.07924
[32m[0906 22-47-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17917, current rewards: 180.76646, mean: 0.07999
[32m[0906 22-47-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17919, current rewards: 187.38573, mean: 0.08112
[32m[0906 22-47-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17924, current rewards: 193.09413, mean: 0.08182
[32m[0906 22-47-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17926, current rewards: 198.83576, mean: 0.08250
[32m[0906 22-47-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17928, current rewards: 192.37057, mean: 0.07820
[32m[0906 22-47-52 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0906 22-47-52 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-47-53 @MBExp.py:227][0m Rewards obtained: [196.7688091727104], Lows: [37], Highs: [31], Total time: 28767.266655
[32m[0906 22-50-04 @MBExp.py:144][0m ####################################################################
[32m[0906 22-50-04 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 22-50-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18475, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-50-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18472, current rewards: -31.20537, mean: -0.52009
[32m[0906 22-50-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18462, current rewards: -27.41024, mean: -0.24918
[32m[0906 22-50-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18470, current rewards: -23.62226, mean: -0.14764
[32m[0906 22-50-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18445, current rewards: -19.59452, mean: -0.09331
[32m[0906 22-50-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18354, current rewards: -15.80597, mean: -0.06079
[32m[0906 22-51-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18244, current rewards: -12.01573, mean: -0.03876
[32m[0906 22-51-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18119, current rewards: -28.98298, mean: -0.08051
[32m[0906 22-51-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17964, current rewards: -24.54010, mean: -0.05985
[32m[0906 22-51-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17844, current rewards: -20.46054, mean: -0.04448
[32m[0906 22-51-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17753, current rewards: -16.37811, mean: -0.03211
[32m[0906 22-51-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17679, current rewards: -12.29494, mean: -0.02196
[32m[0906 22-51-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17611, current rewards: -18.70622, mean: -0.03067
[32m[0906 22-52-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17554, current rewards: -13.03572, mean: -0.01975
[32m[0906 22-52-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17503, current rewards: -6.79833, mean: -0.00958
[32m[0906 22-52-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17458, current rewards: -0.56679, mean: -0.00075
[32m[0906 22-52-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17420, current rewards: 5.66515, mean: 0.00699
[32m[0906 22-52-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17385, current rewards: 11.89925, mean: 0.01384
[32m[0906 22-52-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17357, current rewards: 18.13368, mean: 0.01993
[32m[0906 22-52-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17331, current rewards: 24.36738, mean: 0.02538
[32m[0906 22-53-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17332, current rewards: 30.60043, mean: 0.03030
[32m[0906 22-53-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17347, current rewards: 41.92957, mean: 0.03956
[32m[0906 22-53-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17376, current rewards: 48.27932, mean: 0.04349
[32m[0906 22-53-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17428, current rewards: 43.69700, mean: 0.03767
[32m[0906 22-53-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17480, current rewards: 49.69941, mean: 0.04107
[32m[0906 22-53-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17525, current rewards: 55.69548, mean: 0.04420
[32m[0906 22-53-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17564, current rewards: 61.69389, mean: 0.04709
[32m[0906 22-54-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17599, current rewards: 67.69843, mean: 0.04978
[32m[0906 22-54-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17628, current rewards: 73.69346, mean: 0.05226
[32m[0906 22-54-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17660, current rewards: 79.32650, mean: 0.05433
[32m[0906 22-54-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17686, current rewards: 85.01077, mean: 0.05630
[32m[0906 22-54-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17714, current rewards: 89.59134, mean: 0.05743
[32m[0906 22-54-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17738, current rewards: 94.14240, mean: 0.05847
[32m[0906 22-54-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17759, current rewards: 98.77678, mean: 0.05950
[32m[0906 22-55-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17781, current rewards: 103.35745, mean: 0.06044
[32m[0906 22-55-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17801, current rewards: 107.88533, mean: 0.06130
[32m[0906 22-55-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17819, current rewards: 112.46477, mean: 0.06214
[32m[0906 22-55-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17835, current rewards: 117.09519, mean: 0.06295
[32m[0906 22-55-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17856, current rewards: 105.09052, mean: 0.05502
[32m[0906 22-55-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17878, current rewards: 84.22014, mean: 0.04297
[32m[0906 22-56-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17891, current rewards: 88.72748, mean: 0.04414
[32m[0906 22-56-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17904, current rewards: 94.67656, mean: 0.04596
[32m[0906 22-56-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17918, current rewards: 100.60626, mean: 0.04768
[32m[0906 22-56-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17921, current rewards: 106.54554, mean: 0.04933
[32m[0906 22-56-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17925, current rewards: 112.47856, mean: 0.05090
[32m[0906 22-56-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17925, current rewards: 118.41472, mean: 0.05240
[32m[0906 22-56-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17926, current rewards: 126.16808, mean: 0.05462
[32m[0906 22-57-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17928, current rewards: 132.04072, mean: 0.05595
[32m[0906 22-57-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17929, current rewards: 137.91150, mean: 0.05722
[32m[0906 22-57-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17931, current rewards: 143.77759, mean: 0.05845
[32m[0906 22-57-33 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0906 22-57-33 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-57-33 @MBExp.py:227][0m Rewards obtained: [148.4774277539209], Lows: [45], Highs: [30], Total time: 29216.286197999998
[32m[0906 22-59-47 @MBExp.py:144][0m ####################################################################
[32m[0906 22-59-47 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 22-59-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18536, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-59-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18654, current rewards: -109.00000, mean: -1.81667
[32m[0906 23-00-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18595, current rewards: -209.00000, mean: -1.90000
[32m[0906 23-00-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18516, current rewards: -309.00000, mean: -1.93125
[32m[0906 23-00-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18486, current rewards: -409.00000, mean: -1.94762
[32m[0906 23-00-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18384, current rewards: -509.00000, mean: -1.95769
[32m[0906 23-00-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18278, current rewards: -609.00000, mean: -1.96452
[32m[0906 23-00-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18137, current rewards: -709.00000, mean: -1.96944
[32m[0906 23-01-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17979, current rewards: -809.00000, mean: -1.97317
[32m[0906 23-01-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17859, current rewards: -909.00000, mean: -1.97609
[32m[0906 23-01-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17757, current rewards: -1009.00000, mean: -1.97843
[32m[0906 23-01-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17678, current rewards: -1109.00000, mean: -1.98036
[32m[0906 23-01-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17610, current rewards: -1209.00000, mean: -1.98197
[32m[0906 23-01-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17553, current rewards: -1309.00000, mean: -1.98333
[32m[0906 23-01-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17504, current rewards: -1409.00000, mean: -1.98451
[32m[0906 23-02-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17462, current rewards: -1509.00000, mean: -1.98553
[32m[0906 23-02-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17431, current rewards: -1609.00000, mean: -1.98642
[32m[0906 23-02-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17397, current rewards: -1709.00000, mean: -1.98721
[32m[0906 23-02-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17368, current rewards: -1809.00000, mean: -1.98791
[32m[0906 23-02-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17343, current rewards: -1909.00000, mean: -1.98854
[32m[0906 23-02-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17333, current rewards: -2009.00000, mean: -1.98911
[32m[0906 23-02-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17340, current rewards: -2109.00000, mean: -1.98962
[32m[0906 23-03-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17369, current rewards: -2209.00000, mean: -1.99009
[32m[0906 23-03-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17412, current rewards: -2309.00000, mean: -1.99052
[32m[0906 23-03-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17458, current rewards: -2409.00000, mean: -1.99091
[32m[0906 23-03-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17501, current rewards: -2509.00000, mean: -1.99127
[32m[0906 23-03-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17541, current rewards: -2609.00000, mean: -1.99160
[32m[0906 23-03-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17579, current rewards: -2709.00000, mean: -1.99191
[32m[0906 23-03-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17610, current rewards: -2809.00000, mean: -1.99220
[32m[0906 23-04-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17639, current rewards: -2909.00000, mean: -1.99247
[32m[0906 23-04-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17671, current rewards: -3009.00000, mean: -1.99272
[32m[0906 23-04-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17694, current rewards: -3109.00000, mean: -1.99295
[32m[0906 23-04-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17716, current rewards: -3209.00000, mean: -1.99317
[32m[0906 23-04-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17737, current rewards: -3309.00000, mean: -1.99337
[32m[0906 23-04-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17756, current rewards: -3409.00000, mean: -1.99357
[32m[0906 23-05-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17776, current rewards: -3509.00000, mean: -1.99375
[32m[0906 23-05-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17795, current rewards: -3609.00000, mean: -1.99392
[32m[0906 23-05-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17812, current rewards: -3709.00000, mean: -1.99409
[32m[0906 23-05-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17829, current rewards: -3809.00000, mean: -1.99424
[32m[0906 23-05-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17843, current rewards: -3909.00000, mean: -1.99439
[32m[0906 23-05-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17860, current rewards: -4009.00000, mean: -1.99453
[32m[0906 23-05-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17874, current rewards: -4109.00000, mean: -1.99466
[32m[0906 23-06-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17886, current rewards: -4209.00000, mean: -1.99479
[32m[0906 23-06-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17891, current rewards: -4309.00000, mean: -1.99491
[32m[0906 23-06-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17895, current rewards: -4409.00000, mean: -1.99502
[32m[0906 23-06-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17897, current rewards: -4509.00000, mean: -1.99513
[32m[0906 23-06-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17899, current rewards: -4609.00000, mean: -1.99524
[32m[0906 23-06-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17900, current rewards: -4709.00000, mean: -1.99534
[32m[0906 23-06-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17902, current rewards: -4809.00000, mean: -1.99544
[32m[0906 23-07-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17905, current rewards: -4909.00000, mean: -1.99553
[32m[0906 23-07-15 @Agent.py:117][0m Average action selection time: 0.1791
[32m[0906 23-07-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-07-15 @MBExp.py:227][0m Rewards obtained: [-4989], Lows: [2489], Highs: [11], Total time: 29664.694720999996
[32m[0906 23-09-31 @MBExp.py:144][0m ####################################################################
[32m[0906 23-09-31 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 23-09-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18463, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-09-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18487, current rewards: -15.46984, mean: -0.25783
[32m[0906 23-09-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18496, current rewards: -11.91755, mean: -0.10834
[32m[0906 23-10-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18482, current rewards: -7.99389, mean: -0.04996
[32m[0906 23-10-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18451, current rewards: -4.75196, mean: -0.02263
[32m[0906 23-10-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18368, current rewards: -1.52076, mean: -0.00585
[32m[0906 23-10-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18291, current rewards: 1.70788, mean: 0.00551
[32m[0906 23-10-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18152, current rewards: 4.93812, mean: 0.01372
[32m[0906 23-10-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17996, current rewards: 8.16952, mean: 0.01993
[32m[0906 23-10-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17871, current rewards: 11.40052, mean: 0.02478
[32m[0906 23-11-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17776, current rewards: 12.50214, mean: 0.02451
[32m[0906 23-11-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17706, current rewards: -15.36981, mean: -0.02745
[32m[0906 23-11-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17671, current rewards: -31.90432, mean: -0.05230
[32m[0906 23-11-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17625, current rewards: -62.38079, mean: -0.09452
[32m[0906 23-11-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17576, current rewards: -88.45654, mean: -0.12459
[32m[0906 23-11-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17545, current rewards: -110.77870, mean: -0.14576
[32m[0906 23-11-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17530, current rewards: -139.67981, mean: -0.17244
[32m[0906 23-12-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17512, current rewards: -160.56030, mean: -0.18670
[32m[0906 23-12-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17487, current rewards: -160.31808, mean: -0.17617
[32m[0906 23-12-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17454, current rewards: -188.20355, mean: -0.19605
[32m[0906 23-12-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17513, current rewards: -218.05707, mean: -0.21590
[32m[0906 23-12-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17533, current rewards: -219.01170, mean: -0.20661
[32m[0906 23-12-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17598, current rewards: -218.73243, mean: -0.19706
[32m[0906 23-12-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17694, current rewards: -215.26246, mean: -0.18557
[32m[0906 23-13-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17765, current rewards: -213.90508, mean: -0.17678
[32m[0906 23-13-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17812, current rewards: -218.24302, mean: -0.17321
[32m[0906 23-13-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17837, current rewards: -210.58537, mean: -0.16075
[32m[0906 23-13-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17860, current rewards: -202.93028, mean: -0.14921
[32m[0906 23-13-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17879, current rewards: -198.29166, mean: -0.14063
[32m[0906 23-13-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17897, current rewards: -195.64249, mean: -0.13400
[32m[0906 23-14-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17916, current rewards: -192.99331, mean: -0.12781
[32m[0906 23-14-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17934, current rewards: -190.34414, mean: -0.12202
[32m[0906 23-14-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17951, current rewards: -187.69496, mean: -0.11658
[32m[0906 23-14-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17968, current rewards: -219.79424, mean: -0.13241
[32m[0906 23-14-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17987, current rewards: -269.79424, mean: -0.15777
[32m[0906 23-14-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18002, current rewards: -319.79424, mean: -0.18170
[32m[0906 23-14-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18012, current rewards: -369.79424, mean: -0.20431
[32m[0906 23-15-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18022, current rewards: -419.79424, mean: -0.22570
[32m[0906 23-15-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18031, current rewards: -469.79424, mean: -0.24597
[32m[0906 23-15-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18040, current rewards: -519.79424, mean: -0.26520
[32m[0906 23-15-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18050, current rewards: -569.79424, mean: -0.28348
[32m[0906 23-15-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18057, current rewards: -619.79424, mean: -0.30087
[32m[0906 23-15-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18059, current rewards: -669.79424, mean: -0.31744
[32m[0906 23-16-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18058, current rewards: -692.62967, mean: -0.32066
[32m[0906 23-16-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18058, current rewards: -683.57623, mean: -0.30931
[32m[0906 23-16-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18056, current rewards: -679.12942, mean: -0.30050
[32m[0906 23-16-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18054, current rewards: -676.48024, mean: -0.29285
[32m[0906 23-16-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18054, current rewards: -673.83107, mean: -0.28552
[32m[0906 23-16-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18056, current rewards: -699.61245, mean: -0.29030
[32m[0906 23-16-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18054, current rewards: -749.61245, mean: -0.30472
[32m[0906 23-17-03 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0906 23-17-03 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-17-03 @MBExp.py:227][0m Rewards obtained: [-789.6124450588669], Lows: [106], Highs: [744], Total time: 30116.799837999995
[32m[0906 23-19-21 @MBExp.py:144][0m ####################################################################
[32m[0906 23-19-21 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 23-19-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18506, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-19-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18537, current rewards: -33.73779, mean: -0.56230
[32m[0906 23-19-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18454, current rewards: -82.66832, mean: -0.75153
[32m[0906 23-19-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18468, current rewards: -132.13863, mean: -0.82587
[32m[0906 23-20-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18433, current rewards: -188.69694, mean: -0.89856
[32m[0906 23-20-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18346, current rewards: -183.23785, mean: -0.70476
[32m[0906 23-20-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18215, current rewards: -177.81554, mean: -0.57360
[32m[0906 23-20-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18112, current rewards: -172.38819, mean: -0.47886
[32m[0906 23-20-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17966, current rewards: -166.96787, mean: -0.40724
[32m[0906 23-20-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17841, current rewards: -180.52507, mean: -0.39245
[32m[0906 23-20-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17746, current rewards: -187.01506, mean: -0.36670
[32m[0906 23-21-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17671, current rewards: -181.49373, mean: -0.32410
[32m[0906 23-21-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17607, current rewards: -175.91030, mean: -0.28838
[32m[0906 23-21-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17550, current rewards: -170.37571, mean: -0.25815
[32m[0906 23-21-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17500, current rewards: -164.84137, mean: -0.23217
[32m[0906 23-21-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17466, current rewards: -168.49172, mean: -0.22170
[32m[0906 23-21-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17428, current rewards: -162.68184, mean: -0.20084
[32m[0906 23-21-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17394, current rewards: -156.80607, mean: -0.18233
[32m[0906 23-21-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17364, current rewards: -150.93037, mean: -0.16586
[32m[0906 23-22-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17340, current rewards: -145.07812, mean: -0.15112
[32m[0906 23-22-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17325, current rewards: -139.77927, mean: -0.13840
[32m[0906 23-22-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17332, current rewards: -133.82355, mean: -0.12625
[32m[0906 23-22-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17363, current rewards: -127.86520, mean: -0.11519
[32m[0906 23-22-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17390, current rewards: -121.90455, mean: -0.10509
[32m[0906 23-22-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17437, current rewards: -115.94054, mean: -0.09582
[32m[0906 23-23-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17487, current rewards: -109.97856, mean: -0.08728
[32m[0906 23-23-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17528, current rewards: -104.01799, mean: -0.07940
[32m[0906 23-23-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17565, current rewards: -98.06325, mean: -0.07211
[32m[0906 23-23-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17604, current rewards: -92.10074, mean: -0.06532
[32m[0906 23-23-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17636, current rewards: -86.13688, mean: -0.05900
[32m[0906 23-23-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17660, current rewards: -80.17691, mean: -0.05310
[32m[0906 23-23-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17686, current rewards: -85.40673, mean: -0.05475
[32m[0906 23-24-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17713, current rewards: -78.26020, mean: -0.04861
[32m[0906 23-24-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17735, current rewards: -72.48742, mean: -0.04367
[32m[0906 23-24-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17756, current rewards: -66.72338, mean: -0.03902
[32m[0906 23-24-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17777, current rewards: -60.95768, mean: -0.03464
[32m[0906 23-24-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17795, current rewards: -54.22547, mean: -0.02996
[32m[0906 23-24-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17811, current rewards: -48.50479, mean: -0.02608
[32m[0906 23-25-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17827, current rewards: -42.78106, mean: -0.02240
[32m[0906 23-25-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17847, current rewards: -37.05812, mean: -0.01891
[32m[0906 23-25-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17862, current rewards: -31.33589, mean: -0.01559
[32m[0906 23-25-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17877, current rewards: -25.61372, mean: -0.01243
[32m[0906 23-25-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17882, current rewards: -19.89432, mean: -0.00943
[32m[0906 23-25-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17884, current rewards: -14.17693, mean: -0.00656
[32m[0906 23-25-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17888, current rewards: -8.85438, mean: -0.00401
[32m[0906 23-26-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17891, current rewards: -11.56022, mean: -0.00512
[32m[0906 23-26-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17902, current rewards: -49.05554, mean: -0.02124
[32m[0906 23-26-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17906, current rewards: -90.33940, mean: -0.03828
[32m[0906 23-26-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17908, current rewards: -129.87698, mean: -0.05389
[32m[0906 23-26-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17913, current rewards: -165.15707, mean: -0.06714
[32m[0906 23-26-49 @Agent.py:117][0m Average action selection time: 0.1791
[32m[0906 23-26-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-26-50 @MBExp.py:227][0m Rewards obtained: [-197.26813922456444], Lows: [227], Highs: [31], Total time: 30565.442075999996
[32m[0906 23-29-10 @MBExp.py:144][0m ####################################################################
[32m[0906 23-29-10 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 23-29-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18472, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-29-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18681, current rewards: -5.78151, mean: -0.09636
[32m[0906 23-29-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18552, current rewards: -0.02011, mean: -0.00018
[32m[0906 23-29-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18507, current rewards: 9.43299, mean: 0.05896
[32m[0906 23-29-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18494, current rewards: 14.79636, mean: 0.07046
[32m[0906 23-29-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18387, current rewards: 20.16148, mean: 0.07754
[32m[0906 23-30-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18254, current rewards: 25.52720, mean: 0.08235
[32m[0906 23-30-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18141, current rewards: 30.89084, mean: 0.08581
[32m[0906 23-30-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17980, current rewards: -7.99731, mean: -0.01951
[32m[0906 23-30-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17857, current rewards: 0.40627, mean: 0.00088
[32m[0906 23-30-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17757, current rewards: 6.86510, mean: 0.01346
[32m[0906 23-30-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17671, current rewards: 12.37119, mean: 0.02209
[32m[0906 23-30-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17604, current rewards: -35.52941, mean: -0.05824
[32m[0906 23-31-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17549, current rewards: -85.52941, mean: -0.12959
[32m[0906 23-31-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17498, current rewards: -135.52941, mean: -0.19089
[32m[0906 23-31-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17454, current rewards: -185.52941, mean: -0.24412
[32m[0906 23-31-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17421, current rewards: -235.52941, mean: -0.29078
[32m[0906 23-31-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17387, current rewards: -285.52941, mean: -0.33201
[32m[0906 23-31-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17357, current rewards: -335.52941, mean: -0.36871
[32m[0906 23-31-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17330, current rewards: -385.52941, mean: -0.40159
[32m[0906 23-32-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17304, current rewards: -435.52941, mean: -0.43122
[32m[0906 23-32-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17305, current rewards: -485.52941, mean: -0.45805
[32m[0906 23-32-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17326, current rewards: -535.52941, mean: -0.48246
[32m[0906 23-32-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17356, current rewards: -585.52941, mean: -0.50477
[32m[0906 23-32-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17397, current rewards: -635.52941, mean: -0.52523
[32m[0906 23-32-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17445, current rewards: -685.52941, mean: -0.54407
[32m[0906 23-32-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17484, current rewards: -735.52941, mean: -0.56147
[32m[0906 23-33-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17520, current rewards: -785.52941, mean: -0.57760
[32m[0906 23-33-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17550, current rewards: -835.52941, mean: -0.59257
[32m[0906 23-33-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17583, current rewards: -885.52941, mean: -0.60653
[32m[0906 23-33-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17613, current rewards: -935.52941, mean: -0.61956
[32m[0906 23-33-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17639, current rewards: -985.52941, mean: -0.63175
[32m[0906 23-33-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17665, current rewards: -1035.52941, mean: -0.64319
[32m[0906 23-34-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17688, current rewards: -1085.52941, mean: -0.65393
[32m[0906 23-34-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17707, current rewards: -1135.52941, mean: -0.66405
[32m[0906 23-34-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17727, current rewards: -1185.52941, mean: -0.67360
[32m[0906 23-34-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17744, current rewards: -1235.52941, mean: -0.68261
[32m[0906 23-34-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17762, current rewards: -1285.52941, mean: -0.69114
[32m[0906 23-34-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17778, current rewards: -1335.52941, mean: -0.69923
[32m[0906 23-34-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17794, current rewards: -1385.52941, mean: -0.70690
[32m[0906 23-35-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17811, current rewards: -1435.52941, mean: -0.71419
[32m[0906 23-35-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17824, current rewards: -1485.52941, mean: -0.72113
[32m[0906 23-35-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17829, current rewards: -1535.52941, mean: -0.72774
[32m[0906 23-35-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17834, current rewards: -1585.52941, mean: -0.73404
[32m[0906 23-35-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17839, current rewards: -1635.52941, mean: -0.74006
[32m[0906 23-35-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17841, current rewards: -1685.52941, mean: -0.74581
[32m[0906 23-36-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17845, current rewards: -1735.52941, mean: -0.75131
[32m[0906 23-36-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17848, current rewards: -1785.52941, mean: -0.75658
[32m[0906 23-36-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17851, current rewards: -1835.52941, mean: -0.76163
[32m[0906 23-36-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17854, current rewards: -1885.52941, mean: -0.76648
[32m[0906 23-36-37 @Agent.py:117][0m Average action selection time: 0.1786
[32m[0906 23-36-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-36-37 @MBExp.py:227][0m Rewards obtained: [-1925.5294143486647], Lows: [21], Highs: [1949], Total time: 31012.615133999996
[32m[0906 23-38-59 @MBExp.py:144][0m ####################################################################
[32m[0906 23-38-59 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 23-39-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18479, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-39-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18499, current rewards: -11.13121, mean: -0.18552
[32m[0906 23-39-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18511, current rewards: -6.21140, mean: -0.05647
[32m[0906 23-39-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18480, current rewards: -0.12917, mean: -0.00081
[32m[0906 23-39-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18446, current rewards: 4.84513, mean: 0.02307
[32m[0906 23-39-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18393, current rewards: 1.89504, mean: 0.00729
[32m[0906 23-39-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18287, current rewards: 8.45838, mean: 0.02729
[32m[0906 23-40-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18168, current rewards: 15.02283, mean: 0.04173
[32m[0906 23-40-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18014, current rewards: 21.58851, mean: 0.05265
[32m[0906 23-40-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17891, current rewards: 28.13317, mean: 0.06116
[32m[0906 23-40-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17788, current rewards: 34.70355, mean: 0.06805
[32m[0906 23-40-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17706, current rewards: 41.17399, mean: 0.07352
[32m[0906 23-40-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17638, current rewards: 26.25969, mean: 0.04305
[32m[0906 23-40-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17579, current rewards: 30.71555, mean: 0.04654
[32m[0906 23-41-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17528, current rewards: 35.12769, mean: 0.04948
[32m[0906 23-41-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17482, current rewards: 39.53732, mean: 0.05202
[32m[0906 23-41-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17446, current rewards: 43.94968, mean: 0.05426
[32m[0906 23-41-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17411, current rewards: 48.36257, mean: 0.05624
[32m[0906 23-41-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17378, current rewards: 44.06928, mean: 0.04843
[32m[0906 23-41-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17352, current rewards: -23.00817, mean: -0.02397
[32m[0906 23-41-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17336, current rewards: -81.33133, mean: -0.08053
[32m[0906 23-42-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17325, current rewards: -142.22529, mean: -0.13417
[32m[0906 23-42-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17338, current rewards: -192.83573, mean: -0.17373
[32m[0906 23-42-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17367, current rewards: -212.46992, mean: -0.18316
[32m[0906 23-42-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17404, current rewards: -245.50380, mean: -0.20290
[32m[0906 23-42-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17454, current rewards: -265.36573, mean: -0.21061
[32m[0906 23-42-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17493, current rewards: -328.62729, mean: -0.25086
[32m[0906 23-42-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17533, current rewards: -390.33337, mean: -0.28701
[32m[0906 23-43-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17568, current rewards: -393.10615, mean: -0.27880
[32m[0906 23-43-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17601, current rewards: -389.86782, mean: -0.26703
[32m[0906 23-43-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17631, current rewards: -386.66453, mean: -0.25607
[32m[0906 23-43-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17662, current rewards: -383.44975, mean: -0.24580
[32m[0906 23-43-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17687, current rewards: -380.23795, mean: -0.23617
[32m[0906 23-43-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17713, current rewards: -377.02513, mean: -0.22712
[32m[0906 23-44-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17738, current rewards: -373.81368, mean: -0.21860
[32m[0906 23-44-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17760, current rewards: -370.60183, mean: -0.21057
[32m[0906 23-44-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17780, current rewards: -367.38942, mean: -0.20298
[32m[0906 23-44-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17798, current rewards: -364.17649, mean: -0.19579
[32m[0906 23-44-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17815, current rewards: -360.96272, mean: -0.18899
[32m[0906 23-44-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17832, current rewards: -357.75079, mean: -0.18253
[32m[0906 23-44-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17847, current rewards: -354.53844, mean: -0.17639
[32m[0906 23-45-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17858, current rewards: -351.32607, mean: -0.17055
[32m[0906 23-45-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17861, current rewards: -348.11355, mean: -0.16498
[32m[0906 23-45-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17865, current rewards: -365.31280, mean: -0.16913
[32m[0906 23-45-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17869, current rewards: -373.02640, mean: -0.16879
[32m[0906 23-45-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17871, current rewards: -370.43918, mean: -0.16391
[32m[0906 23-45-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17874, current rewards: -367.85195, mean: -0.15924
[32m[0906 23-46-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17878, current rewards: -365.26473, mean: -0.15477
[32m[0906 23-46-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17882, current rewards: -362.67751, mean: -0.15049
[32m[0906 23-46-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17885, current rewards: -360.09028, mean: -0.14638
[32m[0906 23-46-26 @Agent.py:117][0m Average action selection time: 0.1789
[32m[0906 23-46-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-46-26 @MBExp.py:227][0m Rewards obtained: [-358.0205016191203], Lows: [267], Highs: [45], Total time: 31460.553948999997
[32m[0906 23-48-50 @MBExp.py:144][0m ####################################################################
[32m[0906 23-48-50 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 23-48-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18343, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-49-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18718, current rewards: -68.69405, mean: -1.14490
[32m[0906 23-49-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19438, current rewards: -112.60954, mean: -1.02372
[32m[0906 23-49-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20206, current rewards: -153.94055, mean: -0.96213
[32m[0906 23-49-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20047, current rewards: -157.20806, mean: -0.74861
[32m[0906 23-49-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19649, current rewards: -151.78933, mean: -0.58381
[32m[0906 23-49-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19307, current rewards: -146.36756, mean: -0.47215
[32m[0906 23-49-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19039, current rewards: -140.94253, mean: -0.39151
[32m[0906 23-50-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18827, current rewards: -204.49004, mean: -0.49876
[32m[0906 23-50-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18664, current rewards: -278.43001, mean: -0.60528
[32m[0906 23-50-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18511, current rewards: -351.07301, mean: -0.68838
[32m[0906 23-50-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18384, current rewards: -419.80502, mean: -0.74965
[32m[0906 23-50-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18258, current rewards: -492.79781, mean: -0.80787
[32m[0906 23-50-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18152, current rewards: -563.72458, mean: -0.85413
[32m[0906 23-50-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18057, current rewards: -631.58480, mean: -0.88956
[32m[0906 23-51-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17998, current rewards: -699.57867, mean: -0.92050
[32m[0906 23-51-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17940, current rewards: -783.83441, mean: -0.96770
[32m[0906 23-51-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17901, current rewards: -873.24564, mean: -1.01540
[32m[0906 23-51-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17889, current rewards: -948.40918, mean: -1.04221
[32m[0906 23-51-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17864, current rewards: -1013.12441, mean: -1.05534
[32m[0906 23-51-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17845, current rewards: -1074.60820, mean: -1.06397
[32m[0906 23-51-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17816, current rewards: -1100.53981, mean: -1.03825
[32m[0906 23-52-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17813, current rewards: -1095.25698, mean: -0.98672
[32m[0906 23-52-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17825, current rewards: -1090.05618, mean: -0.93970
[32m[0906 23-52-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17844, current rewards: -1084.84943, mean: -0.89657
[32m[0906 23-52-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17872, current rewards: -1079.64333, mean: -0.85686
[32m[0906 23-52-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17896, current rewards: -1074.44039, mean: -0.82018
[32m[0906 23-52-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17919, current rewards: -1069.12477, mean: -0.78612
[32m[0906 23-53-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17941, current rewards: -1063.92238, mean: -0.75455
[32m[0906 23-53-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17960, current rewards: -1058.72627, mean: -0.72515
[32m[0906 23-53-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17977, current rewards: -1053.52965, mean: -0.69770
[32m[0906 23-53-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17993, current rewards: -1048.33371, mean: -0.67201
[32m[0906 23-53-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18009, current rewards: -1076.80912, mean: -0.66883
[32m[0906 23-53-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18019, current rewards: -1151.10773, mean: -0.69344
[32m[0906 23-53-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18035, current rewards: -1235.25138, mean: -0.72237
[32m[0906 23-54-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18050, current rewards: -1311.95432, mean: -0.74543
[32m[0906 23-54-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18061, current rewards: -1390.34954, mean: -0.76815
[32m[0906 23-54-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18077, current rewards: -1466.62344, mean: -0.78851
[32m[0906 23-54-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18087, current rewards: -1552.50690, mean: -0.81283
[32m[0906 23-54-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18095, current rewards: -1629.13832, mean: -0.83119
[32m[0906 23-54-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18102, current rewards: -1713.52305, mean: -0.85250
[32m[0906 23-55-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18103, current rewards: -1790.35664, mean: -0.86911
[32m[0906 23-55-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18100, current rewards: -1866.79541, mean: -0.88474
[32m[0906 23-55-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18098, current rewards: -1938.92843, mean: -0.89765
[32m[0906 23-55-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18096, current rewards: -2021.06075, mean: -0.91451
[32m[0906 23-55-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18095, current rewards: -2095.01098, mean: -0.92700
[32m[0906 23-55-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18092, current rewards: -2141.15999, mean: -0.92691
[32m[0906 23-55-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18090, current rewards: -2184.45751, mean: -0.92562
[32m[0906 23-56-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18088, current rewards: -2176.60042, mean: -0.90315
[32m[0906 23-56-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18084, current rewards: -2168.93911, mean: -0.88168
[32m[0906 23-56-23 @Agent.py:117][0m Average action selection time: 0.1808
[32m[0906 23-56-23 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-56-23 @MBExp.py:227][0m Rewards obtained: [-2162.8021193959216], Lows: [1177], Highs: [19], Total time: 31913.374556
[32m[0906 23-58-49 @MBExp.py:144][0m ####################################################################
[32m[0906 23-58-49 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 23-58-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18598, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-59-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18455, current rewards: -5.62832, mean: -0.09381
[32m[0906 23-59-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18418, current rewards: -0.17061, mean: -0.00155
[32m[0906 23-59-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18448, current rewards: 6.35424, mean: 0.03971
[32m[0906 23-59-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18427, current rewards: 12.87194, mean: 0.06129
[32m[0906 23-59-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18320, current rewards: 19.39251, mean: 0.07459
[32m[0906 23-59-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18175, current rewards: 25.91999, mean: 0.08361
[32m[0906 23-59-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18065, current rewards: 32.44951, mean: 0.09014
[32m[0907 00-00-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17924, current rewards: 38.97242, mean: 0.09505
[32m[0907 00-00-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17847, current rewards: 25.09882, mean: 0.05456
[32m[0907 00-00-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17747, current rewards: 32.05640, mean: 0.06286
[32m[0907 00-00-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17664, current rewards: 45.08048, mean: 0.08050
[32m[0907 00-00-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17594, current rewards: 57.62937, mean: 0.09447
[32m[0907 00-00-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17542, current rewards: 70.17236, mean: 0.10632
[32m[0907 00-00-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17493, current rewards: 82.73936, mean: 0.11653
[32m[0907 00-01-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17448, current rewards: 95.24808, mean: 0.12533
[32m[0907 00-01-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17409, current rewards: 107.74901, mean: 0.13302
[32m[0907 00-01-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17376, current rewards: 120.25548, mean: 0.13983
[32m[0907 00-01-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17346, current rewards: 124.80118, mean: 0.13714
[32m[0907 00-01-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17320, current rewards: 117.46410, mean: 0.12236
[32m[0907 00-01-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17296, current rewards: 127.51244, mean: 0.12625
[32m[0907 00-01-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17282, current rewards: 137.57260, mean: 0.12979
[32m[0907 00-02-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17299, current rewards: 118.32961, mean: 0.10660
[32m[0907 00-02-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17328, current rewards: 127.77494, mean: 0.11015
[32m[0907 00-02-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17364, current rewards: 137.19058, mean: 0.11338
[32m[0907 00-02-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17411, current rewards: 146.59252, mean: 0.11634
[32m[0907 00-02-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17456, current rewards: 155.99881, mean: 0.11908
[32m[0907 00-02-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17496, current rewards: 163.01023, mean: 0.11986
[32m[0907 00-02-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17533, current rewards: 171.88675, mean: 0.12191
[32m[0907 00-03-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17566, current rewards: 167.28513, mean: 0.11458
[32m[0907 00-03-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17597, current rewards: 173.28942, mean: 0.11476
[32m[0907 00-03-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17624, current rewards: 179.18251, mean: 0.11486
[32m[0907 00-03-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17645, current rewards: 185.07823, mean: 0.11496
[32m[0907 00-03-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17668, current rewards: 190.96456, mean: 0.11504
[32m[0907 00-03-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17690, current rewards: 196.85517, mean: 0.11512
[32m[0907 00-04-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17718, current rewards: 192.85655, mean: 0.10958
[32m[0907 00-04-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17768, current rewards: 163.21436, mean: 0.09017
[32m[0907 00-04-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17786, current rewards: 165.87785, mean: 0.08918
[32m[0907 00-04-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17803, current rewards: 166.46091, mean: 0.08715
[32m[0907 00-04-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17819, current rewards: 169.19877, mean: 0.08633
[32m[0907 00-04-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17831, current rewards: 169.71875, mean: 0.08444
[32m[0907 00-04-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17838, current rewards: 170.24639, mean: 0.08264
[32m[0907 00-05-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17843, current rewards: 169.31946, mean: 0.08025
[32m[0907 00-05-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17859, current rewards: 108.54657, mean: 0.05025
[32m[0907 00-05-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17875, current rewards: 58.53520, mean: 0.02649
[32m[0907 00-05-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17880, current rewards: -2.69044, mean: -0.00119
[32m[0907 00-05-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17902, current rewards: -55.98373, mean: -0.02424
[32m[0907 00-05-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17916, current rewards: -108.93773, mean: -0.04616
[32m[0907 00-06-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17942, current rewards: -170.36207, mean: -0.07069
[32m[0907 00-06-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17955, current rewards: -228.35814, mean: -0.09283
[32m[0907 00-06-19 @Agent.py:117][0m Average action selection time: 0.1797
[32m[0907 00-06-19 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-06-19 @MBExp.py:227][0m Rewards obtained: [-268.23962965191396], Lows: [335], Highs: [32], Total time: 32363.362855
[32m[0907 00-08-47 @MBExp.py:144][0m ####################################################################
[32m[0907 00-08-47 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 00-08-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.21050, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-08-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18897, current rewards: -7.98877, mean: -0.13315
[32m[0907 00-09-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18759, current rewards: -0.35918, mean: -0.00327
[32m[0907 00-09-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18671, current rewards: 7.26626, mean: 0.04541
[32m[0907 00-09-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18551, current rewards: 14.88576, mean: 0.07088
[32m[0907 00-09-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18385, current rewards: 22.50680, mean: 0.08656
[32m[0907 00-09-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18228, current rewards: 30.13231, mean: 0.09720
[32m[0907 00-09-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18086, current rewards: 37.75525, mean: 0.10488
[32m[0907 00-10-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17932, current rewards: 45.38650, mean: 0.11070
[32m[0907 00-10-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17812, current rewards: 52.33904, mean: 0.11378
[32m[0907 00-10-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17715, current rewards: 59.73649, mean: 0.11713
[32m[0907 00-10-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17631, current rewards: 61.31899, mean: 0.10950
[32m[0907 00-10-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17582, current rewards: 41.04826, mean: 0.06729
[32m[0907 00-10-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17524, current rewards: 47.41089, mean: 0.07183
[32m[0907 00-10-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17471, current rewards: 53.75831, mean: 0.07572
[32m[0907 00-11-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17428, current rewards: 60.13117, mean: 0.07912
[32m[0907 00-11-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17390, current rewards: 66.50096, mean: 0.08210
[32m[0907 00-11-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17362, current rewards: 73.67825, mean: 0.08567
[32m[0907 00-11-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17356, current rewards: 62.09765, mean: 0.06824
[32m[0907 00-11-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17323, current rewards: 60.66520, mean: 0.06319
[32m[0907 00-11-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17299, current rewards: 58.09396, mean: 0.05752
[32m[0907 00-11-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17289, current rewards: 57.62380, mean: 0.05436
[32m[0907 00-12-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17307, current rewards: 54.95657, mean: 0.04951
[32m[0907 00-12-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17336, current rewards: 54.37863, mean: 0.04688
[32m[0907 00-12-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17370, current rewards: 33.50529, mean: 0.02769
[32m[0907 00-12-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17418, current rewards: 39.72701, mean: 0.03153
[32m[0907 00-12-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17459, current rewards: 44.38851, mean: 0.03388
[32m[0907 00-12-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17499, current rewards: 50.00980, mean: 0.03677
[32m[0907 00-12-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17535, current rewards: 55.63679, mean: 0.03946
[32m[0907 00-13-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17567, current rewards: 61.27386, mean: 0.04197
[32m[0907 00-13-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17597, current rewards: 66.91429, mean: 0.04431
[32m[0907 00-13-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17629, current rewards: 72.56115, mean: 0.04651
[32m[0907 00-13-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17653, current rewards: 78.18348, mean: 0.04856
[32m[0907 00-13-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17676, current rewards: 83.82704, mean: 0.05050
[32m[0907 00-13-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17701, current rewards: 90.90795, mean: 0.05316
[32m[0907 00-14-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17720, current rewards: 97.39620, mean: 0.05534
[32m[0907 00-14-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17738, current rewards: 102.64057, mean: 0.05671
[32m[0907 00-14-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17754, current rewards: 107.88878, mean: 0.05800
[32m[0907 00-14-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17782, current rewards: 91.99261, mean: 0.04816
[32m[0907 00-14-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17797, current rewards: 99.39145, mean: 0.05071
[32m[0907 00-14-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17811, current rewards: 106.77589, mean: 0.05312
[32m[0907 00-14-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17816, current rewards: 114.16613, mean: 0.05542
[32m[0907 00-15-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17819, current rewards: 121.55595, mean: 0.05761
[32m[0907 00-15-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17822, current rewards: 128.14823, mean: 0.05933
[32m[0907 00-15-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17827, current rewards: 135.74886, mean: 0.06142
[32m[0907 00-15-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17833, current rewards: 143.35639, mean: 0.06343
[32m[0907 00-15-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17835, current rewards: 150.94643, mean: 0.06534
[32m[0907 00-15-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17838, current rewards: 129.37975, mean: 0.05482
[32m[0907 00-15-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17841, current rewards: 136.03186, mean: 0.05644
[32m[0907 00-16-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17844, current rewards: 142.46429, mean: 0.05791
[32m[0907 00-16-14 @Agent.py:117][0m Average action selection time: 0.1785
[32m[0907 00-16-14 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-16-14 @MBExp.py:227][0m Rewards obtained: [147.60859270202272], Lows: [81], Highs: [26], Total time: 32810.271283
[32m[0907 00-18-44 @MBExp.py:144][0m ####################################################################
[32m[0907 00-18-44 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 00-18-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18446, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-18-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18621, current rewards: -49.91415, mean: -0.83190
[32m[0907 00-19-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19259, current rewards: -119.47788, mean: -1.08616
[32m[0907 00-19-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19343, current rewards: -189.33368, mean: -1.18334
[32m[0907 00-19-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19044, current rewards: -255.79115, mean: -1.21805
[32m[0907 00-19-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18852, current rewards: -316.88746, mean: -1.21880
[32m[0907 00-19-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18722, current rewards: -365.55958, mean: -1.17922
[32m[0907 00-19-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18531, current rewards: -416.69149, mean: -1.15748
[32m[0907 00-19-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18325, current rewards: -476.05140, mean: -1.16110
[32m[0907 00-20-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18173, current rewards: -533.30838, mean: -1.15937
[32m[0907 00-20-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18039, current rewards: -591.23490, mean: -1.15928
[32m[0907 00-20-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17948, current rewards: -640.80135, mean: -1.14429
[32m[0907 00-20-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17902, current rewards: -711.33422, mean: -1.16612
[32m[0907 00-20-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17944, current rewards: -766.17980, mean: -1.16088
[32m[0907 00-20-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17884, current rewards: -816.17178, mean: -1.14954
[32m[0907 00-21-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17914, current rewards: -874.49473, mean: -1.15065
[32m[0907 00-21-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17896, current rewards: -930.58923, mean: -1.14888
[32m[0907 00-21-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17871, current rewards: -989.81363, mean: -1.15095
[32m[0907 00-21-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17857, current rewards: -1042.40717, mean: -1.14550
[32m[0907 00-21-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17812, current rewards: -1093.15167, mean: -1.13870
[32m[0907 00-21-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17784, current rewards: -1146.27407, mean: -1.13492
[32m[0907 00-21-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17761, current rewards: -1200.38199, mean: -1.13244
[32m[0907 00-22-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17776, current rewards: -1259.42046, mean: -1.13461
[32m[0907 00-22-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17821, current rewards: -1308.06771, mean: -1.12764
[32m[0907 00-22-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17854, current rewards: -1359.27898, mean: -1.12337
[32m[0907 00-22-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17906, current rewards: -1408.37487, mean: -1.11776
[32m[0907 00-22-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17960, current rewards: -1454.98106, mean: -1.11067
[32m[0907 00-22-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17988, current rewards: -1499.27764, mean: -1.10241
[32m[0907 00-22-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18004, current rewards: -1545.70100, mean: -1.09624
[32m[0907 00-23-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18033, current rewards: -1597.16979, mean: -1.09395
[32m[0907 00-23-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18049, current rewards: -1637.83146, mean: -1.08466
[32m[0907 00-23-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18070, current rewards: -1692.95795, mean: -1.08523
[32m[0907 00-23-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18096, current rewards: -1735.40726, mean: -1.07789
[32m[0907 00-23-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18117, current rewards: -1784.92387, mean: -1.07526
[32m[0907 00-23-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18128, current rewards: -1830.10733, mean: -1.07024
[32m[0907 00-24-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18142, current rewards: -1874.26746, mean: -1.06492
[32m[0907 00-24-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18149, current rewards: -1876.79248, mean: -1.03690
[32m[0907 00-24-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18154, current rewards: -1872.16793, mean: -1.00654
[32m[0907 00-24-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18159, current rewards: -1864.78826, mean: -0.97633
[32m[0907 00-24-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18165, current rewards: -1857.40414, mean: -0.94766
[32m[0907 00-24-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18165, current rewards: -1850.02472, mean: -0.92041
[32m[0907 00-24-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18162, current rewards: -1842.63992, mean: -0.89449
[32m[0907 00-25-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18157, current rewards: -1835.24052, mean: -0.86978
[32m[0907 00-25-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18194, current rewards: -1876.54392, mean: -0.86877
[32m[0907 00-25-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18234, current rewards: -1925.74316, mean: -0.87138
[32m[0907 00-25-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18258, current rewards: -1976.41970, mean: -0.87452
[32m[0907 00-25-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18301, current rewards: -2024.46102, mean: -0.87639
[32m[0907 00-25-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18333, current rewards: -2067.74371, mean: -0.87616
[32m[0907 00-26-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18363, current rewards: -2113.42151, mean: -0.87694
[32m[0907 00-26-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18387, current rewards: -2158.80890, mean: -0.87756
[32m[0907 00-26-25 @Agent.py:117][0m Average action selection time: 0.1841
[32m[0907 00-26-25 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-26-25 @MBExp.py:227][0m Rewards obtained: [-2199.781295495211], Lows: [1161], Highs: [98], Total time: 33271.347549
[32m[0907 00-28-58 @MBExp.py:144][0m ####################################################################
[32m[0907 00-28-58 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 00-28-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18260, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-29-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18485, current rewards: -10.12644, mean: -0.16877
[32m[0907 00-29-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18435, current rewards: -4.60628, mean: -0.04188
[32m[0907 00-29-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18305, current rewards: 0.90019, mean: 0.00563
[32m[0907 00-29-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18145, current rewards: 6.41607, mean: 0.03055
[32m[0907 00-29-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18004, current rewards: 11.93064, mean: 0.04589
[32m[0907 00-29-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17811, current rewards: 17.44175, mean: 0.05626
[32m[0907 00-30-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17683, current rewards: 22.94708, mean: 0.06374
[32m[0907 00-30-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17597, current rewards: 28.42455, mean: 0.06933
[32m[0907 00-30-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17514, current rewards: 33.28488, mean: 0.07236
[32m[0907 00-30-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17451, current rewards: 39.12172, mean: 0.07671
[32m[0907 00-30-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17398, current rewards: 44.93523, mean: 0.08024
[32m[0907 00-30-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17353, current rewards: 29.53838, mean: 0.04842
[32m[0907 00-30-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17310, current rewards: 34.57830, mean: 0.05239
[32m[0907 00-31-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17271, current rewards: 39.60326, mean: 0.05578
[32m[0907 00-31-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17244, current rewards: 44.62339, mean: 0.05871
[32m[0907 00-31-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17219, current rewards: 49.64571, mean: 0.06129
[32m[0907 00-31-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17196, current rewards: 57.24267, mean: 0.06656
[32m[0907 00-31-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17175, current rewards: 63.38667, mean: 0.06966
[32m[0907 00-31-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17161, current rewards: 68.27619, mean: 0.07112
[32m[0907 00-31-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17152, current rewards: 73.16900, mean: 0.07244
[32m[0907 00-32-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17167, current rewards: 78.05765, mean: 0.07364
[32m[0907 00-32-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17210, current rewards: 82.94671, mean: 0.07473
[32m[0907 00-32-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17259, current rewards: 77.95787, mean: 0.06721
[32m[0907 00-32-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17305, current rewards: 82.34793, mean: 0.06806
[32m[0907 00-32-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17352, current rewards: 87.32569, mean: 0.06931
[32m[0907 00-32-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17394, current rewards: 92.08470, mean: 0.07029
[32m[0907 00-32-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17433, current rewards: 97.03297, mean: 0.07135
[32m[0907 00-33-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17472, current rewards: 101.98095, mean: 0.07233
[32m[0907 00-33-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17507, current rewards: 78.79379, mean: 0.05397
[32m[0907 00-33-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17535, current rewards: 70.15288, mean: 0.04646
[32m[0907 00-33-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17562, current rewards: 59.53476, mean: 0.03816
[32m[0907 00-33-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17591, current rewards: 51.04206, mean: 0.03170
[32m[0907 00-33-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17618, current rewards: 42.50176, mean: 0.02560
[32m[0907 00-34-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17642, current rewards: 31.74708, mean: 0.01857
[32m[0907 00-34-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17665, current rewards: 25.50983, mean: 0.01449
[32m[0907 00-34-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17689, current rewards: 14.60820, mean: 0.00807
[32m[0907 00-34-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17718, current rewards: -12.83873, mean: -0.00690
[32m[0907 00-34-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17744, current rewards: -56.63655, mean: -0.02965
[32m[0907 00-34-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17761, current rewards: -56.05373, mean: -0.02860
[32m[0907 00-34-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17768, current rewards: -51.91678, mean: -0.02583
[32m[0907 00-35-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17774, current rewards: -47.78208, mean: -0.02320
[32m[0907 00-35-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17779, current rewards: -43.82907, mean: -0.02077
[32m[0907 00-35-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17785, current rewards: -39.59148, mean: -0.01833
[32m[0907 00-35-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17790, current rewards: -35.35389, mean: -0.01600
[32m[0907 00-35-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17796, current rewards: -31.11587, mean: -0.01377
[32m[0907 00-35-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17806, current rewards: -47.45401, mean: -0.02054
[32m[0907 00-35-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17811, current rewards: -28.96868, mean: -0.01227
[32m[0907 00-36-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17816, current rewards: -7.36358, mean: -0.00306
[32m[0907 00-36-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17819, current rewards: 14.38414, mean: 0.00585
[32m[0907 00-36-24 @Agent.py:117][0m Average action selection time: 0.1782
[32m[0907 00-36-24 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-36-24 @MBExp.py:227][0m Rewards obtained: [28.231566322405858], Lows: [144], Highs: [32], Total time: 33717.739972999996
[32m[0907 00-38-59 @MBExp.py:144][0m ####################################################################
[32m[0907 00-38-59 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 00-39-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18481, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-39-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18503, current rewards: -13.23070, mean: -0.22051
[32m[0907 00-39-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18473, current rewards: -7.96300, mean: -0.07239
[32m[0907 00-39-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18402, current rewards: -2.69137, mean: -0.01682
[32m[0907 00-39-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18227, current rewards: 2.57369, mean: 0.01226
[32m[0907 00-39-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18058, current rewards: 7.84020, mean: 0.03015
[32m[0907 00-39-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17858, current rewards: 13.10798, mean: 0.04228
[32m[0907 00-40-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17709, current rewards: 18.37593, mean: 0.05104
[32m[0907 00-40-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17596, current rewards: 23.60050, mean: 0.05756
[32m[0907 00-40-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17513, current rewards: 28.41610, mean: 0.06177
[32m[0907 00-40-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17440, current rewards: 38.28449, mean: 0.07507
[32m[0907 00-40-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17388, current rewards: 48.16897, mean: 0.08602
[32m[0907 00-40-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17342, current rewards: 58.03432, mean: 0.09514
[32m[0907 00-40-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17297, current rewards: 44.68901, mean: 0.06771
[32m[0907 00-41-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17265, current rewards: 48.08093, mean: 0.06772
[32m[0907 00-41-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17233, current rewards: 55.76127, mean: 0.07337
[32m[0907 00-41-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17209, current rewards: 64.03885, mean: 0.07906
[32m[0907 00-41-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17190, current rewards: 73.75991, mean: 0.08577
[32m[0907 00-41-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17166, current rewards: 81.44816, mean: 0.08950
[32m[0907 00-41-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17150, current rewards: 89.13712, mean: 0.09285
[32m[0907 00-41-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17134, current rewards: 96.82582, mean: 0.09587
[32m[0907 00-42-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17140, current rewards: 83.15443, mean: 0.07845
[32m[0907 00-42-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17228, current rewards: 92.02444, mean: 0.08290
[32m[0907 00-42-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17326, current rewards: 109.09893, mean: 0.09405
[32m[0907 00-42-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17448, current rewards: 126.60483, mean: 0.10463
[32m[0907 00-42-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17540, current rewards: 139.59268, mean: 0.11079
[32m[0907 00-42-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17624, current rewards: 151.15135, mean: 0.11538
[32m[0907 00-42-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17675, current rewards: 159.53476, mean: 0.11730
[32m[0907 00-43-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17709, current rewards: 128.74940, mean: 0.09131
[32m[0907 00-43-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17733, current rewards: 136.02788, mean: 0.09317
[32m[0907 00-43-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17759, current rewards: 143.30817, mean: 0.09491
[32m[0907 00-43-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17780, current rewards: 150.58007, mean: 0.09653
[32m[0907 00-43-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17799, current rewards: 157.85497, mean: 0.09805
[32m[0907 00-43-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17821, current rewards: 164.37613, mean: 0.09902
[32m[0907 00-44-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17839, current rewards: 171.70440, mean: 0.10041
[32m[0907 00-44-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17856, current rewards: 167.51309, mean: 0.09518
[32m[0907 00-44-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17874, current rewards: 174.24149, mean: 0.09627
[32m[0907 00-44-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17887, current rewards: 181.02438, mean: 0.09732
[32m[0907 00-44-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17903, current rewards: 187.80546, mean: 0.09833
[32m[0907 00-44-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17922, current rewards: 194.59076, mean: 0.09928
[32m[0907 00-45-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17933, current rewards: 201.37928, mean: 0.10019
[32m[0907 00-45-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17946, current rewards: 208.45525, mean: 0.10119
[32m[0907 00-45-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17951, current rewards: 215.30023, mean: 0.10204
[32m[0907 00-45-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17953, current rewards: 222.15986, mean: 0.10285
[32m[0907 00-45-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17954, current rewards: 229.01099, mean: 0.10362
[32m[0907 00-45-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17954, current rewards: 235.86864, mean: 0.10437
[32m[0907 00-45-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17956, current rewards: 222.13631, mean: 0.09616
[32m[0907 00-46-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17957, current rewards: 231.88855, mean: 0.09826
[32m[0907 00-46-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17958, current rewards: 241.59584, mean: 0.10025
[32m[0907 00-46-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17959, current rewards: 249.49096, mean: 0.10142
[32m[0907 00-46-28 @Agent.py:117][0m Average action selection time: 0.1796
[32m[0907 00-46-28 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-46-28 @MBExp.py:227][0m Rewards obtained: [257.9028763288353], Lows: [54], Highs: [43], Total time: 34167.45965999999
[32m[0907 00-49-04 @MBExp.py:144][0m ####################################################################
[32m[0907 00-49-04 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 00-49-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18330, current rewards: 0.82823, mean: 0.08282
[32m[0907 00-49-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18457, current rewards: 8.04601, mean: 0.13410
[32m[0907 00-49-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18408, current rewards: 15.14256, mean: 0.13766
[32m[0907 00-49-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18347, current rewards: 22.23911, mean: 0.13899
[32m[0907 00-49-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18148, current rewards: 29.33567, mean: 0.13969
[32m[0907 00-49-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17971, current rewards: 36.43222, mean: 0.14012
[32m[0907 00-49-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17772, current rewards: 43.52877, mean: 0.14042
[32m[0907 00-50-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17639, current rewards: 9.51581, mean: 0.02643
[32m[0907 00-50-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17539, current rewards: -40.48419, mean: -0.09874
[32m[0907 00-50-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17464, current rewards: -90.48419, mean: -0.19670
[32m[0907 00-50-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17403, current rewards: -140.48419, mean: -0.27546
[32m[0907 00-50-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17351, current rewards: -190.48419, mean: -0.34015
[32m[0907 00-50-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17311, current rewards: -240.48419, mean: -0.39424
[32m[0907 00-50-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17274, current rewards: -290.48419, mean: -0.44013
[32m[0907 00-51-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17247, current rewards: -340.48419, mean: -0.47956
[32m[0907 00-51-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17219, current rewards: -390.48419, mean: -0.51379
[32m[0907 00-51-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17193, current rewards: -440.48419, mean: -0.54381
[32m[0907 00-51-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17173, current rewards: -490.48419, mean: -0.57033
[32m[0907 00-51-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17152, current rewards: -540.48419, mean: -0.59394
[32m[0907 00-51-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17133, current rewards: -590.48419, mean: -0.61509
[32m[0907 00-51-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17115, current rewards: -640.48419, mean: -0.63414
[32m[0907 00-52-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17105, current rewards: -690.48419, mean: -0.65140
[32m[0907 00-52-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17140, current rewards: -740.48419, mean: -0.66710
[32m[0907 00-52-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17181, current rewards: -790.48419, mean: -0.68145
[32m[0907 00-52-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17236, current rewards: -840.48419, mean: -0.69462
[32m[0907 00-52-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17291, current rewards: -890.48419, mean: -0.70673
[32m[0907 00-52-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17333, current rewards: -940.48419, mean: -0.71793
[32m[0907 00-53-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17373, current rewards: -990.48419, mean: -0.72830
[32m[0907 00-53-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17415, current rewards: -1040.48419, mean: -0.73793
[32m[0907 00-53-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17450, current rewards: -1090.48419, mean: -0.74691
[32m[0907 00-53-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17478, current rewards: -1140.48419, mean: -0.75529
[32m[0907 00-53-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17507, current rewards: -1190.48419, mean: -0.76313
[32m[0907 00-53-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17534, current rewards: -1240.48419, mean: -0.77049
[32m[0907 00-53-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17562, current rewards: -1290.48419, mean: -0.77740
[32m[0907 00-54-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17588, current rewards: -1340.48419, mean: -0.78391
[32m[0907 00-54-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17612, current rewards: -1390.48419, mean: -0.79005
[32m[0907 00-54-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17633, current rewards: -1440.48419, mean: -0.79585
[32m[0907 00-54-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17653, current rewards: -1490.48419, mean: -0.80134
[32m[0907 00-54-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17676, current rewards: -1540.48419, mean: -0.80654
[32m[0907 00-54-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17697, current rewards: -1590.48419, mean: -0.81147
[32m[0907 00-55-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17716, current rewards: -1640.48419, mean: -0.81616
[32m[0907 00-55-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17735, current rewards: -1690.48419, mean: -0.82062
[32m[0907 00-55-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17747, current rewards: -1740.48419, mean: -0.82487
[32m[0907 00-55-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17753, current rewards: -1790.48419, mean: -0.82893
[32m[0907 00-55-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17759, current rewards: -1840.48419, mean: -0.83280
[32m[0907 00-55-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17765, current rewards: -1890.48419, mean: -0.83650
[32m[0907 00-55-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17771, current rewards: -1940.48419, mean: -0.84004
[32m[0907 00-56-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17776, current rewards: -1990.48419, mean: -0.84343
[32m[0907 00-56-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17780, current rewards: -2040.48419, mean: -0.84667
[32m[0907 00-56-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17785, current rewards: -2090.48419, mean: -0.84979
[32m[0907 00-56-29 @Agent.py:117][0m Average action selection time: 0.1779
[32m[0907 00-56-29 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-56-29 @MBExp.py:227][0m Rewards obtained: [-2130.4841921739394], Lows: [0], Highs: [2176], Total time: 34612.940857999994
[32m[0907 00-59-07 @MBExp.py:144][0m ####################################################################
[32m[0907 00-59-07 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 00-59-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18510, current rewards: 0.77320, mean: 0.07732
[32m[0907 00-59-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18497, current rewards: 7.93066, mean: 0.13218
[32m[0907 00-59-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18526, current rewards: 16.53267, mean: 0.15030
[32m[0907 00-59-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18490, current rewards: 25.14629, mean: 0.15716
[32m[0907 00-59-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18292, current rewards: 33.77054, mean: 0.16081
[32m[0907 00-59-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18114, current rewards: 42.38367, mean: 0.16301
[32m[0907 01-00-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17999, current rewards: 50.99327, mean: 0.16449
[32m[0907 01-00-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17875, current rewards: 60.03829, mean: 0.16677
[32m[0907 01-00-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17744, current rewards: 68.68226, mean: 0.16752
[32m[0907 01-00-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17647, current rewards: 77.30909, mean: 0.16806
[32m[0907 01-00-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17560, current rewards: 85.93489, mean: 0.16850
[32m[0907 01-00-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17488, current rewards: 85.97859, mean: 0.15353
[32m[0907 01-00-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17436, current rewards: 95.34055, mean: 0.15630
[32m[0907 01-01-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17393, current rewards: 102.73349, mean: 0.15566
[32m[0907 01-01-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17352, current rewards: 110.13186, mean: 0.15512
[32m[0907 01-01-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17312, current rewards: 117.79124, mean: 0.15499
[32m[0907 01-01-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17282, current rewards: 125.16506, mean: 0.15452
[32m[0907 01-01-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17257, current rewards: 132.51025, mean: 0.15408
[32m[0907 01-01-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17229, current rewards: 116.53483, mean: 0.12806
[32m[0907 01-01-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17206, current rewards: 124.59232, mean: 0.12978
[32m[0907 01-02-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17183, current rewards: 133.64860, mean: 0.13233
[32m[0907 01-02-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17164, current rewards: 142.71858, mean: 0.13464
[32m[0907 01-02-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17177, current rewards: 151.76246, mean: 0.13672
[32m[0907 01-02-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17211, current rewards: 160.24613, mean: 0.13814
[32m[0907 01-02-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17242, current rewards: 169.27918, mean: 0.13990
[32m[0907 01-02-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17280, current rewards: 178.81730, mean: 0.14192
[32m[0907 01-02-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17327, current rewards: 188.34842, mean: 0.14378
[32m[0907 01-03-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17370, current rewards: 170.67345, mean: 0.12550
[32m[0907 01-03-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17409, current rewards: 70.67345, mean: 0.05012
[32m[0907 01-03-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17444, current rewards: -29.32655, mean: -0.02009
[32m[0907 01-03-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17476, current rewards: -129.32655, mean: -0.08565
[32m[0907 01-03-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17511, current rewards: -229.32655, mean: -0.14700
[32m[0907 01-03-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17543, current rewards: -329.32655, mean: -0.20455
[32m[0907 01-03-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17568, current rewards: -429.32655, mean: -0.25863
[32m[0907 01-04-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17594, current rewards: -529.32655, mean: -0.30955
[32m[0907 01-04-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17618, current rewards: -629.32655, mean: -0.35757
[32m[0907 01-04-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17640, current rewards: -729.32655, mean: -0.40294
[32m[0907 01-04-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17662, current rewards: -829.32655, mean: -0.44587
[32m[0907 01-04-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17683, current rewards: -929.32655, mean: -0.48656
[32m[0907 01-04-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17704, current rewards: -1029.32655, mean: -0.52517
[32m[0907 01-05-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17724, current rewards: -1129.32655, mean: -0.56185
[32m[0907 01-05-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17739, current rewards: -1229.32655, mean: -0.59676
[32m[0907 01-05-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17747, current rewards: -1329.32655, mean: -0.63001
[32m[0907 01-05-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17752, current rewards: -1429.32655, mean: -0.66173
[32m[0907 01-05-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17758, current rewards: -1529.32655, mean: -0.69200
[32m[0907 01-05-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17764, current rewards: -1629.32655, mean: -0.72094
[32m[0907 01-05-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17768, current rewards: -1729.32655, mean: -0.74863
[32m[0907 01-06-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17772, current rewards: -1829.32655, mean: -0.77514
[32m[0907 01-06-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17775, current rewards: -1929.32655, mean: -0.80055
[32m[0907 01-06-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17779, current rewards: -2029.32655, mean: -0.82493
[32m[0907 01-06-32 @Agent.py:117][0m Average action selection time: 0.1778
[32m[0907 01-06-32 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-06-32 @MBExp.py:227][0m Rewards obtained: [-2109.3265527529898], Lows: [1159], Highs: [20], Total time: 35058.281265
[32m[0907 01-09-12 @MBExp.py:144][0m ####################################################################
[32m[0907 01-09-12 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 01-09-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19840, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-09-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18700, current rewards: -89.54751, mean: -1.49246
[32m[0907 01-09-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18579, current rewards: -169.74424, mean: -1.54313
[32m[0907 01-09-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18520, current rewards: -252.13846, mean: -1.57587
[32m[0907 01-09-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18472, current rewards: -341.40614, mean: -1.62574
[32m[0907 01-10-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18403, current rewards: -418.88498, mean: -1.61110
[32m[0907 01-10-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18261, current rewards: -500.82555, mean: -1.61557
[32m[0907 01-10-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18099, current rewards: -576.83202, mean: -1.60231
[32m[0907 01-10-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17945, current rewards: -659.04619, mean: -1.60743
[32m[0907 01-10-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17823, current rewards: -739.09423, mean: -1.60673
[32m[0907 01-10-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17725, current rewards: -821.25390, mean: -1.61030
[32m[0907 01-10-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17640, current rewards: -903.38960, mean: -1.61320
[32m[0907 01-10-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17573, current rewards: -985.55729, mean: -1.61567
[32m[0907 01-11-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17518, current rewards: -1065.29503, mean: -1.61408
[32m[0907 01-11-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17514, current rewards: -1124.35143, mean: -1.58359
[32m[0907 01-11-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17467, current rewards: -1113.59935, mean: -1.46526
[32m[0907 01-11-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17432, current rewards: -1107.88047, mean: -1.36775
[32m[0907 01-11-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17393, current rewards: -1102.20340, mean: -1.28163
[32m[0907 01-11-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17360, current rewards: -1096.52633, mean: -1.20497
[32m[0907 01-11-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17333, current rewards: -1090.84927, mean: -1.13630
[32m[0907 01-12-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17310, current rewards: -1085.17220, mean: -1.07443
[32m[0907 01-12-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17287, current rewards: -1079.49514, mean: -1.01839
[32m[0907 01-12-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17277, current rewards: -1073.81807, mean: -0.96740
[32m[0907 01-12-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17283, current rewards: -1090.41183, mean: -0.94001
[32m[0907 01-12-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17302, current rewards: -1140.41183, mean: -0.94249
[32m[0907 01-12-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17330, current rewards: -1190.41183, mean: -0.94477
[32m[0907 01-13-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17375, current rewards: -1240.41183, mean: -0.94688
[32m[0907 01-13-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17413, current rewards: -1290.41183, mean: -0.94883
[32m[0907 01-13-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17451, current rewards: -1340.41183, mean: -0.95065
[32m[0907 01-13-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17486, current rewards: -1390.41183, mean: -0.95234
[32m[0907 01-13-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17519, current rewards: -1440.41183, mean: -0.95392
[32m[0907 01-13-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17548, current rewards: -1490.41183, mean: -0.95539
[32m[0907 01-13-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17577, current rewards: -1540.41183, mean: -0.95678
[32m[0907 01-14-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17607, current rewards: -1590.41183, mean: -0.95808
[32m[0907 01-14-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17632, current rewards: -1640.41183, mean: -0.95931
[32m[0907 01-14-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17652, current rewards: -1690.41183, mean: -0.96046
[32m[0907 01-14-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17674, current rewards: -1740.41183, mean: -0.96155
[32m[0907 01-14-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17694, current rewards: -1790.41183, mean: -0.96259
[32m[0907 01-14-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17714, current rewards: -1840.41183, mean: -0.96357
[32m[0907 01-15-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17729, current rewards: -1890.41183, mean: -0.96450
[32m[0907 01-15-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17748, current rewards: -1940.41183, mean: -0.96538
[32m[0907 01-15-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17762, current rewards: -1990.41183, mean: -0.96622
[32m[0907 01-15-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17767, current rewards: -2040.41183, mean: -0.96702
[32m[0907 01-15-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17771, current rewards: -2090.41183, mean: -0.96778
[32m[0907 01-15-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17777, current rewards: -2140.41183, mean: -0.96851
[32m[0907 01-15-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17781, current rewards: -2190.41183, mean: -0.96921
[32m[0907 01-16-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17785, current rewards: -2240.41183, mean: -0.96988
[32m[0907 01-16-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17790, current rewards: -2290.41183, mean: -0.97051
[32m[0907 01-16-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17794, current rewards: -2340.41183, mean: -0.97113
[32m[0907 01-16-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17796, current rewards: -2390.41183, mean: -0.97171
[32m[0907 01-16-37 @Agent.py:117][0m Average action selection time: 0.1780
[32m[0907 01-16-37 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-16-37 @MBExp.py:227][0m Rewards obtained: [-2430.4118291928307], Lows: [571], Highs: [1371], Total time: 35504.030747
[32m[0907 01-19-19 @MBExp.py:144][0m ####################################################################
[32m[0907 01-19-19 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 01-19-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18398, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-19-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18432, current rewards: -20.69618, mean: -0.34494
[32m[0907 01-19-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18427, current rewards: -9.15936, mean: -0.08327
[32m[0907 01-19-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18465, current rewards: 2.38545, mean: 0.01491
[32m[0907 01-19-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18395, current rewards: 13.92285, mean: 0.06630
[32m[0907 01-20-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18314, current rewards: -10.68579, mean: -0.04110
[32m[0907 01-20-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18255, current rewards: -20.83060, mean: -0.06720
[32m[0907 01-20-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18174, current rewards: -14.87695, mean: -0.04132
[32m[0907 01-20-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18013, current rewards: -5.24440, mean: -0.01279
[32m[0907 01-20-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17877, current rewards: 4.21697, mean: 0.00917
[32m[0907 01-20-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17775, current rewards: 14.30339, mean: 0.02805
[32m[0907 01-20-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17685, current rewards: 24.37924, mean: 0.04353
[32m[0907 01-21-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17617, current rewards: 34.73503, mean: 0.05694
[32m[0907 01-21-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17559, current rewards: 45.72317, mean: 0.06928
[32m[0907 01-21-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17507, current rewards: 56.05168, mean: 0.07895
[32m[0907 01-21-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17462, current rewards: 24.08095, mean: 0.03169
[32m[0907 01-21-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17422, current rewards: 34.83187, mean: 0.04300
[32m[0907 01-21-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17388, current rewards: 55.13244, mean: 0.06411
[32m[0907 01-21-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17357, current rewards: 75.44933, mean: 0.08291
[32m[0907 01-22-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17329, current rewards: 95.64593, mean: 0.09963
[32m[0907 01-22-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17308, current rewards: 115.71446, mean: 0.11457
[32m[0907 01-22-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17286, current rewards: 136.01060, mean: 0.12831
[32m[0907 01-22-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17267, current rewards: 156.22608, mean: 0.14074
[32m[0907 01-22-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17305, current rewards: 127.43976, mean: 0.10986
[32m[0907 01-22-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17369, current rewards: 126.70321, mean: 0.10471
[32m[0907 01-22-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17383, current rewards: 136.46818, mean: 0.10831
[32m[0907 01-23-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17415, current rewards: 145.58747, mean: 0.11114
[32m[0907 01-23-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17454, current rewards: 148.30768, mean: 0.10905
[32m[0907 01-23-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17488, current rewards: 150.31934, mean: 0.10661
[32m[0907 01-23-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17520, current rewards: 155.94317, mean: 0.10681
[32m[0907 01-23-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17552, current rewards: 161.57483, mean: 0.10700
[32m[0907 01-23-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17579, current rewards: 167.20549, mean: 0.10718
[32m[0907 01-24-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17606, current rewards: 172.77520, mean: 0.10731
[32m[0907 01-24-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17633, current rewards: 178.40227, mean: 0.10747
[32m[0907 01-24-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17655, current rewards: 184.02759, mean: 0.10762
[32m[0907 01-24-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17679, current rewards: 189.65989, mean: 0.10776
[32m[0907 01-24-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17702, current rewards: 195.29247, mean: 0.10790
[32m[0907 01-24-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17722, current rewards: 200.91939, mean: 0.10802
[32m[0907 01-24-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17738, current rewards: 186.69510, mean: 0.09775
[32m[0907 01-25-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17755, current rewards: 189.34110, mean: 0.09660
[32m[0907 01-25-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17771, current rewards: 195.20870, mean: 0.09712
[32m[0907 01-25-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17798, current rewards: 187.42067, mean: 0.09098
[32m[0907 01-25-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17809, current rewards: 191.28245, mean: 0.09066
[32m[0907 01-25-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17813, current rewards: 198.24378, mean: 0.09178
[32m[0907 01-25-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17817, current rewards: 205.62681, mean: 0.09304
[32m[0907 01-26-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17838, current rewards: 187.01385, mean: 0.08275
[32m[0907 01-26-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17851, current rewards: 192.93871, mean: 0.08352
[32m[0907 01-26-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17855, current rewards: 201.25287, mean: 0.08528
[32m[0907 01-26-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17859, current rewards: 209.52366, mean: 0.08694
[32m[0907 01-26-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17863, current rewards: 217.79347, mean: 0.08853
[32m[0907 01-26-46 @Agent.py:117][0m Average action selection time: 0.1787
[32m[0907 01-26-46 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-26-47 @MBExp.py:227][0m Rewards obtained: [224.4073353698221], Lows: [121], Highs: [29], Total time: 35951.48209
[32m[0907 01-29-31 @MBExp.py:144][0m ####################################################################
[32m[0907 01-29-31 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 01-29-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18553, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-29-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18601, current rewards: -7.23037, mean: -0.12051
[32m[0907 01-29-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18616, current rewards: -2.06333, mean: -0.01876
[32m[0907 01-30-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18594, current rewards: 3.10490, mean: 0.01941
[32m[0907 01-30-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18514, current rewards: 8.27342, mean: 0.03940
[32m[0907 01-30-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18427, current rewards: 13.43936, mean: 0.05169
[32m[0907 01-30-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18371, current rewards: -6.61486, mean: -0.02134
[32m[0907 01-30-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18314, current rewards: -5.49081, mean: -0.01525
[32m[0907 01-30-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18206, current rewards: 0.82184, mean: 0.00200
[32m[0907 01-30-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18059, current rewards: 7.18381, mean: 0.01562
[32m[0907 01-31-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17942, current rewards: 13.54839, mean: 0.02657
[32m[0907 01-31-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17838, current rewards: 19.92390, mean: 0.03558
[32m[0907 01-31-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17750, current rewards: 26.29226, mean: 0.04310
[32m[0907 01-31-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17679, current rewards: 8.59875, mean: 0.01303
[32m[0907 01-31-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17618, current rewards: -8.52059, mean: -0.01200
[32m[0907 01-31-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17563, current rewards: -31.88916, mean: -0.04196
[32m[0907 01-31-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17516, current rewards: -64.45951, mean: -0.07958
[32m[0907 01-32-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17479, current rewards: -83.37725, mean: -0.09695
[32m[0907 01-32-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17441, current rewards: -121.14099, mean: -0.13312
[32m[0907 01-32-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17411, current rewards: -137.44590, mean: -0.14317
[32m[0907 01-32-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17382, current rewards: -185.64408, mean: -0.18381
[32m[0907 01-32-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17354, current rewards: -224.43547, mean: -0.21173
[32m[0907 01-32-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17330, current rewards: -251.02030, mean: -0.22614
[32m[0907 01-32-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17323, current rewards: -292.87720, mean: -0.25248
[32m[0907 01-33-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17332, current rewards: -325.31204, mean: -0.26885
[32m[0907 01-33-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17336, current rewards: -351.28393, mean: -0.27880
[32m[0907 01-33-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17340, current rewards: -379.21148, mean: -0.28947
[32m[0907 01-33-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17366, current rewards: -400.26341, mean: -0.29431
[32m[0907 01-33-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17408, current rewards: -394.97965, mean: -0.28013
[32m[0907 01-33-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17448, current rewards: -389.62426, mean: -0.26687
[32m[0907 01-33-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17483, current rewards: -384.40377, mean: -0.25457
[32m[0907 01-34-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17516, current rewards: -379.40703, mean: -0.24321
[32m[0907 01-34-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17543, current rewards: -373.87223, mean: -0.23222
[32m[0907 01-34-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17569, current rewards: -368.34263, mean: -0.22189
[32m[0907 01-34-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17595, current rewards: -362.80908, mean: -0.21217
[32m[0907 01-34-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17620, current rewards: -357.27306, mean: -0.20300
[32m[0907 01-34-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17643, current rewards: -364.39944, mean: -0.20133
[32m[0907 01-35-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17663, current rewards: -368.89119, mean: -0.19833
[32m[0907 01-35-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17685, current rewards: -364.20493, mean: -0.19068
[32m[0907 01-35-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17703, current rewards: -359.04154, mean: -0.18318
[32m[0907 01-35-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17723, current rewards: -353.87749, mean: -0.17606
[32m[0907 01-35-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17740, current rewards: -348.71325, mean: -0.16928
[32m[0907 01-35-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17746, current rewards: -343.54965, mean: -0.16282
[32m[0907 01-35-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17752, current rewards: -338.38694, mean: -0.15666
[32m[0907 01-36-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17756, current rewards: -333.22358, mean: -0.15078
[32m[0907 01-36-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17762, current rewards: -340.24825, mean: -0.15055
[32m[0907 01-36-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17766, current rewards: -369.75117, mean: -0.16007
[32m[0907 01-36-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17770, current rewards: -426.31169, mean: -0.18064
[32m[0907 01-36-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17775, current rewards: -464.13851, mean: -0.19259
[32m[0907 01-36-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17779, current rewards: -519.24163, mean: -0.21107
[32m[0907 01-36-56 @Agent.py:117][0m Average action selection time: 0.1778
[32m[0907 01-36-56 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-36-56 @MBExp.py:227][0m Rewards obtained: [-556.8364568437561], Lows: [268], Highs: [261], Total time: 36396.822595
[32m[0907 01-39-42 @MBExp.py:144][0m ####################################################################
[32m[0907 01-39-42 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 01-39-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18449, current rewards: 0.68979, mean: 0.06898
[32m[0907 01-39-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19093, current rewards: -5.52389, mean: -0.09206
[32m[0907 01-40-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19231, current rewards: -8.81716, mean: -0.08016
[32m[0907 01-40-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19183, current rewards: -11.25654, mean: -0.07035
[32m[0907 01-40-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19041, current rewards: -15.91865, mean: -0.07580
[32m[0907 01-40-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18942, current rewards: -27.77509, mean: -0.10683
[32m[0907 01-40-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18779, current rewards: -37.78843, mean: -0.12190
[32m[0907 01-40-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18648, current rewards: -42.01212, mean: -0.11670
[32m[0907 01-40-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18496, current rewards: -35.57150, mean: -0.08676
[32m[0907 01-41-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18385, current rewards: -29.13302, mean: -0.06333
[32m[0907 01-41-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18285, current rewards: -33.68448, mean: -0.06605
[32m[0907 01-41-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18193, current rewards: -24.67529, mean: -0.04406
[32m[0907 01-41-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18083, current rewards: -15.64127, mean: -0.02564
[32m[0907 01-41-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17990, current rewards: -6.66970, mean: -0.01011
[32m[0907 01-41-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17908, current rewards: 1.61741, mean: 0.00228
[32m[0907 01-41-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17833, current rewards: 11.05505, mean: 0.01455
[32m[0907 01-42-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17770, current rewards: -27.59292, mean: -0.03407
[32m[0907 01-42-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17715, current rewards: -83.70295, mean: -0.09733
[32m[0907 01-42-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17663, current rewards: -151.51993, mean: -0.16651
[32m[0907 01-42-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17618, current rewards: -217.04711, mean: -0.22609
[32m[0907 01-42-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17579, current rewards: -280.70357, mean: -0.27792
[32m[0907 01-42-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17545, current rewards: -345.43483, mean: -0.32588
[32m[0907 01-42-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17512, current rewards: -377.25389, mean: -0.33987
[32m[0907 01-43-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17493, current rewards: -358.69107, mean: -0.30922
[32m[0907 01-43-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17488, current rewards: -356.00219, mean: -0.29422
[32m[0907 01-43-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17485, current rewards: -349.17581, mean: -0.27712
[32m[0907 01-43-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17489, current rewards: -345.99725, mean: -0.26412
[32m[0907 01-43-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17512, current rewards: -361.22218, mean: -0.26560
[32m[0907 01-43-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17528, current rewards: -362.91700, mean: -0.25739
[32m[0907 01-43-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17551, current rewards: -371.87347, mean: -0.25471
[32m[0907 01-44-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17573, current rewards: -367.88390, mean: -0.24363
[32m[0907 01-44-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17601, current rewards: -358.43523, mean: -0.22977
[32m[0907 01-44-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17625, current rewards: -349.46837, mean: -0.21706
[32m[0907 01-44-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17649, current rewards: -340.53197, mean: -0.20514
[32m[0907 01-44-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17671, current rewards: -331.56294, mean: -0.19390
[32m[0907 01-44-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17693, current rewards: -322.58011, mean: -0.18328
[32m[0907 01-45-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17717, current rewards: -313.61249, mean: -0.17327
[32m[0907 01-45-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17737, current rewards: -304.64424, mean: -0.16379
[32m[0907 01-45-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17759, current rewards: -295.96787, mean: -0.15496
[32m[0907 01-45-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17778, current rewards: -286.91592, mean: -0.14639
[32m[0907 01-45-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17795, current rewards: -277.80030, mean: -0.13821
[32m[0907 01-45-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17812, current rewards: -268.73455, mean: -0.13045
[32m[0907 01-45-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17828, current rewards: -259.63105, mean: -0.12305
[32m[0907 01-46-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17838, current rewards: -250.51106, mean: -0.11598
[32m[0907 01-46-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17840, current rewards: -241.39605, mean: -0.10923
[32m[0907 01-46-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17843, current rewards: -232.25800, mean: -0.10277
[32m[0907 01-46-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17846, current rewards: -222.67670, mean: -0.09640
[32m[0907 01-46-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17848, current rewards: -294.22583, mean: -0.12467
[32m[0907 01-46-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17850, current rewards: -352.14466, mean: -0.14612
[32m[0907 01-47-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17852, current rewards: -417.72479, mean: -0.16981
[32m[0907 01-47-09 @Agent.py:117][0m Average action selection time: 0.1785
[32m[0907 01-47-09 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-47-09 @MBExp.py:227][0m Rewards obtained: [-457.04946223688916], Lows: [406], Highs: [78], Total time: 36843.992193
[32m[0907 01-49-56 @MBExp.py:144][0m ####################################################################
[32m[0907 01-49-56 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 01-49-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19702, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-50-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18759, current rewards: -46.63690, mean: -0.77728
[32m[0907 01-50-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18603, current rewards: -96.63690, mean: -0.87852
[32m[0907 01-50-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18531, current rewards: -146.63690, mean: -0.91648
[32m[0907 01-50-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18419, current rewards: -196.63690, mean: -0.93637
[32m[0907 01-50-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18330, current rewards: -246.63690, mean: -0.94860
[32m[0907 01-50-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18266, current rewards: -296.63690, mean: -0.95689
[32m[0907 01-51-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18200, current rewards: -346.63690, mean: -0.96288
[32m[0907 01-51-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18107, current rewards: -396.63690, mean: -0.96741
[32m[0907 01-51-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18030, current rewards: -446.63690, mean: -0.97095
[32m[0907 01-51-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17968, current rewards: -496.63690, mean: -0.97380
[32m[0907 01-51-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17917, current rewards: -546.63690, mean: -0.97614
[32m[0907 01-51-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17872, current rewards: -596.63690, mean: -0.97809
[32m[0907 01-51-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17798, current rewards: -646.63690, mean: -0.97975
[32m[0907 01-52-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17727, current rewards: -696.63690, mean: -0.98118
[32m[0907 01-52-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17662, current rewards: -746.63690, mean: -0.98242
[32m[0907 01-52-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17610, current rewards: -796.63690, mean: -0.98350
[32m[0907 01-52-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17565, current rewards: -846.63690, mean: -0.98446
[32m[0907 01-52-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17521, current rewards: -896.63690, mean: -0.98532
[32m[0907 01-52-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17481, current rewards: -946.63690, mean: -0.98608
[32m[0907 01-52-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17447, current rewards: -996.63690, mean: -0.98677
[32m[0907 01-53-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17416, current rewards: -1016.57427, mean: -0.95903
[32m[0907 01-53-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17389, current rewards: -1053.04543, mean: -0.94869
[32m[0907 01-53-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17369, current rewards: -1085.38124, mean: -0.93567
[32m[0907 01-53-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17373, current rewards: -1107.88983, mean: -0.91561
[32m[0907 01-53-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17374, current rewards: -1132.46815, mean: -0.89878
[32m[0907 01-53-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17375, current rewards: -1171.95423, mean: -0.89462
[32m[0907 01-53-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17396, current rewards: -1193.62102, mean: -0.87766
[32m[0907 01-54-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17420, current rewards: -1223.04610, mean: -0.86741
[32m[0907 01-54-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17441, current rewards: -1259.04213, mean: -0.86236
[32m[0907 01-54-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17457, current rewards: -1283.42346, mean: -0.84995
[32m[0907 01-54-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17473, current rewards: -1280.28547, mean: -0.82070
[32m[0907 01-54-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17500, current rewards: -1275.93340, mean: -0.79251
[32m[0907 01-54-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17532, current rewards: -1273.02508, mean: -0.76688
[32m[0907 01-54-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17558, current rewards: -1269.93500, mean: -0.74265
[32m[0907 01-55-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17583, current rewards: -1283.90547, mean: -0.72949
[32m[0907 01-55-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17607, current rewards: -1276.22283, mean: -0.70510
[32m[0907 01-55-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17631, current rewards: -1268.31384, mean: -0.68189
[32m[0907 01-55-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17655, current rewards: -1260.40144, mean: -0.65990
[32m[0907 01-55-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17676, current rewards: -1252.48664, mean: -0.63902
[32m[0907 01-55-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17697, current rewards: -1244.57144, mean: -0.61919
[32m[0907 01-56-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17716, current rewards: -1236.66159, mean: -0.60032
[32m[0907 01-56-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17734, current rewards: -1252.29032, mean: -0.59350
[32m[0907 01-56-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17745, current rewards: -1243.99019, mean: -0.57592
[32m[0907 01-56-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17750, current rewards: -1235.69007, mean: -0.55914
[32m[0907 01-56-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17754, current rewards: -1227.38995, mean: -0.54309
[32m[0907 01-56-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17759, current rewards: -1222.56337, mean: -0.52925
[32m[0907 01-56-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17763, current rewards: -1221.92654, mean: -0.51777
[32m[0907 01-57-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17767, current rewards: -1271.92654, mean: -0.52777
[32m[0907 01-57-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17772, current rewards: -1321.92654, mean: -0.53737
[32m[0907 01-57-21 @Agent.py:117][0m Average action selection time: 0.1778
[32m[0907 01-57-21 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-57-22 @MBExp.py:227][0m Rewards obtained: [-1361.9265393986993], Lows: [167], Highs: [1199], Total time: 37289.167149
[32m[0907 02-00-11 @MBExp.py:144][0m ####################################################################
[32m[0907 02-00-11 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 02-00-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18593, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-00-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18572, current rewards: -10.57410, mean: -0.17623
[32m[0907 02-00-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18526, current rewards: -5.47967, mean: -0.04982
[32m[0907 02-00-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18476, current rewards: -0.38809, mean: -0.00243
[32m[0907 02-00-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18458, current rewards: 4.36095, mean: 0.02077
[32m[0907 02-00-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18419, current rewards: 9.68567, mean: 0.03725
[32m[0907 02-01-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18338, current rewards: 15.06420, mean: 0.04859
[32m[0907 02-01-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18272, current rewards: 20.42780, mean: 0.05674
[32m[0907 02-01-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18173, current rewards: 25.77823, mean: 0.06287
[32m[0907 02-01-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18091, current rewards: -48.48234, mean: -0.10540
[32m[0907 02-01-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18018, current rewards: -148.48234, mean: -0.29114
[32m[0907 02-01-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17963, current rewards: -248.48234, mean: -0.44372
[32m[0907 02-02-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17913, current rewards: -348.48234, mean: -0.57128
[32m[0907 02-02-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17842, current rewards: -448.48234, mean: -0.67952
[32m[0907 02-02-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17773, current rewards: -548.48234, mean: -0.77251
[32m[0907 02-02-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17714, current rewards: -648.48234, mean: -0.85327
[32m[0907 02-02-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17655, current rewards: -748.48234, mean: -0.92405
[32m[0907 02-02-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17605, current rewards: -848.48234, mean: -0.98661
[32m[0907 02-02-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17562, current rewards: -948.48234, mean: -1.04229
[32m[0907 02-02-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17521, current rewards: -1048.48234, mean: -1.09217
[32m[0907 02-03-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17487, current rewards: -1148.48234, mean: -1.13711
[32m[0907 02-03-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17454, current rewards: -1248.48234, mean: -1.17781
[32m[0907 02-03-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17425, current rewards: -1348.48234, mean: -1.21485
[32m[0907 02-03-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17396, current rewards: -1448.48234, mean: -1.24869
[32m[0907 02-03-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17372, current rewards: -1548.48234, mean: -1.27974
[32m[0907 02-03-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17361, current rewards: -1648.48234, mean: -1.30832
[32m[0907 02-03-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17364, current rewards: -1748.48234, mean: -1.33472
[32m[0907 02-04-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17379, current rewards: -1848.48234, mean: -1.35918
[32m[0907 02-04-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17400, current rewards: -1948.48234, mean: -1.38190
[32m[0907 02-04-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17423, current rewards: -2048.48234, mean: -1.40307
[32m[0907 02-04-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17442, current rewards: -2148.48234, mean: -1.42284
[32m[0907 02-04-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17457, current rewards: -2248.48234, mean: -1.44133
[32m[0907 02-04-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17474, current rewards: -2348.48234, mean: -1.45868
[32m[0907 02-05-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17505, current rewards: -2448.48234, mean: -1.47499
[32m[0907 02-05-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17533, current rewards: -2548.48234, mean: -1.49034
[32m[0907 02-05-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17560, current rewards: -2648.48234, mean: -1.50482
[32m[0907 02-05-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17584, current rewards: -2748.48234, mean: -1.51850
[32m[0907 02-05-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17609, current rewards: -2848.48234, mean: -1.53144
[32m[0907 02-05-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17629, current rewards: -2948.48234, mean: -1.54371
[32m[0907 02-05-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17651, current rewards: -3048.48234, mean: -1.55535
[32m[0907 02-06-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17668, current rewards: -3148.48234, mean: -1.56641
[32m[0907 02-06-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17686, current rewards: -3248.48234, mean: -1.57693
[32m[0907 02-06-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17704, current rewards: -3348.48234, mean: -1.58696
[32m[0907 02-06-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17717, current rewards: -3448.48234, mean: -1.59652
[32m[0907 02-06-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17723, current rewards: -3548.48234, mean: -1.60565
[32m[0907 02-06-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17729, current rewards: -3648.48234, mean: -1.61437
[32m[0907 02-07-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17734, current rewards: -3748.48234, mean: -1.62272
[32m[0907 02-07-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17739, current rewards: -3848.48234, mean: -1.63071
[32m[0907 02-07-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17743, current rewards: -3948.48234, mean: -1.63837
[32m[0907 02-07-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17749, current rewards: -4048.48234, mean: -1.64572
[32m[0907 02-07-35 @Agent.py:117][0m Average action selection time: 0.1775
[32m[0907 02-07-35 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-07-35 @MBExp.py:227][0m Rewards obtained: [-4128.482341837442], Lows: [2072], Highs: [25], Total time: 37733.796822000004
[32m[0907 02-10-27 @MBExp.py:144][0m ####################################################################
[32m[0907 02-10-27 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 02-10-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19014, current rewards: 0.57914, mean: 0.05791
[32m[0907 02-10-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18567, current rewards: -2.54952, mean: -0.04249
[32m[0907 02-10-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18591, current rewards: 5.52476, mean: 0.05023
[32m[0907 02-10-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18538, current rewards: 13.59905, mean: 0.08499
[32m[0907 02-11-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18517, current rewards: 21.67334, mean: 0.10321
[32m[0907 02-11-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18503, current rewards: -19.19085, mean: -0.07381
[32m[0907 02-11-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18423, current rewards: -69.19085, mean: -0.22320
[32m[0907 02-11-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18339, current rewards: -119.19085, mean: -0.33109
[32m[0907 02-11-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18221, current rewards: -169.19085, mean: -0.41266
[32m[0907 02-11-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18129, current rewards: -219.19085, mean: -0.47650
[32m[0907 02-11-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18056, current rewards: -269.19085, mean: -0.52783
[32m[0907 02-12-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17995, current rewards: -319.19085, mean: -0.56998
[32m[0907 02-12-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17945, current rewards: -369.19085, mean: -0.60523
[32m[0907 02-12-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17879, current rewards: -419.19085, mean: -0.63514
[32m[0907 02-12-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17804, current rewards: -469.19085, mean: -0.66083
[32m[0907 02-12-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17741, current rewards: -519.19085, mean: -0.68315
[32m[0907 02-12-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17690, current rewards: -569.19085, mean: -0.70270
[32m[0907 02-12-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17642, current rewards: -619.19085, mean: -0.71999
[32m[0907 02-13-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17599, current rewards: -669.19085, mean: -0.73537
[32m[0907 02-13-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17557, current rewards: -719.19085, mean: -0.74916
[32m[0907 02-13-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17521, current rewards: -769.19085, mean: -0.76158
[32m[0907 02-13-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17486, current rewards: -819.19085, mean: -0.77282
[32m[0907 02-13-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17456, current rewards: -869.19085, mean: -0.78305
[32m[0907 02-13-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17429, current rewards: -919.19085, mean: -0.79241
[32m[0907 02-13-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17403, current rewards: -969.19085, mean: -0.80098
[32m[0907 02-14-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17380, current rewards: -1019.19085, mean: -0.80888
[32m[0907 02-14-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17381, current rewards: -1069.19085, mean: -0.81618
[32m[0907 02-14-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17391, current rewards: -1119.19085, mean: -0.82293
[32m[0907 02-14-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17415, current rewards: -1169.19085, mean: -0.82921
[32m[0907 02-14-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17433, current rewards: -1219.19085, mean: -0.83506
[32m[0907 02-14-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17454, current rewards: -1269.19085, mean: -0.84052
[32m[0907 02-15-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17474, current rewards: -1319.19085, mean: -0.84564
[32m[0907 02-15-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17490, current rewards: -1369.19085, mean: -0.85043
[32m[0907 02-15-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17519, current rewards: -1419.19085, mean: -0.85493
[32m[0907 02-15-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17547, current rewards: -1469.19085, mean: -0.85918
[32m[0907 02-15-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17571, current rewards: -1519.19085, mean: -0.86318
[32m[0907 02-15-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17595, current rewards: -1569.19085, mean: -0.86696
[32m[0907 02-15-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17621, current rewards: -1619.19085, mean: -0.87053
[32m[0907 02-16-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17641, current rewards: -1669.19085, mean: -0.87392
[32m[0907 02-16-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17661, current rewards: -1719.19085, mean: -0.87714
[32m[0907 02-16-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17681, current rewards: -1769.19085, mean: -0.88019
[32m[0907 02-16-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17701, current rewards: -1819.19085, mean: -0.88310
[32m[0907 02-16-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17717, current rewards: -1869.19085, mean: -0.88587
[32m[0907 02-16-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17727, current rewards: -1919.19085, mean: -0.88851
[32m[0907 02-16-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17736, current rewards: -1969.19085, mean: -0.89104
[32m[0907 02-17-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17744, current rewards: -2019.19085, mean: -0.89345
[32m[0907 02-17-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17749, current rewards: -2069.19085, mean: -0.89575
[32m[0907 02-17-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17754, current rewards: -2119.19085, mean: -0.89796
[32m[0907 02-17-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17758, current rewards: -2169.19085, mean: -0.90008
[32m[0907 02-17-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17764, current rewards: -2219.19085, mean: -0.90211
[32m[0907 02-17-52 @Agent.py:117][0m Average action selection time: 0.1777
[32m[0907 02-17-52 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-17-52 @MBExp.py:227][0m Rewards obtained: [-2259.1908464477947], Lows: [5], Highs: [2282], Total time: 38178.76519500001
[32m[0907 02-20-45 @MBExp.py:144][0m ####################################################################
[32m[0907 02-20-45 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 02-20-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19529, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-20-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18627, current rewards: -6.19622, mean: -0.10327
[32m[0907 02-21-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18553, current rewards: -0.06125, mean: -0.00056
[32m[0907 02-21-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18565, current rewards: 6.07837, mean: 0.03799
[32m[0907 02-21-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18541, current rewards: 12.17012, mean: 0.05795
[32m[0907 02-21-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18509, current rewards: 18.29166, mean: 0.07035
[32m[0907 02-21-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18517, current rewards: -2.96469, mean: -0.00956
[32m[0907 02-21-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18457, current rewards: -5.60142, mean: -0.01556
[32m[0907 02-22-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18347, current rewards: -7.02629, mean: -0.01714
[32m[0907 02-22-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18285, current rewards: -13.19425, mean: -0.02868
[32m[0907 02-22-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18206, current rewards: -20.18434, mean: -0.03958
[32m[0907 02-22-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18196, current rewards: -26.10152, mean: -0.04661
[32m[0907 02-22-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18175, current rewards: -33.15684, mean: -0.05436
[32m[0907 02-22-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18146, current rewards: -32.44264, mean: -0.04916
[32m[0907 02-22-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18099, current rewards: -34.05260, mean: -0.04796
[32m[0907 02-23-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18087, current rewards: -46.55958, mean: -0.06126
[32m[0907 02-23-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18036, current rewards: -80.74100, mean: -0.09968
[32m[0907 02-23-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18007, current rewards: -120.45808, mean: -0.14007
[32m[0907 02-23-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17942, current rewards: -166.14425, mean: -0.18258
[32m[0907 02-23-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17891, current rewards: -209.46352, mean: -0.21819
[32m[0907 02-23-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17883, current rewards: -247.15917, mean: -0.24471
[32m[0907 02-23-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17869, current rewards: -266.10657, mean: -0.25104
[32m[0907 02-24-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17906, current rewards: -280.40089, mean: -0.25261
[32m[0907 02-24-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17888, current rewards: -312.18010, mean: -0.26912
[32m[0907 02-24-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17889, current rewards: -339.77178, mean: -0.28080
[32m[0907 02-24-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17959, current rewards: -352.38388, mean: -0.27967
[32m[0907 02-24-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17935, current rewards: -370.31893, mean: -0.28269
[32m[0907 02-24-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17936, current rewards: -364.60274, mean: -0.26809
[32m[0907 02-24-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17938, current rewards: -358.05752, mean: -0.25394
[32m[0907 02-25-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17940, current rewards: -352.00787, mean: -0.24110
[32m[0907 02-25-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17942, current rewards: -345.46224, mean: -0.22878
[32m[0907 02-25-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17946, current rewards: -338.91321, mean: -0.21725
[32m[0907 02-25-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17954, current rewards: -353.74411, mean: -0.21972
[32m[0907 02-25-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17971, current rewards: -353.82026, mean: -0.21314
[32m[0907 02-25-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17981, current rewards: -354.30696, mean: -0.20720
[32m[0907 02-26-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18004, current rewards: -355.36044, mean: -0.20191
[32m[0907 02-26-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18026, current rewards: -354.91252, mean: -0.19608
[32m[0907 02-26-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18047, current rewards: -379.09794, mean: -0.20382
[32m[0907 02-26-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18064, current rewards: -377.36894, mean: -0.19758
[32m[0907 02-26-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18082, current rewards: -367.35046, mean: -0.18742
[32m[0907 02-26-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18102, current rewards: -357.30240, mean: -0.17776
[32m[0907 02-26-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18119, current rewards: -347.24580, mean: -0.16857
[32m[0907 02-27-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18135, current rewards: -337.18583, mean: -0.15980
[32m[0907 02-27-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18144, current rewards: -327.13276, mean: -0.15145
[32m[0907 02-27-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18149, current rewards: -317.08490, mean: -0.14348
[32m[0907 02-27-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18155, current rewards: -307.47307, mean: -0.13605
[32m[0907 02-27-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18184, current rewards: -316.86928, mean: -0.13717
[32m[0907 02-27-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18210, current rewards: -334.64741, mean: -0.14180
[32m[0907 02-28-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18213, current rewards: -377.00444, mean: -0.15643
[32m[0907 02-28-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18223, current rewards: -416.46491, mean: -0.16929
[32m[0907 02-28-22 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0907 02-28-22 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-28-22 @MBExp.py:227][0m Rewards obtained: [-453.2489518912146], Lows: [304], Highs: [126], Total time: 38635.372628000005
[32m[0907 02-31-21 @MBExp.py:144][0m ####################################################################
[32m[0907 02-31-21 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 02-31-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19968, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-31-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19064, current rewards: -15.53675, mean: -0.25895
[32m[0907 02-31-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18940, current rewards: -9.67732, mean: -0.08798
[32m[0907 02-31-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18890, current rewards: -3.95566, mean: -0.02472
[32m[0907 02-32-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18850, current rewards: 2.52803, mean: 0.01204
[32m[0907 02-32-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18836, current rewards: 8.33284, mean: 0.03205
[32m[0907 02-32-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18784, current rewards: 14.13898, mean: 0.04561
[32m[0907 02-32-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18643, current rewards: 19.93889, mean: 0.05539
[32m[0907 02-32-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18542, current rewards: 25.74293, mean: 0.06279
[32m[0907 02-32-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18457, current rewards: 31.55544, mean: 0.06860
[32m[0907 02-32-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18391, current rewards: 37.36378, mean: 0.07326
[32m[0907 02-33-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18351, current rewards: 21.08075, mean: 0.03764
[32m[0907 02-33-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18302, current rewards: 28.07336, mean: 0.04602
[32m[0907 02-33-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18258, current rewards: 33.77856, mean: 0.05118
[32m[0907 02-33-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18213, current rewards: 39.48543, mean: 0.05561
[32m[0907 02-33-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18144, current rewards: 45.18814, mean: 0.05946
[32m[0907 02-33-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18083, current rewards: 48.67241, mean: 0.06009
[32m[0907 02-33-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18028, current rewards: 47.87882, mean: 0.05567
[32m[0907 02-34-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17989, current rewards: 46.24217, mean: 0.05082
[32m[0907 02-34-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17957, current rewards: 7.89024, mean: 0.00822
[32m[0907 02-34-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17975, current rewards: -24.94643, mean: -0.02470
[32m[0907 02-34-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17990, current rewards: -76.05382, mean: -0.07175
[32m[0907 02-34-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17950, current rewards: -125.58107, mean: -0.11314
[32m[0907 02-34-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17927, current rewards: -168.94625, mean: -0.14564
[32m[0907 02-34-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17910, current rewards: -227.81174, mean: -0.18827
[32m[0907 02-35-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17893, current rewards: -274.47605, mean: -0.21784
[32m[0907 02-35-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17881, current rewards: -325.89849, mean: -0.24878
[32m[0907 02-35-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17915, current rewards: -361.11694, mean: -0.26553
[32m[0907 02-35-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17935, current rewards: -413.02005, mean: -0.29292
[32m[0907 02-35-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17960, current rewards: -432.03438, mean: -0.29591
[32m[0907 02-35-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17975, current rewards: -425.86621, mean: -0.28203
[32m[0907 02-36-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17986, current rewards: -420.18540, mean: -0.26935
[32m[0907 02-36-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17997, current rewards: -414.49773, mean: -0.25745
[32m[0907 02-36-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18009, current rewards: -408.92050, mean: -0.24634
[32m[0907 02-36-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18023, current rewards: -404.39656, mean: -0.23649
[32m[0907 02-36-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18047, current rewards: -399.82550, mean: -0.22717
[32m[0907 02-36-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18069, current rewards: -395.38631, mean: -0.21845
[32m[0907 02-36-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18089, current rewards: -391.41103, mean: -0.21044
[32m[0907 02-37-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18112, current rewards: -387.11609, mean: -0.20268
[32m[0907 02-37-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18131, current rewards: -382.82169, mean: -0.19532
[32m[0907 02-37-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18148, current rewards: -378.52689, mean: -0.18832
[32m[0907 02-37-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18164, current rewards: -374.23148, mean: -0.18167
[32m[0907 02-37-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18177, current rewards: -369.93317, mean: -0.17532
[32m[0907 02-37-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18181, current rewards: -365.63916, mean: -0.16928
[32m[0907 02-38-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18185, current rewards: -361.34305, mean: -0.16350
[32m[0907 02-38-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18187, current rewards: -356.24991, mean: -0.15763
[32m[0907 02-38-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18190, current rewards: -351.78001, mean: -0.15229
[32m[0907 02-38-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18194, current rewards: -357.76228, mean: -0.15159
[32m[0907 02-38-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18198, current rewards: -407.38633, mean: -0.16904
[32m[0907 02-38-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18218, current rewards: -451.18613, mean: -0.18341
[32m[0907 02-38-58 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0907 02-38-58 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-38-58 @MBExp.py:227][0m Rewards obtained: [-466.13717266133614], Lows: [353], Highs: [48], Total time: 39092.23888800001
[32m[0907 02-41-59 @MBExp.py:144][0m ####################################################################
[32m[0907 02-41-59 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 02-42-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19431, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-42-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19161, current rewards: -78.29217, mean: -1.30487
[32m[0907 02-42-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19194, current rewards: -154.01932, mean: -1.40018
[32m[0907 02-42-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19124, current rewards: -224.62351, mean: -1.40390
[32m[0907 02-42-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19036, current rewards: -286.52921, mean: -1.36442
[32m[0907 02-42-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19039, current rewards: -341.56262, mean: -1.31370
[32m[0907 02-42-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18889, current rewards: -398.41227, mean: -1.28520
[32m[0907 02-43-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18749, current rewards: -469.08985, mean: -1.30303
[32m[0907 02-43-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18630, current rewards: -537.06334, mean: -1.30991
[32m[0907 02-43-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18574, current rewards: -607.14214, mean: -1.31987
[32m[0907 02-43-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18487, current rewards: -663.62615, mean: -1.30123
[32m[0907 02-43-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18419, current rewards: -729.57482, mean: -1.30281
[32m[0907 02-43-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18369, current rewards: -802.20771, mean: -1.31509
[32m[0907 02-44-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18320, current rewards: -890.92135, mean: -1.34988
[32m[0907 02-44-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18270, current rewards: -982.49564, mean: -1.38380
[32m[0907 02-44-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18212, current rewards: -1074.10011, mean: -1.41329
[32m[0907 02-44-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18156, current rewards: -1163.59885, mean: -1.43654
[32m[0907 02-44-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18111, current rewards: -1255.19619, mean: -1.45953
[32m[0907 02-44-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18069, current rewards: -1346.79731, mean: -1.48000
[32m[0907 02-44-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18022, current rewards: -1438.39100, mean: -1.49832
[32m[0907 02-45-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17981, current rewards: -1529.98671, mean: -1.51484
[32m[0907 02-45-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17953, current rewards: -1621.57516, mean: -1.52979
[32m[0907 02-45-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17914, current rewards: -1711.06525, mean: -1.54150
[32m[0907 02-45-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17877, current rewards: -1802.64825, mean: -1.55401
[32m[0907 02-45-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17849, current rewards: -1894.24156, mean: -1.56549
[32m[0907 02-45-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17823, current rewards: -1985.82760, mean: -1.57605
[32m[0907 02-45-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17803, current rewards: -2069.31170, mean: -1.57963
[32m[0907 02-46-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17822, current rewards: -2062.68387, mean: -1.51668
[32m[0907 02-46-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17842, current rewards: -2089.40970, mean: -1.48185
[32m[0907 02-46-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17859, current rewards: -2086.61604, mean: -1.42919
[32m[0907 02-46-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17876, current rewards: -2079.31520, mean: -1.37703
[32m[0907 02-46-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17891, current rewards: -2071.84488, mean: -1.32811
[32m[0907 02-46-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17904, current rewards: -2064.37279, mean: -1.28222
[32m[0907 02-46-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17917, current rewards: -2056.90073, mean: -1.23910
[32m[0907 02-47-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17930, current rewards: -2049.42849, mean: -1.19850
[32m[0907 02-47-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17954, current rewards: -2041.95735, mean: -1.16020
[32m[0907 02-47-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17980, current rewards: -2044.83096, mean: -1.12974
[32m[0907 02-47-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18040, current rewards: -2077.36254, mean: -1.11686
[32m[0907 02-47-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18101, current rewards: -2152.40565, mean: -1.12691
[32m[0907 02-47-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18135, current rewards: -2226.19149, mean: -1.13581
[32m[0907 02-48-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18175, current rewards: -2287.74207, mean: -1.13818
[32m[0907 02-48-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18227, current rewards: -2345.35503, mean: -1.13852
[32m[0907 02-48-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18256, current rewards: -2415.25110, mean: -1.14467
[32m[0907 02-48-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18281, current rewards: -2489.80377, mean: -1.15269
[32m[0907 02-48-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18304, current rewards: -2569.22939, mean: -1.16255
[32m[0907 02-48-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18323, current rewards: -2642.13341, mean: -1.16909
[32m[0907 02-49-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18335, current rewards: -2680.03387, mean: -1.16019
[32m[0907 02-49-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18336, current rewards: -2677.21864, mean: -1.13441
[32m[0907 02-49-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18336, current rewards: -2672.15965, mean: -1.10878
[32m[0907 02-49-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18336, current rewards: -2667.24871, mean: -1.08425
[32m[0907 02-49-38 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0907 02-49-38 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-49-39 @MBExp.py:227][0m Rewards obtained: [-2663.3193531340953], Lows: [1436], Highs: [22], Total time: 39551.470097000005
[32m[0907 02-52-42 @MBExp.py:144][0m ####################################################################
[32m[0907 02-52-42 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 02-52-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19952, current rewards: -6.85344, mean: -0.68534
[32m[0907 02-52-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19400, current rewards: -15.06895, mean: -0.25115
[32m[0907 02-53-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19329, current rewards: -29.56416, mean: -0.26877
[32m[0907 02-53-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19162, current rewards: -47.13665, mean: -0.29460
[32m[0907 02-53-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19118, current rewards: -64.09027, mean: -0.30519
[32m[0907 02-53-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19167, current rewards: -84.03470, mean: -0.32321
[32m[0907 02-53-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19063, current rewards: -84.71089, mean: -0.27326
[32m[0907 02-53-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18994, current rewards: -87.42004, mean: -0.24283
[32m[0907 02-54-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18916, current rewards: -73.56758, mean: -0.17943
[32m[0907 02-54-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18848, current rewards: -60.63210, mean: -0.13181
[32m[0907 02-54-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18750, current rewards: -47.44109, mean: -0.09302
[32m[0907 02-54-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18696, current rewards: -71.91885, mean: -0.12843
[32m[0907 02-54-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18615, current rewards: -91.31353, mean: -0.14969
[32m[0907 02-54-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18565, current rewards: -95.59267, mean: -0.14484
[32m[0907 02-54-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18514, current rewards: -98.21945, mean: -0.13834
[32m[0907 02-55-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18507, current rewards: -128.05448, mean: -0.16849
[32m[0907 02-55-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18420, current rewards: -160.05484, mean: -0.19760
[32m[0907 02-55-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18347, current rewards: -155.49591, mean: -0.18081
[32m[0907 02-55-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18277, current rewards: -150.88894, mean: -0.16581
[32m[0907 02-55-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18236, current rewards: -154.41728, mean: -0.16085
[32m[0907 02-55-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18180, current rewards: -153.93880, mean: -0.15241
[32m[0907 02-55-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18135, current rewards: -153.83794, mean: -0.14513
[32m[0907 02-56-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18089, current rewards: -148.01849, mean: -0.13335
[32m[0907 02-56-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18057, current rewards: -142.65414, mean: -0.12298
[32m[0907 02-56-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18029, current rewards: -143.44969, mean: -0.11855
[32m[0907 02-56-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17993, current rewards: -151.75112, mean: -0.12044
[32m[0907 02-56-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17973, current rewards: -146.08004, mean: -0.11151
[32m[0907 02-56-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17965, current rewards: -140.75196, mean: -0.10349
[32m[0907 02-56-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17958, current rewards: -135.55577, mean: -0.09614
[32m[0907 02-57-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17951, current rewards: -137.81794, mean: -0.09440
[32m[0907 02-57-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17949, current rewards: -132.22639, mean: -0.08757
[32m[0907 02-57-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17960, current rewards: -126.89965, mean: -0.08135
[32m[0907 02-57-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17973, current rewards: -121.57132, mean: -0.07551
[32m[0907 02-57-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17984, current rewards: -116.24463, mean: -0.07003
[32m[0907 02-57-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17993, current rewards: -110.91556, mean: -0.06486
[32m[0907 02-58-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18026, current rewards: -128.76032, mean: -0.07316
[32m[0907 02-58-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18065, current rewards: -146.90915, mean: -0.08117
[32m[0907 02-58-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18142, current rewards: -159.48432, mean: -0.08574
[32m[0907 02-58-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18226, current rewards: -153.74290, mean: -0.08049
[32m[0907 02-58-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18302, current rewards: -148.69272, mean: -0.07586
[32m[0907 02-58-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18366, current rewards: -142.89423, mean: -0.07109
[32m[0907 02-59-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18390, current rewards: -166.47225, mean: -0.08081
[32m[0907 02-59-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18389, current rewards: -166.48391, mean: -0.07890
[32m[0907 02-59-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18388, current rewards: -159.42281, mean: -0.07381
[32m[0907 02-59-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18387, current rewards: -152.62918, mean: -0.06906
[32m[0907 02-59-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18384, current rewards: -144.60172, mean: -0.06398
[32m[0907 02-59-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18382, current rewards: -136.58582, mean: -0.05913
[32m[0907 02-59-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18380, current rewards: -128.55874, mean: -0.05447
[32m[0907 03-00-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18380, current rewards: -120.53361, mean: -0.05001
[32m[0907 03-00-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18378, current rewards: -112.50393, mean: -0.04573
[32m[0907 03-00-22 @Agent.py:117][0m Average action selection time: 0.1838
[32m[0907 03-00-22 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-00-22 @MBExp.py:227][0m Rewards obtained: [-106.07901545277677], Lows: [158], Highs: [110], Total time: 40011.703293000006
[32m[0907 03-03-28 @MBExp.py:144][0m ####################################################################
[32m[0907 03-03-28 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 03-03-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18742, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-03-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18866, current rewards: -70.82031, mean: -1.18034
[32m[0907 03-03-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18819, current rewards: -129.74370, mean: -1.17949
[32m[0907 03-03-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18866, current rewards: -182.22184, mean: -1.13889
[32m[0907 03-04-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18885, current rewards: -239.25916, mean: -1.13933
[32m[0907 03-04-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18896, current rewards: -295.24361, mean: -1.13555
[32m[0907 03-04-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18878, current rewards: -352.86337, mean: -1.13827
[32m[0907 03-04-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18944, current rewards: -417.56205, mean: -1.15989
[32m[0907 03-04-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18947, current rewards: -476.00307, mean: -1.16098
[32m[0907 03-04-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18906, current rewards: -529.60664, mean: -1.15132
[32m[0907 03-05-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18872, current rewards: -569.46284, mean: -1.11659
[32m[0907 03-05-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18769, current rewards: -590.51897, mean: -1.05450
[32m[0907 03-05-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18684, current rewards: -604.41284, mean: -0.99084
[32m[0907 03-05-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18611, current rewards: -607.46806, mean: -0.92041
[32m[0907 03-05-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18546, current rewards: -608.65929, mean: -0.85727
[32m[0907 03-05-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18458, current rewards: -611.69401, mean: -0.80486
[32m[0907 03-05-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18379, current rewards: -612.77967, mean: -0.75652
[32m[0907 03-06-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18306, current rewards: -619.25346, mean: -0.72006
[32m[0907 03-06-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18317, current rewards: -655.72759, mean: -0.72058
[32m[0907 03-06-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18254, current rewards: -706.44253, mean: -0.73588
[32m[0907 03-06-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18199, current rewards: -750.61922, mean: -0.74319
[32m[0907 03-06-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18148, current rewards: -787.35258, mean: -0.74279
[32m[0907 03-06-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18101, current rewards: -826.65713, mean: -0.74474
[32m[0907 03-06-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18058, current rewards: -876.01631, mean: -0.75519
[32m[0907 03-07-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18019, current rewards: -918.66671, mean: -0.75923
[32m[0907 03-07-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17983, current rewards: -910.24601, mean: -0.72242
[32m[0907 03-07-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17953, current rewards: -901.92161, mean: -0.68849
[32m[0907 03-07-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17944, current rewards: -893.59619, mean: -0.65706
[32m[0907 03-07-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17936, current rewards: -885.53176, mean: -0.62804
[32m[0907 03-07-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17929, current rewards: -877.14745, mean: -0.60079
[32m[0907 03-07-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17922, current rewards: -868.76076, mean: -0.57534
[32m[0907 03-08-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17922, current rewards: -860.37834, mean: -0.55152
[32m[0907 03-08-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17935, current rewards: -851.98744, mean: -0.52918
[32m[0907 03-08-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17948, current rewards: -843.59568, mean: -0.50819
[32m[0907 03-08-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17966, current rewards: -863.26682, mean: -0.50483
[32m[0907 03-08-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17980, current rewards: -880.94238, mean: -0.50054
[32m[0907 03-08-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18008, current rewards: -929.70742, mean: -0.51365
[32m[0907 03-09-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18028, current rewards: -978.59232, mean: -0.52612
[32m[0907 03-09-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18055, current rewards: -1037.01471, mean: -0.54294
[32m[0907 03-09-23 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18085, current rewards: -1083.95514, mean: -0.55304
[32m[0907 03-09-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18107, current rewards: -1122.81818, mean: -0.55862
[32m[0907 03-09-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18126, current rewards: -1188.84374, mean: -0.57711
[32m[0907 03-09-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18143, current rewards: -1187.86893, mean: -0.56297
[32m[0907 03-10-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18149, current rewards: -1193.92032, mean: -0.55274
[32m[0907 03-10-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18162, current rewards: -1197.09277, mean: -0.54167
[32m[0907 03-10-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18166, current rewards: -1197.67372, mean: -0.52994
[32m[0907 03-10-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18173, current rewards: -1197.89045, mean: -0.51857
[32m[0907 03-10-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18176, current rewards: -1198.21202, mean: -0.50772
[32m[0907 03-10-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18185, current rewards: -1210.48726, mean: -0.50228
[32m[0907 03-10-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18193, current rewards: -1234.39094, mean: -0.50178
[32m[0907 03-11-03 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0907 03-11-03 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-11-03 @MBExp.py:227][0m Rewards obtained: [-1233.2139078750686], Lows: [756], Highs: [33], Total time: 40467.42514200001
[32m[0907 03-14-11 @MBExp.py:144][0m ####################################################################
[32m[0907 03-14-11 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 03-14-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18857, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-14-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18850, current rewards: -20.31721, mean: -0.33862
[32m[0907 03-14-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18834, current rewards: -16.64788, mean: -0.15134
[32m[0907 03-14-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18816, current rewards: -12.95338, mean: -0.08096
[32m[0907 03-14-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18809, current rewards: -9.21313, mean: -0.04387
[32m[0907 03-15-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18793, current rewards: -5.46419, mean: -0.02102
[32m[0907 03-15-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18718, current rewards: -26.53390, mean: -0.08559
[32m[0907 03-15-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18654, current rewards: -30.20553, mean: -0.08390
[32m[0907 03-15-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18616, current rewards: -34.96590, mean: -0.08528
[32m[0907 03-15-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18587, current rewards: -38.30979, mean: -0.08328
[32m[0907 03-15-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18543, current rewards: -42.96305, mean: -0.08424
[32m[0907 03-15-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18470, current rewards: -41.36095, mean: -0.07386
[32m[0907 03-16-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18414, current rewards: -38.62930, mean: -0.06333
[32m[0907 03-16-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18363, current rewards: -35.89176, mean: -0.05438
[32m[0907 03-16-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18316, current rewards: -33.15511, mean: -0.04670
[32m[0907 03-16-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18235, current rewards: -48.40849, mean: -0.06370
[32m[0907 03-16-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18165, current rewards: -45.12545, mean: -0.05571
[32m[0907 03-16-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18106, current rewards: -42.01126, mean: -0.04885
[32m[0907 03-16-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18053, current rewards: -38.89980, mean: -0.04275
[32m[0907 03-17-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18006, current rewards: -47.39540, mean: -0.04937
[32m[0907 03-17-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17963, current rewards: -43.30574, mean: -0.04288
[32m[0907 03-17-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17923, current rewards: -39.65604, mean: -0.03741
[32m[0907 03-17-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17886, current rewards: -36.00488, mean: -0.03244
[32m[0907 03-17-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17851, current rewards: -32.35224, mean: -0.02789
[32m[0907 03-17-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17822, current rewards: -28.69823, mean: -0.02372
[32m[0907 03-17-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17797, current rewards: -25.04406, mean: -0.01988
[32m[0907 03-18-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17772, current rewards: -21.39190, mean: -0.01633
[32m[0907 03-18-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17773, current rewards: -41.47011, mean: -0.03049
[32m[0907 03-18-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17773, current rewards: -27.91819, mean: -0.01980
[32m[0907 03-18-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17770, current rewards: -20.96021, mean: -0.01436
[32m[0907 03-18-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17771, current rewards: -14.00008, mean: -0.00927
[32m[0907 03-18-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17773, current rewards: -7.03911, mean: -0.00451
[32m[0907 03-18-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17790, current rewards: -0.07846, mean: -0.00005
[32m[0907 03-19-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17806, current rewards: 6.88160, mean: 0.00415
[32m[0907 03-19-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17822, current rewards: -4.24718, mean: -0.00248
[32m[0907 03-19-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17836, current rewards: -15.56451, mean: -0.00884
[32m[0907 03-19-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17864, current rewards: -17.60778, mean: -0.00973
[32m[0907 03-19-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17893, current rewards: -24.12904, mean: -0.01297
[32m[0907 03-19-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17919, current rewards: -29.46327, mean: -0.01543
[32m[0907 03-20-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17943, current rewards: -56.36335, mean: -0.02876
[32m[0907 03-20-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17964, current rewards: -71.89856, mean: -0.03577
[32m[0907 03-20-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17986, current rewards: -91.41974, mean: -0.04438
[32m[0907 03-20-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17997, current rewards: -91.47828, mean: -0.04335
[32m[0907 03-20-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18006, current rewards: -113.12687, mean: -0.05237
[32m[0907 03-20-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18015, current rewards: -125.23421, mean: -0.05667
[32m[0907 03-20-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18023, current rewards: -120.56299, mean: -0.05335
[32m[0907 03-21-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18030, current rewards: -115.92665, mean: -0.05018
[32m[0907 03-21-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18036, current rewards: -111.29213, mean: -0.04716
[32m[0907 03-21-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18042, current rewards: -106.65317, mean: -0.04425
[32m[0907 03-21-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18048, current rewards: -102.01383, mean: -0.04147
[32m[0907 03-21-43 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 03-21-43 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-21-43 @MBExp.py:227][0m Rewards obtained: [-98.30334300845682], Lows: [141], Highs: [78], Total time: 40919.55646600001
[32m[0907 03-24-53 @MBExp.py:144][0m ####################################################################
[32m[0907 03-24-53 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 03-24-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18875, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-25-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18888, current rewards: -54.52135, mean: -0.90869
[32m[0907 03-25-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18887, current rewards: -98.21888, mean: -0.89290
[32m[0907 03-25-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18875, current rewards: -134.55351, mean: -0.84096
[32m[0907 03-25-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18871, current rewards: -168.77031, mean: -0.80367
[32m[0907 03-25-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18848, current rewards: -206.15406, mean: -0.79290
[32m[0907 03-25-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18776, current rewards: -237.22168, mean: -0.76523
[32m[0907 03-26-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18720, current rewards: -271.45958, mean: -0.75405
[32m[0907 03-26-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18714, current rewards: -336.24450, mean: -0.82011
[32m[0907 03-26-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18678, current rewards: -352.64212, mean: -0.76661
[32m[0907 03-26-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18649, current rewards: -356.03260, mean: -0.69810
[32m[0907 03-26-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18602, current rewards: -361.21796, mean: -0.64503
[32m[0907 03-26-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18525, current rewards: -356.96501, mean: -0.58519
[32m[0907 03-26-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18464, current rewards: -352.71031, mean: -0.53441
[32m[0907 03-27-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18412, current rewards: -348.45562, mean: -0.49078
[32m[0907 03-27-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18366, current rewards: -344.19752, mean: -0.45289
[32m[0907 03-27-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18330, current rewards: -380.88770, mean: -0.47023
[32m[0907 03-27-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18261, current rewards: -376.84616, mean: -0.43819
[32m[0907 03-27-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18195, current rewards: -372.80462, mean: -0.40968
[32m[0907 03-27-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18139, current rewards: -368.14624, mean: -0.38349
[32m[0907 03-27-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18092, current rewards: -395.44062, mean: -0.39153
[32m[0907 03-28-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18048, current rewards: -445.44062, mean: -0.42023
[32m[0907 03-28-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18007, current rewards: -495.44062, mean: -0.44634
[32m[0907 03-28-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17968, current rewards: -545.44062, mean: -0.47021
[32m[0907 03-28-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17933, current rewards: -595.44062, mean: -0.49210
[32m[0907 03-28-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17903, current rewards: -645.44062, mean: -0.51225
[32m[0907 03-28-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17876, current rewards: -695.44062, mean: -0.53087
[32m[0907 03-28-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17856, current rewards: -745.44062, mean: -0.54812
[32m[0907 03-29-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17851, current rewards: -795.44062, mean: -0.56414
[32m[0907 03-29-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17848, current rewards: -845.44062, mean: -0.57907
[32m[0907 03-29-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17845, current rewards: -895.44062, mean: -0.59301
[32m[0907 03-29-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17845, current rewards: -945.44062, mean: -0.60605
[32m[0907 03-29-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17843, current rewards: -995.44062, mean: -0.61829
[32m[0907 03-29-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17858, current rewards: -1045.44062, mean: -0.62978
[32m[0907 03-29-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17871, current rewards: -1095.44062, mean: -0.64061
[32m[0907 03-30-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17885, current rewards: -1145.44062, mean: -0.65082
[32m[0907 03-30-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17897, current rewards: -1195.44062, mean: -0.66046
[32m[0907 03-30-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17909, current rewards: -1245.44062, mean: -0.66959
[32m[0907 03-30-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17934, current rewards: -1295.44062, mean: -0.67824
[32m[0907 03-30-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17957, current rewards: -1345.44062, mean: -0.68645
[32m[0907 03-30-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17980, current rewards: -1395.44062, mean: -0.69425
[32m[0907 03-31-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18001, current rewards: -1445.44062, mean: -0.70167
[32m[0907 03-31-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18011, current rewards: -1495.44062, mean: -0.70874
[32m[0907 03-31-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18020, current rewards: -1545.44062, mean: -0.71548
[32m[0907 03-31-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18028, current rewards: -1595.44062, mean: -0.72192
[32m[0907 03-31-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18035, current rewards: -1645.44062, mean: -0.72807
[32m[0907 03-31-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18042, current rewards: -1695.44062, mean: -0.73396
[32m[0907 03-31-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18049, current rewards: -1745.44062, mean: -0.73959
[32m[0907 03-32-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18056, current rewards: -1795.44062, mean: -0.74500
[32m[0907 03-32-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18061, current rewards: -1845.44062, mean: -0.75018
[32m[0907 03-32-25 @Agent.py:117][0m Average action selection time: 0.1807
[32m[0907 03-32-25 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-32-25 @MBExp.py:227][0m Rewards obtained: [-1885.4406239387135], Lows: [49], Highs: [1838], Total time: 41372.04981100001
[32m[0907 03-35-37 @MBExp.py:144][0m ####################################################################
[32m[0907 03-35-37 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 03-35-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18838, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-35-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18874, current rewards: -18.35047, mean: -0.30584
[32m[0907 03-35-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18860, current rewards: -12.54754, mean: -0.11407
[32m[0907 03-36-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18819, current rewards: -6.54269, mean: -0.04089
[32m[0907 03-36-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18805, current rewards: -0.93041, mean: -0.00443
[32m[0907 03-36-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18793, current rewards: 4.69738, mean: 0.01807
[32m[0907 03-36-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18801, current rewards: -9.69045, mean: -0.03126
[32m[0907 03-36-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18737, current rewards: -6.55783, mean: -0.01822
[32m[0907 03-36-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18682, current rewards: -2.63023, mean: -0.00642
[32m[0907 03-37-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18641, current rewards: 1.30441, mean: 0.00284
[32m[0907 03-37-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18607, current rewards: 5.23939, mean: 0.01027
[32m[0907 03-37-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18582, current rewards: 9.15373, mean: 0.01635
[32m[0907 03-37-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18556, current rewards: 13.22079, mean: 0.02167
[32m[0907 03-37-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18497, current rewards: 17.38738, mean: 0.02634
[32m[0907 03-37-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18444, current rewards: 21.55567, mean: 0.03036
[32m[0907 03-37-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18399, current rewards: 25.71984, mean: 0.03384
[32m[0907 03-38-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18353, current rewards: 29.88939, mean: 0.03690
[32m[0907 03-38-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18364, current rewards: -12.51753, mean: -0.01456
[32m[0907 03-38-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18427, current rewards: -53.36346, mean: -0.05864
[32m[0907 03-38-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18579, current rewards: -105.13176, mean: -0.10951
[32m[0907 03-38-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18603, current rewards: -148.55683, mean: -0.14709
[32m[0907 03-38-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18743, current rewards: -177.75652, mean: -0.16769
[32m[0907 03-39-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18755, current rewards: -215.70859, mean: -0.19433
[32m[0907 03-39-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18790, current rewards: -255.95430, mean: -0.22065
[32m[0907 03-39-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18919, current rewards: -292.15196, mean: -0.24145
[32m[0907 03-39-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18927, current rewards: -358.76052, mean: -0.28473
[32m[0907 03-39-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18930, current rewards: -390.35103, mean: -0.29798
[32m[0907 03-39-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18969, current rewards: -428.10915, mean: -0.31479
[32m[0907 03-40-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18933, current rewards: -461.10225, mean: -0.32702
[32m[0907 03-40-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18897, current rewards: -508.25362, mean: -0.34812
[32m[0907 03-40-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18860, current rewards: -541.81265, mean: -0.35882
[32m[0907 03-40-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18832, current rewards: -585.13856, mean: -0.37509
[32m[0907 03-40-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18808, current rewards: -620.05046, mean: -0.38512
[32m[0907 03-40-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18795, current rewards: -668.89076, mean: -0.40295
[32m[0907 03-40-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18786, current rewards: -717.49855, mean: -0.41959
[32m[0907 03-41-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18783, current rewards: -751.91124, mean: -0.42722
[32m[0907 03-41-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18776, current rewards: -797.67886, mean: -0.44071
[32m[0907 03-41-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18802, current rewards: -791.10985, mean: -0.42533
[32m[0907 03-41-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18803, current rewards: -784.66979, mean: -0.41082
[32m[0907 03-41-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18805, current rewards: -778.23029, mean: -0.39706
[32m[0907 03-41-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18796, current rewards: -771.80075, mean: -0.38398
[32m[0907 03-42-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18785, current rewards: -765.36602, mean: -0.37154
[32m[0907 03-42-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18775, current rewards: -758.93354, mean: -0.35968
[32m[0907 03-42-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18765, current rewards: -752.49912, mean: -0.34838
[32m[0907 03-42-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18757, current rewards: -745.10740, mean: -0.33715
[32m[0907 03-42-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18749, current rewards: -739.33361, mean: -0.32714
[32m[0907 03-42-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18747, current rewards: -752.20385, mean: -0.32563
[32m[0907 03-43-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18743, current rewards: -755.71975, mean: -0.32022
[32m[0907 03-43-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18737, current rewards: -750.16483, mean: -0.31127
[32m[0907 03-43-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18728, current rewards: -744.49282, mean: -0.30264
[32m[0907 03-43-25 @Agent.py:117][0m Average action selection time: 0.1872
[32m[0907 03-43-25 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-43-26 @MBExp.py:227][0m Rewards obtained: [-739.9559551189426], Lows: [382], Highs: [201], Total time: 41840.94166000001
[32m[0907 03-46-40 @MBExp.py:144][0m ####################################################################
[32m[0907 03-46-40 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 03-46-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18719, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-46-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18841, current rewards: -110.00000, mean: -1.83333
[32m[0907 03-47-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18821, current rewards: -210.00000, mean: -1.90909
[32m[0907 03-47-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18812, current rewards: -310.00000, mean: -1.93750
[32m[0907 03-47-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18803, current rewards: -410.00000, mean: -1.95238
[32m[0907 03-47-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18804, current rewards: -510.00000, mean: -1.96154
[32m[0907 03-47-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18744, current rewards: -610.00000, mean: -1.96774
[32m[0907 03-47-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18681, current rewards: -710.00000, mean: -1.97222
[32m[0907 03-47-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18635, current rewards: -810.00000, mean: -1.97561
[32m[0907 03-48-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18602, current rewards: -910.00000, mean: -1.97826
[32m[0907 03-48-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18578, current rewards: -1010.00000, mean: -1.98039
[32m[0907 03-48-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18522, current rewards: -1110.00000, mean: -1.98214
[32m[0907 03-48-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18456, current rewards: -1210.00000, mean: -1.98361
[32m[0907 03-48-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18400, current rewards: -1310.00000, mean: -1.98485
[32m[0907 03-48-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18354, current rewards: -1410.00000, mean: -1.98592
[32m[0907 03-48-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18274, current rewards: -1510.00000, mean: -1.98684
[32m[0907 03-49-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18202, current rewards: -1610.00000, mean: -1.98765
[32m[0907 03-49-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18140, current rewards: -1710.00000, mean: -1.98837
[32m[0907 03-49-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18084, current rewards: -1810.00000, mean: -1.98901
[32m[0907 03-49-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18033, current rewards: -1910.00000, mean: -1.98958
[32m[0907 03-49-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17986, current rewards: -2010.00000, mean: -1.99010
[32m[0907 03-49-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17949, current rewards: -2110.00000, mean: -1.99057
[32m[0907 03-49-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17912, current rewards: -2210.00000, mean: -1.99099
[32m[0907 03-50-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17879, current rewards: -2310.00000, mean: -1.99138
[32m[0907 03-50-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17847, current rewards: -2410.00000, mean: -1.99174
[32m[0907 03-50-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17817, current rewards: -2510.00000, mean: -1.99206
[32m[0907 03-50-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17791, current rewards: -2610.00000, mean: -1.99237
[32m[0907 03-50-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17768, current rewards: -2710.00000, mean: -1.99265
[32m[0907 03-50-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17761, current rewards: -2810.00000, mean: -1.99291
[32m[0907 03-51-00 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17758, current rewards: -2910.00000, mean: -1.99315
[32m[0907 03-51-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17759, current rewards: -3010.00000, mean: -1.99338
[32m[0907 03-51-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17760, current rewards: -3110.00000, mean: -1.99359
[32m[0907 03-51-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17761, current rewards: -3210.00000, mean: -1.99379
[32m[0907 03-51-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17771, current rewards: -3310.00000, mean: -1.99398
[32m[0907 03-51-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17787, current rewards: -3410.00000, mean: -1.99415
[32m[0907 03-51-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17801, current rewards: -3510.00000, mean: -1.99432
[32m[0907 03-52-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17816, current rewards: -3610.00000, mean: -1.99448
[32m[0907 03-52-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17845, current rewards: -3710.00000, mean: -1.99462
[32m[0907 03-52-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17871, current rewards: -3810.00000, mean: -1.99476
[32m[0907 03-52-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17897, current rewards: -3910.00000, mean: -1.99490
[32m[0907 03-52-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17909, current rewards: -4010.00000, mean: -1.99502
[32m[0907 03-52-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17919, current rewards: -4110.00000, mean: -1.99515
[32m[0907 03-52-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17929, current rewards: -4210.00000, mean: -1.99526
[32m[0907 03-53-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17937, current rewards: -4310.00000, mean: -1.99537
[32m[0907 03-53-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17946, current rewards: -4410.00000, mean: -1.99548
[32m[0907 03-53-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17955, current rewards: -4510.00000, mean: -1.99558
[32m[0907 03-53-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17964, current rewards: -4610.00000, mean: -1.99567
[32m[0907 03-53-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17973, current rewards: -4710.00000, mean: -1.99576
[32m[0907 03-53-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17981, current rewards: -4810.00000, mean: -1.99585
[32m[0907 03-54-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17989, current rewards: -4910.00000, mean: -1.99593
[32m[0907 03-54-11 @Agent.py:117][0m Average action selection time: 0.1799
[32m[0907 03-54-11 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-54-11 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 42291.60652900001
[32m[0907 03-57-28 @MBExp.py:144][0m ####################################################################
[32m[0907 03-57-28 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 03-57-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.23726, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-57-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19640, current rewards: -64.92218, mean: -1.08204
[32m[0907 03-57-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19476, current rewards: -115.16193, mean: -1.04693
[32m[0907 03-57-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19281, current rewards: -177.01909, mean: -1.10637
[32m[0907 03-58-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19209, current rewards: -225.96692, mean: -1.07603
[32m[0907 03-58-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19136, current rewards: -325.96692, mean: -1.25372
[32m[0907 03-58-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19020, current rewards: -425.96692, mean: -1.37409
[32m[0907 03-58-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18919, current rewards: -525.96692, mean: -1.46102
[32m[0907 03-58-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18843, current rewards: -625.96692, mean: -1.52675
[32m[0907 03-58-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18781, current rewards: -725.96692, mean: -1.57819
[32m[0907 03-59-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18733, current rewards: -825.96692, mean: -1.61954
[32m[0907 03-59-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18696, current rewards: -925.96692, mean: -1.65351
[32m[0907 03-59-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18615, current rewards: -1025.96692, mean: -1.68191
[32m[0907 03-59-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18550, current rewards: -1125.96692, mean: -1.70601
[32m[0907 03-59-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18495, current rewards: -1225.96692, mean: -1.72671
[32m[0907 03-59-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18445, current rewards: -1325.96692, mean: -1.74469
[32m[0907 03-59-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18386, current rewards: -1425.96692, mean: -1.76045
[32m[0907 04-00-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18316, current rewards: -1525.96692, mean: -1.77438
[32m[0907 04-00-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18253, current rewards: -1625.96692, mean: -1.78678
[32m[0907 04-00-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18193, current rewards: -1725.96692, mean: -1.79788
[32m[0907 04-00-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18138, current rewards: -1825.96692, mean: -1.80789
[32m[0907 04-00-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18090, current rewards: -1925.96692, mean: -1.81695
[32m[0907 04-00-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18046, current rewards: -2025.96692, mean: -1.82520
[32m[0907 04-00-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18007, current rewards: -2125.96692, mean: -1.83273
[32m[0907 04-01-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17970, current rewards: -2225.96692, mean: -1.83964
[32m[0907 04-01-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17935, current rewards: -2325.96692, mean: -1.84601
[32m[0907 04-01-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17904, current rewards: -2425.96692, mean: -1.85188
[32m[0907 04-01-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17876, current rewards: -2525.96692, mean: -1.85733
[32m[0907 04-01-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17861, current rewards: -2625.96692, mean: -1.86239
[32m[0907 04-01-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17855, current rewards: -2725.96692, mean: -1.86710
[32m[0907 04-01-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17851, current rewards: -2825.96692, mean: -1.87150
[32m[0907 04-02-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17850, current rewards: -2925.96692, mean: -1.87562
[32m[0907 04-02-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17847, current rewards: -3025.96692, mean: -1.87948
[32m[0907 04-02-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17845, current rewards: -3125.96692, mean: -1.88311
[32m[0907 04-02-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17858, current rewards: -3225.96692, mean: -1.88653
[32m[0907 04-02-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17872, current rewards: -3325.96692, mean: -1.88975
[32m[0907 04-02-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17885, current rewards: -3425.96692, mean: -1.89280
[32m[0907 04-03-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17897, current rewards: -3525.96692, mean: -1.89568
[32m[0907 04-03-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17912, current rewards: -3625.96692, mean: -1.89841
[32m[0907 04-03-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17936, current rewards: -3725.96692, mean: -1.90100
[32m[0907 04-03-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17958, current rewards: -3825.96692, mean: -1.90347
[32m[0907 04-03-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17979, current rewards: -3925.96692, mean: -1.90581
[32m[0907 04-03-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17999, current rewards: -4025.96692, mean: -1.90804
[32m[0907 04-03-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18020, current rewards: -4125.96692, mean: -1.91017
[32m[0907 04-04-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18038, current rewards: -4225.96692, mean: -1.91220
[32m[0907 04-04-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18057, current rewards: -4325.96692, mean: -1.91414
[32m[0907 04-04-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18074, current rewards: -4425.96692, mean: -1.91600
[32m[0907 04-04-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18080, current rewards: -4525.96692, mean: -1.91778
[32m[0907 04-04-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18086, current rewards: -4625.96692, mean: -1.91949
[32m[0907 04-04-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18091, current rewards: -4725.96692, mean: -1.92112
[32m[0907 04-05-01 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0907 04-05-01 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-05-01 @MBExp.py:227][0m Rewards obtained: [-4805.966919253457], Lows: [2324], Highs: [160], Total time: 42744.787268000015
[32m[0907 04-08-18 @MBExp.py:144][0m ####################################################################
[32m[0907 04-08-18 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 04-08-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18884, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-08-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19244, current rewards: -60.80172, mean: -1.01336
[32m[0907 04-08-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19307, current rewards: -61.46231, mean: -0.55875
[32m[0907 04-08-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19157, current rewards: -56.55870, mean: -0.35349
[32m[0907 04-08-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19083, current rewards: -51.35652, mean: -0.24455
[32m[0907 04-09-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19028, current rewards: -75.47787, mean: -0.29030
[32m[0907 04-09-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18952, current rewards: -70.94223, mean: -0.22885
[32m[0907 04-09-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18859, current rewards: -66.40664, mean: -0.18446
[32m[0907 04-09-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18794, current rewards: -61.87105, mean: -0.15091
[32m[0907 04-09-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18740, current rewards: -88.26376, mean: -0.19188
[32m[0907 04-09-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18694, current rewards: -138.26376, mean: -0.27111
[32m[0907 04-10-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18658, current rewards: -188.26376, mean: -0.33619
[32m[0907 04-10-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18628, current rewards: -238.26376, mean: -0.39060
[32m[0907 04-10-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18603, current rewards: -288.26376, mean: -0.43676
[32m[0907 04-10-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18545, current rewards: -338.26376, mean: -0.47643
[32m[0907 04-10-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18490, current rewards: -388.26376, mean: -0.51087
[32m[0907 04-10-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18429, current rewards: -438.26376, mean: -0.54107
[32m[0907 04-10-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18356, current rewards: -462.59804, mean: -0.53790
[32m[0907 04-11-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18289, current rewards: -512.59804, mean: -0.56329
[32m[0907 04-11-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18227, current rewards: -562.59804, mean: -0.58604
[32m[0907 04-11-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18170, current rewards: -612.59804, mean: -0.60653
[32m[0907 04-11-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18123, current rewards: -662.59804, mean: -0.62509
[32m[0907 04-11-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18077, current rewards: -712.59804, mean: -0.64198
[32m[0907 04-11-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18036, current rewards: -762.59804, mean: -0.65741
[32m[0907 04-11-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17998, current rewards: -812.59804, mean: -0.67157
[32m[0907 04-12-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17966, current rewards: -862.59804, mean: -0.68460
[32m[0907 04-12-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17936, current rewards: -912.59804, mean: -0.69664
[32m[0907 04-12-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17908, current rewards: -962.59804, mean: -0.70779
[32m[0907 04-12-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17881, current rewards: -1012.59804, mean: -0.71815
[32m[0907 04-12-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17874, current rewards: -1062.59804, mean: -0.72781
[32m[0907 04-12-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17871, current rewards: -1112.59804, mean: -0.73682
[32m[0907 04-12-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17866, current rewards: -1162.59804, mean: -0.74526
[32m[0907 04-13-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17861, current rewards: -1212.59804, mean: -0.75317
[32m[0907 04-13-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17856, current rewards: -1262.59804, mean: -0.76060
[32m[0907 04-13-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17853, current rewards: -1312.59804, mean: -0.76760
[32m[0907 04-13-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17849, current rewards: -1362.59804, mean: -0.77420
[32m[0907 04-13-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17853, current rewards: -1412.59804, mean: -0.78044
[32m[0907 04-13-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17866, current rewards: -1462.59804, mean: -0.78634
[32m[0907 04-13-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17878, current rewards: -1512.59804, mean: -0.79194
[32m[0907 04-14-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17902, current rewards: -1562.59804, mean: -0.79724
[32m[0907 04-14-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17926, current rewards: -1612.59804, mean: -0.80229
[32m[0907 04-14-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17945, current rewards: -1662.59804, mean: -0.80709
[32m[0907 04-14-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17966, current rewards: -1712.59804, mean: -0.81166
[32m[0907 04-14-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17984, current rewards: -1762.59804, mean: -0.81602
[32m[0907 04-14-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18002, current rewards: -1812.59804, mean: -0.82018
[32m[0907 04-15-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18019, current rewards: -1862.59804, mean: -0.82416
[32m[0907 04-15-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18038, current rewards: -1912.59804, mean: -0.82796
[32m[0907 04-15-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18055, current rewards: -1962.59804, mean: -0.83161
[32m[0907 04-15-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18072, current rewards: -2012.59804, mean: -0.83510
[32m[0907 04-15-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18087, current rewards: -2062.59804, mean: -0.83845
[32m[0907 04-15-51 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0907 04-15-51 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-15-51 @MBExp.py:227][0m Rewards obtained: [-2102.598035984464], Lows: [36], Highs: [2069], Total time: 43198.09671200001
[32m[0907 04-19-09 @MBExp.py:144][0m ####################################################################
[32m[0907 04-19-09 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 04-19-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18329, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-19-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19699, current rewards: -100.10742, mean: -1.66846
[32m[0907 04-19-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20132, current rewards: -183.95817, mean: -1.67235
[32m[0907 04-19-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20197, current rewards: -274.96274, mean: -1.71852
[32m[0907 04-19-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20310, current rewards: -361.64898, mean: -1.72214
[32m[0907 04-20-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20194, current rewards: -447.88544, mean: -1.72264
[32m[0907 04-20-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20050, current rewards: -539.23890, mean: -1.73948
[32m[0907 04-20-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19935, current rewards: -628.23015, mean: -1.74508
[32m[0907 04-20-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19742, current rewards: -728.23015, mean: -1.77617
[32m[0907 04-20-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19589, current rewards: -828.23015, mean: -1.80050
[32m[0907 04-20-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19466, current rewards: -928.23015, mean: -1.82006
[32m[0907 04-20-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19364, current rewards: -1028.23015, mean: -1.83613
[32m[0907 04-21-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19274, current rewards: -1128.23015, mean: -1.84956
[32m[0907 04-21-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19202, current rewards: -1228.23015, mean: -1.86095
[32m[0907 04-21-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19119, current rewards: -1328.23015, mean: -1.87075
[32m[0907 04-21-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19026, current rewards: -1428.23015, mean: -1.87925
[32m[0907 04-21-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18919, current rewards: -1528.23015, mean: -1.88670
[32m[0907 04-21-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18835, current rewards: -1628.23015, mean: -1.89329
[32m[0907 04-22-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18913, current rewards: -1717.41874, mean: -1.88727
[32m[0907 04-22-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18922, current rewards: -1800.92468, mean: -1.87596
[32m[0907 04-22-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18972, current rewards: -1888.56318, mean: -1.86986
[32m[0907 04-22-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18975, current rewards: -1970.44028, mean: -1.85891
[32m[0907 04-22-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19047, current rewards: -2050.56274, mean: -1.84735
[32m[0907 04-22-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19119, current rewards: -2101.24299, mean: -1.81142
[32m[0907 04-23-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19037, current rewards: -2099.18317, mean: -1.73486
[32m[0907 04-23-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18962, current rewards: -2093.41576, mean: -1.66144
[32m[0907 04-23-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18893, current rewards: -2087.65439, mean: -1.59363
[32m[0907 04-23-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18828, current rewards: -2081.89450, mean: -1.53080
[32m[0907 04-23-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18773, current rewards: -2076.13391, mean: -1.47244
[32m[0907 04-23-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18737, current rewards: -2070.37478, mean: -1.41806
[32m[0907 04-23-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18706, current rewards: -2064.61371, mean: -1.36729
[32m[0907 04-24-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18675, current rewards: -2058.85453, mean: -1.31978
[32m[0907 04-24-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18647, current rewards: -2050.40107, mean: -1.27354
[32m[0907 04-24-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18621, current rewards: -2042.94087, mean: -1.23069
[32m[0907 04-24-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18597, current rewards: -2066.50918, mean: -1.20848
[32m[0907 04-24-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18575, current rewards: -2116.50918, mean: -1.20256
[32m[0907 04-24-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18565, current rewards: -2166.50918, mean: -1.19697
[32m[0907 04-24-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18561, current rewards: -2216.50918, mean: -1.19167
[32m[0907 04-25-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18570, current rewards: -2266.50918, mean: -1.18665
[32m[0907 04-25-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18578, current rewards: -2316.50918, mean: -1.18189
[32m[0907 04-25-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18586, current rewards: -2366.50918, mean: -1.17737
[32m[0907 04-25-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18590, current rewards: -2416.50918, mean: -1.17306
[32m[0907 04-25-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18595, current rewards: -2466.50918, mean: -1.16896
[32m[0907 04-25-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18600, current rewards: -2516.50918, mean: -1.16505
[32m[0907 04-26-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18606, current rewards: -2566.50918, mean: -1.16132
[32m[0907 04-26-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18612, current rewards: -2616.50918, mean: -1.15775
[32m[0907 04-26-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18618, current rewards: -2666.50918, mean: -1.15433
[32m[0907 04-26-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18620, current rewards: -2716.50918, mean: -1.15106
[32m[0907 04-26-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18623, current rewards: -2766.50918, mean: -1.14793
[32m[0907 04-26-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18624, current rewards: -2816.50918, mean: -1.14492
[32m[0907 04-26-55 @Agent.py:117][0m Average action selection time: 0.1862
[32m[0907 04-26-55 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-26-56 @MBExp.py:227][0m Rewards obtained: [-2856.50918160784], Lows: [1059], Highs: [828], Total time: 43664.45328200002
[32m[0907 04-30-16 @MBExp.py:144][0m ####################################################################
[32m[0907 04-30-16 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 04-30-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18755, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-30-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18886, current rewards: -48.64141, mean: -0.81069
[32m[0907 04-30-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18857, current rewards: -100.11671, mean: -0.91015
[32m[0907 04-30-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18816, current rewards: -166.16079, mean: -1.03850
[32m[0907 04-30-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18826, current rewards: -222.79637, mean: -1.06094
[32m[0907 04-31-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18825, current rewards: -283.86338, mean: -1.09178
[32m[0907 04-31-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18751, current rewards: -349.21344, mean: -1.12649
[32m[0907 04-31-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18708, current rewards: -398.75401, mean: -1.10765
[32m[0907 04-31-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18663, current rewards: -439.85992, mean: -1.07283
[32m[0907 04-31-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18629, current rewards: -482.91733, mean: -1.04982
[32m[0907 04-31-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18600, current rewards: -528.25952, mean: -1.03580
[32m[0907 04-32-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18576, current rewards: -570.69758, mean: -1.01910
[32m[0907 04-32-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18556, current rewards: -617.16180, mean: -1.01174
[32m[0907 04-32-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18536, current rewards: -660.42351, mean: -1.00064
[32m[0907 04-32-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18481, current rewards: -704.92243, mean: -0.99285
[32m[0907 04-32-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18405, current rewards: -748.40273, mean: -0.98474
[32m[0907 04-32-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18328, current rewards: -793.68715, mean: -0.97986
[32m[0907 04-32-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18260, current rewards: -839.46522, mean: -0.97612
[32m[0907 04-33-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18198, current rewards: -884.07315, mean: -0.97151
[32m[0907 04-33-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18144, current rewards: -929.73978, mean: -0.96848
[32m[0907 04-33-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18093, current rewards: -975.36207, mean: -0.96571
[32m[0907 04-33-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18050, current rewards: -1017.85996, mean: -0.96025
[32m[0907 04-33-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18011, current rewards: -1060.57529, mean: -0.95547
[32m[0907 04-33-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17974, current rewards: -1103.38160, mean: -0.95119
[32m[0907 04-33-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17941, current rewards: -1149.20140, mean: -0.94975
[32m[0907 04-34-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17909, current rewards: -1186.95812, mean: -0.94203
[32m[0907 04-34-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17880, current rewards: -1236.54137, mean: -0.94392
[32m[0907 04-34-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17855, current rewards: -1289.44593, mean: -0.94812
[32m[0907 04-34-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17830, current rewards: -1333.07239, mean: -0.94544
[32m[0907 04-34-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17823, current rewards: -1387.05925, mean: -0.95004
[32m[0907 04-34-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17821, current rewards: -1439.14180, mean: -0.95307
[32m[0907 04-34-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17820, current rewards: -1476.41883, mean: -0.94642
[32m[0907 04-35-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17822, current rewards: -1513.02541, mean: -0.93977
[32m[0907 04-35-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17820, current rewards: -1507.78830, mean: -0.90831
[32m[0907 04-35-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17819, current rewards: -1503.68202, mean: -0.87935
[32m[0907 04-35-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17817, current rewards: -1499.57574, mean: -0.85203
[32m[0907 04-35-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17821, current rewards: -1511.70134, mean: -0.83519
[32m[0907 04-35-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17836, current rewards: -1561.70134, mean: -0.83962
[32m[0907 04-35-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17861, current rewards: -1611.70134, mean: -0.84382
[32m[0907 04-36-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17886, current rewards: -1661.70134, mean: -0.84781
[32m[0907 04-36-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17908, current rewards: -1711.70134, mean: -0.85159
[32m[0907 04-36-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17931, current rewards: -1761.70134, mean: -0.85519
[32m[0907 04-36-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17952, current rewards: -1811.70134, mean: -0.85863
[32m[0907 04-36-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17975, current rewards: -1861.70134, mean: -0.86190
[32m[0907 04-36-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17994, current rewards: -1911.70134, mean: -0.86502
[32m[0907 04-37-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18013, current rewards: -1961.70134, mean: -0.86801
[32m[0907 04-37-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18030, current rewards: -2011.70134, mean: -0.87087
[32m[0907 04-37-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18048, current rewards: -2061.70134, mean: -0.87360
[32m[0907 04-37-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18064, current rewards: -2111.70134, mean: -0.87622
[32m[0907 04-37-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18081, current rewards: -2161.70134, mean: -0.87874
[32m[0907 04-37-49 @Agent.py:117][0m Average action selection time: 0.1808
[32m[0907 04-37-49 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-37-49 @MBExp.py:227][0m Rewards obtained: [-2201.7013410135933], Lows: [266], Highs: [1734], Total time: 44117.408597000016
[32m[0907 04-41-12 @MBExp.py:144][0m ####################################################################
[32m[0907 04-41-12 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 04-41-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18943, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-41-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19487, current rewards: -94.52656, mean: -1.57544
[32m[0907 04-41-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19519, current rewards: -161.05708, mean: -1.46416
[32m[0907 04-41-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19413, current rewards: -224.61413, mean: -1.40384
[32m[0907 04-41-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19551, current rewards: -276.32497, mean: -1.31583
[32m[0907 04-42-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20156, current rewards: -351.29909, mean: -1.35115
[32m[0907 04-42-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20250, current rewards: -418.88672, mean: -1.35125
[32m[0907 04-42-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20031, current rewards: -518.88672, mean: -1.44135
[32m[0907 04-42-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19825, current rewards: -618.88672, mean: -1.50948
[32m[0907 04-42-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19662, current rewards: -718.88672, mean: -1.56280
[32m[0907 04-42-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19528, current rewards: -818.88672, mean: -1.60566
[32m[0907 04-43-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19415, current rewards: -918.88672, mean: -1.64087
[32m[0907 04-43-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19324, current rewards: -1018.88672, mean: -1.67031
[32m[0907 04-43-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19214, current rewards: -1118.88672, mean: -1.69528
[32m[0907 04-43-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19107, current rewards: -1218.88672, mean: -1.71674
[32m[0907 04-43-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18978, current rewards: -1318.88672, mean: -1.73538
[32m[0907 04-43-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18865, current rewards: -1418.88672, mean: -1.75171
[32m[0907 04-43-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18768, current rewards: -1518.88672, mean: -1.76615
[32m[0907 04-44-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18683, current rewards: -1618.88672, mean: -1.77900
[32m[0907 04-44-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18607, current rewards: -1718.88672, mean: -1.79051
[32m[0907 04-44-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18535, current rewards: -1818.88672, mean: -1.80088
[32m[0907 04-44-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18468, current rewards: -1918.88672, mean: -1.81027
[32m[0907 04-44-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18409, current rewards: -2018.88672, mean: -1.81882
[32m[0907 04-44-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18356, current rewards: -2118.88672, mean: -1.82663
[32m[0907 04-44-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18307, current rewards: -2218.88672, mean: -1.83379
[32m[0907 04-45-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18262, current rewards: -2318.88672, mean: -1.84039
[32m[0907 04-45-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18220, current rewards: -2418.88672, mean: -1.84648
[32m[0907 04-45-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18182, current rewards: -2518.88672, mean: -1.85212
[32m[0907 04-45-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18147, current rewards: -2618.88672, mean: -1.85737
[32m[0907 04-45-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18115, current rewards: -2718.88672, mean: -1.86225
[32m[0907 04-45-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18082, current rewards: -2818.88672, mean: -1.86681
[32m[0907 04-45-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18071, current rewards: -2918.88672, mean: -1.87108
[32m[0907 04-46-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18063, current rewards: -3018.88672, mean: -1.87508
[32m[0907 04-46-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18054, current rewards: -3118.88672, mean: -1.87885
[32m[0907 04-46-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18048, current rewards: -3218.88672, mean: -1.88239
[32m[0907 04-46-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18040, current rewards: -3318.88672, mean: -1.88573
[32m[0907 04-46-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18044, current rewards: -3418.88672, mean: -1.88889
[32m[0907 04-46-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18054, current rewards: -3518.88672, mean: -1.89187
[32m[0907 04-46-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18078, current rewards: -3618.88672, mean: -1.89471
[32m[0907 04-47-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18100, current rewards: -3718.88672, mean: -1.89739
[32m[0907 04-47-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18119, current rewards: -3818.88672, mean: -1.89994
[32m[0907 04-47-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18137, current rewards: -3918.88672, mean: -1.90237
[32m[0907 04-47-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18154, current rewards: -4018.88672, mean: -1.90469
[32m[0907 04-47-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18170, current rewards: -4118.88672, mean: -1.90689
[32m[0907 04-47-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18186, current rewards: -4218.88672, mean: -1.90900
[32m[0907 04-48-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18201, current rewards: -4318.88672, mean: -1.91101
[32m[0907 04-48-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18217, current rewards: -4418.88672, mean: -1.91294
[32m[0907 04-48-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18231, current rewards: -4518.88672, mean: -1.91478
[32m[0907 04-48-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18245, current rewards: -4618.88672, mean: -1.91655
[32m[0907 04-48-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18252, current rewards: -4718.88672, mean: -1.91825
[32m[0907 04-48-49 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0907 04-48-49 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-48-49 @MBExp.py:227][0m Rewards obtained: [-4798.886717203241], Lows: [2346], Highs: [113], Total time: 44574.60261900002
[32m[0907 04-52-14 @MBExp.py:144][0m ####################################################################
[32m[0907 04-52-14 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 04-52-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18984, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-52-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18955, current rewards: -97.86080, mean: -1.63101
[32m[0907 04-52-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18915, current rewards: -184.88692, mean: -1.68079
[32m[0907 04-52-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18876, current rewards: -279.83842, mean: -1.74899
[32m[0907 04-52-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18889, current rewards: -370.06888, mean: -1.76223
[32m[0907 04-53-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18860, current rewards: -458.28096, mean: -1.76262
[32m[0907 04-53-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18846, current rewards: -533.01063, mean: -1.71939
[32m[0907 04-53-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18849, current rewards: -607.29408, mean: -1.68693
[32m[0907 04-53-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18804, current rewards: -687.07280, mean: -1.67579
[32m[0907 04-53-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18766, current rewards: -762.74072, mean: -1.65813
[32m[0907 04-53-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18726, current rewards: -841.62842, mean: -1.65025
[32m[0907 04-53-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18697, current rewards: -925.49972, mean: -1.65268
[32m[0907 04-54-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18666, current rewards: -1004.12484, mean: -1.64611
[32m[0907 04-54-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18648, current rewards: -1079.90129, mean: -1.63621
[32m[0907 04-54-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18605, current rewards: -1152.96737, mean: -1.62390
[32m[0907 04-54-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18508, current rewards: -1168.38134, mean: -1.53734
[32m[0907 04-54-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18459, current rewards: -1242.00512, mean: -1.53334
[32m[0907 04-54-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18412, current rewards: -1309.03736, mean: -1.52214
[32m[0907 04-55-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18343, current rewards: -1382.24578, mean: -1.51895
[32m[0907 04-55-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18306, current rewards: -1467.49400, mean: -1.52864
[32m[0907 04-55-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18258, current rewards: -1547.73622, mean: -1.53241
[32m[0907 04-55-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18228, current rewards: -1610.04317, mean: -1.51891
[32m[0907 04-55-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18220, current rewards: -1682.72473, mean: -1.51597
[32m[0907 04-55-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18182, current rewards: -1762.48092, mean: -1.51938
[32m[0907 04-55-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18149, current rewards: -1831.16805, mean: -1.51336
[32m[0907 04-56-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18111, current rewards: -1913.74682, mean: -1.51885
[32m[0907 04-56-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18090, current rewards: -1974.77273, mean: -1.50746
[32m[0907 04-56-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18067, current rewards: -2050.29604, mean: -1.50757
[32m[0907 04-56-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18046, current rewards: -2112.58429, mean: -1.49829
[32m[0907 04-56-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18024, current rewards: -2190.83116, mean: -1.50057
[32m[0907 04-56-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18001, current rewards: -2261.22663, mean: -1.49750
[32m[0907 04-56-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17983, current rewards: -2336.45652, mean: -1.49773
[32m[0907 04-57-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17986, current rewards: -2402.50032, mean: -1.49224
[32m[0907 04-57-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17983, current rewards: -2471.66531, mean: -1.48896
[32m[0907 04-57-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17980, current rewards: -2545.75173, mean: -1.48874
[32m[0907 04-57-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17975, current rewards: -2619.22570, mean: -1.48820
[32m[0907 04-57-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17973, current rewards: -2680.35982, mean: -1.48086
[32m[0907 04-57-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17986, current rewards: -2748.99660, mean: -1.47796
[32m[0907 04-57-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18010, current rewards: -2817.28162, mean: -1.47502
[32m[0907 04-58-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18036, current rewards: -2897.79974, mean: -1.47847
[32m[0907 04-58-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18058, current rewards: -2991.60337, mean: -1.48836
[32m[0907 04-58-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18077, current rewards: -3091.60337, mean: -1.50078
[32m[0907 04-58-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18095, current rewards: -3191.60337, mean: -1.51261
[32m[0907 04-58-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18112, current rewards: -3291.60337, mean: -1.52389
[32m[0907 04-58-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18128, current rewards: -3391.60337, mean: -1.53466
[32m[0907 04-59-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18145, current rewards: -3491.60337, mean: -1.54496
[32m[0907 04-59-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18162, current rewards: -3591.60337, mean: -1.55481
[32m[0907 04-59-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18177, current rewards: -3691.60337, mean: -1.56424
[32m[0907 04-59-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18191, current rewards: -3791.60337, mean: -1.57328
[32m[0907 04-59-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18196, current rewards: -3891.60337, mean: -1.58195
[32m[0907 04-59-50 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0907 04-59-50 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-59-50 @MBExp.py:227][0m Rewards obtained: [-3971.6033716705942], Lows: [1780], Highs: [454], Total time: 45030.40852700002
[32m[0907 05-03-18 @MBExp.py:144][0m ####################################################################
[32m[0907 05-03-18 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 05-03-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.21510, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-03-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19429, current rewards: -60.00000, mean: -1.00000
[32m[0907 05-03-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19167, current rewards: -110.00000, mean: -1.00000
[32m[0907 05-03-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19049, current rewards: -160.00000, mean: -1.00000
[32m[0907 05-03-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19010, current rewards: -210.00000, mean: -1.00000
[32m[0907 05-04-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18967, current rewards: -260.00000, mean: -1.00000
[32m[0907 05-04-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18939, current rewards: -310.00000, mean: -1.00000
[32m[0907 05-04-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18921, current rewards: -360.00000, mean: -1.00000
[32m[0907 05-04-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18899, current rewards: -410.00000, mean: -1.00000
[32m[0907 05-04-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18840, current rewards: -460.00000, mean: -1.00000
[32m[0907 05-04-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18791, current rewards: -510.00000, mean: -1.00000
[32m[0907 05-05-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18750, current rewards: -560.00000, mean: -1.00000
[32m[0907 05-05-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18717, current rewards: -610.00000, mean: -1.00000
[32m[0907 05-05-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18680, current rewards: -660.00000, mean: -1.00000
[32m[0907 05-05-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18617, current rewards: -710.00000, mean: -1.00000
[32m[0907 05-05-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18563, current rewards: -760.00000, mean: -1.00000
[32m[0907 05-05-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18518, current rewards: -810.00000, mean: -1.00000
[32m[0907 05-05-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18474, current rewards: -860.00000, mean: -1.00000
[32m[0907 05-06-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18432, current rewards: -910.00000, mean: -1.00000
[32m[0907 05-06-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18366, current rewards: -960.00000, mean: -1.00000
[32m[0907 05-06-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18309, current rewards: -1010.00000, mean: -1.00000
[32m[0907 05-06-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18273, current rewards: -1060.00000, mean: -1.00000
[32m[0907 05-06-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18251, current rewards: -1110.00000, mean: -1.00000
[32m[0907 05-06-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18205, current rewards: -1193.76391, mean: -1.02911
[32m[0907 05-06-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18211, current rewards: -1272.78229, mean: -1.05189
[32m[0907 05-07-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18172, current rewards: -1366.67874, mean: -1.08467
[32m[0907 05-07-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18136, current rewards: -1466.67874, mean: -1.11960
[32m[0907 05-07-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18101, current rewards: -1566.67874, mean: -1.15197
[32m[0907 05-07-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18070, current rewards: -1666.67874, mean: -1.18204
[32m[0907 05-07-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18038, current rewards: -1766.67874, mean: -1.21005
[32m[0907 05-07-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18011, current rewards: -1866.67874, mean: -1.23621
[32m[0907 05-07-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17985, current rewards: -1966.67874, mean: -1.26069
[32m[0907 05-08-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17969, current rewards: -2066.67874, mean: -1.28365
[32m[0907 05-08-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17963, current rewards: -2166.67874, mean: -1.30523
[32m[0907 05-08-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17959, current rewards: -2266.67874, mean: -1.32554
[32m[0907 05-08-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17953, current rewards: -2366.67874, mean: -1.34470
[32m[0907 05-08-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17950, current rewards: -2466.67874, mean: -1.36281
[32m[0907 05-08-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17956, current rewards: -2566.67874, mean: -1.37993
[32m[0907 05-09-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17967, current rewards: -2666.67874, mean: -1.39617
[32m[0907 05-09-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17978, current rewards: -2766.67874, mean: -1.41157
[32m[0907 05-09-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17987, current rewards: -2866.67874, mean: -1.42621
[32m[0907 05-09-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17996, current rewards: -2966.67874, mean: -1.44014
[32m[0907 05-09-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18014, current rewards: -3066.67874, mean: -1.45340
[32m[0907 05-09-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18034, current rewards: -3166.67874, mean: -1.46605
[32m[0907 05-09-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18053, current rewards: -3266.67874, mean: -1.47814
[32m[0907 05-10-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18072, current rewards: -3366.67874, mean: -1.48968
[32m[0907 05-10-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18089, current rewards: -3466.67874, mean: -1.50073
[32m[0907 05-10-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18104, current rewards: -3566.67874, mean: -1.51130
[32m[0907 05-10-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18120, current rewards: -3666.67874, mean: -1.52144
[32m[0907 05-10-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18130, current rewards: -3766.67874, mean: -1.53117
[32m[0907 05-10-52 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0907 05-10-52 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-10-52 @MBExp.py:227][0m Rewards obtained: [-3846.6787436158684], Lows: [1354], Highs: [1140], Total time: 45484.61998100002
[32m[0907 05-14-21 @MBExp.py:144][0m ####################################################################
[32m[0907 05-14-21 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 05-14-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18825, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-14-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18899, current rewards: -29.60761, mean: -0.49346
[32m[0907 05-14-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18865, current rewards: -27.20693, mean: -0.24734
[32m[0907 05-14-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18857, current rewards: -24.80626, mean: -0.15504
[32m[0907 05-15-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18855, current rewards: -42.31784, mean: -0.20151
[32m[0907 05-15-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18856, current rewards: -92.31784, mean: -0.35507
[32m[0907 05-15-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18866, current rewards: -144.31784, mean: -0.46554
[32m[0907 05-15-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18865, current rewards: -194.31784, mean: -0.53977
[32m[0907 05-15-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18863, current rewards: -244.31784, mean: -0.59590
[32m[0907 05-15-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18856, current rewards: -294.31784, mean: -0.63982
[32m[0907 05-15-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18802, current rewards: -344.31784, mean: -0.67513
[32m[0907 05-16-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18764, current rewards: -394.31784, mean: -0.70414
[32m[0907 05-16-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18733, current rewards: -444.31784, mean: -0.72839
[32m[0907 05-16-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18695, current rewards: -494.31784, mean: -0.74897
[32m[0907 05-16-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18628, current rewards: -544.31784, mean: -0.76664
[32m[0907 05-16-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18570, current rewards: -594.31784, mean: -0.78200
[32m[0907 05-16-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18521, current rewards: -644.31784, mean: -0.79545
[32m[0907 05-17-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18478, current rewards: -694.31784, mean: -0.80735
[32m[0907 05-17-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18440, current rewards: -744.31784, mean: -0.81793
[32m[0907 05-17-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18387, current rewards: -783.81811, mean: -0.81648
[32m[0907 05-17-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18333, current rewards: -781.31955, mean: -0.77358
[32m[0907 05-17-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18280, current rewards: -778.82099, mean: -0.73474
[32m[0907 05-17-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18235, current rewards: -776.32243, mean: -0.69939
[32m[0907 05-17-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18191, current rewards: -773.75508, mean: -0.66703
[32m[0907 05-18-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18150, current rewards: -770.75669, mean: -0.63699
[32m[0907 05-18-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18113, current rewards: -767.75830, mean: -0.60933
[32m[0907 05-18-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18078, current rewards: -764.75991, mean: -0.58379
[32m[0907 05-18-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18046, current rewards: -761.76152, mean: -0.56012
[32m[0907 05-18-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18015, current rewards: -758.76313, mean: -0.53813
[32m[0907 05-18-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17988, current rewards: -755.76474, mean: -0.51765
[32m[0907 05-18-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17963, current rewards: -752.76636, mean: -0.49852
[32m[0907 05-19-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17940, current rewards: -782.62697, mean: -0.50168
[32m[0907 05-19-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17918, current rewards: -832.62697, mean: -0.51716
[32m[0907 05-19-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17894, current rewards: -882.62697, mean: -0.53170
[32m[0907 05-19-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17890, current rewards: -932.62697, mean: -0.54540
[32m[0907 05-19-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17888, current rewards: -982.62697, mean: -0.55831
[32m[0907 05-19-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17885, current rewards: -1032.62697, mean: -0.57051
[32m[0907 05-19-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17887, current rewards: -1082.62697, mean: -0.58206
[32m[0907 05-20-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17899, current rewards: -1132.62697, mean: -0.59300
[32m[0907 05-20-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17911, current rewards: -1182.62697, mean: -0.60338
[32m[0907 05-20-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17922, current rewards: -1232.62697, mean: -0.61325
[32m[0907 05-20-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17933, current rewards: -1282.62697, mean: -0.62263
[32m[0907 05-20-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17943, current rewards: -1332.62697, mean: -0.63158
[32m[0907 05-20-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17961, current rewards: -1382.62697, mean: -0.64011
[32m[0907 05-20-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17985, current rewards: -1432.62697, mean: -0.64825
[32m[0907 05-21-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18004, current rewards: -1482.62697, mean: -0.65603
[32m[0907 05-21-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18022, current rewards: -1532.62697, mean: -0.66347
[32m[0907 05-21-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18041, current rewards: -1582.62697, mean: -0.67060
[32m[0907 05-21-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18059, current rewards: -1632.62697, mean: -0.67744
[32m[0907 05-21-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18073, current rewards: -1682.62697, mean: -0.68399
[32m[0907 05-21-54 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0907 05-21-54 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-21-54 @MBExp.py:227][0m Rewards obtained: [-1722.6269683039422], Lows: [2], Highs: [1759], Total time: 45937.63073700002
[32m[0907 05-25-27 @MBExp.py:144][0m ####################################################################
[32m[0907 05-25-27 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 05-25-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18089, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-25-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18298, current rewards: -60.00000, mean: -1.00000
[32m[0907 05-25-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18344, current rewards: -110.00000, mean: -1.00000
[32m[0907 05-25-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18404, current rewards: -160.00000, mean: -1.00000
[32m[0907 05-26-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18526, current rewards: -210.00000, mean: -1.00000
[32m[0907 05-26-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18598, current rewards: -260.00000, mean: -1.00000
[32m[0907 05-26-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18652, current rewards: -310.00000, mean: -1.00000
[32m[0907 05-26-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18673, current rewards: -360.00000, mean: -1.00000
[32m[0907 05-26-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18703, current rewards: -410.00000, mean: -1.00000
[32m[0907 05-26-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18708, current rewards: -460.00000, mean: -1.00000
[32m[0907 05-27-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18677, current rewards: -510.00000, mean: -1.00000
[32m[0907 05-27-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18650, current rewards: -560.00000, mean: -1.00000
[32m[0907 05-27-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18629, current rewards: -610.00000, mean: -1.00000
[32m[0907 05-27-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18610, current rewards: -660.00000, mean: -1.00000
[32m[0907 05-27-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18592, current rewards: -710.00000, mean: -1.00000
[32m[0907 05-27-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18545, current rewards: -760.00000, mean: -1.00000
[32m[0907 05-27-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18502, current rewards: -810.00000, mean: -1.00000
[32m[0907 05-28-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18462, current rewards: -860.00000, mean: -1.00000
[32m[0907 05-28-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18427, current rewards: -910.00000, mean: -1.00000
[32m[0907 05-28-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18392, current rewards: -960.00000, mean: -1.00000
[32m[0907 05-28-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18362, current rewards: -1010.00000, mean: -1.00000
[32m[0907 05-28-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18306, current rewards: -1060.00000, mean: -1.00000
[32m[0907 05-28-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18258, current rewards: -1110.00000, mean: -1.00000
[32m[0907 05-28-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18213, current rewards: -1160.00000, mean: -1.00000
[32m[0907 05-29-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18173, current rewards: -1210.00000, mean: -1.00000
[32m[0907 05-29-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18135, current rewards: -1260.00000, mean: -1.00000
[32m[0907 05-29-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18099, current rewards: -1310.00000, mean: -1.00000
[32m[0907 05-29-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18066, current rewards: -1360.00000, mean: -1.00000
[32m[0907 05-29-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18038, current rewards: -1410.00000, mean: -1.00000
[32m[0907 05-29-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18008, current rewards: -1460.00000, mean: -1.00000
[32m[0907 05-29-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17983, current rewards: -1510.00000, mean: -1.00000
[32m[0907 05-30-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17960, current rewards: -1560.00000, mean: -1.00000
[32m[0907 05-30-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17938, current rewards: -1610.00000, mean: -1.00000
[32m[0907 05-30-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17917, current rewards: -1660.00000, mean: -1.00000
[32m[0907 05-30-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17907, current rewards: -1710.00000, mean: -1.00000
[32m[0907 05-30-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17903, current rewards: -1760.00000, mean: -1.00000
[32m[0907 05-30-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17902, current rewards: -1810.00000, mean: -1.00000
[32m[0907 05-31-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17900, current rewards: -1860.00000, mean: -1.00000
[32m[0907 05-31-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17898, current rewards: -1910.00000, mean: -1.00000
[32m[0907 05-31-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17908, current rewards: -1960.00000, mean: -1.00000
[32m[0907 05-31-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17920, current rewards: -2010.00000, mean: -1.00000
[32m[0907 05-31-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17931, current rewards: -2060.00000, mean: -1.00000
[32m[0907 05-31-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17941, current rewards: -2062.00868, mean: -0.97726
[32m[0907 05-31-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17951, current rewards: -2057.47309, mean: -0.95253
[32m[0907 05-32-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17961, current rewards: -2052.93750, mean: -0.92893
[32m[0907 05-32-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17983, current rewards: -2048.40192, mean: -0.90637
[32m[0907 05-32-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18004, current rewards: -2094.03907, mean: -0.90651
[32m[0907 05-32-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18024, current rewards: -2144.03907, mean: -0.90849
[32m[0907 05-32-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18043, current rewards: -2194.03907, mean: -0.91039
[32m[0907 05-32-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18060, current rewards: -2244.03907, mean: -0.91221
[32m[0907 05-32-59 @Agent.py:117][0m Average action selection time: 0.1807
[32m[0907 05-32-59 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-33-00 @MBExp.py:227][0m Rewards obtained: [-2284.0390684634817], Lows: [0], Highs: [2302], Total time: 46390.29974900002
[32m[0907 05-36-35 @MBExp.py:144][0m ####################################################################
[32m[0907 05-36-35 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 05-36-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18383, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-36-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18774, current rewards: -105.92474, mean: -1.76541
[32m[0907 05-36-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18595, current rewards: -205.92474, mean: -1.87204
[32m[0907 05-37-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18534, current rewards: -305.92474, mean: -1.91203
[32m[0907 05-37-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18508, current rewards: -405.92474, mean: -1.93297
[32m[0907 05-37-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18585, current rewards: -505.92474, mean: -1.94586
[32m[0907 05-37-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18642, current rewards: -605.92474, mean: -1.95460
[32m[0907 05-37-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18675, current rewards: -705.92474, mean: -1.96090
[32m[0907 05-37-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18698, current rewards: -805.92474, mean: -1.96567
[32m[0907 05-38-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18723, current rewards: -905.92474, mean: -1.96940
[32m[0907 05-38-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18701, current rewards: -1005.92474, mean: -1.97240
[32m[0907 05-38-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18670, current rewards: -1105.92474, mean: -1.97487
[32m[0907 05-38-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18646, current rewards: -1205.92474, mean: -1.97693
[32m[0907 05-38-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18625, current rewards: -1305.92474, mean: -1.97867
[32m[0907 05-38-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18606, current rewards: -1405.92474, mean: -1.98018
[32m[0907 05-38-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18557, current rewards: -1505.92474, mean: -1.98148
[32m[0907 05-39-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18505, current rewards: -1605.92474, mean: -1.98262
[32m[0907 05-39-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18467, current rewards: -1705.92474, mean: -1.98363
[32m[0907 05-39-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18431, current rewards: -1805.92474, mean: -1.98453
[32m[0907 05-39-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18397, current rewards: -1905.92474, mean: -1.98534
[32m[0907 05-39-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18361, current rewards: -2005.92474, mean: -1.98606
[32m[0907 05-39-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18306, current rewards: -2105.92474, mean: -1.98672
[32m[0907 05-39-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18257, current rewards: -2205.92474, mean: -1.98732
[32m[0907 05-40-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18213, current rewards: -2305.92474, mean: -1.98787
[32m[0907 05-40-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18171, current rewards: -2405.92474, mean: -1.98837
[32m[0907 05-40-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18131, current rewards: -2505.92474, mean: -1.98883
[32m[0907 05-40-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18098, current rewards: -2605.92474, mean: -1.98926
[32m[0907 05-40-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18064, current rewards: -2705.92474, mean: -1.98965
[32m[0907 05-40-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18035, current rewards: -2805.92474, mean: -1.99002
[32m[0907 05-40-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18006, current rewards: -2905.92474, mean: -1.99036
[32m[0907 05-41-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17979, current rewards: -3005.92474, mean: -1.99068
[32m[0907 05-41-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17955, current rewards: -3105.92474, mean: -1.99098
[32m[0907 05-41-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17932, current rewards: -3205.92474, mean: -1.99126
[32m[0907 05-41-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17912, current rewards: -3305.92474, mean: -1.99152
[32m[0907 05-41-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17892, current rewards: -3405.92474, mean: -1.99177
[32m[0907 05-41-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17889, current rewards: -3505.92474, mean: -1.99200
[32m[0907 05-41-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17886, current rewards: -3605.92474, mean: -1.99222
[32m[0907 05-42-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17884, current rewards: -3705.92474, mean: -1.99243
[32m[0907 05-42-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17882, current rewards: -3805.92474, mean: -1.99263
[32m[0907 05-42-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17886, current rewards: -3905.92474, mean: -1.99282
[32m[0907 05-42-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17896, current rewards: -4005.92474, mean: -1.99300
[32m[0907 05-42-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17908, current rewards: -4105.92474, mean: -1.99317
[32m[0907 05-42-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17920, current rewards: -4205.92474, mean: -1.99333
[32m[0907 05-43-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17932, current rewards: -4305.92474, mean: -1.99348
[32m[0907 05-43-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17941, current rewards: -4405.92474, mean: -1.99363
[32m[0907 05-43-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17960, current rewards: -4505.92474, mean: -1.99377
[32m[0907 05-43-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17982, current rewards: -4605.92474, mean: -1.99391
[32m[0907 05-43-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18002, current rewards: -4705.92474, mean: -1.99404
[32m[0907 05-43-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18020, current rewards: -4805.92474, mean: -1.99416
[32m[0907 05-43-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18039, current rewards: -4905.92474, mean: -1.99428
[32m[0907 05-44-07 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 05-44-07 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-44-07 @MBExp.py:227][0m Rewards obtained: [-4985.9247394613685], Lows: [2487], Highs: [12], Total time: 46842.47724900002
[32m[0907 05-47-44 @MBExp.py:144][0m ####################################################################
[32m[0907 05-47-44 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 05-47-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19495, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-47-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18796, current rewards: -45.60526, mean: -0.76009
[32m[0907 05-48-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18615, current rewards: -95.60526, mean: -0.86914
[32m[0907 05-48-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18543, current rewards: -145.60526, mean: -0.91003
[32m[0907 05-48-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18488, current rewards: -195.60526, mean: -0.93145
[32m[0907 05-48-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18535, current rewards: -245.60526, mean: -0.94464
[32m[0907 05-48-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18593, current rewards: -295.60526, mean: -0.95357
[32m[0907 05-48-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18625, current rewards: -345.60526, mean: -0.96001
[32m[0907 05-49-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18650, current rewards: -395.60526, mean: -0.96489
[32m[0907 05-49-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18664, current rewards: -445.60526, mean: -0.96871
[32m[0907 05-49-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18670, current rewards: -495.60526, mean: -0.97178
[32m[0907 05-49-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18647, current rewards: -545.60526, mean: -0.97430
[32m[0907 05-49-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18627, current rewards: -595.60526, mean: -0.97640
[32m[0907 05-49-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18609, current rewards: -645.60526, mean: -0.97819
[32m[0907 05-49-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18591, current rewards: -695.60526, mean: -0.97973
[32m[0907 05-50-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18568, current rewards: -745.60526, mean: -0.98106
[32m[0907 05-50-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18521, current rewards: -795.60526, mean: -0.98223
[32m[0907 05-50-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18482, current rewards: -845.60526, mean: -0.98326
[32m[0907 05-50-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18447, current rewards: -895.60526, mean: -0.98418
[32m[0907 05-50-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18415, current rewards: -945.60526, mean: -0.98501
[32m[0907 05-50-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18384, current rewards: -995.60526, mean: -0.98575
[32m[0907 05-50-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18331, current rewards: -1045.60526, mean: -0.98642
[32m[0907 05-51-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18281, current rewards: -1095.60526, mean: -0.98703
[32m[0907 05-51-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18235, current rewards: -1145.60526, mean: -0.98759
[32m[0907 05-51-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18195, current rewards: -1195.60526, mean: -0.98810
[32m[0907 05-51-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18154, current rewards: -1245.60526, mean: -0.98858
[32m[0907 05-51-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18117, current rewards: -1295.60526, mean: -0.98901
[32m[0907 05-51-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18083, current rewards: -1345.60526, mean: -0.98942
[32m[0907 05-51-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18054, current rewards: -1395.60526, mean: -0.98979
[32m[0907 05-52-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18025, current rewards: -1445.60526, mean: -0.99014
[32m[0907 05-52-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17997, current rewards: -1495.60526, mean: -0.99047
[32m[0907 05-52-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17975, current rewards: -1545.60526, mean: -0.99077
[32m[0907 05-52-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17953, current rewards: -1595.60526, mean: -0.99106
[32m[0907 05-52-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17932, current rewards: -1645.60526, mean: -0.99133
[32m[0907 05-52-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17913, current rewards: -1695.60526, mean: -0.99158
[32m[0907 05-53-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17901, current rewards: -1745.60526, mean: -0.99182
[32m[0907 05-53-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17898, current rewards: -1795.60526, mean: -0.99205
[32m[0907 05-53-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17895, current rewards: -1845.60526, mean: -0.99226
[32m[0907 05-53-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17895, current rewards: -1890.08079, mean: -0.98957
[32m[0907 05-53-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17893, current rewards: -1885.32294, mean: -0.96190
[32m[0907 05-53-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17899, current rewards: -1882.07705, mean: -0.93636
[32m[0907 05-53-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17912, current rewards: -1878.83117, mean: -0.91205
[32m[0907 05-54-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17925, current rewards: -1875.58529, mean: -0.88890
[32m[0907 05-54-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17936, current rewards: -1872.33940, mean: -0.86682
[32m[0907 05-54-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17948, current rewards: -1869.09352, mean: -0.84574
[32m[0907 05-54-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17963, current rewards: -1865.84763, mean: -0.82560
[32m[0907 05-54-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17984, current rewards: -1866.86142, mean: -0.80817
[32m[0907 05-54-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18004, current rewards: -1916.86142, mean: -0.81223
[32m[0907 05-54-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18021, current rewards: -1966.86142, mean: -0.81613
[32m[0907 05-55-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18041, current rewards: -2016.86142, mean: -0.81986
[32m[0907 05-55-16 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 05-55-16 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-55-17 @MBExp.py:227][0m Rewards obtained: [-2056.861419441877], Lows: [0], Highs: [2087], Total time: 47294.71136400002
[32m[0907 05-58-56 @MBExp.py:144][0m ####################################################################
[32m[0907 05-58-56 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 05-58-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18265, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-59-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18394, current rewards: -110.00000, mean: -1.83333
[32m[0907 05-59-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18380, current rewards: -210.00000, mean: -1.90909
[32m[0907 05-59-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18387, current rewards: -310.00000, mean: -1.93750
[32m[0907 05-59-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18388, current rewards: -410.00000, mean: -1.95238
[32m[0907 05-59-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18472, current rewards: -510.00000, mean: -1.96154
[32m[0907 05-59-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18537, current rewards: -610.00000, mean: -1.96774
[32m[0907 06-00-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18570, current rewards: -710.00000, mean: -1.97222
[32m[0907 06-00-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18609, current rewards: -810.00000, mean: -1.97561
[32m[0907 06-00-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18640, current rewards: -910.00000, mean: -1.97826
[32m[0907 06-00-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18651, current rewards: -1010.00000, mean: -1.98039
[32m[0907 06-00-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18636, current rewards: -1110.00000, mean: -1.98214
[32m[0907 06-00-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18619, current rewards: -1210.00000, mean: -1.98361
[32m[0907 06-00-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18600, current rewards: -1310.00000, mean: -1.98485
[32m[0907 06-01-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18585, current rewards: -1410.00000, mean: -1.98592
[32m[0907 06-01-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18571, current rewards: -1510.00000, mean: -1.98684
[32m[0907 06-01-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18523, current rewards: -1610.00000, mean: -1.98765
[32m[0907 06-01-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18480, current rewards: -1710.00000, mean: -1.98837
[32m[0907 06-01-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18446, current rewards: -1810.00000, mean: -1.98901
[32m[0907 06-01-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18412, current rewards: -1910.00000, mean: -1.98958
[32m[0907 06-02-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18380, current rewards: -2010.00000, mean: -1.99010
[32m[0907 06-02-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18353, current rewards: -2110.00000, mean: -1.99057
[32m[0907 06-02-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18309, current rewards: -2210.00000, mean: -1.99099
[32m[0907 06-02-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18261, current rewards: -2310.00000, mean: -1.99138
[32m[0907 06-02-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18218, current rewards: -2410.00000, mean: -1.99174
[32m[0907 06-02-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18178, current rewards: -2510.00000, mean: -1.99206
[32m[0907 06-02-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18143, current rewards: -2610.00000, mean: -1.99237
[32m[0907 06-03-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18108, current rewards: -2710.00000, mean: -1.99265
[32m[0907 06-03-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18077, current rewards: -2810.00000, mean: -1.99291
[32m[0907 06-03-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18049, current rewards: -2910.00000, mean: -1.99315
[32m[0907 06-03-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18022, current rewards: -3010.00000, mean: -1.99338
[32m[0907 06-03-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17996, current rewards: -3110.00000, mean: -1.99359
[32m[0907 06-03-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17971, current rewards: -3210.00000, mean: -1.99379
[32m[0907 06-03-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17947, current rewards: -3310.00000, mean: -1.99398
[32m[0907 06-04-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17927, current rewards: -3410.00000, mean: -1.99415
[32m[0907 06-04-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17908, current rewards: -3510.00000, mean: -1.99432
[32m[0907 06-04-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17907, current rewards: -3610.00000, mean: -1.99448
[32m[0907 06-04-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17905, current rewards: -3710.00000, mean: -1.99462
[32m[0907 06-04-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17904, current rewards: -3810.00000, mean: -1.99476
[32m[0907 06-04-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17902, current rewards: -3910.00000, mean: -1.99490
[32m[0907 06-04-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17902, current rewards: -4010.00000, mean: -1.99502
[32m[0907 06-05-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17914, current rewards: -4110.00000, mean: -1.99515
[32m[0907 06-05-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17926, current rewards: -4210.00000, mean: -1.99526
[32m[0907 06-05-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17935, current rewards: -4310.00000, mean: -1.99537
[32m[0907 06-05-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17944, current rewards: -4410.00000, mean: -1.99548
[32m[0907 06-05-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17955, current rewards: -4510.00000, mean: -1.99558
[32m[0907 06-05-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17964, current rewards: -4610.00000, mean: -1.99567
[32m[0907 06-06-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17982, current rewards: -4710.00000, mean: -1.99576
[32m[0907 06-06-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18002, current rewards: -4810.00000, mean: -1.99585
[32m[0907 06-06-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18022, current rewards: -4910.00000, mean: -1.99593
[32m[0907 06-06-28 @Agent.py:117][0m Average action selection time: 0.1804
[32m[0907 06-06-28 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-06-28 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 47746.45807800002
[32m[0907 06-10-10 @MBExp.py:144][0m ####################################################################
[32m[0907 06-10-10 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 06-10-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18283, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-10-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18407, current rewards: -60.00000, mean: -1.00000
[32m[0907 06-10-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18402, current rewards: -110.00000, mean: -1.00000
[32m[0907 06-10-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18403, current rewards: -160.00000, mean: -1.00000
[32m[0907 06-10-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18387, current rewards: -210.00000, mean: -1.00000
[32m[0907 06-10-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18496, current rewards: -260.00000, mean: -1.00000
[32m[0907 06-11-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18565, current rewards: -310.00000, mean: -1.00000
[32m[0907 06-11-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18612, current rewards: -360.00000, mean: -1.00000
[32m[0907 06-11-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18634, current rewards: -410.00000, mean: -1.00000
[32m[0907 06-11-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18667, current rewards: -460.00000, mean: -1.00000
[32m[0907 06-11-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18688, current rewards: -510.00000, mean: -1.00000
[32m[0907 06-11-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18697, current rewards: -560.00000, mean: -1.00000
[32m[0907 06-12-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18677, current rewards: -610.00000, mean: -1.00000
[32m[0907 06-12-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18654, current rewards: -660.00000, mean: -1.00000
[32m[0907 06-12-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18640, current rewards: -710.00000, mean: -1.00000
[32m[0907 06-12-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18618, current rewards: -760.00000, mean: -1.00000
[32m[0907 06-12-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18572, current rewards: -810.00000, mean: -1.00000
[32m[0907 06-12-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18528, current rewards: -860.00000, mean: -1.00000
[32m[0907 06-12-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18489, current rewards: -910.00000, mean: -1.00000
[32m[0907 06-13-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: -960.00000, mean: -1.00000
[32m[0907 06-13-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18419, current rewards: -1010.00000, mean: -1.00000
[32m[0907 06-13-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18392, current rewards: -1060.00000, mean: -1.00000
[32m[0907 06-13-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18351, current rewards: -1110.00000, mean: -1.00000
[32m[0907 06-13-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18301, current rewards: -1160.00000, mean: -1.00000
[32m[0907 06-13-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18258, current rewards: -1210.00000, mean: -1.00000
[32m[0907 06-13-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18217, current rewards: -1260.00000, mean: -1.00000
[32m[0907 06-14-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18179, current rewards: -1310.00000, mean: -1.00000
[32m[0907 06-14-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18146, current rewards: -1360.00000, mean: -1.00000
[32m[0907 06-14-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18114, current rewards: -1410.00000, mean: -1.00000
[32m[0907 06-14-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18085, current rewards: -1460.00000, mean: -1.00000
[32m[0907 06-14-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18058, current rewards: -1489.78556, mean: -0.98661
[32m[0907 06-14-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18034, current rewards: -1481.24764, mean: -0.94952
[32m[0907 06-15-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18010, current rewards: -1472.70972, mean: -0.91473
[32m[0907 06-15-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17988, current rewards: -1464.17180, mean: -0.88203
[32m[0907 06-15-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17966, current rewards: -1455.63389, mean: -0.85125
[32m[0907 06-15-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17946, current rewards: -1457.63279, mean: -0.82820
[32m[0907 06-15-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17927, current rewards: -1507.63279, mean: -0.83295
[32m[0907 06-15-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17922, current rewards: -1557.63279, mean: -0.83744
[32m[0907 06-15-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17919, current rewards: -1607.63279, mean: -0.84169
[32m[0907 06-16-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17918, current rewards: -1657.63279, mean: -0.84573
[32m[0907 06-16-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17916, current rewards: -1707.63279, mean: -0.84957
[32m[0907 06-16-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17926, current rewards: -1757.63279, mean: -0.85322
[32m[0907 06-16-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17936, current rewards: -1807.63279, mean: -0.85670
[32m[0907 06-16-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17947, current rewards: -1857.63279, mean: -0.86002
[32m[0907 06-16-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17957, current rewards: -1907.63279, mean: -0.86318
[32m[0907 06-16-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17967, current rewards: -1957.63279, mean: -0.86621
[32m[0907 06-17-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17978, current rewards: -2007.63279, mean: -0.86911
[32m[0907 06-17-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17994, current rewards: -2057.63279, mean: -0.87188
[32m[0907 06-17-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18012, current rewards: -2107.63279, mean: -0.87454
[32m[0907 06-17-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18032, current rewards: -2157.63279, mean: -0.87709
[32m[0907 06-17-41 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 06-17-41 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-17-42 @MBExp.py:227][0m Rewards obtained: [-2197.632791671344], Lows: [0], Highs: [2241], Total time: 48198.455274000014
[32m[0907 06-21-25 @MBExp.py:144][0m ####################################################################
[32m[0907 06-21-25 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 06-21-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20665, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-21-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18862, current rewards: -68.79661, mean: -1.14661
[32m[0907 06-21-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18673, current rewards: -168.79661, mean: -1.53451
[32m[0907 06-21-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18586, current rewards: -268.79661, mean: -1.67998
[32m[0907 06-22-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18560, current rewards: -368.79661, mean: -1.75617
[32m[0907 06-22-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18639, current rewards: -468.79661, mean: -1.80306
[32m[0907 06-22-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18671, current rewards: -568.79661, mean: -1.83483
[32m[0907 06-22-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18691, current rewards: -668.79661, mean: -1.85777
[32m[0907 06-22-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18717, current rewards: -768.79661, mean: -1.87511
[32m[0907 06-22-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18734, current rewards: -868.79661, mean: -1.88869
[32m[0907 06-23-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18744, current rewards: -968.79661, mean: -1.89960
[32m[0907 06-23-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18758, current rewards: -1068.79661, mean: -1.90857
[32m[0907 06-23-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18732, current rewards: -1168.79661, mean: -1.91606
[32m[0907 06-23-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18707, current rewards: -1268.79661, mean: -1.92242
[32m[0907 06-23-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18685, current rewards: -1368.79661, mean: -1.92788
[32m[0907 06-23-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18667, current rewards: -1468.79661, mean: -1.93263
[32m[0907 06-23-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18651, current rewards: -1568.79661, mean: -1.93679
[32m[0907 06-24-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18636, current rewards: -1668.79661, mean: -1.94046
[32m[0907 06-24-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18612, current rewards: -1768.79661, mean: -1.94373
[32m[0907 06-24-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18573, current rewards: -1868.79661, mean: -1.94666
[32m[0907 06-24-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18535, current rewards: -1968.79661, mean: -1.94930
[32m[0907 06-24-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18501, current rewards: -2068.79661, mean: -1.95169
[32m[0907 06-24-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18451, current rewards: -2168.79661, mean: -1.95387
[32m[0907 06-24-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18399, current rewards: -2268.79661, mean: -1.95586
[32m[0907 06-25-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18352, current rewards: -2368.79661, mean: -1.95768
[32m[0907 06-25-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18312, current rewards: -2468.79661, mean: -1.95936
[32m[0907 06-25-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18272, current rewards: -2568.79661, mean: -1.96091
[32m[0907 06-25-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18233, current rewards: -2668.79661, mean: -1.96235
[32m[0907 06-25-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18197, current rewards: -2768.79661, mean: -1.96369
[32m[0907 06-25-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18166, current rewards: -2868.79661, mean: -1.96493
[32m[0907 06-26-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18136, current rewards: -2968.79661, mean: -1.96609
[32m[0907 06-26-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18108, current rewards: -3068.79661, mean: -1.96718
[32m[0907 06-26-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18082, current rewards: -3168.79661, mean: -1.96820
[32m[0907 06-26-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18057, current rewards: -3268.79661, mean: -1.96915
[32m[0907 06-26-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18032, current rewards: -3368.79661, mean: -1.97006
[32m[0907 06-26-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18011, current rewards: -3468.79661, mean: -1.97091
[32m[0907 06-26-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17989, current rewards: -3568.79661, mean: -1.97171
[32m[0907 06-27-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17976, current rewards: -3668.79661, mean: -1.97247
[32m[0907 06-27-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17975, current rewards: -3768.79661, mean: -1.97319
[32m[0907 06-27-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17972, current rewards: -3868.79661, mean: -1.97388
[32m[0907 06-27-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17970, current rewards: -3968.79661, mean: -1.97453
[32m[0907 06-27-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17968, current rewards: -4068.79661, mean: -1.97514
[32m[0907 06-27-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17966, current rewards: -4168.79661, mean: -1.97573
[32m[0907 06-27-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17963, current rewards: -4268.79661, mean: -1.97629
[32m[0907 06-28-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17972, current rewards: -4368.79661, mean: -1.97683
[32m[0907 06-28-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17982, current rewards: -4468.79661, mean: -1.97734
[32m[0907 06-28-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17992, current rewards: -4568.79661, mean: -1.97783
[32m[0907 06-28-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18005, current rewards: -4668.79661, mean: -1.97830
[32m[0907 06-28-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18026, current rewards: -4768.79661, mean: -1.97875
[32m[0907 06-28-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18043, current rewards: -4868.79661, mean: -1.97919
[32m[0907 06-28-57 @Agent.py:117][0m Average action selection time: 0.1806
[32m[0907 06-28-57 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-28-58 @MBExp.py:227][0m Rewards obtained: [-4948.796612609209], Lows: [2468], Highs: [15], Total time: 48650.771578000014
[32m[0907 06-32-44 @MBExp.py:144][0m ####################################################################
[32m[0907 06-32-44 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 06-32-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19616, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-32-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18591, current rewards: -110.00000, mean: -1.83333
[32m[0907 06-33-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18515, current rewards: -210.00000, mean: -1.90909
[32m[0907 06-33-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18488, current rewards: -310.00000, mean: -1.93750
[32m[0907 06-33-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18470, current rewards: -410.00000, mean: -1.95238
[32m[0907 06-33-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18565, current rewards: -510.00000, mean: -1.96154
[32m[0907 06-33-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18611, current rewards: -610.00000, mean: -1.96774
[32m[0907 06-33-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18647, current rewards: -710.00000, mean: -1.97222
[32m[0907 06-34-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18675, current rewards: -810.00000, mean: -1.97561
[32m[0907 06-34-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18701, current rewards: -910.00000, mean: -1.97826
[32m[0907 06-34-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18716, current rewards: -1010.00000, mean: -1.98039
[32m[0907 06-34-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18719, current rewards: -1110.00000, mean: -1.98214
[32m[0907 06-34-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18730, current rewards: -1205.84166, mean: -1.97679
[32m[0907 06-34-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18724, current rewards: -1305.84166, mean: -1.97855
[32m[0907 06-34-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18696, current rewards: -1398.77189, mean: -1.97010
[32m[0907 06-35-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18678, current rewards: -1498.77189, mean: -1.97207
[32m[0907 06-35-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18662, current rewards: -1594.55116, mean: -1.96858
[32m[0907 06-35-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18656, current rewards: -1685.45767, mean: -1.95983
[32m[0907 06-35-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18675, current rewards: -1778.45854, mean: -1.95435
[32m[0907 06-35-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18680, current rewards: -1878.45854, mean: -1.95673
[32m[0907 06-35-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18690, current rewards: -1976.00790, mean: -1.95644
[32m[0907 06-36-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18694, current rewards: -2064.37424, mean: -1.94752
[32m[0907 06-36-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18647, current rewards: -2156.84722, mean: -1.94311
[32m[0907 06-36-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18606, current rewards: -2243.83805, mean: -1.93434
[32m[0907 06-36-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18562, current rewards: -2337.07912, mean: -1.93147
[32m[0907 06-36-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18533, current rewards: -2434.94466, mean: -1.93250
[32m[0907 06-36-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18498, current rewards: -2520.90426, mean: -1.92435
[32m[0907 06-36-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18459, current rewards: -2620.90426, mean: -1.92714
[32m[0907 06-37-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18424, current rewards: -2709.32839, mean: -1.92151
[32m[0907 06-37-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18392, current rewards: -2806.42632, mean: -1.92221
[32m[0907 06-37-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18363, current rewards: -2891.02104, mean: -1.91458
[32m[0907 06-37-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18329, current rewards: -2991.02104, mean: -1.91732
[32m[0907 06-37-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18296, current rewards: -3091.02104, mean: -1.91989
[32m[0907 06-37-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18265, current rewards: -3191.02104, mean: -1.92230
[32m[0907 06-37-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18235, current rewards: -3291.02104, mean: -1.92457
[32m[0907 06-38-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18210, current rewards: -3391.02104, mean: -1.92672
[32m[0907 06-38-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18184, current rewards: -3491.02104, mean: -1.92874
[32m[0907 06-38-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18160, current rewards: -3591.02104, mean: -1.93066
[32m[0907 06-38-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18139, current rewards: -3691.02104, mean: -1.93247
[32m[0907 06-38-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18131, current rewards: -3791.02104, mean: -1.93419
[32m[0907 06-38-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18124, current rewards: -3891.02104, mean: -1.93583
[32m[0907 06-38-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18118, current rewards: -3991.02104, mean: -1.93739
[32m[0907 06-39-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18111, current rewards: -4091.02104, mean: -1.93887
[32m[0907 06-39-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18106, current rewards: -4191.02104, mean: -1.94029
[32m[0907 06-39-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18099, current rewards: -4291.02104, mean: -1.94164
[32m[0907 06-39-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18107, current rewards: -4391.02104, mean: -1.94293
[32m[0907 06-39-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18114, current rewards: -4491.02104, mean: -1.94416
[32m[0907 06-39-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18124, current rewards: -4591.02104, mean: -1.94535
[32m[0907 06-40-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18142, current rewards: -4691.02104, mean: -1.94648
[32m[0907 06-40-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18160, current rewards: -4791.02104, mean: -1.94757
[32m[0907 06-40-19 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0907 06-40-19 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-40-19 @MBExp.py:227][0m Rewards obtained: [-4871.02103750616], Lows: [2434], Highs: [16], Total time: 49105.94580700001
[32m[0907 06-44-07 @MBExp.py:144][0m ####################################################################
[32m[0907 06-44-07 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 06-44-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18395, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-44-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18386, current rewards: -110.00000, mean: -1.83333
[32m[0907 06-44-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18401, current rewards: -210.00000, mean: -1.90909
[32m[0907 06-44-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18389, current rewards: -310.00000, mean: -1.93750
[32m[0907 06-44-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18448, current rewards: -410.00000, mean: -1.95238
[32m[0907 06-44-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18537, current rewards: -510.00000, mean: -1.96154
[32m[0907 06-45-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18576, current rewards: -610.00000, mean: -1.96774
[32m[0907 06-45-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18624, current rewards: -702.87386, mean: -1.95243
[32m[0907 06-45-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18642, current rewards: -802.87386, mean: -1.95823
[32m[0907 06-45-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18668, current rewards: -902.87386, mean: -1.96277
[32m[0907 06-45-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18689, current rewards: -961.87386, mean: -1.88603
[32m[0907 06-45-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18705, current rewards: -1011.87386, mean: -1.80692
[32m[0907 06-46-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18716, current rewards: -1061.87386, mean: -1.74078
[32m[0907 06-46-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18725, current rewards: -1111.87386, mean: -1.68466
[32m[0907 06-46-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18716, current rewards: -1161.87386, mean: -1.63644
[32m[0907 06-46-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18696, current rewards: -1211.87386, mean: -1.59457
[32m[0907 06-46-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18678, current rewards: -1261.87386, mean: -1.55787
[32m[0907 06-46-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18662, current rewards: -1311.87386, mean: -1.52543
[32m[0907 06-46-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18647, current rewards: -1361.87386, mean: -1.49656
[32m[0907 06-47-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18613, current rewards: -1411.87386, mean: -1.47070
[32m[0907 06-47-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18575, current rewards: -1461.87386, mean: -1.44740
[32m[0907 06-47-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18539, current rewards: -1511.87386, mean: -1.42630
[32m[0907 06-47-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18489, current rewards: -1561.87386, mean: -1.40709
[32m[0907 06-47-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18436, current rewards: -1611.87386, mean: -1.38955
[32m[0907 06-47-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18387, current rewards: -1661.87386, mean: -1.37345
[32m[0907 06-47-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18340, current rewards: -1711.87386, mean: -1.35863
[32m[0907 06-48-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18300, current rewards: -1761.87386, mean: -1.34494
[32m[0907 06-48-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18262, current rewards: -1811.87386, mean: -1.33226
[32m[0907 06-48-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18225, current rewards: -1861.87386, mean: -1.32048
[32m[0907 06-48-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18190, current rewards: -1911.87386, mean: -1.30950
[32m[0907 06-48-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18159, current rewards: -1961.87386, mean: -1.29925
[32m[0907 06-48-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18129, current rewards: -2011.87386, mean: -1.28966
[32m[0907 06-48-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18101, current rewards: -2061.87386, mean: -1.28067
[32m[0907 06-49-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18075, current rewards: -2111.87386, mean: -1.27221
[32m[0907 06-49-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18051, current rewards: -2161.87386, mean: -1.26425
[32m[0907 06-49-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18028, current rewards: -2211.87386, mean: -1.25675
[32m[0907 06-49-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18006, current rewards: -2261.87386, mean: -1.24965
[32m[0907 06-49-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17985, current rewards: -2311.87386, mean: -1.24294
[32m[0907 06-49-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17966, current rewards: -2361.87386, mean: -1.23658
[32m[0907 06-49-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17947, current rewards: -2411.87386, mean: -1.23055
[32m[0907 06-50-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17932, current rewards: -2435.35514, mean: -1.21162
[32m[0907 06-50-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17930, current rewards: -2432.31771, mean: -1.18074
[32m[0907 06-50-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17928, current rewards: -2429.28028, mean: -1.15132
[32m[0907 06-50-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17926, current rewards: -2426.24285, mean: -1.12326
[32m[0907 06-50-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17925, current rewards: -2423.20543, mean: -1.09647
[32m[0907 06-50-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17931, current rewards: -2420.19093, mean: -1.07088
[32m[0907 06-51-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17942, current rewards: -2417.26819, mean: -1.04644
[32m[0907 06-51-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17953, current rewards: -2414.34545, mean: -1.02303
[32m[0907 06-51-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17972, current rewards: -2411.42271, mean: -1.00059
[32m[0907 06-51-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17993, current rewards: -2408.49997, mean: -0.97907
[32m[0907 06-51-38 @Agent.py:117][0m Average action selection time: 0.1801
[32m[0907 06-51-38 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-51-38 @MBExp.py:227][0m Rewards obtained: [-2407.2202314455694], Lows: [453], Highs: [1532], Total time: 49557.038943000014
[32m[0907 06-55-28 @MBExp.py:144][0m ####################################################################
[32m[0907 06-55-28 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 06-55-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19556, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-55-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18614, current rewards: -110.00000, mean: -1.83333
[32m[0907 06-55-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18511, current rewards: -210.00000, mean: -1.90909
[32m[0907 06-55-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18458, current rewards: -310.00000, mean: -1.93750
[32m[0907 06-56-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18511, current rewards: -410.00000, mean: -1.95238
[32m[0907 06-56-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18595, current rewards: -510.00000, mean: -1.96154
[32m[0907 06-56-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18641, current rewards: -610.00000, mean: -1.96774
[32m[0907 06-56-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18677, current rewards: -710.00000, mean: -1.97222
[32m[0907 06-56-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18713, current rewards: -810.00000, mean: -1.97561
[32m[0907 06-56-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18732, current rewards: -910.00000, mean: -1.97826
[32m[0907 06-57-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18746, current rewards: -1010.00000, mean: -1.98039
[32m[0907 06-57-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18763, current rewards: -1110.00000, mean: -1.98214
[32m[0907 06-57-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18771, current rewards: -1210.00000, mean: -1.98361
[32m[0907 06-57-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18774, current rewards: -1310.00000, mean: -1.98485
[32m[0907 06-57-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18782, current rewards: -1410.00000, mean: -1.98592
[32m[0907 06-57-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18757, current rewards: -1510.00000, mean: -1.98684
[32m[0907 06-58-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18733, current rewards: -1610.00000, mean: -1.98765
[32m[0907 06-58-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18712, current rewards: -1710.00000, mean: -1.98837
[32m[0907 06-58-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18689, current rewards: -1810.00000, mean: -1.98901
[32m[0907 06-58-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18670, current rewards: -1910.00000, mean: -1.98958
[32m[0907 06-58-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18626, current rewards: -2010.00000, mean: -1.99010
[32m[0907 06-58-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18591, current rewards: -2110.00000, mean: -1.99057
[32m[0907 06-58-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18542, current rewards: -2210.00000, mean: -1.99099
[32m[0907 06-59-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18485, current rewards: -2310.00000, mean: -1.99138
[32m[0907 06-59-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18434, current rewards: -2410.00000, mean: -1.99174
[32m[0907 06-59-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18387, current rewards: -2510.00000, mean: -1.99206
[32m[0907 06-59-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18343, current rewards: -2610.00000, mean: -1.99237
[32m[0907 06-59-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18303, current rewards: -2710.00000, mean: -1.99265
[32m[0907 06-59-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18266, current rewards: -2810.00000, mean: -1.99291
[32m[0907 06-59-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18230, current rewards: -2910.00000, mean: -1.99315
[32m[0907 07-00-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18197, current rewards: -3010.00000, mean: -1.99338
[32m[0907 07-00-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18167, current rewards: -3110.00000, mean: -1.99359
[32m[0907 07-00-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18138, current rewards: -3210.00000, mean: -1.99379
[32m[0907 07-00-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18110, current rewards: -3310.00000, mean: -1.99398
[32m[0907 07-00-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18083, current rewards: -3410.00000, mean: -1.99415
[32m[0907 07-00-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18058, current rewards: -3510.00000, mean: -1.99432
[32m[0907 07-00-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18035, current rewards: -3610.00000, mean: -1.99448
[32m[0907 07-01-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18015, current rewards: -3710.00000, mean: -1.99462
[32m[0907 07-01-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17994, current rewards: -3810.00000, mean: -1.99476
[32m[0907 07-01-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17974, current rewards: -3910.00000, mean: -1.99490
[32m[0907 07-01-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17955, current rewards: -4010.00000, mean: -1.99502
[32m[0907 07-01-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17947, current rewards: -4110.00000, mean: -1.99515
[32m[0907 07-01-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17944, current rewards: -4210.00000, mean: -1.99526
[32m[0907 07-01-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17942, current rewards: -4310.00000, mean: -1.99537
[32m[0907 07-02-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17940, current rewards: -4410.00000, mean: -1.99548
[32m[0907 07-02-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17938, current rewards: -4510.00000, mean: -1.99558
[32m[0907 07-02-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17947, current rewards: -4610.00000, mean: -1.99567
[32m[0907 07-02-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17957, current rewards: -4710.00000, mean: -1.99576
[32m[0907 07-02-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17971, current rewards: -4810.00000, mean: -1.99585
[32m[0907 07-02-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17991, current rewards: -4910.00000, mean: -1.99593
[32m[0907 07-02-59 @Agent.py:117][0m Average action selection time: 0.1801
[32m[0907 07-02-59 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-03-00 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 50008.094202000015
[32m[0907 07-06-52 @MBExp.py:144][0m ####################################################################
[32m[0907 07-06-52 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 07-06-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18227, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-07-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18343, current rewards: -60.00000, mean: -1.00000
[32m[0907 07-07-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18339, current rewards: -110.00000, mean: -1.00000
[32m[0907 07-07-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18349, current rewards: -160.00000, mean: -1.00000
[32m[0907 07-07-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18349, current rewards: -210.00000, mean: -1.00000
[32m[0907 07-07-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18359, current rewards: -260.00000, mean: -1.00000
[32m[0907 07-07-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18363, current rewards: -310.00000, mean: -1.00000
[32m[0907 07-07-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18378, current rewards: -360.00000, mean: -1.00000
[32m[0907 07-08-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18460, current rewards: -410.00000, mean: -1.00000
[32m[0907 07-08-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18513, current rewards: -460.00000, mean: -1.00000
[32m[0907 07-08-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18550, current rewards: -510.00000, mean: -1.00000
[32m[0907 07-08-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18581, current rewards: -560.00000, mean: -1.00000
[32m[0907 07-08-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18608, current rewards: -610.00000, mean: -1.00000
[32m[0907 07-08-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18629, current rewards: -660.00000, mean: -1.00000
[32m[0907 07-09-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18642, current rewards: -710.00000, mean: -1.00000
[32m[0907 07-09-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18644, current rewards: -760.00000, mean: -1.00000
[32m[0907 07-09-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18625, current rewards: -810.00000, mean: -1.00000
[32m[0907 07-09-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18609, current rewards: -855.44587, mean: -0.99470
[32m[0907 07-09-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18598, current rewards: -848.51921, mean: -0.93244
[32m[0907 07-09-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18589, current rewards: -841.59255, mean: -0.87666
[32m[0907 07-10-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18561, current rewards: -835.24716, mean: -0.82698
[32m[0907 07-10-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18527, current rewards: -875.73663, mean: -0.82617
[32m[0907 07-10-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18485, current rewards: -925.73663, mean: -0.83400
[32m[0907 07-10-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18432, current rewards: -975.73663, mean: -0.84115
[32m[0907 07-10-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18384, current rewards: -1025.73663, mean: -0.84772
[32m[0907 07-10-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18340, current rewards: -1075.73663, mean: -0.85376
[32m[0907 07-10-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18298, current rewards: -1125.73663, mean: -0.85934
[32m[0907 07-11-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18259, current rewards: -1175.73663, mean: -0.86451
[32m[0907 07-11-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18222, current rewards: -1225.73663, mean: -0.86932
[32m[0907 07-11-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18187, current rewards: -1235.78087, mean: -0.84643
[32m[0907 07-11-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18155, current rewards: -1227.70658, mean: -0.81305
[32m[0907 07-11-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18124, current rewards: -1277.70658, mean: -0.81904
[32m[0907 07-11-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18096, current rewards: -1327.70658, mean: -0.82466
[32m[0907 07-11-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18070, current rewards: -1377.70658, mean: -0.82994
[32m[0907 07-12-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18047, current rewards: -1427.70658, mean: -0.83492
[32m[0907 07-12-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18024, current rewards: -1477.70658, mean: -0.83961
[32m[0907 07-12-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18002, current rewards: -1527.70658, mean: -0.84404
[32m[0907 07-12-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17982, current rewards: -1577.70658, mean: -0.84823
[32m[0907 07-12-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17962, current rewards: -1627.70658, mean: -0.85220
[32m[0907 07-12-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17944, current rewards: -1677.70658, mean: -0.85597
[32m[0907 07-12-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17926, current rewards: -1727.70658, mean: -0.85956
[32m[0907 07-13-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17909, current rewards: -1777.70658, mean: -0.86296
[32m[0907 07-13-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17905, current rewards: -1827.70658, mean: -0.86621
[32m[0907 07-13-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17902, current rewards: -1877.70658, mean: -0.86931
[32m[0907 07-13-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17900, current rewards: -1927.70658, mean: -0.87227
[32m[0907 07-13-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17898, current rewards: -1977.70658, mean: -0.87509
[32m[0907 07-13-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17897, current rewards: -2027.70658, mean: -0.87780
[32m[0907 07-13-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17907, current rewards: -2077.70658, mean: -0.88038
[32m[0907 07-14-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17918, current rewards: -2127.70658, mean: -0.88287
[32m[0907 07-14-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17938, current rewards: -2177.70658, mean: -0.88525
[32m[0907 07-14-22 @Agent.py:117][0m Average action selection time: 0.1795
[32m[0907 07-14-22 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-14-22 @MBExp.py:227][0m Rewards obtained: [-2217.7065837067685], Lows: [0], Highs: [2251], Total time: 50457.785982000016
[32m[0907 07-18-17 @MBExp.py:144][0m ####################################################################
[32m[0907 07-18-17 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 07-18-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18327, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-18-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18434, current rewards: -60.71790, mean: -1.01196
[32m[0907 07-18-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18422, current rewards: -110.71790, mean: -1.00653
[32m[0907 07-18-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18421, current rewards: -160.71790, mean: -1.00449
[32m[0907 07-18-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18426, current rewards: -210.71790, mean: -1.00342
[32m[0907 07-19-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18422, current rewards: -260.71790, mean: -1.00276
[32m[0907 07-19-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18417, current rewards: -310.71790, mean: -1.00232
[32m[0907 07-19-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18423, current rewards: -360.71790, mean: -1.00199
[32m[0907 07-19-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18484, current rewards: -410.71790, mean: -1.00175
[32m[0907 07-19-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18527, current rewards: -460.71790, mean: -1.00156
[32m[0907 07-19-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18562, current rewards: -510.71790, mean: -1.00141
[32m[0907 07-20-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18591, current rewards: -560.71790, mean: -1.00128
[32m[0907 07-20-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18612, current rewards: -610.71790, mean: -1.00118
[32m[0907 07-20-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18626, current rewards: -660.71790, mean: -1.00109
[32m[0907 07-20-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18637, current rewards: -663.27570, mean: -0.93419
[32m[0907 07-20-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18653, current rewards: -660.56215, mean: -0.86916
[32m[0907 07-20-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18637, current rewards: -657.84860, mean: -0.81216
[32m[0907 07-20-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18622, current rewards: -655.13505, mean: -0.76178
[32m[0907 07-21-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18610, current rewards: -652.42149, mean: -0.71695
[32m[0907 07-21-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18596, current rewards: -649.70794, mean: -0.67678
[32m[0907 07-21-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18585, current rewards: -646.99439, mean: -0.64059
[32m[0907 07-21-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18557, current rewards: -642.63041, mean: -0.60626
[32m[0907 07-21-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18521, current rewards: -636.95334, mean: -0.57383
[32m[0907 07-21-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18466, current rewards: -653.54710, mean: -0.56340
[32m[0907 07-22-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18415, current rewards: -703.54710, mean: -0.58144
[32m[0907 07-22-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18368, current rewards: -753.54710, mean: -0.59805
[32m[0907 07-22-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18323, current rewards: -803.54710, mean: -0.61339
[32m[0907 07-22-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18283, current rewards: -853.54710, mean: -0.62761
[32m[0907 07-22-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18244, current rewards: -903.54710, mean: -0.64081
[32m[0907 07-22-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18210, current rewards: -953.54710, mean: -0.65311
[32m[0907 07-22-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18178, current rewards: -1003.54710, mean: -0.66460
[32m[0907 07-23-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18147, current rewards: -1053.54710, mean: -0.67535
[32m[0907 07-23-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18117, current rewards: -1103.54710, mean: -0.68543
[32m[0907 07-23-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18089, current rewards: -1153.54710, mean: -0.69491
[32m[0907 07-23-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18063, current rewards: -1203.54710, mean: -0.70383
[32m[0907 07-23-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18041, current rewards: -1253.54710, mean: -0.71224
[32m[0907 07-23-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18018, current rewards: -1303.54710, mean: -0.72019
[32m[0907 07-23-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17996, current rewards: -1353.54710, mean: -0.72771
[32m[0907 07-24-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17977, current rewards: -1403.54710, mean: -0.73484
[32m[0907 07-24-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17959, current rewards: -1453.54710, mean: -0.74161
[32m[0907 07-24-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17942, current rewards: -1503.54710, mean: -0.74803
[32m[0907 07-24-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17925, current rewards: -1553.54710, mean: -0.75415
[32m[0907 07-24-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17907, current rewards: -1603.54710, mean: -0.75997
[32m[0907 07-24-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17907, current rewards: -1653.54710, mean: -0.76553
[32m[0907 07-24-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17904, current rewards: -1703.54710, mean: -0.77084
[32m[0907 07-25-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17906, current rewards: -1753.54710, mean: -0.77591
[32m[0907 07-25-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17905, current rewards: -1803.54710, mean: -0.78076
[32m[0907 07-25-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17904, current rewards: -1853.54710, mean: -0.78540
[32m[0907 07-25-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17915, current rewards: -1903.54710, mean: -0.78985
[32m[0907 07-25-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17932, current rewards: -1953.54710, mean: -0.79412
[32m[0907 07-25-46 @Agent.py:117][0m Average action selection time: 0.1795
[32m[0907 07-25-46 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-25-47 @MBExp.py:227][0m Rewards obtained: [-1993.5471037991142], Lows: [2], Highs: [2022], Total time: 50907.390797000015
[32m[0907 07-29-44 @MBExp.py:144][0m ####################################################################
[32m[0907 07-29-44 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 07-29-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28610, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-29-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20321, current rewards: -58.80237, mean: -0.98004
[32m[0907 07-30-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19453, current rewards: -108.80237, mean: -0.98911
[32m[0907 07-30-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19139, current rewards: -158.80237, mean: -0.99251
[32m[0907 07-30-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18970, current rewards: -208.80237, mean: -0.99430
[32m[0907 07-30-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18886, current rewards: -258.80237, mean: -0.99539
[32m[0907 07-30-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18814, current rewards: -308.80237, mean: -0.99614
[32m[0907 07-30-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18793, current rewards: -358.80237, mean: -0.99667
[32m[0907 07-31-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18823, current rewards: -408.80237, mean: -0.99708
[32m[0907 07-31-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18825, current rewards: -458.80237, mean: -0.99740
[32m[0907 07-31-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18830, current rewards: -508.80237, mean: -0.99765
[32m[0907 07-31-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18832, current rewards: -558.80237, mean: -0.99786
[32m[0907 07-31-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18840, current rewards: -608.80237, mean: -0.99804
[32m[0907 07-31-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18844, current rewards: -658.80237, mean: -0.99819
[32m[0907 07-31-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18849, current rewards: -708.80237, mean: -0.99831
[32m[0907 07-32-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18852, current rewards: -758.80237, mean: -0.99842
[32m[0907 07-32-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18857, current rewards: -808.80237, mean: -0.99852
[32m[0907 07-32-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18862, current rewards: -858.80237, mean: -0.99861
[32m[0907 07-32-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18862, current rewards: -908.80237, mean: -0.99868
[32m[0907 07-32-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18856, current rewards: -958.80237, mean: -0.99875
[32m[0907 07-32-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18833, current rewards: -1008.80237, mean: -0.99881
[32m[0907 07-33-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18798, current rewards: -1058.80237, mean: -0.99887
[32m[0907 07-33-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18753, current rewards: -1108.80237, mean: -0.99892
[32m[0907 07-33-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18688, current rewards: -1158.80237, mean: -0.99897
[32m[0907 07-33-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18629, current rewards: -1208.80237, mean: -0.99901
[32m[0907 07-33-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18573, current rewards: -1258.80237, mean: -0.99905
[32m[0907 07-33-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18523, current rewards: -1308.80237, mean: -0.99909
[32m[0907 07-33-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18475, current rewards: -1358.80237, mean: -0.99912
[32m[0907 07-34-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18431, current rewards: -1408.80237, mean: -0.99915
[32m[0907 07-34-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18391, current rewards: -1458.80237, mean: -0.99918
[32m[0907 07-34-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18353, current rewards: -1508.80237, mean: -0.99921
[32m[0907 07-34-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18318, current rewards: -1558.80237, mean: -0.99923
[32m[0907 07-34-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18282, current rewards: -1608.80237, mean: -0.99926
[32m[0907 07-34-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18251, current rewards: -1658.80237, mean: -0.99928
[32m[0907 07-34-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18223, current rewards: -1708.80237, mean: -0.99930
[32m[0907 07-35-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18196, current rewards: -1758.80237, mean: -0.99932
[32m[0907 07-35-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18169, current rewards: -1808.80237, mean: -0.99934
[32m[0907 07-35-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18144, current rewards: -1858.80237, mean: -0.99936
[32m[0907 07-35-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18122, current rewards: -1908.80237, mean: -0.99937
[32m[0907 07-35-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18098, current rewards: -1958.80237, mean: -0.99939
[32m[0907 07-35-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18076, current rewards: -2008.80237, mean: -0.99940
[32m[0907 07-35-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18055, current rewards: -2058.80237, mean: -0.99942
[32m[0907 07-36-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18037, current rewards: -2108.80237, mean: -0.99943
[32m[0907 07-36-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18018, current rewards: -2153.27791, mean: -0.99689
[32m[0907 07-36-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18001, current rewards: -2148.03322, mean: -0.97196
[32m[0907 07-36-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17986, current rewards: -2142.88627, mean: -0.94818
[32m[0907 07-36-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17970, current rewards: -2137.92906, mean: -0.92551
[32m[0907 07-36-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17968, current rewards: -2132.97185, mean: -0.90380
[32m[0907 07-36-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17970, current rewards: -2128.01464, mean: -0.88299
[32m[0907 07-37-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17981, current rewards: -2123.05743, mean: -0.86303
[32m[0907 07-37-15 @Agent.py:117][0m Average action selection time: 0.1800
[32m[0907 07-37-15 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-37-15 @MBExp.py:227][0m Rewards obtained: [-2119.0916670677643], Lows: [0], Highs: [2154], Total time: 51358.214131000015
[32m[0907 07-41-15 @MBExp.py:144][0m ####################################################################
[32m[0907 07-41-15 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 07-41-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18323, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-41-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18424, current rewards: -82.54415, mean: -1.37574
[32m[0907 07-41-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18396, current rewards: -132.54415, mean: -1.20495
[32m[0907 07-41-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18404, current rewards: -182.54415, mean: -1.14090
[32m[0907 07-41-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18400, current rewards: -232.54415, mean: -1.10735
[32m[0907 07-42-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18410, current rewards: -228.30394, mean: -0.87809
[32m[0907 07-42-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18407, current rewards: -222.95678, mean: -0.71922
[32m[0907 07-42-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18406, current rewards: -217.60962, mean: -0.60447
[32m[0907 07-42-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18466, current rewards: -212.26246, mean: -0.51771
[32m[0907 07-42-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18510, current rewards: -206.91530, mean: -0.44982
[32m[0907 07-42-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18543, current rewards: -201.56814, mean: -0.39523
[32m[0907 07-42-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18573, current rewards: -196.25449, mean: -0.35045
[32m[0907 07-43-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18599, current rewards: -230.28218, mean: -0.37751
[32m[0907 07-43-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18617, current rewards: -280.28218, mean: -0.42467
[32m[0907 07-43-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18639, current rewards: -330.28218, mean: -0.46519
[32m[0907 07-43-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18656, current rewards: -380.28218, mean: -0.50037
[32m[0907 07-43-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18670, current rewards: -430.28218, mean: -0.53121
[32m[0907 07-43-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18681, current rewards: -480.28218, mean: -0.55847
[32m[0907 07-44-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18688, current rewards: -530.28218, mean: -0.58273
[32m[0907 07-44-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18698, current rewards: -580.28218, mean: -0.60446
[32m[0907 07-44-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18689, current rewards: -630.28218, mean: -0.62404
[32m[0907 07-44-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18677, current rewards: -680.28218, mean: -0.64178
[32m[0907 07-44-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18658, current rewards: -730.28218, mean: -0.65791
[32m[0907 07-44-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18600, current rewards: -780.28218, mean: -0.67266
[32m[0907 07-44-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18547, current rewards: -830.28218, mean: -0.68618
[32m[0907 07-45-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18496, current rewards: -880.28218, mean: -0.69864
[32m[0907 07-45-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18451, current rewards: -930.28218, mean: -0.71014
[32m[0907 07-45-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18409, current rewards: -980.28218, mean: -0.72080
[32m[0907 07-45-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18368, current rewards: -1030.28218, mean: -0.73070
[32m[0907 07-45-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18332, current rewards: -1080.28218, mean: -0.73992
[32m[0907 07-45-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18296, current rewards: -1130.28218, mean: -0.74853
[32m[0907 07-46-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18262, current rewards: -1180.28218, mean: -0.75659
[32m[0907 07-46-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18231, current rewards: -1230.28218, mean: -0.76415
[32m[0907 07-46-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18201, current rewards: -1280.28218, mean: -0.77125
[32m[0907 07-46-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18171, current rewards: -1330.28218, mean: -0.77794
[32m[0907 07-46-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18145, current rewards: -1380.28218, mean: -0.78425
[32m[0907 07-46-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18120, current rewards: -1430.28218, mean: -0.79021
[32m[0907 07-46-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18098, current rewards: -1480.28218, mean: -0.79585
[32m[0907 07-47-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18077, current rewards: -1530.28218, mean: -0.80119
[32m[0907 07-47-09 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18054, current rewards: -1580.28218, mean: -0.80627
[32m[0907 07-47-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18035, current rewards: -1630.28218, mean: -0.81109
[32m[0907 07-47-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18017, current rewards: -1680.28218, mean: -0.81567
[32m[0907 07-47-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17999, current rewards: -1730.28218, mean: -0.82004
[32m[0907 07-47-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17983, current rewards: -1780.28218, mean: -0.82420
[32m[0907 07-47-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17966, current rewards: -1830.28218, mean: -0.82818
[32m[0907 07-48-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17952, current rewards: -1880.28218, mean: -0.83198
[32m[0907 07-48-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17937, current rewards: -1930.28218, mean: -0.83562
[32m[0907 07-48-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17929, current rewards: -1980.28218, mean: -0.83910
[32m[0907 07-48-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17927, current rewards: -2030.28218, mean: -0.84244
[32m[0907 07-48-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17926, current rewards: -2080.28218, mean: -0.84564
[32m[0907 07-48-44 @Agent.py:117][0m Average action selection time: 0.1794
[32m[0907 07-48-44 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-48-44 @MBExp.py:227][0m Rewards obtained: [-2120.2821793304274], Lows: [26], Highs: [2107], Total time: 51807.572218000016
[32m[0907 07-52-46 @MBExp.py:144][0m ####################################################################
[32m[0907 07-52-46 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 07-52-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18229, current rewards: 0.59416, mean: 0.05942
[32m[0907 07-52-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18367, current rewards: -48.35480, mean: -0.80591
[32m[0907 07-53-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18371, current rewards: -98.35480, mean: -0.89413
[32m[0907 07-53-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18380, current rewards: -148.35480, mean: -0.92722
[32m[0907 07-53-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18385, current rewards: -198.35480, mean: -0.94455
[32m[0907 07-53-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18393, current rewards: -248.35480, mean: -0.95521
[32m[0907 07-53-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18386, current rewards: -298.35480, mean: -0.96243
[32m[0907 07-53-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18397, current rewards: -348.35480, mean: -0.96765
[32m[0907 07-54-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18463, current rewards: -398.35480, mean: -0.97160
[32m[0907 07-54-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18522, current rewards: -448.35480, mean: -0.97468
[32m[0907 07-54-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18560, current rewards: -498.35480, mean: -0.97717
[32m[0907 07-54-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18593, current rewards: -548.35480, mean: -0.97921
[32m[0907 07-54-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18619, current rewards: -598.35480, mean: -0.98091
[32m[0907 07-54-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18647, current rewards: -648.35480, mean: -0.98236
[32m[0907 07-54-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18660, current rewards: -698.35480, mean: -0.98360
[32m[0907 07-55-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18679, current rewards: -748.35480, mean: -0.98468
[32m[0907 07-55-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18693, current rewards: -798.35480, mean: -0.98562
[32m[0907 07-55-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18702, current rewards: -848.35480, mean: -0.98646
[32m[0907 07-55-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18713, current rewards: -898.35480, mean: -0.98720
[32m[0907 07-55-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18723, current rewards: -948.35480, mean: -0.98787
[32m[0907 07-55-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18728, current rewards: -998.35480, mean: -0.98847
[32m[0907 07-56-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18727, current rewards: -1048.35480, mean: -0.98901
[32m[0907 07-56-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18713, current rewards: -1098.35480, mean: -0.98951
[32m[0907 07-56-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18659, current rewards: -1148.35480, mean: -0.98996
[32m[0907 07-56-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18599, current rewards: -1198.35480, mean: -0.99038
[32m[0907 07-56-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18546, current rewards: -1248.35480, mean: -0.99076
[32m[0907 07-56-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18499, current rewards: -1298.35480, mean: -0.99111
[32m[0907 07-56-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18454, current rewards: -1348.35480, mean: -0.99144
[32m[0907 07-57-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18411, current rewards: -1398.35480, mean: -0.99174
[32m[0907 07-57-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18370, current rewards: -1448.35480, mean: -0.99202
[32m[0907 07-57-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18334, current rewards: -1498.35480, mean: -0.99229
[32m[0907 07-57-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18299, current rewards: -1548.35480, mean: -0.99254
[32m[0907 07-57-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18266, current rewards: -1598.35480, mean: -0.99277
[32m[0907 07-57-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18236, current rewards: -1648.35480, mean: -0.99298
[32m[0907 07-57-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18206, current rewards: -1659.52570, mean: -0.97048
[32m[0907 07-58-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18181, current rewards: -1657.05394, mean: -0.94151
[32m[0907 07-58-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18155, current rewards: -1654.58218, mean: -0.91413
[32m[0907 07-58-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18130, current rewards: -1652.11042, mean: -0.88823
[32m[0907 07-58-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18106, current rewards: -1698.96354, mean: -0.88951
[32m[0907 07-58-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18084, current rewards: -1748.96354, mean: -0.89233
[32m[0907 07-58-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18063, current rewards: -1798.96354, mean: -0.89501
[32m[0907 07-58-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18045, current rewards: -1848.96354, mean: -0.89756
[32m[0907 07-59-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18026, current rewards: -1898.96354, mean: -0.89998
[32m[0907 07-59-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18008, current rewards: -1948.96354, mean: -0.90230
[32m[0907 07-59-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17991, current rewards: -1998.96354, mean: -0.90451
[32m[0907 07-59-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17974, current rewards: -2048.96354, mean: -0.90662
[32m[0907 07-59-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17959, current rewards: -2098.96354, mean: -0.90864
[32m[0907 07-59-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17945, current rewards: -2148.96354, mean: -0.91058
[32m[0907 07-59-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17932, current rewards: -2198.96354, mean: -0.91243
[32m[0907 08-00-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17928, current rewards: -2248.96354, mean: -0.91421
[32m[0907 08-00-14 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0907 08-00-14 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-00-15 @MBExp.py:227][0m Rewards obtained: [-2288.9635352941677], Lows: [0], Highs: [2299], Total time: 52256.71565000001
[32m[0907 08-04-19 @MBExp.py:144][0m ####################################################################
[32m[0907 08-04-19 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 08-04-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18467, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-04-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19840, current rewards: -64.38605, mean: -1.07310
[32m[0907 08-04-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19166, current rewards: -114.38605, mean: -1.03987
[32m[0907 08-04-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18923, current rewards: -164.38605, mean: -1.02741
[32m[0907 08-04-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18794, current rewards: -214.38605, mean: -1.02089
[32m[0907 08-05-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18725, current rewards: -264.38605, mean: -1.01687
[32m[0907 08-05-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18681, current rewards: -314.38605, mean: -1.01415
[32m[0907 08-05-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18644, current rewards: -364.38605, mean: -1.01218
[32m[0907 08-05-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18682, current rewards: -414.38605, mean: -1.01070
[32m[0907 08-05-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18713, current rewards: -464.38605, mean: -1.00953
[32m[0907 08-05-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18735, current rewards: -514.38605, mean: -1.00860
[32m[0907 08-06-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18743, current rewards: -564.38605, mean: -1.00783
[32m[0907 08-06-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18747, current rewards: -587.19376, mean: -0.96261
[32m[0907 08-06-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18762, current rewards: -582.80929, mean: -0.88304
[32m[0907 08-06-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18768, current rewards: -578.42504, mean: -0.81468
[32m[0907 08-06-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18782, current rewards: -574.04084, mean: -0.75532
[32m[0907 08-06-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18792, current rewards: -569.65666, mean: -0.70328
[32m[0907 08-07-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18803, current rewards: -565.27250, mean: -0.65729
[32m[0907 08-07-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18807, current rewards: -560.88835, mean: -0.61636
[32m[0907 08-07-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18812, current rewards: -556.50420, mean: -0.57969
[32m[0907 08-07-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18810, current rewards: -574.96138, mean: -0.56927
[32m[0907 08-07-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18812, current rewards: -624.96138, mean: -0.58959
[32m[0907 08-07-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18792, current rewards: -674.96138, mean: -0.60807
[32m[0907 08-07-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18772, current rewards: -736.90451, mean: -0.63526
[32m[0907 08-08-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18735, current rewards: -836.90451, mean: -0.69166
[32m[0907 08-08-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18701, current rewards: -936.90451, mean: -0.74358
[32m[0907 08-08-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18655, current rewards: -1036.90451, mean: -0.79153
[32m[0907 08-08-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18602, current rewards: -1136.90451, mean: -0.83596
[32m[0907 08-08-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18555, current rewards: -1236.90451, mean: -0.87724
[32m[0907 08-08-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18511, current rewards: -1336.90451, mean: -0.91569
[32m[0907 08-08-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18471, current rewards: -1436.90451, mean: -0.95159
[32m[0907 08-09-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18433, current rewards: -1536.90451, mean: -0.98520
[32m[0907 08-09-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18397, current rewards: -1636.90451, mean: -1.01671
[32m[0907 08-09-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18365, current rewards: -1736.90451, mean: -1.04633
[32m[0907 08-09-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18333, current rewards: -1836.90451, mean: -1.07421
[32m[0907 08-09-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18304, current rewards: -1936.90451, mean: -1.10051
[32m[0907 08-09-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18277, current rewards: -2036.90451, mean: -1.12536
[32m[0907 08-09-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18250, current rewards: -2136.90451, mean: -1.14887
[32m[0907 08-10-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18225, current rewards: -2236.90451, mean: -1.17115
[32m[0907 08-10-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18202, current rewards: -2336.90451, mean: -1.19230
[32m[0907 08-10-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18179, current rewards: -2436.90451, mean: -1.21239
[32m[0907 08-10-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18157, current rewards: -2536.90451, mean: -1.23151
[32m[0907 08-10-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18137, current rewards: -2636.90451, mean: -1.24972
[32m[0907 08-10-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18117, current rewards: -2736.90451, mean: -1.26709
[32m[0907 08-10-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18097, current rewards: -2836.90451, mean: -1.28367
[32m[0907 08-11-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18080, current rewards: -2936.90451, mean: -1.29952
[32m[0907 08-11-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18063, current rewards: -3036.90451, mean: -1.31468
[32m[0907 08-11-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18046, current rewards: -3136.90451, mean: -1.32920
[32m[0907 08-11-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18030, current rewards: -3236.90451, mean: -1.34311
[32m[0907 08-11-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18019, current rewards: -3336.90451, mean: -1.35647
[32m[0907 08-11-50 @Agent.py:117][0m Average action selection time: 0.1802
[32m[0907 08-11-50 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-11-50 @MBExp.py:227][0m Rewards obtained: [-3416.904507078072], Lows: [1364], Highs: [725], Total time: 52707.985753000015
[32m[0907 08-15-55 @MBExp.py:144][0m ####################################################################
[32m[0907 08-15-55 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 08-15-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18916, current rewards: 1.14253, mean: 0.11425
[32m[0907 08-16-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20214, current rewards: -98.85747, mean: -1.64762
[32m[0907 08-16-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19400, current rewards: -97.80699, mean: -0.88915
[32m[0907 08-16-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19081, current rewards: -95.14641, mean: -0.59467
[32m[0907 08-16-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19233, current rewards: -178.62477, mean: -0.85059
[32m[0907 08-16-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19450, current rewards: -247.07194, mean: -0.95028
[32m[0907 08-16-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19880, current rewards: -299.34457, mean: -0.96563
[32m[0907 08-17-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19921, current rewards: -339.04871, mean: -0.94180
[32m[0907 08-17-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19991, current rewards: -430.83235, mean: -1.05081
[32m[0907 08-17-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19926, current rewards: -500.33410, mean: -1.08768
[32m[0907 08-17-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20063, current rewards: -555.98893, mean: -1.09017
[32m[0907 08-17-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20263, current rewards: -620.00128, mean: -1.10715
[32m[0907 08-17-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20183, current rewards: -707.23590, mean: -1.15940
[32m[0907 08-18-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.20170, current rewards: -758.56928, mean: -1.14935
[32m[0907 08-18-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.20234, current rewards: -833.97792, mean: -1.17462
[32m[0907 08-18-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.20226, current rewards: -871.80132, mean: -1.14711
[32m[0907 08-18-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.20138, current rewards: -920.75312, mean: -1.13673
[32m[0907 08-18-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.20064, current rewards: -970.75312, mean: -1.12878
[32m[0907 08-18-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.20083, current rewards: -1033.57752, mean: -1.13580
[32m[0907 08-19-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.20019, current rewards: -1133.57752, mean: -1.18081
[32m[0907 08-19-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19961, current rewards: -1233.57752, mean: -1.22136
[32m[0907 08-19-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19886, current rewards: -1333.57752, mean: -1.25809
[32m[0907 08-19-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19810, current rewards: -1433.57752, mean: -1.29151
[32m[0907 08-19-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19725, current rewards: -1533.57752, mean: -1.32205
[32m[0907 08-19-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19645, current rewards: -1633.57752, mean: -1.35006
[32m[0907 08-20-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19566, current rewards: -1733.57752, mean: -1.37586
[32m[0907 08-20-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19476, current rewards: -1833.57752, mean: -1.39968
[32m[0907 08-20-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19393, current rewards: -1933.57752, mean: -1.42175
[32m[0907 08-20-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19317, current rewards: -2033.57752, mean: -1.44225
[32m[0907 08-20-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19245, current rewards: -2133.57752, mean: -1.46135
[32m[0907 08-20-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19180, current rewards: -2233.57752, mean: -1.47919
[32m[0907 08-20-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19118, current rewards: -2333.57752, mean: -1.49588
[32m[0907 08-21-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19059, current rewards: -2433.57752, mean: -1.51154
[32m[0907 08-21-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19005, current rewards: -2533.57752, mean: -1.52625
[32m[0907 08-21-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18954, current rewards: -2633.57752, mean: -1.54010
[32m[0907 08-21-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18906, current rewards: -2733.57752, mean: -1.55317
[32m[0907 08-21-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18859, current rewards: -2833.57752, mean: -1.56551
[32m[0907 08-21-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18814, current rewards: -2933.57752, mean: -1.57719
[32m[0907 08-21-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18774, current rewards: -3033.57752, mean: -1.58826
[32m[0907 08-22-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18734, current rewards: -3133.57752, mean: -1.59876
[32m[0907 08-22-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18698, current rewards: -3233.57752, mean: -1.60875
[32m[0907 08-22-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18663, current rewards: -3333.57752, mean: -1.61824
[32m[0907 08-22-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18629, current rewards: -3433.57752, mean: -1.62729
[32m[0907 08-22-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18597, current rewards: -3533.57752, mean: -1.63592
[32m[0907 08-22-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18573, current rewards: -3633.57752, mean: -1.64415
[32m[0907 08-22-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18547, current rewards: -3733.57752, mean: -1.65203
[32m[0907 08-23-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18520, current rewards: -3833.57752, mean: -1.65956
[32m[0907 08-23-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18529, current rewards: -3915.66917, mean: -1.65918
[32m[0907 08-23-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18503, current rewards: -4015.66917, mean: -1.66625
[32m[0907 08-23-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18490, current rewards: -4115.66917, mean: -1.67304
[32m[0907 08-23-38 @Agent.py:117][0m Average action selection time: 0.1848
[32m[0907 08-23-38 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-23-38 @MBExp.py:227][0m Rewards obtained: [-4195.669167759142], Lows: [1981], Highs: [263], Total time: 53170.98393600002
[32m[0907 08-27-45 @MBExp.py:144][0m ####################################################################
[32m[0907 08-27-45 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 08-27-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18279, current rewards: -7.90174, mean: -0.79017
[32m[0907 08-27-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18341, current rewards: -5.30813, mean: -0.08847
[32m[0907 08-28-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18352, current rewards: -2.72091, mean: -0.02474
[32m[0907 08-28-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18366, current rewards: 0.68238, mean: 0.00426
[32m[0907 08-28-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18370, current rewards: 5.37879, mean: 0.02561
[32m[0907 08-28-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18374, current rewards: 10.07520, mean: 0.03875
[32m[0907 08-28-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18401, current rewards: 14.77161, mean: 0.04765
[32m[0907 08-28-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18473, current rewards: -29.75875, mean: -0.08266
[32m[0907 08-29-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18521, current rewards: -79.75875, mean: -0.19453
[32m[0907 08-29-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18553, current rewards: -129.75875, mean: -0.28208
[32m[0907 08-29-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18581, current rewards: -179.75875, mean: -0.35247
[32m[0907 08-29-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18605, current rewards: -229.75875, mean: -0.41028
[32m[0907 08-29-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18630, current rewards: -279.75875, mean: -0.45862
[32m[0907 08-29-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18644, current rewards: -329.75875, mean: -0.49963
[32m[0907 08-29-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18659, current rewards: -379.75875, mean: -0.53487
[32m[0907 08-30-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18671, current rewards: -429.75875, mean: -0.56547
[32m[0907 08-30-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18683, current rewards: -479.75875, mean: -0.59229
[32m[0907 08-30-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18691, current rewards: -529.75875, mean: -0.61600
[32m[0907 08-30-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18696, current rewards: -579.75875, mean: -0.63710
[32m[0907 08-30-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18701, current rewards: -629.75875, mean: -0.65600
[32m[0907 08-30-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18705, current rewards: -679.75875, mean: -0.67303
[32m[0907 08-31-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18702, current rewards: -729.75875, mean: -0.68845
[32m[0907 08-31-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18680, current rewards: -779.75875, mean: -0.70249
[32m[0907 08-31-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18640, current rewards: -829.75875, mean: -0.71531
[32m[0907 08-31-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18606, current rewards: -879.75875, mean: -0.72707
[32m[0907 08-31-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18569, current rewards: -929.75875, mean: -0.73790
[32m[0907 08-31-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18517, current rewards: -979.75875, mean: -0.74791
[32m[0907 08-31-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18468, current rewards: -1029.75875, mean: -0.75718
[32m[0907 08-32-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18424, current rewards: -1079.75875, mean: -0.76579
[32m[0907 08-32-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18384, current rewards: -1129.75875, mean: -0.77381
[32m[0907 08-32-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18345, current rewards: -1179.75875, mean: -0.78130
[32m[0907 08-32-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18309, current rewards: -1229.75875, mean: -0.78831
[32m[0907 08-32-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18275, current rewards: -1279.75875, mean: -0.79488
[32m[0907 08-32-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18243, current rewards: -1329.75875, mean: -0.80106
[32m[0907 08-32-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18214, current rewards: -1379.75875, mean: -0.80688
[32m[0907 08-33-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18187, current rewards: -1429.75875, mean: -0.81236
[32m[0907 08-33-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18162, current rewards: -1479.75875, mean: -0.81755
[32m[0907 08-33-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18136, current rewards: -1529.75875, mean: -0.82245
[32m[0907 08-33-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18113, current rewards: -1579.75875, mean: -0.82710
[32m[0907 08-33-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18091, current rewards: -1629.75875, mean: -0.83151
[32m[0907 08-33-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18071, current rewards: -1679.75875, mean: -0.83570
[32m[0907 08-33-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18051, current rewards: -1729.75875, mean: -0.83969
[32m[0907 08-34-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18032, current rewards: -1779.75875, mean: -0.84349
[32m[0907 08-34-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18014, current rewards: -1829.75875, mean: -0.84711
[32m[0907 08-34-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17996, current rewards: -1879.75875, mean: -0.85057
[32m[0907 08-34-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17978, current rewards: -1929.75875, mean: -0.85388
[32m[0907 08-34-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17963, current rewards: -1979.75875, mean: -0.85704
[32m[0907 08-34-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17948, current rewards: -2029.75875, mean: -0.86007
[32m[0907 08-34-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17934, current rewards: -2079.75875, mean: -0.86297
[32m[0907 08-35-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17921, current rewards: -2129.75875, mean: -0.86576
[32m[0907 08-35-14 @Agent.py:117][0m Average action selection time: 0.1792
[32m[0907 08-35-14 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-35-14 @MBExp.py:227][0m Rewards obtained: [-2169.758750073868], Lows: [0], Highs: [2193], Total time: 53619.834683000016
[32m[0907 08-39-23 @MBExp.py:144][0m ####################################################################
[32m[0907 08-39-23 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 08-39-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20188, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-39-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18702, current rewards: -107.94559, mean: -1.79909
[32m[0907 08-39-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18574, current rewards: -207.94559, mean: -1.89041
[32m[0907 08-39-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18500, current rewards: -307.94559, mean: -1.92466
[32m[0907 08-40-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18480, current rewards: -407.94559, mean: -1.94260
[32m[0907 08-40-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18462, current rewards: -507.94559, mean: -1.95364
[32m[0907 08-40-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18485, current rewards: -607.94559, mean: -1.96111
[32m[0907 08-40-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18553, current rewards: -707.94559, mean: -1.96652
[32m[0907 08-40-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18598, current rewards: -807.94559, mean: -1.97060
[32m[0907 08-40-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18632, current rewards: -907.94559, mean: -1.97379
[32m[0907 08-40-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18661, current rewards: -1007.94559, mean: -1.97636
[32m[0907 08-41-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18684, current rewards: -1107.94559, mean: -1.97847
[32m[0907 08-41-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18698, current rewards: -1207.94559, mean: -1.98024
[32m[0907 08-41-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18716, current rewards: -1307.94559, mean: -1.98174
[32m[0907 08-41-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18727, current rewards: -1407.94559, mean: -1.98302
[32m[0907 08-41-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18738, current rewards: -1507.94559, mean: -1.98414
[32m[0907 08-41-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18746, current rewards: -1607.94559, mean: -1.98512
[32m[0907 08-42-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18756, current rewards: -1707.94559, mean: -1.98598
[32m[0907 08-42-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18764, current rewards: -1807.94559, mean: -1.98675
[32m[0907 08-42-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18771, current rewards: -1907.94559, mean: -1.98744
[32m[0907 08-42-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18773, current rewards: -2007.94559, mean: -1.98806
[32m[0907 08-42-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18776, current rewards: -2107.94559, mean: -1.98863
[32m[0907 08-42-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18760, current rewards: -2207.94559, mean: -1.98914
[32m[0907 08-43-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18717, current rewards: -2307.94559, mean: -1.98961
[32m[0907 08-43-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18681, current rewards: -2407.94559, mean: -1.99004
[32m[0907 08-43-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18646, current rewards: -2507.94559, mean: -1.99043
[32m[0907 08-43-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18594, current rewards: -2607.94559, mean: -1.99080
[32m[0907 08-43-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18543, current rewards: -2707.94559, mean: -1.99114
[32m[0907 08-43-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18497, current rewards: -2807.94559, mean: -1.99145
[32m[0907 08-43-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18455, current rewards: -2907.94559, mean: -1.99174
[32m[0907 08-44-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18416, current rewards: -3007.94559, mean: -1.99202
[32m[0907 08-44-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18379, current rewards: -3107.94559, mean: -1.99227
[32m[0907 08-44-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18345, current rewards: -3207.94559, mean: -1.99251
[32m[0907 08-44-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18311, current rewards: -3307.94559, mean: -1.99274
[32m[0907 08-44-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18279, current rewards: -3407.94559, mean: -1.99295
[32m[0907 08-44-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18250, current rewards: -3507.94559, mean: -1.99315
[32m[0907 08-44-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18222, current rewards: -3607.94559, mean: -1.99334
[32m[0907 08-45-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18195, current rewards: -3707.94559, mean: -1.99352
[32m[0907 08-45-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18170, current rewards: -3807.94559, mean: -1.99369
[32m[0907 08-45-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18147, current rewards: -3907.94559, mean: -1.99385
[32m[0907 08-45-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18123, current rewards: -4007.94559, mean: -1.99400
[32m[0907 08-45-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18101, current rewards: -4107.94559, mean: -1.99415
[32m[0907 08-45-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18080, current rewards: -4207.94559, mean: -1.99429
[32m[0907 08-45-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18060, current rewards: -4307.94559, mean: -1.99442
[32m[0907 08-46-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18041, current rewards: -4407.94559, mean: -1.99455
[32m[0907 08-46-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18023, current rewards: -4507.94559, mean: -1.99467
[32m[0907 08-46-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18005, current rewards: -4607.94559, mean: -1.99478
[32m[0907 08-46-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17990, current rewards: -4707.94559, mean: -1.99489
[32m[0907 08-46-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17974, current rewards: -4807.94559, mean: -1.99500
[32m[0907 08-46-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17959, current rewards: -4907.94559, mean: -1.99510
[32m[0907 08-46-52 @Agent.py:117][0m Average action selection time: 0.1795
[32m[0907 08-46-52 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-46-53 @MBExp.py:227][0m Rewards obtained: [-4987.945588470341], Lows: [2489], Highs: [10], Total time: 54069.447732000015
[32m[0907 08-51-04 @MBExp.py:144][0m ####################################################################
[32m[0907 08-51-04 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 08-51-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18379, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-51-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18397, current rewards: -60.00000, mean: -1.00000
[32m[0907 08-51-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18419, current rewards: -110.00000, mean: -1.00000
[32m[0907 08-51-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.21751, current rewards: -160.00000, mean: -1.00000
[32m[0907 08-51-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.23821, current rewards: -208.94499, mean: -0.99498
[32m[0907 08-52-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.24295, current rewards: -263.56074, mean: -1.01370
[32m[0907 08-52-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.23419, current rewards: -363.56074, mean: -1.17278
[32m[0907 08-52-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.22790, current rewards: -463.56074, mean: -1.28767
[32m[0907 08-52-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.22321, current rewards: -563.56074, mean: -1.37454
[32m[0907 08-52-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.21946, current rewards: -663.56074, mean: -1.44252
[32m[0907 08-52-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.21640, current rewards: -763.56074, mean: -1.49718
[32m[0907 08-53-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.21401, current rewards: -863.56074, mean: -1.54207
[32m[0907 08-53-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.21187, current rewards: -963.56074, mean: -1.57961
[32m[0907 08-53-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.21006, current rewards: -1063.56074, mean: -1.61146
[32m[0907 08-53-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.20864, current rewards: -1163.56074, mean: -1.63882
[32m[0907 08-53-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.20729, current rewards: -1263.56074, mean: -1.66258
[32m[0907 08-53-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.20610, current rewards: -1363.56074, mean: -1.68341
[32m[0907 08-54-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.20508, current rewards: -1463.56074, mean: -1.70181
[32m[0907 08-54-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.20419, current rewards: -1563.56074, mean: -1.71820
[32m[0907 08-54-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.20338, current rewards: -1663.56074, mean: -1.73288
[32m[0907 08-54-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.20261, current rewards: -1763.56074, mean: -1.74610
[32m[0907 08-54-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.20163, current rewards: -1863.56074, mean: -1.75808
[32m[0907 08-54-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.20058, current rewards: -1963.56074, mean: -1.76897
[32m[0907 08-54-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19961, current rewards: -2063.56074, mean: -1.77893
[32m[0907 08-55-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19875, current rewards: -2163.56074, mean: -1.78807
[32m[0907 08-55-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19779, current rewards: -2263.56074, mean: -1.79648
[32m[0907 08-55-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19683, current rewards: -2363.56074, mean: -1.80424
[32m[0907 08-55-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19593, current rewards: -2463.56074, mean: -1.81144
[32m[0907 08-55-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19510, current rewards: -2563.56074, mean: -1.81813
[32m[0907 08-55-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19432, current rewards: -2663.56074, mean: -1.82436
[32m[0907 08-55-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19360, current rewards: -2763.56074, mean: -1.83017
[32m[0907 08-56-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19292, current rewards: -2863.56074, mean: -1.83562
[32m[0907 08-56-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19228, current rewards: -2963.56074, mean: -1.84072
[32m[0907 08-56-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19166, current rewards: -3063.56074, mean: -1.84552
[32m[0907 08-56-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19110, current rewards: -3163.56074, mean: -1.85004
[32m[0907 08-56-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19058, current rewards: -3263.56074, mean: -1.85430
[32m[0907 08-56-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19007, current rewards: -3363.56074, mean: -1.85832
[32m[0907 08-56-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18961, current rewards: -3463.56074, mean: -1.86213
[32m[0907 08-57-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18916, current rewards: -3563.56074, mean: -1.86574
[32m[0907 08-57-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18875, current rewards: -3663.56074, mean: -1.86916
[32m[0907 08-57-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18836, current rewards: -3763.56074, mean: -1.87242
[32m[0907 08-57-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18797, current rewards: -3863.56074, mean: -1.87551
[32m[0907 08-57-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18761, current rewards: -3963.56074, mean: -1.87846
[32m[0907 08-57-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18726, current rewards: -4063.56074, mean: -1.88128
[32m[0907 08-57-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18693, current rewards: -4163.56074, mean: -1.88396
[32m[0907 08-58-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18662, current rewards: -4263.56074, mean: -1.88653
[32m[0907 08-58-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18633, current rewards: -4363.56074, mean: -1.88899
[32m[0907 08-58-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18604, current rewards: -4463.56074, mean: -1.89134
[32m[0907 08-58-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18576, current rewards: -4563.56074, mean: -1.89359
[32m[0907 08-58-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18554, current rewards: -4663.56074, mean: -1.89576
[32m[0907 08-58-48 @Agent.py:117][0m Average action selection time: 0.1855
[32m[0907 08-58-48 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-58-48 @MBExp.py:227][0m Rewards obtained: [-4743.560735605458], Lows: [2252], Highs: [240], Total time: 54534.087630000016
