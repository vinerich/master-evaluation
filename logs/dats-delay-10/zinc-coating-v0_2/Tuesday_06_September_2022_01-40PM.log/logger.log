[32m[0906 13-40-11 @logger.py:99][0m Log file set to /app/logs/dats-delay-10/zinc-coating-v0_2/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-11 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -56.76555, mean: -0.94609
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -105.98670, mean: -0.96352
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -159.86532, mean: -0.99916
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -214.20063, mean: -1.02000
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -272.71731, mean: -1.04891
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -324.12490, mean: -1.04556
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -370.02231, mean: -1.02784
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -409.70091, mean: -0.99927
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -456.28602, mean: -0.99193
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -503.93856, mean: -0.98811
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -554.64126, mean: -0.99043
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -610.77544, mean: -1.00127
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -665.25164, mean: -1.00796
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -713.02628, mean: -1.00426
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -760.22159, mean: -1.00029
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -809.63668, mean: -0.99955
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -863.25291, mean: -1.00378
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -921.53367, mean: -1.01267
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -977.07464, mean: -1.01779
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1032.29461, mean: -1.02207
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1086.00591, mean: -1.02453
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1144.38978, mean: -1.03098
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1203.74092, mean: -1.03771
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1263.06010, mean: -1.04385
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1354.33838, mean: -1.07487
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1443.15469, mean: -1.10164
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1533.23530, mean: -1.12738
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1624.45748, mean: -1.15210
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1710.58146, mean: -1.17163
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1782.05041, mean: -1.18017
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1870.95393, mean: -1.19933
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1955.06919, mean: -1.21433
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -2030.83257, mean: -1.22339
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2100.11142, mean: -1.22814
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2159.08912, mean: -1.22676
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2217.31566, mean: -1.22504
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2278.62909, mean: -1.22507
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2334.53842, mean: -1.22227
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2380.83632, mean: -1.21471
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2428.92649, mean: -1.20842
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2478.15969, mean: -1.20299
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2527.20509, mean: -1.19773
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2573.32322, mean: -1.19135
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2623.26634, mean: -1.18700
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2668.00626, mean: -1.18053
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2716.25711, mean: -1.17587
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2762.30940, mean: -1.17047
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2809.73812, mean: -1.16587
[32m[0906 13-40-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2853.95677, mean: -1.16015
[32m[0906 13-40-11 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-40-13 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-13 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.16074, current rewards: -8.95171, mean: -0.89517
[32m[0906 13-40-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.14945, current rewards: -101.84345, mean: -1.69739
[32m[0906 13-40-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.14937, current rewards: -201.84345, mean: -1.83494
[32m[0906 13-40-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.15214, current rewards: -301.84345, mean: -1.88652
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.15645, current rewards: -401.84345, mean: -1.91354
[32m[0906 13-40-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.15908, current rewards: -501.84345, mean: -1.93017
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.16088, current rewards: -601.84345, mean: -1.94143
[32m[0906 13-41-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.16212, current rewards: -701.84345, mean: -1.94957
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.16329, current rewards: -801.84345, mean: -1.95572
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.16509, current rewards: -901.84345, mean: -1.96053
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.16765, current rewards: -977.48557, mean: -1.91664
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.16961, current rewards: -1077.48557, mean: -1.92408
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17118, current rewards: -1177.48557, mean: -1.93030
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17255, current rewards: -1277.48557, mean: -1.93558
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17375, current rewards: -1377.48557, mean: -1.94012
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17474, current rewards: -1477.48557, mean: -1.94406
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17551, current rewards: -1554.78319, mean: -1.91949
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17628, current rewards: -1654.78319, mean: -1.92417
[32m[0906 13-42-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17693, current rewards: -1754.78319, mean: -1.92833
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17751, current rewards: -1854.78319, mean: -1.93207
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17809, current rewards: -1954.78319, mean: -1.93543
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17858, current rewards: -2054.78319, mean: -1.93847
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17902, current rewards: -2131.16975, mean: -1.91997
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17943, current rewards: -2231.16975, mean: -1.92342
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17978, current rewards: -2331.16975, mean: -1.92659
[32m[0906 13-44-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18008, current rewards: -2316.53658, mean: -1.83852
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18039, current rewards: -2282.34871, mean: -1.74225
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18068, current rewards: -2282.72118, mean: -1.67847
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18100, current rewards: -2382.72118, mean: -1.68987
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18121, current rewards: -2482.72118, mean: -1.70049
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18142, current rewards: -2582.72118, mean: -1.71041
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18164, current rewards: -2682.72118, mean: -1.71969
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18186, current rewards: -2782.72118, mean: -1.72840
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18206, current rewards: -2882.72118, mean: -1.73658
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18224, current rewards: -2982.72118, mean: -1.74428
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18239, current rewards: -3082.72118, mean: -1.75155
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18255, current rewards: -3182.72118, mean: -1.75841
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18271, current rewards: -3282.72118, mean: -1.76490
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18284, current rewards: -3382.72118, mean: -1.77106
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18295, current rewards: -3482.72118, mean: -1.77690
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18302, current rewards: -3582.72118, mean: -1.78245
[32m[0906 13-46-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18313, current rewards: -3682.72118, mean: -1.78773
[32m[0906 13-46-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18325, current rewards: -3782.72118, mean: -1.79276
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18336, current rewards: -3882.72118, mean: -1.79756
[32m[0906 13-46-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18344, current rewards: -3906.82548, mean: -1.76779
[32m[0906 13-47-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18354, current rewards: -3897.12585, mean: -1.72439
[32m[0906 13-47-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18364, current rewards: -3887.51187, mean: -1.68291
[32m[0906 13-47-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18370, current rewards: -3877.90696, mean: -1.64318
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18377, current rewards: -3868.30504, mean: -1.60511
[32m[0906 13-47-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18387, current rewards: -3858.72341, mean: -1.56859
[32m[0906 13-47-54 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 13-47-54 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-47-54 @MBExp.py:227][0m Rewards obtained: [-3851.0316919109987], Lows: [1994], Highs: [19], Total time: 460.509864
[32m[0906 13-47-58 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-58 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-48-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18718, current rewards: 0.73621, mean: 0.07362
[32m[0906 13-48-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18653, current rewards: 4.17164, mean: 0.06953
[32m[0906 13-48-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18605, current rewards: 7.60207, mean: 0.06911
[32m[0906 13-48-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18524, current rewards: 11.03250, mean: 0.06895
[32m[0906 13-48-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18554, current rewards: 14.46293, mean: 0.06887
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18558, current rewards: 17.89336, mean: 0.06882
[32m[0906 13-48-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18562, current rewards: 21.32380, mean: 0.06879
[32m[0906 13-49-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18551, current rewards: 21.46303, mean: 0.05962
[32m[0906 13-49-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18544, current rewards: -28.53697, mean: -0.06960
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18521, current rewards: -78.53697, mean: -0.17073
[32m[0906 13-49-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18539, current rewards: -128.53697, mean: -0.25203
[32m[0906 13-49-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18542, current rewards: -178.53697, mean: -0.31882
[32m[0906 13-49-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18543, current rewards: -228.53697, mean: -0.37465
[32m[0906 13-50-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18548, current rewards: -278.53697, mean: -0.42203
[32m[0906 13-50-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18546, current rewards: -328.53697, mean: -0.46273
[32m[0906 13-50-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18547, current rewards: -378.53697, mean: -0.49807
[32m[0906 13-50-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18547, current rewards: -428.53697, mean: -0.52906
[32m[0906 13-50-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18546, current rewards: -478.53697, mean: -0.55644
[32m[0906 13-50-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18544, current rewards: -528.53697, mean: -0.58081
[32m[0906 13-50-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18542, current rewards: -578.53697, mean: -0.60264
[32m[0906 13-51-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18540, current rewards: -628.53697, mean: -0.62231
[32m[0906 13-51-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18541, current rewards: -678.53697, mean: -0.64013
[32m[0906 13-51-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18538, current rewards: -728.53697, mean: -0.65634
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18540, current rewards: -778.53697, mean: -0.67115
[32m[0906 13-51-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18539, current rewards: -828.53697, mean: -0.68474
[32m[0906 13-51-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18538, current rewards: -878.53697, mean: -0.69725
[32m[0906 13-52-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18537, current rewards: -928.53697, mean: -0.70881
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18538, current rewards: -978.53697, mean: -0.71951
[32m[0906 13-52-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18538, current rewards: -1028.53697, mean: -0.72946
[32m[0906 13-52-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18537, current rewards: -1078.53697, mean: -0.73872
[32m[0906 13-52-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18536, current rewards: -1128.53697, mean: -0.74738
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18532, current rewards: -1178.53697, mean: -0.75547
[32m[0906 13-52-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18529, current rewards: -1228.53697, mean: -0.76307
[32m[0906 13-53-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18529, current rewards: -1278.53697, mean: -0.77020
[32m[0906 13-53-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18529, current rewards: -1328.53697, mean: -0.77692
[32m[0906 13-53-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18529, current rewards: -1378.53697, mean: -0.78326
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18527, current rewards: -1428.53697, mean: -0.78925
[32m[0906 13-53-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18525, current rewards: -1478.53697, mean: -0.79491
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18525, current rewards: -1528.53697, mean: -0.80028
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18521, current rewards: -1578.53697, mean: -0.80538
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18519, current rewards: -1628.53697, mean: -0.81022
[32m[0906 13-54-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18522, current rewards: -1678.53697, mean: -0.81482
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18521, current rewards: -1728.53697, mean: -0.81921
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18519, current rewards: -1778.53697, mean: -0.82340
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18517, current rewards: -1828.53697, mean: -0.82739
[32m[0906 13-54-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18517, current rewards: -1878.53697, mean: -0.83121
[32m[0906 13-55-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18516, current rewards: -1928.53697, mean: -0.83486
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18509, current rewards: -1978.53697, mean: -0.83836
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18510, current rewards: -2028.53697, mean: -0.84172
[32m[0906 13-55-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18509, current rewards: -2078.53697, mean: -0.84493
[32m[0906 13-55-42 @Agent.py:117][0m Average action selection time: 0.1851
[32m[0906 13-55-42 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-55-42 @MBExp.py:227][0m Rewards obtained: [-2118.536973243165], Lows: [0], Highs: [2143], Total time: 923.889587
[32m[0906 13-55-48 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-48 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-55-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18666, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-55-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18617, current rewards: -2.84694, mean: -0.04745
[32m[0906 13-56-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18583, current rewards: 5.65362, mean: 0.05140
[32m[0906 13-56-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18496, current rewards: 14.15727, mean: 0.08848
[32m[0906 13-56-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18504, current rewards: 22.65652, mean: 0.10789
[32m[0906 13-56-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18492, current rewards: 31.17916, mean: 0.11992
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18496, current rewards: 20.42991, mean: 0.06590
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18504, current rewards: 27.04179, mean: 0.07512
[32m[0906 13-57-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18510, current rewards: 44.71788, mean: 0.10907
[32m[0906 13-57-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18486, current rewards: 62.38132, mean: 0.13561
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18496, current rewards: 80.08518, mean: 0.15703
[32m[0906 13-57-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18500, current rewards: 97.79083, mean: 0.17463
[32m[0906 13-57-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18500, current rewards: 115.43443, mean: 0.18924
[32m[0906 13-57-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18507, current rewards: 133.09183, mean: 0.20165
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18515, current rewards: 150.79864, mean: 0.21239
[32m[0906 13-58-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18525, current rewards: 97.66102, mean: 0.12850
[32m[0906 13-58-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18529, current rewards: 105.96129, mean: 0.13082
[32m[0906 13-58-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18539, current rewards: 114.26141, mean: 0.13286
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18543, current rewards: 122.56153, mean: 0.13468
[32m[0906 13-58-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18539, current rewards: 130.86165, mean: 0.13631
[32m[0906 13-58-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18532, current rewards: 139.16177, mean: 0.13778
[32m[0906 13-59-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18533, current rewards: 147.46189, mean: 0.13911
[32m[0906 13-59-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18534, current rewards: 155.76201, mean: 0.14033
[32m[0906 13-59-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18531, current rewards: 158.23212, mean: 0.13641
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18531, current rewards: 108.23212, mean: 0.08945
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18528, current rewards: 58.23212, mean: 0.04622
[32m[0906 13-59-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18526, current rewards: 8.23212, mean: 0.00628
[32m[0906 14-00-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18527, current rewards: -41.76788, mean: -0.03071
[32m[0906 14-00-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18525, current rewards: -91.76788, mean: -0.06508
[32m[0906 14-00-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18524, current rewards: -141.76788, mean: -0.09710
[32m[0906 14-00-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18529, current rewards: -191.76788, mean: -0.12700
[32m[0906 14-00-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18529, current rewards: -241.76788, mean: -0.15498
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18527, current rewards: -291.76788, mean: -0.18122
[32m[0906 14-00-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18528, current rewards: -341.76788, mean: -0.20588
[32m[0906 14-01-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18528, current rewards: -391.76788, mean: -0.22910
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18529, current rewards: -441.76788, mean: -0.25100
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18529, current rewards: -491.76788, mean: -0.27169
[32m[0906 14-01-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18529, current rewards: -541.76788, mean: -0.29127
[32m[0906 14-01-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18528, current rewards: -591.76788, mean: -0.30983
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18522, current rewards: -641.76788, mean: -0.32743
[32m[0906 14-02-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18515, current rewards: -691.76788, mean: -0.34416
[32m[0906 14-02-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18519, current rewards: -741.76788, mean: -0.36008
[32m[0906 14-02-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18522, current rewards: -791.76788, mean: -0.37525
[32m[0906 14-02-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18523, current rewards: -841.76788, mean: -0.38971
[32m[0906 14-02-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18525, current rewards: -891.76788, mean: -0.40351
[32m[0906 14-02-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18522, current rewards: -941.76788, mean: -0.41671
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18524, current rewards: -991.76788, mean: -0.42934
[32m[0906 14-03-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18515, current rewards: -1041.76788, mean: -0.44143
[32m[0906 14-03-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18516, current rewards: -1091.76788, mean: -0.45302
[32m[0906 14-03-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18517, current rewards: -1141.76788, mean: -0.46413
[32m[0906 14-03-32 @Agent.py:117][0m Average action selection time: 0.1852
[32m[0906 14-03-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-03-32 @MBExp.py:227][0m Rewards obtained: [-1181.7678777851986], Lows: [46], Highs: [1356], Total time: 1387.46761
[32m[0906 14-03-40 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-40 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-03-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18638, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-03-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18614, current rewards: -11.85547, mean: -0.19759
[32m[0906 14-04-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18526, current rewards: -6.39815, mean: -0.05816
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18429, current rewards: -0.93987, mean: -0.00587
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18465, current rewards: 4.51961, mean: 0.02152
[32m[0906 14-04-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18478, current rewards: 9.97774, mean: 0.03838
[32m[0906 14-04-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18497, current rewards: 14.95247, mean: 0.04823
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18509, current rewards: 19.82972, mean: 0.05508
[32m[0906 14-04-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18497, current rewards: 24.71492, mean: 0.06028
[32m[0906 14-05-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18465, current rewards: 29.59513, mean: 0.06434
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18482, current rewards: 34.47361, mean: 0.06760
[32m[0906 14-05-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18485, current rewards: 19.61871, mean: 0.03503
[32m[0906 14-05-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18484, current rewards: -25.03083, mean: -0.04103
[32m[0906 14-05-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18483, current rewards: -70.75043, mean: -0.10720
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18479, current rewards: -116.49578, mean: -0.16408
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18480, current rewards: -166.49578, mean: -0.21907
[32m[0906 14-06-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18484, current rewards: -216.49578, mean: -0.26728
[32m[0906 14-06-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18487, current rewards: -266.49578, mean: -0.30988
[32m[0906 14-06-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18486, current rewards: -316.49578, mean: -0.34780
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18481, current rewards: -366.49578, mean: -0.38177
[32m[0906 14-06-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18488, current rewards: -416.49578, mean: -0.41237
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18489, current rewards: -466.49578, mean: -0.44009
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18488, current rewards: -516.49578, mean: -0.46531
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18487, current rewards: -566.49578, mean: -0.48836
[32m[0906 14-07-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18485, current rewards: -616.49578, mean: -0.50950
[32m[0906 14-07-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18483, current rewards: -666.49578, mean: -0.52896
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18485, current rewards: -716.49578, mean: -0.54694
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18483, current rewards: -776.49578, mean: -0.57095
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18484, current rewards: -772.38682, mean: -0.54779
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18482, current rewards: -766.45074, mean: -0.52497
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18483, current rewards: -760.55410, mean: -0.50368
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18482, current rewards: -754.78345, mean: -0.48384
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18481, current rewards: -748.97599, mean: -0.46520
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18482, current rewards: -743.16923, mean: -0.44769
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18483, current rewards: -737.36262, mean: -0.43121
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18483, current rewards: -732.67146, mean: -0.41629
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18483, current rewards: -781.61113, mean: -0.43183
[32m[0906 14-09-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18480, current rewards: -831.61113, mean: -0.44710
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18478, current rewards: -881.61113, mean: -0.46158
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18473, current rewards: -931.61113, mean: -0.47531
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18464, current rewards: -981.61113, mean: -0.48836
[32m[0906 14-10-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18464, current rewards: -1031.61113, mean: -0.50078
[32m[0906 14-10-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18466, current rewards: -1081.61113, mean: -0.51261
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18466, current rewards: -1131.61113, mean: -0.52389
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18467, current rewards: -1165.73314, mean: -0.52748
[32m[0906 14-10-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18468, current rewards: -1162.01361, mean: -0.51417
[32m[0906 14-10-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18465, current rewards: -1158.29574, mean: -0.50143
[32m[0906 14-10-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18459, current rewards: -1153.89925, mean: -0.48894
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18463, current rewards: -1149.55633, mean: -0.47699
[32m[0906 14-11-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18466, current rewards: -1170.71387, mean: -0.47590
[32m[0906 14-11-23 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0906 14-11-23 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-11-23 @MBExp.py:227][0m Rewards obtained: [-1167.0206445554647], Lows: [20], Highs: [1251], Total time: 1849.753772
[32m[0906 14-11-33 @MBExp.py:144][0m ####################################################################
[32m[0906 14-11-33 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-11-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18576, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-11-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18588, current rewards: -3.32689, mean: -0.05545
[32m[0906 14-11-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18484, current rewards: 3.91565, mean: 0.03560
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18359, current rewards: 11.16291, mean: 0.06977
[32m[0906 14-12-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18422, current rewards: 18.40341, mean: 0.08764
[32m[0906 14-12-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18458, current rewards: 6.86981, mean: 0.02642
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18472, current rewards: -93.13019, mean: -0.30042
[32m[0906 14-12-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18483, current rewards: -193.13019, mean: -0.53647
[32m[0906 14-12-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18458, current rewards: -293.13019, mean: -0.71495
[32m[0906 14-12-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18436, current rewards: -393.13019, mean: -0.85463
[32m[0906 14-13-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18468, current rewards: -397.64940, mean: -0.77970
[32m[0906 14-13-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18469, current rewards: -402.86007, mean: -0.71939
[32m[0906 14-13-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18485, current rewards: -405.97132, mean: -0.66553
[32m[0906 14-13-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18486, current rewards: -411.19178, mean: -0.62302
[32m[0906 14-13-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18490, current rewards: -415.03583, mean: -0.58456
[32m[0906 14-13-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18486, current rewards: -420.70780, mean: -0.55356
[32m[0906 14-14-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18487, current rewards: -424.28172, mean: -0.52380
[32m[0906 14-14-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18486, current rewards: -429.95371, mean: -0.49995
[32m[0906 14-14-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18489, current rewards: -433.52354, mean: -0.47640
[32m[0906 14-14-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18489, current rewards: -460.12946, mean: -0.47930
[32m[0906 14-14-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18495, current rewards: -560.12946, mean: -0.55458
[32m[0906 14-14-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18494, current rewards: -660.12946, mean: -0.62276
[32m[0906 14-14-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18494, current rewards: -737.12378, mean: -0.66408
[32m[0906 14-15-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18505, current rewards: -837.12378, mean: -0.72166
[32m[0906 14-15-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18507, current rewards: -937.12378, mean: -0.77448
[32m[0906 14-15-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18504, current rewards: -1037.12378, mean: -0.82311
[32m[0906 14-15-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18504, current rewards: -1137.12378, mean: -0.86803
[32m[0906 14-15-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18505, current rewards: -1237.12378, mean: -0.90965
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18504, current rewards: -1337.12378, mean: -0.94831
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18502, current rewards: -1437.12378, mean: -0.98433
[32m[0906 14-16-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18501, current rewards: -1454.81522, mean: -0.96345
[32m[0906 14-16-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18500, current rewards: -1449.23601, mean: -0.92900
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18501, current rewards: -1443.65487, mean: -0.89668
[32m[0906 14-16-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18501, current rewards: -1438.07178, mean: -0.86631
[32m[0906 14-16-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18503, current rewards: -1427.26264, mean: -0.83466
[32m[0906 14-16-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18504, current rewards: -1415.40100, mean: -0.80421
[32m[0906 14-17-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18505, current rewards: -1405.38860, mean: -0.77646
[32m[0906 14-17-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18507, current rewards: -1395.40019, mean: -0.75022
[32m[0906 14-17-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18506, current rewards: -1386.50633, mean: -0.72592
[32m[0906 14-17-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18502, current rewards: -1380.92362, mean: -0.70455
[32m[0906 14-17-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18491, current rewards: -1396.63968, mean: -0.69485
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18492, current rewards: -1404.41496, mean: -0.68175
[32m[0906 14-18-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18493, current rewards: -1396.08640, mean: -0.66165
[32m[0906 14-18-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18495, current rewards: -1387.75650, mean: -0.64248
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18497, current rewards: -1379.41894, mean: -0.62417
[32m[0906 14-18-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18498, current rewards: -1371.08584, mean: -0.60668
[32m[0906 14-18-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18491, current rewards: -1362.75654, mean: -0.58994
[32m[0906 14-18-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18485, current rewards: -1424.12587, mean: -0.60344
[32m[0906 14-18-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18485, current rewards: -1524.12587, mean: -0.63242
[32m[0906 14-19-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18487, current rewards: -1624.12587, mean: -0.66021
[32m[0906 14-19-16 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0906 14-19-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-19-16 @MBExp.py:227][0m Rewards obtained: [-1704.1258723783], Lows: [957], Highs: [22], Total time: 2312.621329
[32m[0906 14-19-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-29 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-19-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18645, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-19-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18583, current rewards: -8.80568, mean: -0.14676
[32m[0906 14-19-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18446, current rewards: -3.98192, mean: -0.03620
[32m[0906 14-19-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18336, current rewards: 0.83329, mean: 0.00521
[32m[0906 14-20-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18407, current rewards: 5.65417, mean: 0.02692
[32m[0906 14-20-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18435, current rewards: 11.71272, mean: 0.04505
[32m[0906 14-20-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18440, current rewards: 18.02825, mean: 0.05816
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18450, current rewards: 23.51764, mean: 0.06533
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18418, current rewards: 28.21140, mean: 0.06881
[32m[0906 14-20-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18405, current rewards: 31.39728, mean: 0.06825
[32m[0906 14-21-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18422, current rewards: 34.60111, mean: 0.06785
[32m[0906 14-21-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18433, current rewards: 37.80752, mean: 0.06751
[32m[0906 14-21-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18440, current rewards: 41.01087, mean: 0.06723
[32m[0906 14-21-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18453, current rewards: 33.50044, mean: 0.05076
[32m[0906 14-21-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18454, current rewards: 9.77647, mean: 0.01377
[32m[0906 14-21-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18460, current rewards: 12.22806, mean: 0.01609
[32m[0906 14-21-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18461, current rewards: 14.68167, mean: 0.01813
[32m[0906 14-22-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18469, current rewards: 17.13566, mean: 0.01993
[32m[0906 14-22-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18475, current rewards: 19.58620, mean: 0.02152
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18477, current rewards: 22.03827, mean: 0.02296
[32m[0906 14-22-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18480, current rewards: 24.48948, mean: 0.02425
[32m[0906 14-22-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18482, current rewards: 26.94165, mean: 0.02542
[32m[0906 14-22-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18481, current rewards: 29.39354, mean: 0.02648
[32m[0906 14-23-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18484, current rewards: 31.84672, mean: 0.02745
[32m[0906 14-23-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18483, current rewards: 34.29751, mean: 0.02835
[32m[0906 14-23-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18483, current rewards: 36.74943, mean: 0.02917
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18488, current rewards: 39.20277, mean: 0.02993
[32m[0906 14-23-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18487, current rewards: 41.65548, mean: 0.03063
[32m[0906 14-23-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18488, current rewards: 44.10836, mean: 0.03128
[32m[0906 14-23-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18488, current rewards: 46.55930, mean: 0.03189
[32m[0906 14-24-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18491, current rewards: 49.11788, mean: 0.03253
[32m[0906 14-24-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18488, current rewards: 51.58421, mean: 0.03307
[32m[0906 14-24-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18489, current rewards: 53.00089, mean: 0.03292
[32m[0906 14-24-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18489, current rewards: 4.05485, mean: 0.00244
[32m[0906 14-24-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18492, current rewards: -45.94515, mean: -0.02687
[32m[0906 14-24-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18494, current rewards: -95.94515, mean: -0.05451
[32m[0906 14-25-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18494, current rewards: -145.94515, mean: -0.08063
[32m[0906 14-25-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18494, current rewards: -195.94515, mean: -0.10535
[32m[0906 14-25-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18496, current rewards: -236.48907, mean: -0.12382
[32m[0906 14-25-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18493, current rewards: -286.48907, mean: -0.14617
[32m[0906 14-25-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18484, current rewards: -336.48907, mean: -0.16741
[32m[0906 14-25-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18483, current rewards: -386.48907, mean: -0.18762
[32m[0906 14-26-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18486, current rewards: -436.48907, mean: -0.20687
[32m[0906 14-26-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18488, current rewards: -486.48907, mean: -0.22523
[32m[0906 14-26-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18489, current rewards: -536.48907, mean: -0.24276
[32m[0906 14-26-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18490, current rewards: -561.22264, mean: -0.24833
[32m[0906 14-26-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18482, current rewards: -557.38723, mean: -0.24129
[32m[0906 14-26-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18477, current rewards: -553.57412, mean: -0.23457
[32m[0906 14-26-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18479, current rewards: -549.69049, mean: -0.22809
[32m[0906 14-27-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18484, current rewards: -545.80558, mean: -0.22187
[32m[0906 14-27-12 @Agent.py:117][0m Average action selection time: 0.1848
[32m[0906 14-27-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-27-12 @MBExp.py:227][0m Rewards obtained: [-542.7014577768283], Lows: [10], Highs: [646], Total time: 2775.378194
[32m[0906 14-27-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-27 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-27-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18660, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-27-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18645, current rewards: -8.45715, mean: -0.14095
[32m[0906 14-27-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18475, current rewards: -3.35344, mean: -0.03049
[32m[0906 14-27-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18380, current rewards: 1.74797, mean: 0.01092
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18432, current rewards: 6.85443, mean: 0.03264
[32m[0906 14-28-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18461, current rewards: 11.95779, mean: 0.04599
[32m[0906 14-28-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18473, current rewards: 17.06216, mean: 0.05504
[32m[0906 14-28-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18480, current rewards: 22.16918, mean: 0.06158
[32m[0906 14-28-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18429, current rewards: 27.27392, mean: 0.06652
[32m[0906 14-28-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18421, current rewards: 32.37853, mean: 0.07039
[32m[0906 14-29-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18443, current rewards: 37.48307, mean: 0.07350
[32m[0906 14-29-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18460, current rewards: 42.58659, mean: 0.07605
[32m[0906 14-29-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18469, current rewards: 47.68787, mean: 0.07818
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18476, current rewards: 54.16340, mean: 0.08207
[32m[0906 14-29-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18479, current rewards: 40.75835, mean: 0.05741
[32m[0906 14-29-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18491, current rewards: 40.95886, mean: 0.05389
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18490, current rewards: 42.25269, mean: 0.05216
[32m[0906 14-30-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18492, current rewards: 42.41820, mean: 0.04932
[32m[0906 14-30-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18489, current rewards: 43.69080, mean: 0.04801
[32m[0906 14-30-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18488, current rewards: 43.85943, mean: 0.04569
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18487, current rewards: 45.12873, mean: 0.04468
[32m[0906 14-30-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18485, current rewards: 48.72650, mean: 0.04597
[32m[0906 14-30-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18486, current rewards: 54.27919, mean: 0.04890
[32m[0906 14-31-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18489, current rewards: 59.83212, mean: 0.05158
[32m[0906 14-31-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18489, current rewards: 65.38486, mean: 0.05404
[32m[0906 14-31-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18489, current rewards: 70.93682, mean: 0.05630
[32m[0906 14-31-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18491, current rewards: 76.48654, mean: 0.05839
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18493, current rewards: 82.03994, mean: 0.06032
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18494, current rewards: 87.59624, mean: 0.06212
[32m[0906 14-31-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18500, current rewards: 94.43876, mean: 0.06468
[32m[0906 14-32-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18499, current rewards: 100.59306, mean: 0.06662
[32m[0906 14-32-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18499, current rewards: 106.75716, mean: 0.06843
[32m[0906 14-32-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18496, current rewards: 101.68467, mean: 0.06316
[32m[0906 14-32-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18497, current rewards: 19.07836, mean: 0.01149
[32m[0906 14-32-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18500, current rewards: -80.92164, mean: -0.04732
[32m[0906 14-32-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18499, current rewards: -180.92164, mean: -0.10280
[32m[0906 14-33-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18500, current rewards: -280.92164, mean: -0.15521
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18500, current rewards: -380.92164, mean: -0.20480
[32m[0906 14-33-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18499, current rewards: -480.92164, mean: -0.25179
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18493, current rewards: -580.92164, mean: -0.29639
[32m[0906 14-33-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18484, current rewards: -680.92164, mean: -0.33877
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18481, current rewards: -705.68827, mean: -0.34257
[32m[0906 14-33-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18486, current rewards: -698.61996, mean: -0.33110
[32m[0906 14-34-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18490, current rewards: -691.53690, mean: -0.32016
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18490, current rewards: -684.47343, mean: -0.30972
[32m[0906 14-34-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18488, current rewards: -677.77818, mean: -0.29990
[32m[0906 14-34-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18478, current rewards: -670.97055, mean: -0.29046
[32m[0906 14-34-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18474, current rewards: -664.14750, mean: -0.28142
[32m[0906 14-34-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18477, current rewards: -657.32663, mean: -0.27275
[32m[0906 14-35-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18481, current rewards: -650.51508, mean: -0.26444
[32m[0906 14-35-09 @Agent.py:117][0m Average action selection time: 0.1848
[32m[0906 14-35-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-35-09 @MBExp.py:227][0m Rewards obtained: [-645.0598612030858], Lows: [407], Highs: [69], Total time: 3238.0658679999997
[32m[0906 14-35-27 @MBExp.py:144][0m ####################################################################
[32m[0906 14-35-27 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-35-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18463, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-35-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18543, current rewards: -7.72469, mean: -0.12874
[32m[0906 14-35-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18334, current rewards: -3.02279, mean: -0.02748
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18278, current rewards: 1.67870, mean: 0.01049
[32m[0906 14-36-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18417, current rewards: 6.94271, mean: 0.03306
[32m[0906 14-36-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18550, current rewards: 11.77656, mean: 0.04529
[32m[0906 14-36-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18580, current rewards: 16.60807, mean: 0.05357
[32m[0906 14-36-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18536, current rewards: 21.44318, mean: 0.05956
[32m[0906 14-36-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18483, current rewards: 26.27874, mean: 0.06409
[32m[0906 14-36-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18477, current rewards: 19.01050, mean: 0.04133
[32m[0906 14-37-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18493, current rewards: 23.43565, mean: 0.04595
[32m[0906 14-37-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18500, current rewards: 27.92921, mean: 0.04987
[32m[0906 14-37-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18509, current rewards: 32.69009, mean: 0.05359
[32m[0906 14-37-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18508, current rewards: 12.18945, mean: 0.01847
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18511, current rewards: 5.97406, mean: 0.00841
[32m[0906 14-37-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18513, current rewards: 16.89008, mean: 0.02222
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18512, current rewards: 27.80196, mean: 0.03432
[32m[0906 14-38-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18516, current rewards: 38.71737, mean: 0.04502
[32m[0906 14-38-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18526, current rewards: 49.63697, mean: 0.05455
[32m[0906 14-38-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18524, current rewards: 60.54897, mean: 0.06307
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18523, current rewards: 67.53067, mean: 0.06686
[32m[0906 14-38-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18523, current rewards: 76.44126, mean: 0.07211
[32m[0906 14-38-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18524, current rewards: 85.58340, mean: 0.07710
[32m[0906 14-39-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18525, current rewards: 78.62545, mean: 0.06778
[32m[0906 14-39-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18527, current rewards: 82.47265, mean: 0.06816
[32m[0906 14-39-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18527, current rewards: 86.31827, mean: 0.06851
[32m[0906 14-39-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18529, current rewards: 90.16194, mean: 0.06883
[32m[0906 14-39-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18528, current rewards: 94.00761, mean: 0.06912
[32m[0906 14-39-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18529, current rewards: 97.88871, mean: 0.06942
[32m[0906 14-39-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18532, current rewards: 104.60417, mean: 0.07165
[32m[0906 14-40-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18531, current rewards: 109.54135, mean: 0.07254
[32m[0906 14-40-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18535, current rewards: 114.47426, mean: 0.07338
[32m[0906 14-40-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18534, current rewards: 118.76479, mean: 0.07377
[32m[0906 14-40-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18534, current rewards: 122.97165, mean: 0.07408
[32m[0906 14-40-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18533, current rewards: 127.17993, mean: 0.07437
[32m[0906 14-40-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18532, current rewards: 131.38879, mean: 0.07465
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18533, current rewards: 135.59755, mean: 0.07492
[32m[0906 14-41-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18531, current rewards: 119.08045, mean: 0.06402
[32m[0906 14-41-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18530, current rewards: 123.77485, mean: 0.06480
[32m[0906 14-41-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18520, current rewards: 128.48632, mean: 0.06555
[32m[0906 14-41-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18507, current rewards: 133.20242, mean: 0.06627
[32m[0906 14-41-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18502, current rewards: 137.91685, mean: 0.06695
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18505, current rewards: 142.63314, mean: 0.06760
[32m[0906 14-42-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18505, current rewards: 136.29526, mean: 0.06310
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18505, current rewards: 140.87113, mean: 0.06374
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18501, current rewards: 145.55516, mean: 0.06440
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18492, current rewards: 151.12414, mean: 0.06542
[32m[0906 14-42-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18489, current rewards: 156.03101, mean: 0.06611
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18491, current rewards: 160.94515, mean: 0.06678
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18493, current rewards: 165.85799, mean: 0.06742
[32m[0906 14-43-10 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0906 14-43-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-43-10 @MBExp.py:227][0m Rewards obtained: [169.78571776554568], Lows: [30], Highs: [44], Total time: 3701.044693
[32m[0906 14-43-29 @MBExp.py:144][0m ####################################################################
[32m[0906 14-43-29 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-43-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18575, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-43-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18441, current rewards: -10.28706, mean: -0.17145
[32m[0906 14-43-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18251, current rewards: -7.40955, mean: -0.06736
[32m[0906 14-43-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18240, current rewards: -4.53429, mean: -0.02834
[32m[0906 14-44-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18330, current rewards: -0.98689, mean: -0.00470
[32m[0906 14-44-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18379, current rewards: 2.23499, mean: 0.00860
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18416, current rewards: 5.38659, mean: 0.01738
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18387, current rewards: 1.09509, mean: 0.00304
[32m[0906 14-44-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18349, current rewards: 4.62483, mean: 0.01128
[32m[0906 14-44-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18354, current rewards: 12.63298, mean: 0.02746
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18373, current rewards: 20.67121, mean: 0.04053
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18388, current rewards: 28.68188, mean: 0.05122
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18397, current rewards: 36.61479, mean: 0.06002
[32m[0906 14-45-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18406, current rewards: 41.54560, mean: 0.06295
[32m[0906 14-45-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18419, current rewards: 46.74739, mean: 0.06584
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18424, current rewards: 51.94983, mean: 0.06836
[32m[0906 14-45-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18432, current rewards: 57.15150, mean: 0.07056
[32m[0906 14-46-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18441, current rewards: 62.35294, mean: 0.07250
[32m[0906 14-46-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18446, current rewards: 67.55976, mean: 0.07424
[32m[0906 14-46-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18450, current rewards: 51.81354, mean: 0.05397
[32m[0906 14-46-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18462, current rewards: 57.17566, mean: 0.05661
[32m[0906 14-46-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18472, current rewards: 62.34830, mean: 0.05882
[32m[0906 14-46-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18473, current rewards: 67.61481, mean: 0.06091
[32m[0906 14-47-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18475, current rewards: 72.87200, mean: 0.06282
[32m[0906 14-47-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18478, current rewards: 78.12649, mean: 0.06457
[32m[0906 14-47-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18481, current rewards: 63.44195, mean: 0.05035
[32m[0906 14-47-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18480, current rewards: 70.27007, mean: 0.05364
[32m[0906 14-47-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18480, current rewards: 77.09079, mean: 0.05668
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18480, current rewards: 83.91427, mean: 0.05951
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18482, current rewards: 90.39163, mean: 0.06191
[32m[0906 14-48-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18484, current rewards: 97.01360, mean: 0.06425
[32m[0906 14-48-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18486, current rewards: 103.62926, mean: 0.06643
[32m[0906 14-48-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18487, current rewards: 110.25227, mean: 0.06848
[32m[0906 14-48-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18488, current rewards: 116.86804, mean: 0.07040
[32m[0906 14-48-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18493, current rewards: 123.48551, mean: 0.07221
[32m[0906 14-48-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18492, current rewards: 130.10886, mean: 0.07393
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18491, current rewards: 136.72815, mean: 0.07554
[32m[0906 14-49-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18491, current rewards: 130.60744, mean: 0.07022
[32m[0906 14-49-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18490, current rewards: 135.30025, mean: 0.07084
[32m[0906 14-49-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18483, current rewards: 139.97001, mean: 0.07141
[32m[0906 14-49-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18471, current rewards: 144.63990, mean: 0.07196
[32m[0906 14-49-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18463, current rewards: 149.30910, mean: 0.07248
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18467, current rewards: 153.97872, mean: 0.07298
[32m[0906 14-50-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18471, current rewards: 158.64638, mean: 0.07345
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18476, current rewards: 163.31625, mean: 0.07390
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18467, current rewards: 167.63400, mean: 0.07417
[32m[0906 14-50-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18457, current rewards: 173.42573, mean: 0.07508
[32m[0906 14-50-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18457, current rewards: 178.38236, mean: 0.07559
[32m[0906 14-50-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18461, current rewards: 183.36198, mean: 0.07608
[32m[0906 14-51-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18464, current rewards: 188.33272, mean: 0.07656
[32m[0906 14-51-11 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0906 14-51-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-51-11 @MBExp.py:227][0m Rewards obtained: [192.31979952057878], Lows: [20], Highs: [34], Total time: 4163.326508
[32m[0906 14-51-32 @MBExp.py:144][0m ####################################################################
[32m[0906 14-51-32 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-51-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18504, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-51-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18315, current rewards: -25.01804, mean: -0.41697
[32m[0906 14-51-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18200, current rewards: -19.29351, mean: -0.17540
[32m[0906 14-52-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18189, current rewards: -13.56976, mean: -0.08481
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18288, current rewards: -8.83154, mean: -0.04205
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18335, current rewards: -4.40481, mean: -0.01694
[32m[0906 14-52-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18354, current rewards: 0.67803, mean: 0.00219
[32m[0906 14-52-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18316, current rewards: 5.75731, mean: 0.01599
[32m[0906 14-52-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18292, current rewards: 10.83832, mean: 0.02643
[32m[0906 14-52-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18323, current rewards: 11.71341, mean: 0.02546
[32m[0906 14-53-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18352, current rewards: 0.00593, mean: 0.00001
[32m[0906 14-53-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18372, current rewards: 5.47987, mean: 0.00979
[32m[0906 14-53-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18388, current rewards: 10.87304, mean: 0.01782
[32m[0906 14-53-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18401, current rewards: 16.45411, mean: 0.02493
[32m[0906 14-53-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18418, current rewards: 22.04429, mean: 0.03105
[32m[0906 14-53-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18422, current rewards: 27.63338, mean: 0.03636
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18432, current rewards: 33.21714, mean: 0.04101
[32m[0906 14-54-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18442, current rewards: 38.80435, mean: 0.04512
[32m[0906 14-54-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18443, current rewards: 44.39100, mean: 0.04878
[32m[0906 14-54-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: 49.97549, mean: 0.05206
[32m[0906 14-54-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18460, current rewards: 57.80334, mean: 0.05723
[32m[0906 14-54-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18463, current rewards: 56.26689, mean: 0.05308
[32m[0906 14-54-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18471, current rewards: 66.77608, mean: 0.06016
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18475, current rewards: 77.29499, mean: 0.06663
[32m[0906 14-55-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18476, current rewards: 87.81548, mean: 0.07257
[32m[0906 14-55-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18480, current rewards: 98.32538, mean: 0.07804
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18480, current rewards: 108.84129, mean: 0.08308
[32m[0906 14-55-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18482, current rewards: 119.35932, mean: 0.08776
[32m[0906 14-55-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18484, current rewards: 106.21207, mean: 0.07533
[32m[0906 14-56-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18485, current rewards: 112.04382, mean: 0.07674
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18483, current rewards: 117.98965, mean: 0.07814
[32m[0906 14-56-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18484, current rewards: 123.93442, mean: 0.07945
[32m[0906 14-56-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18486, current rewards: 129.88002, mean: 0.08067
[32m[0906 14-56-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18485, current rewards: 135.82591, mean: 0.08182
[32m[0906 14-56-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18483, current rewards: 141.77128, mean: 0.08291
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18484, current rewards: 147.71633, mean: 0.08393
[32m[0906 14-57-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18488, current rewards: 142.47280, mean: 0.07871
[32m[0906 14-57-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18491, current rewards: 112.65195, mean: 0.06057
[32m[0906 14-57-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18491, current rewards: 63.93428, mean: 0.03347
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18482, current rewards: 21.63869, mean: 0.01104
[32m[0906 14-57-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18471, current rewards: -24.98356, mean: -0.01243
[32m[0906 14-57-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18462, current rewards: -66.69062, mean: -0.03237
[32m[0906 14-58-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18465, current rewards: -65.81675, mean: -0.03119
[32m[0906 14-58-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18466, current rewards: -60.78197, mean: -0.02814
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18464, current rewards: -55.74863, mean: -0.02523
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18455, current rewards: -49.26930, mean: -0.02180
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18446, current rewards: -43.93995, mean: -0.01902
[32m[0906 14-58-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18445, current rewards: -38.61891, mean: -0.01636
[32m[0906 14-58-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18448, current rewards: -33.29213, mean: -0.01381
[32m[0906 14-59-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18453, current rewards: -27.97009, mean: -0.01137
[32m[0906 14-59-14 @Agent.py:117][0m Average action selection time: 0.1846
[32m[0906 14-59-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-59-14 @MBExp.py:227][0m Rewards obtained: [-23.70949867641123], Lows: [147], Highs: [35], Total time: 4625.395619
[32m[0906 14-59-38 @MBExp.py:144][0m ####################################################################
[32m[0906 14-59-38 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-59-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18544, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-59-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18206, current rewards: -4.16636, mean: -0.06944
[32m[0906 14-59-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18155, current rewards: 1.05372, mean: 0.00958
[32m[0906 15-00-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18151, current rewards: 6.21890, mean: 0.03887
[32m[0906 15-00-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18246, current rewards: 10.98300, mean: 0.05230
[32m[0906 15-00-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18295, current rewards: 16.13396, mean: 0.06205
[32m[0906 15-00-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18295, current rewards: 21.27841, mean: 0.06864
[32m[0906 15-00-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18268, current rewards: 5.42874, mean: 0.01508
[32m[0906 15-00-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18237, current rewards: 10.68742, mean: 0.02607
[32m[0906 15-01-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18265, current rewards: 15.94672, mean: 0.03467
[32m[0906 15-01-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18296, current rewards: 21.20680, mean: 0.04158
[32m[0906 15-01-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18324, current rewards: 26.46685, mean: 0.04726
[32m[0906 15-01-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18344, current rewards: 31.53840, mean: 0.05170
[32m[0906 15-01-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18361, current rewards: 36.64477, mean: 0.05552
[32m[0906 15-01-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18372, current rewards: 41.74888, mean: 0.05880
[32m[0906 15-01-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18383, current rewards: 46.85647, mean: 0.06165
[32m[0906 15-02-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18394, current rewards: 51.95967, mean: 0.06415
[32m[0906 15-02-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18404, current rewards: 47.41518, mean: 0.05513
[32m[0906 15-02-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18411, current rewards: 52.11584, mean: 0.05727
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18416, current rewards: 56.81859, mean: 0.05919
[32m[0906 15-02-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18419, current rewards: 62.43527, mean: 0.06182
[32m[0906 15-02-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18429, current rewards: 67.13521, mean: 0.06334
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18439, current rewards: 71.83292, mean: 0.06471
[32m[0906 15-03-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18443, current rewards: 76.53528, mean: 0.06598
[32m[0906 15-03-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18452, current rewards: 81.23473, mean: 0.06714
[32m[0906 15-03-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18459, current rewards: 67.63806, mean: 0.05368
[32m[0906 15-03-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18463, current rewards: 75.09825, mean: 0.05733
[32m[0906 15-03-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18470, current rewards: 82.55845, mean: 0.06070
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18469, current rewards: 61.19388, mean: 0.04340
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18472, current rewards: 11.19388, mean: 0.00767
[32m[0906 15-04-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18471, current rewards: -38.80612, mean: -0.02570
[32m[0906 15-04-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18472, current rewards: -88.80612, mean: -0.05693
[32m[0906 15-04-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18475, current rewards: -136.28788, mean: -0.08465
[32m[0906 15-04-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18477, current rewards: -129.54690, mean: -0.07804
[32m[0906 15-04-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18478, current rewards: -125.22528, mean: -0.07323
[32m[0906 15-05-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18481, current rewards: -120.89824, mean: -0.06869
[32m[0906 15-05-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18481, current rewards: -116.57281, mean: -0.06440
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18482, current rewards: -111.45207, mean: -0.05992
[32m[0906 15-05-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18485, current rewards: -107.06668, mean: -0.05606
[32m[0906 15-05-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18478, current rewards: -123.55308, mean: -0.06304
[32m[0906 15-05-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18467, current rewards: -118.62962, mean: -0.05902
[32m[0906 15-05-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18456, current rewards: -113.70513, mean: -0.05520
[32m[0906 15-06-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18461, current rewards: -108.78304, mean: -0.05156
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18462, current rewards: -103.85674, mean: -0.04808
[32m[0906 15-06-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18458, current rewards: -98.93063, mean: -0.04476
[32m[0906 15-06-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18449, current rewards: -104.59148, mean: -0.04628
[32m[0906 15-06-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18441, current rewards: -99.88587, mean: -0.04324
[32m[0906 15-06-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18441, current rewards: -95.17620, mean: -0.04033
[32m[0906 15-07-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18446, current rewards: -90.47252, mean: -0.03754
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18447, current rewards: -85.76941, mean: -0.03487
[32m[0906 15-07-20 @Agent.py:117][0m Average action selection time: 0.1845
[32m[0906 15-07-20 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-07-20 @MBExp.py:227][0m Rewards obtained: [-82.00578162624713], Lows: [30], Highs: [252], Total time: 5087.330421
[32m[0906 15-07-45 @MBExp.py:144][0m ####################################################################
[32m[0906 15-07-45 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 15-07-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18482, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-07-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18113, current rewards: -5.44489, mean: -0.09075
[32m[0906 15-08-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18084, current rewards: 0.34025, mean: 0.00309
[32m[0906 15-08-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18127, current rewards: 8.56643, mean: 0.05354
[32m[0906 15-08-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18228, current rewards: 14.16444, mean: 0.06745
[32m[0906 15-08-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18296, current rewards: 19.81653, mean: 0.07622
[32m[0906 15-08-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18275, current rewards: 25.46905, mean: 0.08216
[32m[0906 15-08-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18252, current rewards: 31.12267, mean: 0.08645
[32m[0906 15-09-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18226, current rewards: 36.77742, mean: 0.08970
[32m[0906 15-09-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18269, current rewards: 42.43127, mean: 0.09224
[32m[0906 15-09-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18297, current rewards: 48.08592, mean: 0.09429
[32m[0906 15-09-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18319, current rewards: 53.59530, mean: 0.09571
[32m[0906 15-09-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18341, current rewards: 59.52675, mean: 0.09758
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18357, current rewards: 52.85287, mean: 0.08008
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18376, current rewards: 57.34586, mean: 0.08077
[32m[0906 15-10-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18391, current rewards: 61.83724, mean: 0.08136
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18399, current rewards: 66.32953, mean: 0.08189
[32m[0906 15-10-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18407, current rewards: 70.81562, mean: 0.08234
[32m[0906 15-10-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18411, current rewards: 75.31278, mean: 0.08276
[32m[0906 15-10-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18415, current rewards: 69.73424, mean: 0.07264
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18424, current rewards: 79.56240, mean: 0.07877
[32m[0906 15-11-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18432, current rewards: 86.86817, mean: 0.08195
[32m[0906 15-11-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18439, current rewards: 94.18029, mean: 0.08485
[32m[0906 15-11-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18445, current rewards: 100.39672, mean: 0.08655
[32m[0906 15-11-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18449, current rewards: 105.62595, mean: 0.08729
[32m[0906 15-11-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18452, current rewards: 110.83834, mean: 0.08797
[32m[0906 15-11-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18462, current rewards: 116.05491, mean: 0.08859
[32m[0906 15-11-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18462, current rewards: 112.85698, mean: 0.08298
[32m[0906 15-12-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18467, current rewards: 104.97107, mean: 0.07445
[32m[0906 15-12-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18467, current rewards: 109.79179, mean: 0.07520
[32m[0906 15-12-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18469, current rewards: 114.56147, mean: 0.07587
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18470, current rewards: 119.33171, mean: 0.07649
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18473, current rewards: 124.10189, mean: 0.07708
[32m[0906 15-12-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18474, current rewards: 128.87566, mean: 0.07764
[32m[0906 15-13-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18474, current rewards: 133.64659, mean: 0.07816
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18474, current rewards: 138.41373, mean: 0.07864
[32m[0906 15-13-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18474, current rewards: 143.44803, mean: 0.07925
[32m[0906 15-13-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18474, current rewards: 149.44628, mean: 0.08035
[32m[0906 15-13-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18475, current rewards: 154.18408, mean: 0.08072
[32m[0906 15-13-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18467, current rewards: 158.92541, mean: 0.08108
[32m[0906 15-13-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18459, current rewards: 142.73840, mean: 0.07101
[32m[0906 15-14-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18448, current rewards: 148.38840, mean: 0.07203
[32m[0906 15-14-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18447, current rewards: 154.07590, mean: 0.07302
[32m[0906 15-14-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18447, current rewards: 159.76164, mean: 0.07396
[32m[0906 15-14-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18438, current rewards: 165.45018, mean: 0.07486
[32m[0906 15-14-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18429, current rewards: 172.02374, mean: 0.07612
[32m[0906 15-14-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18419, current rewards: 177.92199, mean: 0.07702
[32m[0906 15-15-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18420, current rewards: 183.82127, mean: 0.07789
[32m[0906 15-15-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18423, current rewards: 189.71945, mean: 0.07872
[32m[0906 15-15-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18424, current rewards: 195.62009, mean: 0.07952
[32m[0906 15-15-27 @Agent.py:117][0m Average action selection time: 0.1843
[32m[0906 15-15-27 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-15-27 @MBExp.py:227][0m Rewards obtained: [200.34161363975986], Lows: [20], Highs: [32], Total time: 5548.641584999999
[32m[0906 15-15-54 @MBExp.py:144][0m ####################################################################
[32m[0906 15-15-54 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 15-15-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18179, current rewards: 0.63468, mean: 0.06347
[32m[0906 15-16-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18082, current rewards: 9.63404, mean: 0.16057
[32m[0906 15-16-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18079, current rewards: 17.28912, mean: 0.15717
[32m[0906 15-16-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18092, current rewards: 24.49951, mean: 0.15312
[32m[0906 15-16-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18227, current rewards: 27.74613, mean: 0.13212
[32m[0906 15-16-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18289, current rewards: 30.94846, mean: 0.11903
[32m[0906 15-16-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18243, current rewards: 34.15078, mean: 0.11016
[32m[0906 15-17-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18221, current rewards: 37.35311, mean: 0.10376
[32m[0906 15-17-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18197, current rewards: 40.55544, mean: 0.09892
[32m[0906 15-17-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18239, current rewards: 43.75777, mean: 0.09513
[32m[0906 15-17-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18276, current rewards: 46.96009, mean: 0.09208
[32m[0906 15-17-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18307, current rewards: 36.32982, mean: 0.06487
[32m[0906 15-17-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18328, current rewards: -13.67018, mean: -0.02241
[32m[0906 15-17-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18346, current rewards: -63.67018, mean: -0.09647
[32m[0906 15-18-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18371, current rewards: -113.67018, mean: -0.16010
[32m[0906 15-18-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18383, current rewards: -163.67018, mean: -0.21536
[32m[0906 15-18-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18397, current rewards: -213.67018, mean: -0.26379
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18405, current rewards: -263.67018, mean: -0.30659
[32m[0906 15-18-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18406, current rewards: -313.67018, mean: -0.34469
[32m[0906 15-18-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18415, current rewards: -363.67018, mean: -0.37882
[32m[0906 15-19-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18420, current rewards: -413.67018, mean: -0.40957
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18428, current rewards: -463.67018, mean: -0.43742
[32m[0906 15-19-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18433, current rewards: -513.67018, mean: -0.46277
[32m[0906 15-19-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18440, current rewards: -563.67018, mean: -0.48592
[32m[0906 15-19-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18447, current rewards: -613.67018, mean: -0.50717
[32m[0906 15-19-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18451, current rewards: -663.67018, mean: -0.52672
[32m[0906 15-19-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18450, current rewards: -713.67018, mean: -0.54479
[32m[0906 15-20-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18455, current rewards: -763.67018, mean: -0.56152
[32m[0906 15-20-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18461, current rewards: -813.67018, mean: -0.57707
[32m[0906 15-20-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18463, current rewards: -863.67018, mean: -0.59155
[32m[0906 15-20-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18464, current rewards: -913.67018, mean: -0.60508
[32m[0906 15-20-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18465, current rewards: -963.67018, mean: -0.61774
[32m[0906 15-20-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18467, current rewards: -1013.67018, mean: -0.62961
[32m[0906 15-21-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18468, current rewards: -1063.67018, mean: -0.64077
[32m[0906 15-21-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18468, current rewards: -1113.67018, mean: -0.65127
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18469, current rewards: -1163.67018, mean: -0.66118
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18471, current rewards: -1213.67018, mean: -0.67054
[32m[0906 15-21-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18473, current rewards: -1263.67018, mean: -0.67939
[32m[0906 15-21-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18472, current rewards: -1313.67018, mean: -0.68779
[32m[0906 15-21-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18464, current rewards: -1363.67018, mean: -0.69575
[32m[0906 15-22-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18453, current rewards: -1413.67018, mean: -0.70332
[32m[0906 15-22-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18446, current rewards: -1463.67018, mean: -0.71052
[32m[0906 15-22-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18443, current rewards: -1513.67018, mean: -0.71738
[32m[0906 15-22-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18445, current rewards: -1563.67018, mean: -0.72392
[32m[0906 15-22-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18435, current rewards: -1613.67018, mean: -0.73017
[32m[0906 15-22-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18426, current rewards: -1663.67018, mean: -0.73614
[32m[0906 15-23-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18417, current rewards: -1713.67018, mean: -0.74185
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18421, current rewards: -1763.67018, mean: -0.74732
[32m[0906 15-23-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18425, current rewards: -1813.67018, mean: -0.75256
[32m[0906 15-23-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18428, current rewards: -1863.67018, mean: -0.75759
[32m[0906 15-23-36 @Agent.py:117][0m Average action selection time: 0.1843
[32m[0906 15-23-36 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-23-36 @MBExp.py:227][0m Rewards obtained: [-1903.670184094433], Lows: [0], Highs: [1953], Total time: 6010.029763999999
[32m[0906 15-24-05 @MBExp.py:144][0m ####################################################################
[32m[0906 15-24-05 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 15-24-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18025, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18116, current rewards: 0.80347, mean: 0.01339
[32m[0906 15-24-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18134, current rewards: 9.88805, mean: 0.08989
[32m[0906 15-24-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18143, current rewards: 18.42891, mean: 0.11518
[32m[0906 15-24-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18253, current rewards: 26.15776, mean: 0.12456
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18278, current rewards: 34.08992, mean: 0.13112
[32m[0906 15-25-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18237, current rewards: 42.02533, mean: 0.13557
[32m[0906 15-25-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18213, current rewards: 49.97108, mean: 0.13881
[32m[0906 15-25-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18192, current rewards: 57.90746, mean: 0.14124
[32m[0906 15-25-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18240, current rewards: 65.84624, mean: 0.14314
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18272, current rewards: 73.79190, mean: 0.14469
[32m[0906 15-25-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18296, current rewards: 68.53069, mean: 0.12238
[32m[0906 15-25-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18316, current rewards: 78.65320, mean: 0.12894
[32m[0906 15-26-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18338, current rewards: 91.68132, mean: 0.13891
[32m[0906 15-26-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18349, current rewards: 104.65703, mean: 0.14740
[32m[0906 15-26-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18363, current rewards: 117.65531, mean: 0.15481
[32m[0906 15-26-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18374, current rewards: 130.68170, mean: 0.16134
[32m[0906 15-26-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18380, current rewards: 143.71518, mean: 0.16711
[32m[0906 15-26-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18385, current rewards: 156.73243, mean: 0.17223
[32m[0906 15-27-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18393, current rewards: 169.76211, mean: 0.17684
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18398, current rewards: 162.31808, mean: 0.16071
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18405, current rewards: 165.47434, mean: 0.15611
[32m[0906 15-27-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18408, current rewards: 172.25013, mean: 0.15518
[32m[0906 15-27-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18411, current rewards: 179.02643, mean: 0.15433
[32m[0906 15-27-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18414, current rewards: 185.80666, mean: 0.15356
[32m[0906 15-27-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18419, current rewards: 192.58441, mean: 0.15284
[32m[0906 15-28-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18423, current rewards: 199.36431, mean: 0.15219
[32m[0906 15-28-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18427, current rewards: 206.14526, mean: 0.15158
[32m[0906 15-28-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18430, current rewards: 212.92777, mean: 0.15101
[32m[0906 15-28-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18436, current rewards: 219.69625, mean: 0.15048
[32m[0906 15-28-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18438, current rewards: 226.46451, mean: 0.14998
[32m[0906 15-28-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18440, current rewards: 233.23476, mean: 0.14951
[32m[0906 15-29-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18442, current rewards: 218.60796, mean: 0.13578
[32m[0906 15-29-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18443, current rewards: 225.79991, mean: 0.13602
[32m[0906 15-29-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18444, current rewards: 232.97719, mean: 0.13624
[32m[0906 15-29-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18445, current rewards: 240.15408, mean: 0.13645
[32m[0906 15-29-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18446, current rewards: 247.12228, mean: 0.13653
[32m[0906 15-29-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18446, current rewards: 254.24069, mean: 0.13669
[32m[0906 15-29-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18446, current rewards: 261.36176, mean: 0.13684
[32m[0906 15-30-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18438, current rewards: 268.48524, mean: 0.13698
[32m[0906 15-30-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18427, current rewards: 275.61513, mean: 0.13712
[32m[0906 15-30-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18416, current rewards: 282.73500, mean: 0.13725
[32m[0906 15-30-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18414, current rewards: 289.86267, mean: 0.13738
[32m[0906 15-30-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18413, current rewards: 296.97081, mean: 0.13749
[32m[0906 15-30-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18404, current rewards: 303.72223, mean: 0.13743
[32m[0906 15-31-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18396, current rewards: 310.74840, mean: 0.13750
[32m[0906 15-31-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18389, current rewards: 317.76312, mean: 0.13756
[32m[0906 15-31-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18393, current rewards: 303.90935, mean: 0.12878
[32m[0906 15-31-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18396, current rewards: 311.33992, mean: 0.12919
[32m[0906 15-31-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18400, current rewards: 318.76540, mean: 0.12958
[32m[0906 15-31-46 @Agent.py:117][0m Average action selection time: 0.1840
[32m[0906 15-31-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-31-46 @MBExp.py:227][0m Rewards obtained: [324.7082922239912], Lows: [34], Highs: [20], Total time: 6470.735427999999
[32m[0906 15-32-18 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-18 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 15-32-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17995, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-32-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18018, current rewards: -25.65168, mean: -0.42753
[32m[0906 15-32-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18031, current rewards: -62.82649, mean: -0.57115
[32m[0906 15-32-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18077, current rewards: -42.94129, mean: -0.26838
[32m[0906 15-32-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18207, current rewards: -50.88744, mean: -0.24232
[32m[0906 15-33-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18217, current rewards: -38.92916, mean: -0.14973
[32m[0906 15-33-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18192, current rewards: -40.95789, mean: -0.13212
[32m[0906 15-33-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18169, current rewards: -46.04199, mean: -0.12789
[32m[0906 15-33-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18163, current rewards: -41.09812, mean: -0.10024
[32m[0906 15-33-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18214, current rewards: -35.99211, mean: -0.07824
[32m[0906 15-33-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18252, current rewards: -30.89088, mean: -0.06057
[32m[0906 15-34-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18282, current rewards: -26.51185, mean: -0.04734
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18306, current rewards: -21.74093, mean: -0.03564
[32m[0906 15-34-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18326, current rewards: -16.96940, mean: -0.02571
[32m[0906 15-34-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18338, current rewards: -12.19995, mean: -0.01718
[32m[0906 15-34-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18352, current rewards: -7.43191, mean: -0.00978
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18370, current rewards: -2.66061, mean: -0.00328
[32m[0906 15-34-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18383, current rewards: 2.10732, mean: 0.00245
[32m[0906 15-35-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18392, current rewards: -4.07555, mean: -0.00448
[32m[0906 15-35-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18403, current rewards: 0.46424, mean: 0.00048
[32m[0906 15-35-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18408, current rewards: 4.51457, mean: 0.00447
[32m[0906 15-35-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18410, current rewards: 8.56140, mean: 0.00808
[32m[0906 15-35-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18412, current rewards: 12.61209, mean: 0.01136
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18414, current rewards: 16.66169, mean: 0.01436
[32m[0906 15-36-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18413, current rewards: 20.71025, mean: 0.01712
[32m[0906 15-36-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18415, current rewards: 24.75665, mean: 0.01965
[32m[0906 15-36-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18417, current rewards: 28.80415, mean: 0.02199
[32m[0906 15-36-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18422, current rewards: 32.81718, mean: 0.02413
[32m[0906 15-36-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18424, current rewards: 16.30666, mean: 0.01157
[32m[0906 15-36-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18427, current rewards: 22.10189, mean: 0.01514
[32m[0906 15-36-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18432, current rewards: 27.89712, mean: 0.01847
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18434, current rewards: 33.69235, mean: 0.02160
[32m[0906 15-37-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18435, current rewards: 4.89453, mean: 0.00304
[32m[0906 15-37-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18435, current rewards: -45.10547, mean: -0.02717
[32m[0906 15-37-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18435, current rewards: -95.10547, mean: -0.05562
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18437, current rewards: -145.10547, mean: -0.08245
[32m[0906 15-37-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18436, current rewards: -195.10547, mean: -0.10779
[32m[0906 15-38-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18437, current rewards: -245.10547, mean: -0.13178
[32m[0906 15-38-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18439, current rewards: -295.10547, mean: -0.15451
[32m[0906 15-38-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18429, current rewards: -345.10547, mean: -0.17607
[32m[0906 15-38-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18419, current rewards: -395.10547, mean: -0.19657
[32m[0906 15-38-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18410, current rewards: -445.10547, mean: -0.21607
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18403, current rewards: -495.10547, mean: -0.23465
[32m[0906 15-38-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18398, current rewards: -545.10547, mean: -0.25236
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18392, current rewards: -595.10547, mean: -0.26928
[32m[0906 15-39-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18385, current rewards: -645.10547, mean: -0.28544
[32m[0906 15-39-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18378, current rewards: -695.10547, mean: -0.30091
[32m[0906 15-39-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18383, current rewards: -745.10547, mean: -0.31572
[32m[0906 15-39-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18385, current rewards: -795.10547, mean: -0.32992
[32m[0906 15-39-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18387, current rewards: -845.10547, mean: -0.34354
[32m[0906 15-39-58 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 15-39-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-39-58 @MBExp.py:227][0m Rewards obtained: [-885.1054660212462], Lows: [78], Highs: [941], Total time: 6931.110315999999
[32m[0906 15-40-32 @MBExp.py:144][0m ####################################################################
[32m[0906 15-40-32 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 15-40-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18065, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-40-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18006, current rewards: -21.56824, mean: -0.35947
[32m[0906 15-40-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18046, current rewards: -37.52771, mean: -0.34116
[32m[0906 15-41-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18085, current rewards: -32.08284, mean: -0.20052
[32m[0906 15-41-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18222, current rewards: -26.73200, mean: -0.12730
[32m[0906 15-41-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18194, current rewards: -21.38618, mean: -0.08225
[32m[0906 15-41-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18174, current rewards: -16.03861, mean: -0.05174
[32m[0906 15-41-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18157, current rewards: -10.68757, mean: -0.02969
[32m[0906 15-41-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18149, current rewards: -5.34056, mean: -0.01303
[32m[0906 15-41-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18195, current rewards: 0.00698, mean: 0.00002
[32m[0906 15-42-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18241, current rewards: 5.51156, mean: 0.01081
[32m[0906 15-42-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18272, current rewards: 6.78615, mean: 0.01212
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18334, current rewards: -5.19389, mean: -0.00851
[32m[0906 15-42-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18351, current rewards: -0.93715, mean: -0.00142
[32m[0906 15-42-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18367, current rewards: 3.26196, mean: 0.00459
[32m[0906 15-42-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18375, current rewards: 7.57467, mean: 0.00997
[32m[0906 15-43-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18383, current rewards: 11.64109, mean: 0.01437
[32m[0906 15-43-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18403, current rewards: 16.15114, mean: 0.01878
[32m[0906 15-43-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18408, current rewards: 0.94167, mean: 0.00103
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18412, current rewards: 4.64810, mean: 0.00484
[32m[0906 15-43-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18415, current rewards: 10.87545, mean: 0.01077
[32m[0906 15-43-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18415, current rewards: 17.09590, mean: 0.01613
[32m[0906 15-43-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18422, current rewards: 23.31290, mean: 0.02100
[32m[0906 15-44-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18423, current rewards: 29.53407, mean: 0.02546
[32m[0906 15-44-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18427, current rewards: 12.38880, mean: 0.01024
[32m[0906 15-44-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18431, current rewards: 21.45796, mean: 0.01703
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18433, current rewards: 29.57798, mean: 0.02258
[32m[0906 15-44-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18436, current rewards: 34.67138, mean: 0.02549
[32m[0906 15-44-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18440, current rewards: 40.18801, mean: 0.02850
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18441, current rewards: 45.70725, mean: 0.03131
[32m[0906 15-45-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18442, current rewards: 51.22445, mean: 0.03392
[32m[0906 15-45-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18448, current rewards: 56.74309, mean: 0.03637
[32m[0906 15-45-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18446, current rewards: 62.25837, mean: 0.03867
[32m[0906 15-45-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18445, current rewards: 67.77216, mean: 0.04083
[32m[0906 15-45-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18445, current rewards: 73.29083, mean: 0.04286
[32m[0906 15-45-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18446, current rewards: 80.33747, mean: 0.04565
[32m[0906 15-46-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18446, current rewards: 86.92679, mean: 0.04803
[32m[0906 15-46-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18447, current rewards: 93.52219, mean: 0.05028
[32m[0906 15-46-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18447, current rewards: 78.44966, mean: 0.04107
[32m[0906 15-46-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18436, current rewards: 74.30200, mean: 0.03791
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18425, current rewards: 76.29359, mean: 0.03796
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18415, current rewards: 60.95258, mean: 0.02959
[32m[0906 15-47-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18406, current rewards: 47.07632, mean: 0.02231
[32m[0906 15-47-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18397, current rewards: 33.80808, mean: 0.01565
[32m[0906 15-47-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18390, current rewards: 20.28003, mean: 0.00918
[32m[0906 15-47-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18384, current rewards: 7.08390, mean: 0.00313
[32m[0906 15-47-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18376, current rewards: -5.54172, mean: -0.00240
[32m[0906 15-47-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18381, current rewards: -11.37939, mean: -0.00482
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18384, current rewards: -9.46887, mean: -0.00393
[32m[0906 15-48-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18387, current rewards: -22.45015, mean: -0.00913
[32m[0906 15-48-12 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 15-48-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-48-12 @MBExp.py:227][0m Rewards obtained: [-27.690396347522938], Lows: [152], Highs: [40], Total time: 7391.478026999999
[32m[0906 15-48-48 @MBExp.py:144][0m ####################################################################
[32m[0906 15-48-48 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 15-48-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18006, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-48-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18037, current rewards: -4.62475, mean: -0.07708
[32m[0906 15-49-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18067, current rewards: 1.31491, mean: 0.01195
[32m[0906 15-49-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18076, current rewards: 6.41281, mean: 0.04008
[32m[0906 15-49-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18178, current rewards: 11.50377, mean: 0.05478
[32m[0906 15-49-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18168, current rewards: -4.65972, mean: -0.01792
[32m[0906 15-49-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18147, current rewards: 2.99536, mean: 0.00966
[32m[0906 15-49-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18131, current rewards: 10.65044, mean: 0.02958
[32m[0906 15-50-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18140, current rewards: 18.30552, mean: 0.04465
[32m[0906 15-50-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18188, current rewards: -15.55105, mean: -0.03381
[32m[0906 15-50-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18229, current rewards: -65.55105, mean: -0.12853
[32m[0906 15-50-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18258, current rewards: -115.55105, mean: -0.20634
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18279, current rewards: -165.55105, mean: -0.27140
[32m[0906 15-50-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18298, current rewards: -215.55105, mean: -0.32659
[32m[0906 15-50-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18318, current rewards: -265.55105, mean: -0.37402
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18335, current rewards: -315.55105, mean: -0.41520
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18345, current rewards: -365.55105, mean: -0.45130
[32m[0906 15-51-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18356, current rewards: -415.55105, mean: -0.48320
[32m[0906 15-51-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18370, current rewards: -465.55105, mean: -0.51159
[32m[0906 15-51-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18378, current rewards: -515.55105, mean: -0.53703
[32m[0906 15-51-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18383, current rewards: -565.55105, mean: -0.55995
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18388, current rewards: -615.55105, mean: -0.58071
[32m[0906 15-52-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18393, current rewards: -665.55105, mean: -0.59960
[32m[0906 15-52-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18400, current rewards: -715.55105, mean: -0.61685
[32m[0906 15-52-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18400, current rewards: -765.55105, mean: -0.63269
[32m[0906 15-52-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18403, current rewards: -815.55105, mean: -0.64726
[32m[0906 15-52-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18407, current rewards: -865.55105, mean: -0.66073
[32m[0906 15-52-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18411, current rewards: -915.55105, mean: -0.67320
[32m[0906 15-53-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18416, current rewards: -965.55105, mean: -0.68479
[32m[0906 15-53-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18418, current rewards: -1015.55105, mean: -0.69558
[32m[0906 15-53-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18418, current rewards: -1065.55105, mean: -0.70566
[32m[0906 15-53-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18422, current rewards: -1115.55105, mean: -0.71510
[32m[0906 15-53-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18424, current rewards: -1165.55105, mean: -0.72394
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18427, current rewards: -1215.55105, mean: -0.73226
[32m[0906 15-54-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18429, current rewards: -1265.55105, mean: -0.74009
[32m[0906 15-54-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18431, current rewards: -1315.55105, mean: -0.74747
[32m[0906 15-54-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18434, current rewards: -1365.55105, mean: -0.75445
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18436, current rewards: -1415.55105, mean: -0.76105
[32m[0906 15-54-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18436, current rewards: -1465.55105, mean: -0.76730
[32m[0906 15-54-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18424, current rewards: -1515.55105, mean: -0.77324
[32m[0906 15-54-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18415, current rewards: -1565.55105, mean: -0.77888
[32m[0906 15-55-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18406, current rewards: -1615.55105, mean: -0.78425
[32m[0906 15-55-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18392, current rewards: -1665.55105, mean: -0.78936
[32m[0906 15-55-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18382, current rewards: -1715.55105, mean: -0.79424
[32m[0906 15-55-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18373, current rewards: -1765.55105, mean: -0.79889
[32m[0906 15-55-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18367, current rewards: -1815.55105, mean: -0.80334
[32m[0906 15-55-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18362, current rewards: -1853.62900, mean: -0.80244
[32m[0906 15-56-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18367, current rewards: -1849.10490, mean: -0.78352
[32m[0906 15-56-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18373, current rewards: -1841.93897, mean: -0.76429
[32m[0906 15-56-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18376, current rewards: -1836.88363, mean: -0.74670
[32m[0906 15-56-28 @Agent.py:117][0m Average action selection time: 0.1838
[32m[0906 15-56-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-56-28 @MBExp.py:227][0m Rewards obtained: [-1833.1746587160205], Lows: [11], Highs: [1886], Total time: 7851.588569
[32m[0906 15-57-06 @MBExp.py:144][0m ####################################################################
[32m[0906 15-57-06 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-57-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18157, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-57-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18052, current rewards: -4.90964, mean: -0.08183
[32m[0906 15-57-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18076, current rewards: -0.11115, mean: -0.00101
[32m[0906 15-57-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18082, current rewards: 4.69108, mean: 0.02932
[32m[0906 15-57-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18128, current rewards: 9.49299, mean: 0.04520
[32m[0906 15-57-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18130, current rewards: 17.53907, mean: 0.06746
[32m[0906 15-58-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18130, current rewards: 22.23863, mean: 0.07174
[32m[0906 15-58-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18115, current rewards: 26.93415, mean: 0.07482
[32m[0906 15-58-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18126, current rewards: 31.63241, mean: 0.07715
[32m[0906 15-58-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18176, current rewards: 36.16973, mean: 0.07863
[32m[0906 15-58-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18216, current rewards: 40.85762, mean: 0.08011
[32m[0906 15-58-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18248, current rewards: 45.53975, mean: 0.08132
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18271, current rewards: 35.56850, mean: 0.05831
[32m[0906 15-59-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18298, current rewards: 35.58063, mean: 0.05391
[32m[0906 15-59-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18315, current rewards: 40.83961, mean: 0.05752
[32m[0906 15-59-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18338, current rewards: 46.09852, mean: 0.06066
[32m[0906 15-59-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18356, current rewards: 51.35737, mean: 0.06340
[32m[0906 15-59-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18369, current rewards: 45.39868, mean: 0.05279
[32m[0906 15-59-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18378, current rewards: 52.46817, mean: 0.05766
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18393, current rewards: 59.54376, mean: 0.06202
[32m[0906 16-00-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18398, current rewards: 66.61903, mean: 0.06596
[32m[0906 16-00-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18403, current rewards: 73.69629, mean: 0.06952
[32m[0906 16-00-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18407, current rewards: 80.77174, mean: 0.07277
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18415, current rewards: 87.84718, mean: 0.07573
[32m[0906 16-00-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18420, current rewards: 94.92458, mean: 0.07845
[32m[0906 16-00-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18423, current rewards: 101.27151, mean: 0.08037
[32m[0906 16-01-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18426, current rewards: 109.02816, mean: 0.08323
[32m[0906 16-01-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18429, current rewards: 116.80328, mean: 0.08588
[32m[0906 16-01-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18431, current rewards: 124.57515, mean: 0.08835
[32m[0906 16-01-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18435, current rewards: 124.22092, mean: 0.08508
[32m[0906 16-01-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18438, current rewards: 113.65805, mean: 0.07527
[32m[0906 16-01-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18439, current rewards: 107.66457, mean: 0.06902
[32m[0906 16-02-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18446, current rewards: 104.17185, mean: 0.06470
[32m[0906 16-02-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18450, current rewards: 99.27497, mean: 0.05980
[32m[0906 16-02-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18450, current rewards: 90.98156, mean: 0.05321
[32m[0906 16-02-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18453, current rewards: 84.85179, mean: 0.04821
[32m[0906 16-02-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18454, current rewards: 82.36207, mean: 0.04550
[32m[0906 16-02-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18456, current rewards: 81.24824, mean: 0.04368
[32m[0906 16-02-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18457, current rewards: 82.38168, mean: 0.04313
[32m[0906 16-03-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18446, current rewards: 81.49827, mean: 0.04158
[32m[0906 16-03-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18434, current rewards: 83.42692, mean: 0.04151
[32m[0906 16-03-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18423, current rewards: 60.73193, mean: 0.02948
[32m[0906 16-03-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18404, current rewards: 74.58279, mean: 0.03535
[32m[0906 16-03-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18393, current rewards: 81.53255, mean: 0.03775
[32m[0906 16-03-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18386, current rewards: 87.08795, mean: 0.03941
[32m[0906 16-04-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18378, current rewards: 92.63808, mean: 0.04099
[32m[0906 16-04-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18375, current rewards: 98.18925, mean: 0.04251
[32m[0906 16-04-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18380, current rewards: 103.73982, mean: 0.04396
[32m[0906 16-04-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18382, current rewards: 109.29055, mean: 0.04535
[32m[0906 16-04-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18385, current rewards: 114.76587, mean: 0.04665
[32m[0906 16-04-46 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 16-04-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-04-46 @MBExp.py:227][0m Rewards obtained: [118.98962194062572], Lows: [122], Highs: [20], Total time: 8311.939914999999
[32m[0906 16-05-26 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-26 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 16-05-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18028, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-05-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18050, current rewards: -6.57450, mean: -0.10957
[32m[0906 16-05-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18048, current rewards: -2.04175, mean: -0.01856
[32m[0906 16-05-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18066, current rewards: 2.49191, mean: 0.01557
[32m[0906 16-06-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18071, current rewards: 7.02676, mean: 0.03346
[32m[0906 16-06-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18094, current rewards: 11.56142, mean: 0.04447
[32m[0906 16-06-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18098, current rewards: 16.09411, mean: 0.05192
[32m[0906 16-06-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18093, current rewards: 20.62978, mean: 0.05730
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18117, current rewards: 25.00829, mean: 0.06100
[32m[0906 16-06-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18177, current rewards: 29.47619, mean: 0.06408
[32m[0906 16-06-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18217, current rewards: 23.49550, mean: 0.04607
[32m[0906 16-07-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18239, current rewards: 17.58395, mean: 0.03140
[32m[0906 16-07-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18258, current rewards: 22.22050, mean: 0.03643
[32m[0906 16-07-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18276, current rewards: 26.85470, mean: 0.04069
[32m[0906 16-07-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18296, current rewards: 31.48774, mean: 0.04435
[32m[0906 16-07-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18313, current rewards: 36.12243, mean: 0.04753
[32m[0906 16-07-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18329, current rewards: 29.61495, mean: 0.03656
[32m[0906 16-08-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18343, current rewards: 34.81627, mean: 0.04048
[32m[0906 16-08-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18353, current rewards: 39.37499, mean: 0.04327
[32m[0906 16-08-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18367, current rewards: 43.92959, mean: 0.04576
[32m[0906 16-08-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18371, current rewards: 48.48530, mean: 0.04801
[32m[0906 16-08-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18380, current rewards: 53.04439, mean: 0.05004
[32m[0906 16-08-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18388, current rewards: 57.59995, mean: 0.05189
[32m[0906 16-09-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18389, current rewards: 62.15366, mean: 0.05358
[32m[0906 16-09-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18393, current rewards: 66.40019, mean: 0.05488
[32m[0906 16-09-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18400, current rewards: 70.13369, mean: 0.05566
[32m[0906 16-09-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18401, current rewards: 74.08706, mean: 0.05656
[32m[0906 16-09-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18404, current rewards: 78.04010, mean: 0.05738
[32m[0906 16-09-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18405, current rewards: 81.99293, mean: 0.05815
[32m[0906 16-09-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18411, current rewards: 85.94417, mean: 0.05887
[32m[0906 16-10-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18415, current rewards: 89.89696, mean: 0.05953
[32m[0906 16-10-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18420, current rewards: 93.84644, mean: 0.06016
[32m[0906 16-10-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18423, current rewards: 98.63739, mean: 0.06127
[32m[0906 16-10-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18428, current rewards: 90.65444, mean: 0.05461
[32m[0906 16-10-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18431, current rewards: 86.03792, mean: 0.05031
[32m[0906 16-10-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18432, current rewards: 91.83315, mean: 0.05218
[32m[0906 16-11-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18433, current rewards: 97.62837, mean: 0.05394
[32m[0906 16-11-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18435, current rewards: 103.42360, mean: 0.05560
[32m[0906 16-11-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18433, current rewards: 109.21883, mean: 0.05718
[32m[0906 16-11-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18423, current rewards: 115.01406, mean: 0.05868
[32m[0906 16-11-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18411, current rewards: 120.52081, mean: 0.05996
[32m[0906 16-11-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18400, current rewards: 76.88427, mean: 0.03732
[32m[0906 16-11-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18378, current rewards: 26.88427, mean: 0.01274
[32m[0906 16-12-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18363, current rewards: -23.11573, mean: -0.01070
[32m[0906 16-12-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18356, current rewards: -73.11573, mean: -0.03308
[32m[0906 16-12-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18349, current rewards: -123.11573, mean: -0.05448
[32m[0906 16-12-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18346, current rewards: -173.11573, mean: -0.07494
[32m[0906 16-12-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18354, current rewards: -223.11573, mean: -0.09454
[32m[0906 16-12-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18359, current rewards: -273.11573, mean: -0.11333
[32m[0906 16-12-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18364, current rewards: -323.11573, mean: -0.13135
[32m[0906 16-13-06 @Agent.py:117][0m Average action selection time: 0.1837
[32m[0906 16-13-06 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-13-06 @MBExp.py:227][0m Rewards obtained: [-363.115733591883], Lows: [21], Highs: [505], Total time: 8771.804751999998
[32m[0906 16-13-48 @MBExp.py:144][0m ####################################################################
[32m[0906 16-13-48 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 16-13-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18004, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-13-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18000, current rewards: -4.91931, mean: -0.08199
[32m[0906 16-14-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18031, current rewards: 0.24733, mean: 0.00225
[32m[0906 16-14-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18014, current rewards: 5.42228, mean: 0.03389
[32m[0906 16-14-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18014, current rewards: 10.59245, mean: 0.05044
[32m[0906 16-14-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18022, current rewards: 15.76324, mean: 0.06063
[32m[0906 16-14-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18042, current rewards: 20.93467, mean: 0.06753
[32m[0906 16-14-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18041, current rewards: 15.55602, mean: 0.04321
[32m[0906 16-15-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18078, current rewards: 20.51222, mean: 0.05003
[32m[0906 16-15-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18130, current rewards: 25.45615, mean: 0.05534
[32m[0906 16-15-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18174, current rewards: 30.39931, mean: 0.05961
[32m[0906 16-15-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18200, current rewards: 35.34095, mean: 0.06311
[32m[0906 16-15-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18228, current rewards: 40.28057, mean: 0.06603
[32m[0906 16-15-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18250, current rewards: 23.16775, mean: 0.03510
[32m[0906 16-15-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18267, current rewards: 29.27298, mean: 0.04123
[32m[0906 16-16-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18286, current rewards: 36.39447, mean: 0.04789
[32m[0906 16-16-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18303, current rewards: 43.00352, mean: 0.05309
[32m[0906 16-16-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18311, current rewards: 49.61175, mean: 0.05769
[32m[0906 16-16-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18316, current rewards: 56.21999, mean: 0.06178
[32m[0906 16-16-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18335, current rewards: 62.82822, mean: 0.06545
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18348, current rewards: 20.75337, mean: 0.02055
[32m[0906 16-17-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18357, current rewards: -29.24663, mean: -0.02759
[32m[0906 16-17-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18364, current rewards: -79.24663, mean: -0.07139
[32m[0906 16-17-21 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18372, current rewards: -129.24663, mean: -0.11142
[32m[0906 16-17-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18377, current rewards: -179.24663, mean: -0.14814
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18381, current rewards: -229.24663, mean: -0.18194
[32m[0906 16-17-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18387, current rewards: -279.24663, mean: -0.21317
[32m[0906 16-17-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18389, current rewards: -329.24663, mean: -0.24209
[32m[0906 16-18-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18394, current rewards: -379.24663, mean: -0.26897
[32m[0906 16-18-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18395, current rewards: -429.24663, mean: -0.29400
[32m[0906 16-18-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18400, current rewards: -479.24663, mean: -0.31738
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18403, current rewards: -529.24663, mean: -0.33926
[32m[0906 16-18-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18408, current rewards: -579.24663, mean: -0.35978
[32m[0906 16-18-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18411, current rewards: -629.24663, mean: -0.37906
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18412, current rewards: -679.24663, mean: -0.39722
[32m[0906 16-19-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18413, current rewards: -729.24663, mean: -0.41434
[32m[0906 16-19-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18413, current rewards: -779.24663, mean: -0.43052
[32m[0906 16-19-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18416, current rewards: -829.24663, mean: -0.44583
[32m[0906 16-19-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18414, current rewards: -879.24663, mean: -0.46034
[32m[0906 16-19-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18403, current rewards: -929.24663, mean: -0.47411
[32m[0906 16-19-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18392, current rewards: -979.24663, mean: -0.48719
[32m[0906 16-20-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18381, current rewards: -1029.24663, mean: -0.49963
[32m[0906 16-20-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18358, current rewards: -1079.24663, mean: -0.51149
[32m[0906 16-20-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18342, current rewards: -1129.24663, mean: -0.52280
[32m[0906 16-20-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18335, current rewards: -1179.24663, mean: -0.53360
[32m[0906 16-20-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18327, current rewards: -1229.24663, mean: -0.54391
[32m[0906 16-20-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18326, current rewards: -1279.24663, mean: -0.55379
[32m[0906 16-21-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18335, current rewards: -1329.24663, mean: -0.56324
[32m[0906 16-21-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18339, current rewards: -1379.24663, mean: -0.57230
[32m[0906 16-21-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18344, current rewards: -1429.24663, mean: -0.58099
[32m[0906 16-21-27 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 16-21-27 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-21-27 @MBExp.py:227][0m Rewards obtained: [-1469.2466271998928], Lows: [11], Highs: [1553], Total time: 9231.127006999997
[32m[0906 16-22-11 @MBExp.py:144][0m ####################################################################
[32m[0906 16-22-11 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 16-22-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18069, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-22-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17991, current rewards: -9.65319, mean: -0.16089
[32m[0906 16-22-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18018, current rewards: -6.21551, mean: -0.05650
[32m[0906 16-22-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17935, current rewards: -2.77891, mean: -0.01737
[32m[0906 16-22-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17960, current rewards: 0.66153, mean: 0.00315
[32m[0906 16-22-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17981, current rewards: 4.10163, mean: 0.01578
[32m[0906 16-23-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18005, current rewards: 7.51846, mean: 0.02425
[32m[0906 16-23-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18009, current rewards: 10.95110, mean: 0.03042
[32m[0906 16-23-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18048, current rewards: 14.38417, mean: 0.03508
[32m[0906 16-23-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18103, current rewards: 3.33582, mean: 0.00725
[32m[0906 16-23-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18142, current rewards: 1.52033, mean: 0.00298
[32m[0906 16-23-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18174, current rewards: 5.99155, mean: 0.01070
[32m[0906 16-24-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18203, current rewards: 10.45753, mean: 0.01714
[32m[0906 16-24-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18229, current rewards: 14.92560, mean: 0.02261
[32m[0906 16-24-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18245, current rewards: 19.08496, mean: 0.02688
[32m[0906 16-24-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18257, current rewards: 24.13623, mean: 0.03176
[32m[0906 16-24-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18280, current rewards: 29.26505, mean: 0.03613
[32m[0906 16-24-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18297, current rewards: 34.38745, mean: 0.03999
[32m[0906 16-24-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18310, current rewards: 39.51020, mean: 0.04342
[32m[0906 16-25-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18323, current rewards: 44.64556, mean: 0.04651
[32m[0906 16-25-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18332, current rewards: 49.77304, mean: 0.04928
[32m[0906 16-25-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18339, current rewards: 54.90169, mean: 0.05179
[32m[0906 16-25-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18347, current rewards: 60.03127, mean: 0.05408
[32m[0906 16-25-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18351, current rewards: 65.15988, mean: 0.05617
[32m[0906 16-25-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18355, current rewards: 59.13038, mean: 0.04887
[32m[0906 16-26-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18362, current rewards: 63.75397, mean: 0.05060
[32m[0906 16-26-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18370, current rewards: 68.37298, mean: 0.05219
[32m[0906 16-26-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18375, current rewards: 72.99316, mean: 0.05367
[32m[0906 16-26-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18382, current rewards: 77.61091, mean: 0.05504
[32m[0906 16-26-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18388, current rewards: 82.22820, mean: 0.05632
[32m[0906 16-26-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18391, current rewards: 86.85121, mean: 0.05752
[32m[0906 16-26-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18395, current rewards: 80.55741, mean: 0.05164
[32m[0906 16-27-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18402, current rewards: 84.23482, mean: 0.05232
[32m[0906 16-27-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18408, current rewards: 87.94218, mean: 0.05298
[32m[0906 16-27-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18411, current rewards: 91.64797, mean: 0.05360
[32m[0906 16-27-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18414, current rewards: 95.35511, mean: 0.05418
[32m[0906 16-27-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18416, current rewards: 99.06226, mean: 0.05473
[32m[0906 16-27-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18417, current rewards: 102.76808, mean: 0.05525
[32m[0906 16-28-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18416, current rewards: 94.02558, mean: 0.04923
[32m[0906 16-28-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18406, current rewards: 89.50307, mean: 0.04566
[32m[0906 16-28-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18396, current rewards: 93.46632, mean: 0.04650
[32m[0906 16-28-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18380, current rewards: 97.43021, mean: 0.04730
[32m[0906 16-28-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18360, current rewards: 101.39556, mean: 0.04805
[32m[0906 16-28-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18341, current rewards: 105.36221, mean: 0.04878
[32m[0906 16-28-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18333, current rewards: 109.32720, mean: 0.04947
[32m[0906 16-29-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18327, current rewards: 113.29138, mean: 0.05013
[32m[0906 16-29-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18326, current rewards: 117.91759, mean: 0.05105
[32m[0906 16-29-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18334, current rewards: 122.45147, mean: 0.05189
[32m[0906 16-29-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18340, current rewards: 115.19312, mean: 0.04780
[32m[0906 16-29-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18343, current rewards: 119.59439, mean: 0.04862
[32m[0906 16-29-50 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 16-29-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-29-51 @MBExp.py:227][0m Rewards obtained: [123.08515812700992], Lows: [20], Highs: [44], Total time: 9690.423549999998
[32m[0906 16-30-37 @MBExp.py:144][0m ####################################################################
[32m[0906 16-30-37 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 16-30-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17914, current rewards: -0.49579, mean: -0.04958
[32m[0906 16-30-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17959, current rewards: 4.69488, mean: 0.07825
[32m[0906 16-30-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18008, current rewards: 9.39166, mean: 0.08538
[32m[0906 16-31-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17872, current rewards: 14.08736, mean: 0.08805
[32m[0906 16-31-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17916, current rewards: 18.78462, mean: 0.08945
[32m[0906 16-31-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17957, current rewards: 23.43310, mean: 0.09013
[32m[0906 16-31-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17976, current rewards: 28.12829, mean: 0.09074
[32m[0906 16-31-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17978, current rewards: 20.69606, mean: 0.05749
[32m[0906 16-31-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18035, current rewards: 24.97491, mean: 0.06091
[32m[0906 16-32-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18093, current rewards: 29.25721, mean: 0.06360
[32m[0906 16-32-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18128, current rewards: 33.54007, mean: 0.06576
[32m[0906 16-32-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18173, current rewards: 37.82168, mean: 0.06754
[32m[0906 16-32-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18210, current rewards: 42.10280, mean: 0.06902
[32m[0906 16-32-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18234, current rewards: 45.94678, mean: 0.06962
[32m[0906 16-32-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18252, current rewards: 50.15588, mean: 0.07064
[32m[0906 16-32-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18272, current rewards: 54.33355, mean: 0.07149
[32m[0906 16-33-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18295, current rewards: 58.51562, mean: 0.07224
[32m[0906 16-33-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18312, current rewards: 62.69647, mean: 0.07290
[32m[0906 16-33-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18322, current rewards: 46.08779, mean: 0.05065
[32m[0906 16-33-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18339, current rewards: 50.84223, mean: 0.05296
[32m[0906 16-33-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18347, current rewards: 55.59068, mean: 0.05504
[32m[0906 16-33-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18356, current rewards: 60.37003, mean: 0.05695
[32m[0906 16-34-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18364, current rewards: 67.80827, mean: 0.06109
[32m[0906 16-34-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18372, current rewards: 72.90215, mean: 0.06285
[32m[0906 16-34-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18374, current rewards: 77.99685, mean: 0.06446
[32m[0906 16-34-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18374, current rewards: 83.09027, mean: 0.06594
[32m[0906 16-34-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18377, current rewards: 77.12322, mean: 0.05887
[32m[0906 16-34-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18380, current rewards: 81.28691, mean: 0.05977
[32m[0906 16-34-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18386, current rewards: 85.52990, mean: 0.06066
[32m[0906 16-35-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18391, current rewards: 89.77330, mean: 0.06149
[32m[0906 16-35-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18396, current rewards: 93.41148, mean: 0.06186
[32m[0906 16-35-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18400, current rewards: 97.41304, mean: 0.06244
[32m[0906 16-35-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18401, current rewards: 101.42017, mean: 0.06299
[32m[0906 16-35-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18404, current rewards: 105.41995, mean: 0.06351
[32m[0906 16-35-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18404, current rewards: 109.42620, mean: 0.06399
[32m[0906 16-36-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18405, current rewards: 113.42611, mean: 0.06445
[32m[0906 16-36-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18410, current rewards: 117.42558, mean: 0.06488
[32m[0906 16-36-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18411, current rewards: 121.42775, mean: 0.06528
[32m[0906 16-36-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18409, current rewards: 125.88603, mean: 0.06591
[32m[0906 16-36-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18400, current rewards: 130.13273, mean: 0.06639
[32m[0906 16-36-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18391, current rewards: 134.26595, mean: 0.06680
[32m[0906 16-36-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18370, current rewards: 138.39799, mean: 0.06718
[32m[0906 16-37-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18350, current rewards: 132.96937, mean: 0.06302
[32m[0906 16-37-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18331, current rewards: 138.03593, mean: 0.06391
[32m[0906 16-37-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18325, current rewards: 143.10972, mean: 0.06476
[32m[0906 16-37-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18319, current rewards: 148.18232, mean: 0.06557
[32m[0906 16-37-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18322, current rewards: 153.33833, mean: 0.06638
[32m[0906 16-37-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18329, current rewards: 159.10881, mean: 0.06742
[32m[0906 16-37-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18334, current rewards: 164.21623, mean: 0.06814
[32m[0906 16-38-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18340, current rewards: 169.31744, mean: 0.06883
[32m[0906 16-38-16 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0906 16-38-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-38-16 @MBExp.py:227][0m Rewards obtained: [173.39908320382523], Lows: [10], Highs: [31], Total time: 10149.663547999997
[32m[0906 16-39-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-39-04 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 16-39-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17961, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-39-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18035, current rewards: -4.03561, mean: -0.06726
[32m[0906 16-39-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17981, current rewards: 2.80757, mean: 0.02552
[32m[0906 16-39-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17833, current rewards: 9.65117, mean: 0.06032
[32m[0906 16-39-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17887, current rewards: 16.48475, mean: 0.07850
[32m[0906 16-39-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17936, current rewards: 25.93861, mean: 0.09976
[32m[0906 16-40-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17955, current rewards: 33.34295, mean: 0.10756
[32m[0906 16-40-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17969, current rewards: 40.59958, mean: 0.11278
[32m[0906 16-40-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18040, current rewards: 47.85806, mean: 0.11673
[32m[0906 16-40-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18102, current rewards: 55.11493, mean: 0.11982
[32m[0906 16-40-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18145, current rewards: 62.36619, mean: 0.12229
[32m[0906 16-40-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18175, current rewards: 69.62609, mean: 0.12433
[32m[0906 16-40-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18206, current rewards: 70.01996, mean: 0.11479
[32m[0906 16-41-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18229, current rewards: 74.72263, mean: 0.11322
[32m[0906 16-41-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18252, current rewards: 84.01100, mean: 0.11833
[32m[0906 16-41-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18277, current rewards: 93.40083, mean: 0.12290
[32m[0906 16-41-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18294, current rewards: 102.79768, mean: 0.12691
[32m[0906 16-41-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18307, current rewards: 112.17587, mean: 0.13044
[32m[0906 16-41-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18324, current rewards: 121.56332, mean: 0.13359
[32m[0906 16-42-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18335, current rewards: 130.94508, mean: 0.13640
[32m[0906 16-42-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18344, current rewards: 140.31726, mean: 0.13893
[32m[0906 16-42-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18350, current rewards: 149.70721, mean: 0.14123
[32m[0906 16-42-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18356, current rewards: 137.49069, mean: 0.12387
[32m[0906 16-42-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18364, current rewards: 147.57082, mean: 0.12722
[32m[0906 16-42-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18369, current rewards: 157.63056, mean: 0.13027
[32m[0906 16-42-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18374, current rewards: 167.69326, mean: 0.13309
[32m[0906 16-43-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18379, current rewards: 177.75403, mean: 0.13569
[32m[0906 16-43-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18383, current rewards: 187.81803, mean: 0.13810
[32m[0906 16-43-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18387, current rewards: 175.52681, mean: 0.12449
[32m[0906 16-43-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18391, current rewards: 181.89680, mean: 0.12459
[32m[0906 16-43-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18395, current rewards: 187.28783, mean: 0.12403
[32m[0906 16-43-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18397, current rewards: 193.40330, mean: 0.12398
[32m[0906 16-44-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18404, current rewards: 199.52274, mean: 0.12393
[32m[0906 16-44-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18406, current rewards: 205.64266, mean: 0.12388
[32m[0906 16-44-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18408, current rewards: 211.75558, mean: 0.12383
[32m[0906 16-44-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18408, current rewards: 217.87142, mean: 0.12379
[32m[0906 16-44-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18409, current rewards: 201.41836, mean: 0.11128
[32m[0906 16-44-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18412, current rewards: 209.35449, mean: 0.11256
[32m[0906 16-44-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18409, current rewards: 219.82784, mean: 0.11509
[32m[0906 16-45-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18400, current rewards: 228.00408, mean: 0.11633
[32m[0906 16-45-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18390, current rewards: 236.17908, mean: 0.11750
[32m[0906 16-45-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18368, current rewards: 244.35437, mean: 0.11862
[32m[0906 16-45-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18347, current rewards: 252.53450, mean: 0.11968
[32m[0906 16-45-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18328, current rewards: 248.31027, mean: 0.11496
[32m[0906 16-45-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18319, current rewards: 256.01853, mean: 0.11585
[32m[0906 16-45-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18312, current rewards: 263.72101, mean: 0.11669
[32m[0906 16-46-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18315, current rewards: 274.89931, mean: 0.11900
[32m[0906 16-46-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18321, current rewards: 271.93874, mean: 0.11523
[32m[0906 16-46-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18324, current rewards: 281.39707, mean: 0.11676
[32m[0906 16-46-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18329, current rewards: 290.89267, mean: 0.11825
[32m[0906 16-46-43 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0906 16-46-43 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-46-43 @MBExp.py:227][0m Rewards obtained: [298.4908273927534], Lows: [31], Highs: [40], Total time: 10608.632635999997
[32m[0906 16-47-33 @MBExp.py:144][0m ####################################################################
[32m[0906 16-47-33 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 16-47-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17856, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-47-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18051, current rewards: -5.12543, mean: -0.08542
[32m[0906 16-47-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17925, current rewards: 1.05190, mean: 0.00956
[32m[0906 16-48-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17791, current rewards: 7.23702, mean: 0.04523
[32m[0906 16-48-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17862, current rewards: 13.55234, mean: 0.06453
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17912, current rewards: 6.95964, mean: 0.02677
[32m[0906 16-48-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17934, current rewards: 0.89686, mean: 0.00289
[32m[0906 16-48-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17939, current rewards: 5.30908, mean: 0.01475
[32m[0906 16-48-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18009, current rewards: 9.71531, mean: 0.02370
[32m[0906 16-48-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18073, current rewards: 14.11983, mean: 0.03070
[32m[0906 16-49-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18117, current rewards: 18.52817, mean: 0.03633
[32m[0906 16-49-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18165, current rewards: 22.93485, mean: 0.04096
[32m[0906 16-49-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18194, current rewards: 27.34295, mean: 0.04482
[32m[0906 16-49-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18216, current rewards: 31.85674, mean: 0.04827
[32m[0906 16-49-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18234, current rewards: 36.69769, mean: 0.05169
[32m[0906 16-49-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18257, current rewards: 41.54275, mean: 0.05466
[32m[0906 16-50-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18277, current rewards: 46.38716, mean: 0.05727
[32m[0906 16-50-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18295, current rewards: 28.17731, mean: 0.03276
[32m[0906 16-50-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18311, current rewards: 33.25581, mean: 0.03654
[32m[0906 16-50-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18323, current rewards: 38.33132, mean: 0.03993
[32m[0906 16-50-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18330, current rewards: 43.41000, mean: 0.04298
[32m[0906 16-50-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18336, current rewards: 46.03830, mean: 0.04343
[32m[0906 16-50-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18345, current rewards: 42.37883, mean: 0.03818
[32m[0906 16-51-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18353, current rewards: 47.37260, mean: 0.04084
[32m[0906 16-51-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18356, current rewards: 52.36810, mean: 0.04328
[32m[0906 16-51-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18359, current rewards: 57.36067, mean: 0.04552
[32m[0906 16-51-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18364, current rewards: 56.85377, mean: 0.04340
[32m[0906 16-51-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18368, current rewards: 55.79324, mean: 0.04102
[32m[0906 16-51-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18374, current rewards: 59.85101, mean: 0.04245
[32m[0906 16-52-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18379, current rewards: 63.73353, mean: 0.04365
[32m[0906 16-52-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18382, current rewards: 67.88475, mean: 0.04496
[32m[0906 16-52-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18386, current rewards: 72.02302, mean: 0.04617
[32m[0906 16-52-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18388, current rewards: 76.15995, mean: 0.04730
[32m[0906 16-52-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18393, current rewards: 80.29821, mean: 0.04837
[32m[0906 16-52-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18396, current rewards: 84.43884, mean: 0.04938
[32m[0906 16-52-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18399, current rewards: 88.57966, mean: 0.05033
[32m[0906 16-53-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18401, current rewards: 92.71734, mean: 0.05123
[32m[0906 16-53-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18402, current rewards: 97.66622, mean: 0.05251
[32m[0906 16-53-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18399, current rewards: 89.26676, mean: 0.04674
[32m[0906 16-53-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18389, current rewards: 86.89307, mean: 0.04433
[32m[0906 16-53-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18374, current rewards: 92.82534, mean: 0.04618
[32m[0906 16-53-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18352, current rewards: 98.75772, mean: 0.04794
[32m[0906 16-54-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18331, current rewards: 104.69086, mean: 0.04962
[32m[0906 16-54-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18311, current rewards: 110.62770, mean: 0.05122
[32m[0906 16-54-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18300, current rewards: 116.55830, mean: 0.05274
[32m[0906 16-54-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18295, current rewards: 122.36889, mean: 0.05415
[32m[0906 16-54-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18298, current rewards: 127.94825, mean: 0.05539
[32m[0906 16-54-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18303, current rewards: 133.89210, mean: 0.05673
[32m[0906 16-54-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18309, current rewards: 139.82178, mean: 0.05802
[32m[0906 16-55-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18313, current rewards: 140.16734, mean: 0.05698
[32m[0906 16-55-12 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 16-55-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-55-12 @MBExp.py:227][0m Rewards obtained: [138.4053610567307], Lows: [28], Highs: [51], Total time: 11067.222426999997
[32m[0906 16-56-04 @MBExp.py:144][0m ####################################################################
[32m[0906 16-56-04 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 16-56-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17958, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-56-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17983, current rewards: -3.38457, mean: -0.05641
[32m[0906 16-56-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17778, current rewards: 1.06640, mean: 0.00969
[32m[0906 16-56-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17708, current rewards: 5.51631, mean: 0.03448
[32m[0906 16-56-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17805, current rewards: 9.88871, mean: 0.04709
[32m[0906 16-56-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17844, current rewards: 14.29436, mean: 0.05498
[32m[0906 16-56-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17866, current rewards: 18.69819, mean: 0.06032
[32m[0906 16-57-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17883, current rewards: 2.41708, mean: 0.00671
[32m[0906 16-57-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17961, current rewards: 7.90989, mean: 0.01929
[32m[0906 16-57-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18033, current rewards: 13.40735, mean: 0.02915
[32m[0906 16-57-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18084, current rewards: 18.90274, mean: 0.03706
[32m[0906 16-57-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18124, current rewards: 24.40136, mean: 0.04357
[32m[0906 16-57-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18159, current rewards: 29.89937, mean: 0.04902
[32m[0906 16-58-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18191, current rewards: 35.39778, mean: 0.05363
[32m[0906 16-58-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18217, current rewards: 40.89753, mean: 0.05760
[32m[0906 16-58-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18234, current rewards: 46.39576, mean: 0.06105
[32m[0906 16-58-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18253, current rewards: 51.89175, mean: 0.06406
[32m[0906 16-58-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18268, current rewards: 56.59406, mean: 0.06581
[32m[0906 16-58-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18281, current rewards: 61.42255, mean: 0.06750
[32m[0906 16-59-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18294, current rewards: 66.25159, mean: 0.06901
[32m[0906 16-59-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18305, current rewards: 71.32562, mean: 0.07062
[32m[0906 16-59-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18314, current rewards: 76.22752, mean: 0.07191
[32m[0906 16-59-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18324, current rewards: 81.12571, mean: 0.07309
[32m[0906 16-59-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18331, current rewards: 86.02056, mean: 0.07416
[32m[0906 16-59-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18339, current rewards: 90.91668, mean: 0.07514
[32m[0906 16-59-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18344, current rewards: 95.81649, mean: 0.07604
[32m[0906 17-00-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18351, current rewards: 79.19048, mean: 0.06045
[32m[0906 17-00-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18357, current rewards: 83.52246, mean: 0.06141
[32m[0906 17-00-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18360, current rewards: 87.42865, mean: 0.06201
[32m[0906 17-00-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18367, current rewards: 93.00232, mean: 0.06370
[32m[0906 17-00-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18373, current rewards: 98.43658, mean: 0.06519
[32m[0906 17-00-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18381, current rewards: 103.87548, mean: 0.06659
[32m[0906 17-01-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18383, current rewards: 109.32123, mean: 0.06790
[32m[0906 17-01-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18386, current rewards: 114.76057, mean: 0.06913
[32m[0906 17-01-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18389, current rewards: 99.84653, mean: 0.05839
[32m[0906 17-01-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18396, current rewards: 106.30732, mean: 0.06040
[32m[0906 17-01-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18397, current rewards: 112.96639, mean: 0.06241
[32m[0906 17-01-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18400, current rewards: 124.19479, mean: 0.06677
[32m[0906 17-01-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18396, current rewards: 130.54807, mean: 0.06835
[32m[0906 17-02-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18388, current rewards: 136.89935, mean: 0.06985
[32m[0906 17-02-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18368, current rewards: 143.25098, mean: 0.07127
[32m[0906 17-02-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18348, current rewards: 149.60213, mean: 0.07262
[32m[0906 17-02-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18327, current rewards: 155.95368, mean: 0.07391
[32m[0906 17-02-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18308, current rewards: 162.30450, mean: 0.07514
[32m[0906 17-02-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18296, current rewards: 168.65544, mean: 0.07631
[32m[0906 17-02-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18292, current rewards: 161.22698, mean: 0.07134
[32m[0906 17-03-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18295, current rewards: 166.58324, mean: 0.07211
[32m[0906 17-03-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18302, current rewards: 172.47757, mean: 0.07308
[32m[0906 17-03-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18307, current rewards: 178.47887, mean: 0.07406
[32m[0906 17-03-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18312, current rewards: 184.45364, mean: 0.07498
[32m[0906 17-03-43 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 17-03-43 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-03-43 @MBExp.py:227][0m Rewards obtained: [180.9029346114506], Lows: [34], Highs: [21], Total time: 11525.787611999996
[32m[0906 17-04-37 @MBExp.py:144][0m ####################################################################
[32m[0906 17-04-37 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 17-04-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18000, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-04-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17965, current rewards: -12.56209, mean: -0.20937
[32m[0906 17-04-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17789, current rewards: -8.28351, mean: -0.07530
[32m[0906 17-05-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17714, current rewards: -3.45464, mean: -0.02159
[32m[0906 17-05-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17794, current rewards: 1.71665, mean: 0.00817
[32m[0906 17-05-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17832, current rewards: 6.61680, mean: 0.02545
[32m[0906 17-05-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17864, current rewards: 11.51192, mean: 0.03714
[32m[0906 17-05-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17882, current rewards: 16.41020, mean: 0.04558
[32m[0906 17-05-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17968, current rewards: 21.30777, mean: 0.05197
[32m[0906 17-06-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18035, current rewards: 26.20137, mean: 0.05696
[32m[0906 17-06-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18084, current rewards: 31.09806, mean: 0.06098
[32m[0906 17-06-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18125, current rewards: 35.98960, mean: 0.06427
[32m[0906 17-06-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18156, current rewards: 29.72084, mean: 0.04872
[32m[0906 17-06-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18188, current rewards: 33.37644, mean: 0.05057
[32m[0906 17-06-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18210, current rewards: 36.60788, mean: 0.05156
[32m[0906 17-06-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18237, current rewards: 39.84663, mean: 0.05243
[32m[0906 17-07-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18263, current rewards: 43.07702, mean: 0.05318
[32m[0906 17-07-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18275, current rewards: 46.30705, mean: 0.05385
[32m[0906 17-07-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18291, current rewards: 49.53904, mean: 0.05444
[32m[0906 17-07-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18302, current rewards: 52.77184, mean: 0.05497
[32m[0906 17-07-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18312, current rewards: 56.67562, mean: 0.05611
[32m[0906 17-07-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18320, current rewards: 59.75250, mean: 0.05637
[32m[0906 17-08-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18331, current rewards: 45.07199, mean: 0.04061
[32m[0906 17-08-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18339, current rewards: 51.53081, mean: 0.04442
[32m[0906 17-08-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18348, current rewards: 57.98963, mean: 0.04793
[32m[0906 17-08-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18354, current rewards: 64.44846, mean: 0.05115
[32m[0906 17-08-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18362, current rewards: 70.90728, mean: 0.05413
[32m[0906 17-08-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18368, current rewards: 77.36610, mean: 0.05689
[32m[0906 17-08-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18373, current rewards: 82.40045, mean: 0.05844
[32m[0906 17-09-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18381, current rewards: 84.92801, mean: 0.05817
[32m[0906 17-09-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18389, current rewards: 87.45558, mean: 0.05792
[32m[0906 17-09-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18392, current rewards: 61.61826, mean: 0.03950
[32m[0906 17-09-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18393, current rewards: 11.61826, mean: 0.00722
[32m[0906 17-09-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18396, current rewards: -38.38174, mean: -0.02312
[32m[0906 17-09-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18400, current rewards: -88.38174, mean: -0.05169
[32m[0906 17-10-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18402, current rewards: -138.38174, mean: -0.07863
[32m[0906 17-10-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18406, current rewards: -188.38174, mean: -0.10408
[32m[0906 17-10-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18408, current rewards: -238.38174, mean: -0.12816
[32m[0906 17-10-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18403, current rewards: -288.38174, mean: -0.15099
[32m[0906 17-10-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18393, current rewards: -338.38174, mean: -0.17264
[32m[0906 17-10-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18370, current rewards: -388.38174, mean: -0.19322
[32m[0906 17-10-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18349, current rewards: -438.38174, mean: -0.21281
[32m[0906 17-11-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18328, current rewards: -488.38174, mean: -0.23146
[32m[0906 17-11-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18310, current rewards: -538.38174, mean: -0.24925
[32m[0906 17-11-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18294, current rewards: -588.38174, mean: -0.26624
[32m[0906 17-11-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18289, current rewards: -638.38174, mean: -0.28247
[32m[0906 17-11-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18290, current rewards: -688.38174, mean: -0.29800
[32m[0906 17-11-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18295, current rewards: -738.38174, mean: -0.31287
[32m[0906 17-11-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18303, current rewards: -788.38174, mean: -0.32713
[32m[0906 17-12-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18309, current rewards: -838.38174, mean: -0.34081
[32m[0906 17-12-15 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0906 17-12-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-12-15 @MBExp.py:227][0m Rewards obtained: [-878.3817400090447], Lows: [10], Highs: [993], Total time: 11984.230273999996
[32m[0906 17-13-11 @MBExp.py:144][0m ####################################################################
[32m[0906 17-13-11 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 17-13-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18118, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-13-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17909, current rewards: -4.76820, mean: -0.07947
[32m[0906 17-13-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17716, current rewards: 0.00981, mean: 0.00009
[32m[0906 17-13-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17642, current rewards: 4.37176, mean: 0.02732
[32m[0906 17-13-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17725, current rewards: 9.34715, mean: 0.04451
[32m[0906 17-13-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17785, current rewards: 14.35910, mean: 0.05523
[32m[0906 17-14-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17827, current rewards: 19.36540, mean: 0.06247
[32m[0906 17-14-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17865, current rewards: 24.37321, mean: 0.06770
[32m[0906 17-14-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17945, current rewards: 29.37648, mean: 0.07165
[32m[0906 17-14-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18025, current rewards: 34.38422, mean: 0.07475
[32m[0906 17-14-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18077, current rewards: 39.39042, mean: 0.07724
[32m[0906 17-14-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18115, current rewards: 44.46774, mean: 0.07941
[32m[0906 17-15-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18149, current rewards: 49.75502, mean: 0.08157
[32m[0906 17-15-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18169, current rewards: 45.39089, mean: 0.06877
[32m[0906 17-15-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18192, current rewards: 52.22654, mean: 0.07356
[32m[0906 17-15-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18215, current rewards: 59.06289, mean: 0.07771
[32m[0906 17-15-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18234, current rewards: 65.89849, mean: 0.08136
[32m[0906 17-15-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18251, current rewards: 72.74258, mean: 0.08458
[32m[0906 17-15-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18263, current rewards: 79.58403, mean: 0.08745
[32m[0906 17-16-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18277, current rewards: 86.41070, mean: 0.09001
[32m[0906 17-16-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18287, current rewards: 73.67570, mean: 0.07295
[32m[0906 17-16-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18295, current rewards: 78.66813, mean: 0.07422
[32m[0906 17-16-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18300, current rewards: 83.65738, mean: 0.07537
[32m[0906 17-16-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18310, current rewards: 88.64516, mean: 0.07642
[32m[0906 17-16-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18314, current rewards: 93.63452, mean: 0.07738
[32m[0906 17-17-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18323, current rewards: 89.82387, mean: 0.07129
[32m[0906 17-17-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18326, current rewards: 106.90880, mean: 0.08161
[32m[0906 17-17-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18330, current rewards: 130.07729, mean: 0.09565
[32m[0906 17-17-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18338, current rewards: 147.16227, mean: 0.10437
[32m[0906 17-17-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18345, current rewards: 163.13699, mean: 0.11174
[32m[0906 17-17-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18347, current rewards: 178.99591, mean: 0.11854
[32m[0906 17-17-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18352, current rewards: 194.89431, mean: 0.12493
[32m[0906 17-18-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18357, current rewards: 210.76968, mean: 0.13091
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18358, current rewards: 226.65503, mean: 0.13654
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18360, current rewards: 242.57503, mean: 0.14186
[32m[0906 17-18-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18364, current rewards: 240.54861, mean: 0.13668
[32m[0906 17-18-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18368, current rewards: 246.02094, mean: 0.13592
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18367, current rewards: 251.66586, mean: 0.13530
[32m[0906 17-19-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18363, current rewards: 257.30487, mean: 0.13471
[32m[0906 17-19-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18351, current rewards: 262.95781, mean: 0.13416
[32m[0906 17-19-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18329, current rewards: 268.59565, mean: 0.13363
[32m[0906 17-19-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18307, current rewards: 274.24442, mean: 0.13313
[32m[0906 17-19-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18290, current rewards: 279.88822, mean: 0.13265
[32m[0906 17-19-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18271, current rewards: 285.52532, mean: 0.13219
[32m[0906 17-19-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18254, current rewards: 291.11656, mean: 0.13173
[32m[0906 17-20-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18249, current rewards: 273.18284, mean: 0.12088
[32m[0906 17-20-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18252, current rewards: 278.41862, mean: 0.12053
[32m[0906 17-20-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18262, current rewards: 283.65421, mean: 0.12019
[32m[0906 17-20-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18269, current rewards: 288.88995, mean: 0.11987
[32m[0906 17-20-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18276, current rewards: 294.12432, mean: 0.11956
[32m[0906 17-20-49 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 17-20-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-20-49 @MBExp.py:227][0m Rewards obtained: [298.31197561252924], Lows: [21], Highs: [40], Total time: 12441.921476999996
[32m[0906 17-21-48 @MBExp.py:144][0m ####################################################################
[32m[0906 17-21-48 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 17-21-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18082, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-21-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17729, current rewards: -3.84685, mean: -0.06411
[32m[0906 17-22-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17575, current rewards: 3.80493, mean: 0.03459
[32m[0906 17-22-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17547, current rewards: 10.40667, mean: 0.06504
[32m[0906 17-22-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17670, current rewards: 16.46267, mean: 0.07839
[32m[0906 17-22-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17743, current rewards: 22.51997, mean: 0.08662
[32m[0906 17-22-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17790, current rewards: 28.58582, mean: 0.09221
[32m[0906 17-22-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17839, current rewards: 34.63746, mean: 0.09622
[32m[0906 17-23-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17929, current rewards: 40.69360, mean: 0.09925
[32m[0906 17-23-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18008, current rewards: 46.75936, mean: 0.10165
[32m[0906 17-23-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18067, current rewards: 32.33786, mean: 0.06341
[32m[0906 17-23-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18099, current rewards: 37.91112, mean: 0.06770
[32m[0906 17-23-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18134, current rewards: 44.14978, mean: 0.07238
[32m[0906 17-23-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18166, current rewards: 50.38542, mean: 0.07634
[32m[0906 17-23-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18196, current rewards: 56.62524, mean: 0.07975
[32m[0906 17-24-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18219, current rewards: 62.86366, mean: 0.08272
[32m[0906 17-24-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18235, current rewards: 69.09971, mean: 0.08531
[32m[0906 17-24-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18253, current rewards: 75.33788, mean: 0.08760
[32m[0906 17-24-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18268, current rewards: 81.57952, mean: 0.08965
[32m[0906 17-24-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18283, current rewards: 76.69585, mean: 0.07989
[32m[0906 17-24-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18291, current rewards: 83.51497, mean: 0.08269
[32m[0906 17-25-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18303, current rewards: 90.32025, mean: 0.08521
[32m[0906 17-25-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18312, current rewards: 97.13034, mean: 0.08750
[32m[0906 17-25-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18319, current rewards: 103.93433, mean: 0.08960
[32m[0906 17-25-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18332, current rewards: 110.74773, mean: 0.09153
[32m[0906 17-25-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18338, current rewards: 117.56447, mean: 0.09331
[32m[0906 17-25-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18344, current rewards: 124.38082, mean: 0.09495
[32m[0906 17-25-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18356, current rewards: 131.19269, mean: 0.09647
[32m[0906 17-26-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18362, current rewards: 137.99719, mean: 0.09787
[32m[0906 17-26-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18366, current rewards: 144.80470, mean: 0.09918
[32m[0906 17-26-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18370, current rewards: 151.62943, mean: 0.10042
[32m[0906 17-26-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18372, current rewards: 158.45143, mean: 0.10157
[32m[0906 17-26-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18376, current rewards: 148.16933, mean: 0.09203
[32m[0906 17-26-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18381, current rewards: 149.87088, mean: 0.09028
[32m[0906 17-27-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18382, current rewards: 156.45588, mean: 0.09149
[32m[0906 17-27-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18387, current rewards: 164.40217, mean: 0.09341
[32m[0906 17-27-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18390, current rewards: 171.01877, mean: 0.09449
[32m[0906 17-27-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18394, current rewards: 177.63734, mean: 0.09550
[32m[0906 17-27-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18388, current rewards: 184.25316, mean: 0.09647
[32m[0906 17-27-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18371, current rewards: 190.87715, mean: 0.09739
[32m[0906 17-27-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18348, current rewards: 197.49860, mean: 0.09826
[32m[0906 17-28-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18330, current rewards: 204.11126, mean: 0.09908
[32m[0906 17-28-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18309, current rewards: 210.73470, mean: 0.09987
[32m[0906 17-28-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18289, current rewards: 221.34668, mean: 0.10248
[32m[0906 17-28-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18270, current rewards: 229.08965, mean: 0.10366
[32m[0906 17-28-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18262, current rewards: 223.77432, mean: 0.09902
[32m[0906 17-28-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18268, current rewards: 229.65796, mean: 0.09942
[32m[0906 17-28-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18274, current rewards: 235.54242, mean: 0.09981
[32m[0906 17-29-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18280, current rewards: 241.42484, mean: 0.10018
[32m[0906 17-29-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18283, current rewards: 247.30300, mean: 0.10053
[32m[0906 17-29-25 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0906 17-29-25 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-29-25 @MBExp.py:227][0m Rewards obtained: [252.0116917290313], Lows: [20], Highs: [30], Total time: 12899.764393999996
[32m[0906 17-30-26 @MBExp.py:144][0m ####################################################################
[32m[0906 17-30-26 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 17-30-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17774, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-30-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17502, current rewards: -4.22198, mean: -0.07037
[32m[0906 17-30-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17458, current rewards: 1.30712, mean: 0.01188
[32m[0906 17-30-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17475, current rewards: 6.94508, mean: 0.04341
[32m[0906 17-31-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17622, current rewards: 12.58345, mean: 0.05992
[32m[0906 17-31-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17705, current rewards: 18.22340, mean: 0.07009
[32m[0906 17-31-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17757, current rewards: 12.64709, mean: 0.04080
[32m[0906 17-31-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17817, current rewards: 18.36503, mean: 0.05101
[32m[0906 17-31-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17912, current rewards: 24.07515, mean: 0.05872
[32m[0906 17-31-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17985, current rewards: 29.78860, mean: 0.06476
[32m[0906 17-31-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18042, current rewards: 14.03647, mean: 0.02752
[32m[0906 17-32-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18094, current rewards: 20.15074, mean: 0.03598
[32m[0906 17-32-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18130, current rewards: 26.22118, mean: 0.04299
[32m[0906 17-32-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18159, current rewards: 32.28992, mean: 0.04892
[32m[0906 17-32-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18183, current rewards: 38.35844, mean: 0.05403
[32m[0906 17-32-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18202, current rewards: 44.42689, mean: 0.05846
[32m[0906 17-32-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18218, current rewards: 50.49520, mean: 0.06234
[32m[0906 17-33-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18235, current rewards: 56.56508, mean: 0.06577
[32m[0906 17-33-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18253, current rewards: 61.88712, mean: 0.06801
[32m[0906 17-33-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18265, current rewards: 67.88822, mean: 0.07072
[32m[0906 17-33-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18280, current rewards: 73.88408, mean: 0.07315
[32m[0906 17-33-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18289, current rewards: 79.88866, mean: 0.07537
[32m[0906 17-33-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18297, current rewards: 74.54297, mean: 0.06716
[32m[0906 17-33-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18304, current rewards: 79.82329, mean: 0.06881
[32m[0906 17-34-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18311, current rewards: 85.08912, mean: 0.07032
[32m[0906 17-34-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18322, current rewards: 90.36011, mean: 0.07171
[32m[0906 17-34-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18332, current rewards: 96.26191, mean: 0.07348
[32m[0906 17-34-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18336, current rewards: 101.62743, mean: 0.07473
[32m[0906 17-34-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18343, current rewards: 107.00361, mean: 0.07589
[32m[0906 17-34-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18348, current rewards: 91.38028, mean: 0.06259
[32m[0906 17-35-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18352, current rewards: 97.15041, mean: 0.06434
[32m[0906 17-35-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18359, current rewards: 102.92078, mean: 0.06597
[32m[0906 17-35-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18363, current rewards: 108.69172, mean: 0.06751
[32m[0906 17-35-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18364, current rewards: 114.45822, mean: 0.06895
[32m[0906 17-35-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18364, current rewards: 119.82920, mean: 0.07008
[32m[0906 17-35-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18367, current rewards: 125.42466, mean: 0.07126
[32m[0906 17-35-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18371, current rewards: 120.40328, mean: 0.06652
[32m[0906 17-36-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18374, current rewards: 125.41945, mean: 0.06743
[32m[0906 17-36-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18368, current rewards: 130.43785, mean: 0.06829
[32m[0906 17-36-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18350, current rewards: 135.45997, mean: 0.06911
[32m[0906 17-36-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18329, current rewards: 140.47736, mean: 0.06989
[32m[0906 17-36-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18308, current rewards: 145.49342, mean: 0.07063
[32m[0906 17-36-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18288, current rewards: 150.56610, mean: 0.07136
[32m[0906 17-37-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18268, current rewards: 157.57778, mean: 0.07295
[32m[0906 17-37-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18251, current rewards: 162.88558, mean: 0.07370
[32m[0906 17-37-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18242, current rewards: 147.45881, mean: 0.06525
[32m[0906 17-37-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18247, current rewards: 153.68670, mean: 0.06653
[32m[0906 17-37-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18253, current rewards: 159.76513, mean: 0.06770
[32m[0906 17-37-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18258, current rewards: 165.85040, mean: 0.06882
[32m[0906 17-37-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18264, current rewards: 171.93079, mean: 0.06989
[32m[0906 17-38-03 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 17-38-03 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-38-03 @MBExp.py:227][0m Rewards obtained: [176.7938723206755], Lows: [30], Highs: [40], Total time: 13357.140071999997
[32m[0906 17-39-06 @MBExp.py:144][0m ####################################################################
[32m[0906 17-39-06 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 17-39-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17514, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-39-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17466, current rewards: -5.11895, mean: -0.08532
[32m[0906 17-39-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17466, current rewards: -0.22616, mean: -0.00206
[32m[0906 17-39-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17457, current rewards: 4.67225, mean: 0.02920
[32m[0906 17-39-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17598, current rewards: 9.57062, mean: 0.04557
[32m[0906 17-39-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17682, current rewards: 14.46997, mean: 0.05565
[32m[0906 17-40-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17728, current rewards: 19.36911, mean: 0.06248
[32m[0906 17-40-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17805, current rewards: 24.27103, mean: 0.06742
[32m[0906 17-40-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17900, current rewards: 29.16932, mean: 0.07114
[32m[0906 17-40-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17968, current rewards: 35.70103, mean: 0.07761
[32m[0906 17-40-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18024, current rewards: 41.46490, mean: 0.08130
[32m[0906 17-40-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18062, current rewards: 36.43264, mean: 0.06506
[32m[0906 17-40-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18104, current rewards: 31.42662, mean: 0.05152
[32m[0906 17-41-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18135, current rewards: 36.89489, mean: 0.05590
[32m[0906 17-41-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18160, current rewards: 42.36498, mean: 0.05967
[32m[0906 17-41-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18176, current rewards: 47.83239, mean: 0.06294
[32m[0906 17-41-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18197, current rewards: 53.30717, mean: 0.06581
[32m[0906 17-41-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18214, current rewards: 58.77481, mean: 0.06834
[32m[0906 17-41-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18233, current rewards: 64.32508, mean: 0.07069
[32m[0906 17-42-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18242, current rewards: 69.80784, mean: 0.07272
[32m[0906 17-42-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18251, current rewards: 75.29261, mean: 0.07455
[32m[0906 17-42-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18262, current rewards: 69.54334, mean: 0.06561
[32m[0906 17-42-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18270, current rewards: 75.10401, mean: 0.06766
[32m[0906 17-42-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18281, current rewards: 80.65841, mean: 0.06953
[32m[0906 17-42-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18288, current rewards: 86.21427, mean: 0.07125
[32m[0906 17-42-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18296, current rewards: 91.77307, mean: 0.07284
[32m[0906 17-43-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18303, current rewards: 97.12382, mean: 0.07414
[32m[0906 17-43-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18308, current rewards: 102.64436, mean: 0.07547
[32m[0906 17-43-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18314, current rewards: 108.16519, mean: 0.07671
[32m[0906 17-43-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18320, current rewards: 113.68983, mean: 0.07787
[32m[0906 17-43-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18324, current rewards: 107.48568, mean: 0.07118
[32m[0906 17-43-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18331, current rewards: 111.78423, mean: 0.07166
[32m[0906 17-44-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18335, current rewards: 116.08333, mean: 0.07210
[32m[0906 17-44-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18340, current rewards: 120.37334, mean: 0.07251
[32m[0906 17-44-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18343, current rewards: 124.70894, mean: 0.07293
[32m[0906 17-44-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18346, current rewards: 129.00411, mean: 0.07330
[32m[0906 17-44-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18347, current rewards: 133.29896, mean: 0.07365
[32m[0906 17-44-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18351, current rewards: 137.59662, mean: 0.07398
[32m[0906 17-44-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18343, current rewards: 141.89514, mean: 0.07429
[32m[0906 17-45-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18320, current rewards: 146.19430, mean: 0.07459
[32m[0906 17-45-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18298, current rewards: 130.20129, mean: 0.06478
[32m[0906 17-45-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18274, current rewards: 135.35405, mean: 0.06571
[32m[0906 17-45-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18254, current rewards: 140.27930, mean: 0.06648
[32m[0906 17-45-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18235, current rewards: 145.38186, mean: 0.06731
[32m[0906 17-45-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18217, current rewards: 150.48553, mean: 0.06809
[32m[0906 17-45-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18205, current rewards: 155.59044, mean: 0.06885
[32m[0906 17-46-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18210, current rewards: 160.69261, mean: 0.06956
[32m[0906 17-46-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18217, current rewards: 165.79399, mean: 0.07025
[32m[0906 17-46-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18225, current rewards: 170.89706, mean: 0.07091
[32m[0906 17-46-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18231, current rewards: 176.00395, mean: 0.07155
[32m[0906 17-46-42 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 17-46-42 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-46-42 @MBExp.py:227][0m Rewards obtained: [158.6869997500469], Lows: [30], Highs: [30], Total time: 13813.680941999997
[32m[0906 17-47-47 @MBExp.py:144][0m ####################################################################
[32m[0906 17-47-47 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 17-47-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17347, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-47-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17418, current rewards: -3.25147, mean: -0.05419
[32m[0906 17-48-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17413, current rewards: 1.43974, mean: 0.01309
[32m[0906 17-48-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17413, current rewards: 6.13256, mean: 0.03833
[32m[0906 17-48-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17546, current rewards: 10.82516, mean: 0.05155
[32m[0906 17-48-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17643, current rewards: 15.51970, mean: 0.05969
[32m[0906 17-48-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17697, current rewards: 20.21273, mean: 0.06520
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17770, current rewards: 24.90597, mean: 0.06918
[32m[0906 17-49-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17880, current rewards: 32.54918, mean: 0.07939
[32m[0906 17-49-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17954, current rewards: 37.42847, mean: 0.08137
[32m[0906 17-49-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18012, current rewards: 42.30524, mean: 0.08295
[32m[0906 17-49-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18060, current rewards: 47.18608, mean: 0.08426
[32m[0906 17-49-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18093, current rewards: 52.06720, mean: 0.08536
[32m[0906 17-49-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18121, current rewards: 56.94071, mean: 0.08627
[32m[0906 17-49-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18147, current rewards: 67.19496, mean: 0.09464
[32m[0906 17-50-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18168, current rewards: 74.60553, mean: 0.09817
[32m[0906 17-50-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18189, current rewards: 81.44787, mean: 0.10055
[32m[0906 17-50-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18204, current rewards: 86.78887, mean: 0.10092
[32m[0906 17-50-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18225, current rewards: 93.42848, mean: 0.10267
[32m[0906 17-50-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18240, current rewards: 100.04926, mean: 0.10422
[32m[0906 17-50-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18258, current rewards: 106.66686, mean: 0.10561
[32m[0906 17-51-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18271, current rewards: 113.28344, mean: 0.10687
[32m[0906 17-51-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18287, current rewards: 119.89451, mean: 0.10801
[32m[0906 17-51-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18296, current rewards: 126.51188, mean: 0.10906
[32m[0906 17-51-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18307, current rewards: 111.39827, mean: 0.09206
[32m[0906 17-51-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18313, current rewards: 120.05888, mean: 0.09528
[32m[0906 17-51-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18320, current rewards: 126.98265, mean: 0.09693
[32m[0906 17-51-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18325, current rewards: 133.92389, mean: 0.09847
[32m[0906 17-52-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18334, current rewards: 140.85906, mean: 0.09990
[32m[0906 17-52-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18337, current rewards: 147.79238, mean: 0.10123
[32m[0906 17-52-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18340, current rewards: 154.72241, mean: 0.10247
[32m[0906 17-52-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18344, current rewards: 161.65760, mean: 0.10363
[32m[0906 17-52-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18348, current rewards: 168.58828, mean: 0.10471
[32m[0906 17-52-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18353, current rewards: 175.11418, mean: 0.10549
[32m[0906 17-53-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18356, current rewards: 181.22335, mean: 0.10598
[32m[0906 17-53-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18363, current rewards: 187.27774, mean: 0.10641
[32m[0906 17-53-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18365, current rewards: 193.34365, mean: 0.10682
[32m[0906 17-53-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18370, current rewards: 199.39632, mean: 0.10720
[32m[0906 17-53-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18356, current rewards: 205.45924, mean: 0.10757
[32m[0906 17-53-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18334, current rewards: 211.52091, mean: 0.10792
[32m[0906 17-53-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18313, current rewards: 217.58481, mean: 0.10825
[32m[0906 17-54-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18293, current rewards: 223.52424, mean: 0.10851
[32m[0906 17-54-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18273, current rewards: 229.36395, mean: 0.10870
[32m[0906 17-54-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18254, current rewards: 214.47288, mean: 0.09929
[32m[0906 17-54-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18235, current rewards: 221.31542, mean: 0.10014
[32m[0906 17-54-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18221, current rewards: 228.13648, mean: 0.10095
[32m[0906 17-54-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18227, current rewards: 234.95634, mean: 0.10171
[32m[0906 17-54-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18236, current rewards: 241.77954, mean: 0.10245
[32m[0906 17-55-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18245, current rewards: 235.26745, mean: 0.09762
[32m[0906 17-55-16 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18254, current rewards: 239.75683, mean: 0.09746
[32m[0906 17-55-24 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 17-55-24 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-55-24 @MBExp.py:227][0m Rewards obtained: [243.46435480039028], Lows: [20], Highs: [21], Total time: 14270.808016999998
[32m[0906 17-56-30 @MBExp.py:144][0m ####################################################################
[32m[0906 17-56-30 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 17-56-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17321, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-56-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17446, current rewards: -0.96461, mean: -0.01608
[32m[0906 17-56-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17456, current rewards: 5.55706, mean: 0.05052
[32m[0906 17-56-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17462, current rewards: 12.07775, mean: 0.07549
[32m[0906 17-57-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17597, current rewards: 18.59836, mean: 0.08856
[32m[0906 17-57-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17670, current rewards: 25.11878, mean: 0.09661
[32m[0906 17-57-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17743, current rewards: 31.63947, mean: 0.10206
[32m[0906 17-57-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17821, current rewards: 38.15996, mean: 0.10600
[32m[0906 17-57-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17905, current rewards: 30.85446, mean: 0.07525
[32m[0906 17-57-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17974, current rewards: 37.81794, mean: 0.08221
[32m[0906 17-58-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18026, current rewards: 44.79526, mean: 0.08783
[32m[0906 17-58-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18068, current rewards: 51.76974, mean: 0.09245
[32m[0906 17-58-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18107, current rewards: 37.38263, mean: 0.06128
[32m[0906 17-58-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18141, current rewards: 43.43124, mean: 0.06580
[32m[0906 17-58-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18163, current rewards: 48.83334, mean: 0.06878
[32m[0906 17-58-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18186, current rewards: 54.23161, mean: 0.07136
[32m[0906 17-58-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18209, current rewards: 59.19069, mean: 0.07307
[32m[0906 17-59-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18231, current rewards: 64.00600, mean: 0.07443
[32m[0906 17-59-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18248, current rewards: 69.62880, mean: 0.07652
[32m[0906 17-59-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18266, current rewards: 75.25010, mean: 0.07839
[32m[0906 17-59-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18284, current rewards: 80.87418, mean: 0.08007
[32m[0906 17-59-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18293, current rewards: 86.50375, mean: 0.08161
[32m[0906 17-59-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18302, current rewards: 92.13094, mean: 0.08300
[32m[0906 18-00-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18313, current rewards: 97.74820, mean: 0.08427
[32m[0906 18-00-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18319, current rewards: 103.36352, mean: 0.08542
[32m[0906 18-00-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18326, current rewards: 108.87832, mean: 0.08641
[32m[0906 18-00-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18331, current rewards: 106.66494, mean: 0.08142
[32m[0906 18-00-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18335, current rewards: 110.23623, mean: 0.08106
[32m[0906 18-00-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18342, current rewards: 116.37289, mean: 0.08253
[32m[0906 18-00-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18348, current rewards: 122.49168, mean: 0.08390
[32m[0906 18-01-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18355, current rewards: 128.61713, mean: 0.08518
[32m[0906 18-01-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18360, current rewards: 134.73287, mean: 0.08637
[32m[0906 18-01-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18365, current rewards: 140.85375, mean: 0.08749
[32m[0906 18-01-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18374, current rewards: 147.79240, mean: 0.08903
[32m[0906 18-01-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18379, current rewards: 153.85017, mean: 0.08997
[32m[0906 18-01-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18384, current rewards: 159.89950, mean: 0.09085
[32m[0906 18-02-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18388, current rewards: 165.95310, mean: 0.09169
[32m[0906 18-02-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18392, current rewards: 172.00140, mean: 0.09247
[32m[0906 18-02-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18377, current rewards: 178.05529, mean: 0.09322
[32m[0906 18-02-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18354, current rewards: 162.56256, mean: 0.08294
[32m[0906 18-02-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18331, current rewards: 170.53426, mean: 0.08484
[32m[0906 18-02-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18311, current rewards: 179.46470, mean: 0.08712
[32m[0906 18-02-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18292, current rewards: 187.64650, mean: 0.08893
[32m[0906 18-03-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18274, current rewards: 195.81672, mean: 0.09066
[32m[0906 18-03-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18257, current rewards: 204.00421, mean: 0.09231
[32m[0906 18-03-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18241, current rewards: 212.16948, mean: 0.09388
[32m[0906 18-03-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18248, current rewards: 208.50039, mean: 0.09026
[32m[0906 18-03-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18257, current rewards: 214.38918, mean: 0.09084
[32m[0906 18-03-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18263, current rewards: 220.26618, mean: 0.09140
[32m[0906 18-04-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18268, current rewards: 227.33411, mean: 0.09241
[32m[0906 18-04-08 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 18-04-08 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-04-08 @MBExp.py:227][0m Rewards obtained: [211.3093620605033], Lows: [32], Highs: [43], Total time: 14728.266589999997
[32m[0906 18-05-16 @MBExp.py:144][0m ####################################################################
[32m[0906 18-05-16 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 18-05-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17373, current rewards: -8.95116, mean: -0.89512
[32m[0906 18-05-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17440, current rewards: -2.84932, mean: -0.04749
[32m[0906 18-05-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17438, current rewards: 3.47360, mean: 0.03158
[32m[0906 18-05-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17453, current rewards: 9.78915, mean: 0.06118
[32m[0906 18-05-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17580, current rewards: 16.09483, mean: 0.07664
[32m[0906 18-06-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17663, current rewards: 22.40133, mean: 0.08616
[32m[0906 18-06-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17721, current rewards: 28.70364, mean: 0.09259
[32m[0906 18-06-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17803, current rewards: 35.00971, mean: 0.09725
[32m[0906 18-06-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17894, current rewards: 27.80310, mean: 0.06781
[32m[0906 18-06-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17951, current rewards: 32.32566, mean: 0.07027
[32m[0906 18-06-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18005, current rewards: 36.84568, mean: 0.07225
[32m[0906 18-06-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18057, current rewards: 41.36184, mean: 0.07386
[32m[0906 18-07-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18091, current rewards: 45.87591, mean: 0.07521
[32m[0906 18-07-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18117, current rewards: 50.38891, mean: 0.07635
[32m[0906 18-07-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18148, current rewards: 54.90253, mean: 0.07733
[32m[0906 18-07-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18170, current rewards: 59.41947, mean: 0.07818
[32m[0906 18-07-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18192, current rewards: 65.19839, mean: 0.08049
[32m[0906 18-07-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18216, current rewards: 70.34647, mean: 0.08180
[32m[0906 18-08-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18233, current rewards: 75.49977, mean: 0.08297
[32m[0906 18-08-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18251, current rewards: 80.65456, mean: 0.08402
[32m[0906 18-08-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18260, current rewards: 81.60287, mean: 0.08079
[32m[0906 18-08-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18272, current rewards: 68.97875, mean: 0.06507
[32m[0906 18-08-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18283, current rewards: 75.84953, mean: 0.06833
[32m[0906 18-08-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18290, current rewards: 82.72115, mean: 0.07131
[32m[0906 18-08-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18298, current rewards: 89.95832, mean: 0.07435
[32m[0906 18-09-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18305, current rewards: 95.95474, mean: 0.07615
[32m[0906 18-09-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18311, current rewards: 102.02764, mean: 0.07788
[32m[0906 18-09-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18318, current rewards: 108.13446, mean: 0.07951
[32m[0906 18-09-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18327, current rewards: 114.24231, mean: 0.08102
[32m[0906 18-09-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18335, current rewards: 120.34699, mean: 0.08243
[32m[0906 18-09-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18341, current rewards: 126.46291, mean: 0.08375
[32m[0906 18-10-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18347, current rewards: 132.56358, mean: 0.08498
[32m[0906 18-10-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18350, current rewards: 139.07378, mean: 0.08638
[32m[0906 18-10-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18355, current rewards: 147.32104, mean: 0.08875
[32m[0906 18-10-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18359, current rewards: 152.48536, mean: 0.08917
[32m[0906 18-10-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18362, current rewards: 157.97956, mean: 0.08976
[32m[0906 18-10-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18366, current rewards: 163.47254, mean: 0.09032
[32m[0906 18-10-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18369, current rewards: 168.96747, mean: 0.09084
[32m[0906 18-11-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18346, current rewards: 174.45720, mean: 0.09134
[32m[0906 18-11-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18324, current rewards: 179.95112, mean: 0.09181
[32m[0906 18-11-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18301, current rewards: 185.44568, mean: 0.09226
[32m[0906 18-11-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18281, current rewards: 190.22030, mean: 0.09234
[32m[0906 18-11-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18261, current rewards: 195.85848, mean: 0.09282
[32m[0906 18-11-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18242, current rewards: 201.49923, mean: 0.09329
[32m[0906 18-11-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18226, current rewards: 206.16292, mean: 0.09329
[32m[0906 18-12-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18211, current rewards: 210.36290, mean: 0.09308
[32m[0906 18-12-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18217, current rewards: 214.55812, mean: 0.09288
[32m[0906 18-12-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18223, current rewards: 218.74378, mean: 0.09269
[32m[0906 18-12-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18230, current rewards: 222.93018, mean: 0.09250
[32m[0906 18-12-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18235, current rewards: 227.80629, mean: 0.09260
[32m[0906 18-12-53 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 18-12-53 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-12-53 @MBExp.py:227][0m Rewards obtained: [231.599495226087], Lows: [11], Highs: [20], Total time: 15184.912112999997
[32m[0906 18-14-03 @MBExp.py:144][0m ####################################################################
[32m[0906 18-14-03 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 18-14-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17308, current rewards: -7.90255, mean: -0.79026
[32m[0906 18-14-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17460, current rewards: -4.01547, mean: -0.06692
[32m[0906 18-14-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17469, current rewards: 0.65061, mean: 0.00591
[32m[0906 18-14-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17461, current rewards: 5.31940, mean: 0.03325
[32m[0906 18-14-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17584, current rewards: 9.98862, mean: 0.04756
[32m[0906 18-14-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17661, current rewards: 14.65622, mean: 0.05637
[32m[0906 18-14-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17720, current rewards: 19.32600, mean: 0.06234
[32m[0906 18-15-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17803, current rewards: 23.99198, mean: 0.06664
[32m[0906 18-15-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17898, current rewards: 29.22428, mean: 0.07128
[32m[0906 18-15-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17977, current rewards: 33.81341, mean: 0.07351
[32m[0906 18-15-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18025, current rewards: 38.40931, mean: 0.07531
[32m[0906 18-15-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18078, current rewards: 43.00654, mean: 0.07680
[32m[0906 18-15-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18105, current rewards: 47.59965, mean: 0.07803
[32m[0906 18-16-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18135, current rewards: 52.19163, mean: 0.07908
[32m[0906 18-16-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18165, current rewards: 56.78296, mean: 0.07998
[32m[0906 18-16-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18193, current rewards: 58.09776, mean: 0.07644
[32m[0906 18-16-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18215, current rewards: 55.65119, mean: 0.06871
[32m[0906 18-16-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18231, current rewards: 61.34683, mean: 0.07133
[32m[0906 18-16-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18246, current rewards: 67.01278, mean: 0.07364
[32m[0906 18-16-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18260, current rewards: 72.68149, mean: 0.07571
[32m[0906 18-17-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18278, current rewards: 78.35402, mean: 0.07758
[32m[0906 18-17-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18289, current rewards: 84.02619, mean: 0.07927
[32m[0906 18-17-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18298, current rewards: 89.69931, mean: 0.08081
[32m[0906 18-17-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18308, current rewards: 95.36789, mean: 0.08221
[32m[0906 18-17-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18315, current rewards: 102.42195, mean: 0.08465
[32m[0906 18-17-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18325, current rewards: 108.66571, mean: 0.08624
[32m[0906 18-18-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18329, current rewards: 102.01426, mean: 0.07787
[32m[0906 18-18-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18336, current rewards: 99.40652, mean: 0.07309
[32m[0906 18-18-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18345, current rewards: 104.63679, mean: 0.07421
[32m[0906 18-18-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18351, current rewards: 109.86906, mean: 0.07525
[32m[0906 18-18-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18355, current rewards: 115.10187, mean: 0.07623
[32m[0906 18-18-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18360, current rewards: 120.33349, mean: 0.07714
[32m[0906 18-18-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18366, current rewards: 125.55839, mean: 0.07799
[32m[0906 18-19-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18369, current rewards: 130.00548, mean: 0.07832
[32m[0906 18-19-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18374, current rewards: 135.01658, mean: 0.07896
[32m[0906 18-19-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18378, current rewards: 140.02501, mean: 0.07956
[32m[0906 18-19-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18380, current rewards: 145.03544, mean: 0.08013
[32m[0906 18-19-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18379, current rewards: 139.80315, mean: 0.07516
[32m[0906 18-19-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18356, current rewards: 144.45702, mean: 0.07563
[32m[0906 18-20-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18334, current rewards: 149.06783, mean: 0.07606
[32m[0906 18-20-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18313, current rewards: 153.67689, mean: 0.07646
[32m[0906 18-20-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18292, current rewards: 160.16208, mean: 0.07775
[32m[0906 18-20-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18274, current rewards: 164.66490, mean: 0.07804
[32m[0906 18-20-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18257, current rewards: 169.13749, mean: 0.07830
[32m[0906 18-20-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18239, current rewards: 173.60425, mean: 0.07855
[32m[0906 18-20-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18224, current rewards: 158.44164, mean: 0.07011
[32m[0906 18-21-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18230, current rewards: 163.59300, mean: 0.07082
[32m[0906 18-21-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18237, current rewards: 168.74398, mean: 0.07150
[32m[0906 18-21-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18244, current rewards: 173.89898, mean: 0.07216
[32m[0906 18-21-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18251, current rewards: 178.93266, mean: 0.07274
[32m[0906 18-21-40 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 18-21-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-21-40 @MBExp.py:227][0m Rewards obtained: [182.68737910711386], Lows: [20], Highs: [29], Total time: 15641.987774999996
[32m[0906 18-22-53 @MBExp.py:144][0m ####################################################################
[32m[0906 18-22-53 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 18-22-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17474, current rewards: -0.48947, mean: -0.04895
[32m[0906 18-23-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17514, current rewards: -3.30191, mean: -0.05503
[32m[0906 18-23-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17464, current rewards: 3.37106, mean: 0.03065
[32m[0906 18-23-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17447, current rewards: 10.05104, mean: 0.06282
[32m[0906 18-23-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17584, current rewards: 16.72920, mean: 0.07966
[32m[0906 18-23-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17674, current rewards: 23.40779, mean: 0.09003
[32m[0906 18-23-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17729, current rewards: 30.08609, mean: 0.09705
[32m[0906 18-23-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17815, current rewards: 36.76455, mean: 0.10212
[32m[0906 18-24-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17913, current rewards: 43.05713, mean: 0.10502
[32m[0906 18-24-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17981, current rewards: 49.15742, mean: 0.10686
[32m[0906 18-24-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18036, current rewards: 45.53050, mean: 0.08928
[32m[0906 18-24-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18089, current rewards: 54.25221, mean: 0.09688
[32m[0906 18-24-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18129, current rewards: 62.97988, mean: 0.10325
[32m[0906 18-24-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18158, current rewards: 71.70946, mean: 0.10865
[32m[0906 18-25-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18183, current rewards: 80.42974, mean: 0.11328
[32m[0906 18-25-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18200, current rewards: 89.15401, mean: 0.11731
[32m[0906 18-25-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18217, current rewards: 98.09290, mean: 0.12110
[32m[0906 18-25-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18231, current rewards: 92.65202, mean: 0.10773
[32m[0906 18-25-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18244, current rewards: 13.34993, mean: 0.01467
[32m[0906 18-25-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18258, current rewards: -86.65007, mean: -0.09026
[32m[0906 18-25-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18271, current rewards: -186.65007, mean: -0.18480
[32m[0906 18-26-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18284, current rewards: -286.65007, mean: -0.27042
[32m[0906 18-26-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18293, current rewards: -386.65007, mean: -0.34833
[32m[0906 18-26-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18301, current rewards: -415.72993, mean: -0.35839
[32m[0906 18-26-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18307, current rewards: -408.87103, mean: -0.33791
[32m[0906 18-26-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18319, current rewards: -402.10564, mean: -0.31913
[32m[0906 18-26-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18325, current rewards: -395.34174, mean: -0.30179
[32m[0906 18-27-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18331, current rewards: -388.57306, mean: -0.28572
[32m[0906 18-27-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18334, current rewards: -381.81040, mean: -0.27079
[32m[0906 18-27-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18339, current rewards: -375.04748, mean: -0.25688
[32m[0906 18-27-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18346, current rewards: -368.28124, mean: -0.24389
[32m[0906 18-27-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18352, current rewards: -363.18609, mean: -0.23281
[32m[0906 18-27-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18356, current rewards: -357.10964, mean: -0.22181
[32m[0906 18-27-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18360, current rewards: -350.84843, mean: -0.21135
[32m[0906 18-28-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18360, current rewards: -344.60026, mean: -0.20152
[32m[0906 18-28-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18365, current rewards: -338.35907, mean: -0.19225
[32m[0906 18-28-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18368, current rewards: -332.10748, mean: -0.18348
[32m[0906 18-28-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18362, current rewards: -325.86231, mean: -0.17519
[32m[0906 18-28-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18339, current rewards: -319.61485, mean: -0.16734
[32m[0906 18-28-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18317, current rewards: -332.49121, mean: -0.16964
[32m[0906 18-29-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18296, current rewards: -419.82025, mean: -0.20887
[32m[0906 18-29-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18275, current rewards: -412.01958, mean: -0.20001
[32m[0906 18-29-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18254, current rewards: -404.54322, mean: -0.19173
[32m[0906 18-29-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18236, current rewards: -397.06302, mean: -0.18383
[32m[0906 18-29-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18219, current rewards: -389.59044, mean: -0.17629
[32m[0906 18-29-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18204, current rewards: -382.10893, mean: -0.16907
[32m[0906 18-29-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18207, current rewards: -374.62386, mean: -0.16217
[32m[0906 18-30-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18215, current rewards: -367.14834, mean: -0.15557
[32m[0906 18-30-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18224, current rewards: -359.67707, mean: -0.14924
[32m[0906 18-30-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18231, current rewards: -348.37791, mean: -0.14162
[32m[0906 18-30-29 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 18-30-29 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-30-29 @MBExp.py:227][0m Rewards obtained: [-343.52986721785203], Lows: [323], Highs: [21], Total time: 16098.485978999995
[32m[0906 18-31-44 @MBExp.py:144][0m ####################################################################
[32m[0906 18-31-44 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 18-31-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17257, current rewards: 1.04401, mean: 0.10440
[32m[0906 18-31-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17397, current rewards: 6.93989, mean: 0.11566
[32m[0906 18-32-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17414, current rewards: 13.26491, mean: 0.12059
[32m[0906 18-32-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17420, current rewards: 19.58909, mean: 0.12243
[32m[0906 18-32-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17558, current rewards: 25.90723, mean: 0.12337
[32m[0906 18-32-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17650, current rewards: 32.23238, mean: 0.12397
[32m[0906 18-32-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17709, current rewards: 38.55055, mean: 0.12436
[32m[0906 18-32-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17803, current rewards: 44.79934, mean: 0.12444
[32m[0906 18-32-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17908, current rewards: 50.24358, mean: 0.12255
[32m[0906 18-33-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17980, current rewards: 56.53530, mean: 0.12290
[32m[0906 18-33-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18033, current rewards: 62.82594, mean: 0.12319
[32m[0906 18-33-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18078, current rewards: 69.11590, mean: 0.12342
[32m[0906 18-33-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18124, current rewards: 75.41056, mean: 0.12362
[32m[0906 18-33-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18155, current rewards: 81.70032, mean: 0.12379
[32m[0906 18-33-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18181, current rewards: 87.99370, mean: 0.12393
[32m[0906 18-34-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18205, current rewards: 82.85821, mean: 0.10902
[32m[0906 18-34-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18222, current rewards: 91.89025, mean: 0.11344
[32m[0906 18-34-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18238, current rewards: 98.76157, mean: 0.11484
[32m[0906 18-34-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18254, current rewards: 105.63345, mean: 0.11608
[32m[0906 18-34-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18267, current rewards: 112.50804, mean: 0.11720
[32m[0906 18-34-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18278, current rewards: 119.37534, mean: 0.11819
[32m[0906 18-34-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18288, current rewards: 126.24209, mean: 0.11910
[32m[0906 18-35-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18303, current rewards: 133.11110, mean: 0.11992
[32m[0906 18-35-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18313, current rewards: 139.97969, mean: 0.12067
[32m[0906 18-35-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18321, current rewards: 147.06166, mean: 0.12154
[32m[0906 18-35-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18330, current rewards: 153.90084, mean: 0.12214
[32m[0906 18-35-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18336, current rewards: 160.75601, mean: 0.12271
[32m[0906 18-35-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18340, current rewards: 167.60609, mean: 0.12324
[32m[0906 18-36-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18346, current rewards: 161.74950, mean: 0.11472
[32m[0906 18-36-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18353, current rewards: 164.80648, mean: 0.11288
[32m[0906 18-36-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18359, current rewards: 167.85601, mean: 0.11116
[32m[0906 18-36-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18363, current rewards: 170.90307, mean: 0.10955
[32m[0906 18-36-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18367, current rewards: 173.88376, mean: 0.10800
[32m[0906 18-36-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18372, current rewards: 156.57565, mean: 0.09432
[32m[0906 18-36-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18376, current rewards: 162.75685, mean: 0.09518
[32m[0906 18-37-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18381, current rewards: 168.99930, mean: 0.09602
[32m[0906 18-37-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18386, current rewards: 175.23657, mean: 0.09682
[32m[0906 18-37-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18376, current rewards: 181.47254, mean: 0.09757
[32m[0906 18-37-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18352, current rewards: 187.71736, mean: 0.09828
[32m[0906 18-37-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18329, current rewards: 193.95525, mean: 0.09896
[32m[0906 18-37-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18309, current rewards: 199.65251, mean: 0.09933
[32m[0906 18-38-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18289, current rewards: 205.60310, mean: 0.09981
[32m[0906 18-38-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18271, current rewards: 211.54162, mean: 0.10026
[32m[0906 18-38-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18253, current rewards: 217.47752, mean: 0.10068
[32m[0906 18-38-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18235, current rewards: 223.41219, mean: 0.10109
[32m[0906 18-38-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18220, current rewards: 221.39560, mean: 0.09796
[32m[0906 18-38-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18222, current rewards: 226.52827, mean: 0.09806
[32m[0906 18-38-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18229, current rewards: 231.66685, mean: 0.09816
[32m[0906 18-39-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18236, current rewards: 237.82968, mean: 0.09868
[32m[0906 18-39-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18242, current rewards: 244.96228, mean: 0.09958
[32m[0906 18-39-21 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 18-39-21 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-39-21 @MBExp.py:227][0m Rewards obtained: [238.52439968082396], Lows: [10], Highs: [40], Total time: 16555.378024999995
[32m[0906 18-40-38 @MBExp.py:144][0m ####################################################################
[32m[0906 18-40-38 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 18-40-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17399, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-40-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17417, current rewards: -4.89410, mean: -0.08157
[32m[0906 18-40-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17453, current rewards: 0.49043, mean: 0.00446
[32m[0906 18-41-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17448, current rewards: 5.87201, mean: 0.03670
[32m[0906 18-41-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17572, current rewards: 11.26012, mean: 0.05362
[32m[0906 18-41-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17669, current rewards: 16.64119, mean: 0.06400
[32m[0906 18-41-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17728, current rewards: 22.02672, mean: 0.07105
[32m[0906 18-41-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17835, current rewards: 26.89219, mean: 0.07470
[32m[0906 18-41-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17928, current rewards: 32.05180, mean: 0.07818
[32m[0906 18-42-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17992, current rewards: 37.20262, mean: 0.08088
[32m[0906 18-42-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18049, current rewards: 42.35413, mean: 0.08305
[32m[0906 18-42-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18092, current rewards: 47.51366, mean: 0.08485
[32m[0906 18-42-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18130, current rewards: 52.66554, mean: 0.08634
[32m[0906 18-42-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18163, current rewards: 57.82097, mean: 0.08761
[32m[0906 18-42-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18193, current rewards: 62.97560, mean: 0.08870
[32m[0906 18-42-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18212, current rewards: 70.64179, mean: 0.09295
[32m[0906 18-43-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18228, current rewards: 76.96534, mean: 0.09502
[32m[0906 18-43-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18247, current rewards: 61.30510, mean: 0.07129
[32m[0906 18-43-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18261, current rewards: 66.79939, mean: 0.07341
[32m[0906 18-43-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18279, current rewards: 72.29417, mean: 0.07531
[32m[0906 18-43-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18290, current rewards: 77.78891, mean: 0.07702
[32m[0906 18-43-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18300, current rewards: 83.28354, mean: 0.07857
[32m[0906 18-44-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18308, current rewards: 88.77829, mean: 0.07998
[32m[0906 18-44-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18318, current rewards: 94.27287, mean: 0.08127
[32m[0906 18-44-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18325, current rewards: 99.32221, mean: 0.08208
[32m[0906 18-44-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18330, current rewards: 104.80047, mean: 0.08317
[32m[0906 18-44-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18333, current rewards: 110.27846, mean: 0.08418
[32m[0906 18-44-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18340, current rewards: 106.87915, mean: 0.07859
[32m[0906 18-44-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18343, current rewards: 108.28099, mean: 0.07680
[32m[0906 18-45-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18347, current rewards: 113.18595, mean: 0.07752
[32m[0906 18-45-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18349, current rewards: 118.08454, mean: 0.07820
[32m[0906 18-45-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18351, current rewards: 122.98562, mean: 0.07884
[32m[0906 18-45-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18360, current rewards: 127.88180, mean: 0.07943
[32m[0906 18-45-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18362, current rewards: 112.83257, mean: 0.06797
[32m[0906 18-45-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18365, current rewards: 118.00283, mean: 0.06901
[32m[0906 18-46-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18369, current rewards: 123.17590, mean: 0.06999
[32m[0906 18-46-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18372, current rewards: 128.34619, mean: 0.07091
[32m[0906 18-46-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18360, current rewards: 133.51721, mean: 0.07178
[32m[0906 18-46-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18336, current rewards: 117.83316, mean: 0.06169
[32m[0906 18-46-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18315, current rewards: 123.70980, mean: 0.06312
[32m[0906 18-46-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18293, current rewards: 128.78343, mean: 0.06407
[32m[0906 18-46-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18272, current rewards: 134.08691, mean: 0.06509
[32m[0906 18-47-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18254, current rewards: 139.39258, mean: 0.06606
[32m[0906 18-47-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18234, current rewards: 133.25135, mean: 0.06169
[32m[0906 18-47-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18217, current rewards: 137.84011, mean: 0.06237
[32m[0906 18-47-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18203, current rewards: 142.42123, mean: 0.06302
[32m[0906 18-47-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18203, current rewards: 147.00646, mean: 0.06364
[32m[0906 18-47-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18214, current rewards: 151.59199, mean: 0.06423
[32m[0906 18-47-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18222, current rewards: 157.22183, mean: 0.06524
[32m[0906 18-48-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18228, current rewards: 162.16927, mean: 0.06592
[32m[0906 18-48-14 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 18-48-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-48-14 @MBExp.py:227][0m Rewards obtained: [166.12674610047452], Lows: [31], Highs: [31], Total time: 17011.862694999996
[32m[0906 18-49-33 @MBExp.py:144][0m ####################################################################
[32m[0906 18-49-33 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 18-49-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17389, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-49-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17514, current rewards: -6.25000, mean: -0.10417
[32m[0906 18-49-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17516, current rewards: -0.98316, mean: -0.00894
[32m[0906 18-50-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17499, current rewards: 4.28599, mean: 0.02679
[32m[0906 18-50-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17605, current rewards: 9.55715, mean: 0.04551
[32m[0906 18-50-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17677, current rewards: 14.82764, mean: 0.05703
[32m[0906 18-50-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17737, current rewards: 20.14923, mean: 0.06500
[32m[0906 18-50-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17855, current rewards: 25.62842, mean: 0.07119
[32m[0906 18-50-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17938, current rewards: 30.84090, mean: 0.07522
[32m[0906 18-50-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18000, current rewards: 36.05369, mean: 0.07838
[32m[0906 18-51-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18052, current rewards: 41.26944, mean: 0.08092
[32m[0906 18-51-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18094, current rewards: 46.48022, mean: 0.08300
[32m[0906 18-51-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18129, current rewards: 51.69125, mean: 0.08474
[32m[0906 18-51-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18153, current rewards: 56.90663, mean: 0.08622
[32m[0906 18-51-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18176, current rewards: 55.88023, mean: 0.07870
[32m[0906 18-51-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18209, current rewards: 74.03071, mean: 0.09741
[32m[0906 18-52-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18235, current rewards: 87.83578, mean: 0.10844
[32m[0906 18-52-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18250, current rewards: 101.56609, mean: 0.11810
[32m[0906 18-52-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18263, current rewards: 115.26266, mean: 0.12666
[32m[0906 18-52-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18274, current rewards: 128.92369, mean: 0.13430
[32m[0906 18-52-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18285, current rewards: 133.81355, mean: 0.13249
[32m[0906 18-52-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18298, current rewards: 138.82770, mean: 0.13097
[32m[0906 18-52-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18305, current rewards: 143.83729, mean: 0.12958
[32m[0906 18-53-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18311, current rewards: 149.83660, mean: 0.12917
[32m[0906 18-53-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18319, current rewards: 154.98503, mean: 0.12809
[32m[0906 18-53-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18327, current rewards: 160.13709, mean: 0.12709
[32m[0906 18-53-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18334, current rewards: 154.77170, mean: 0.11815
[32m[0906 18-53-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18343, current rewards: 149.85439, mean: 0.11019
[32m[0906 18-53-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18352, current rewards: 155.32251, mean: 0.11016
[32m[0906 18-54-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18359, current rewards: 160.79175, mean: 0.11013
[32m[0906 18-54-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18364, current rewards: 166.25560, mean: 0.11010
[32m[0906 18-54-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18369, current rewards: 170.72470, mean: 0.10944
[32m[0906 18-54-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18373, current rewards: 154.85373, mean: 0.09618
[32m[0906 18-54-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18374, current rewards: 159.64447, mean: 0.09617
[32m[0906 18-54-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18379, current rewards: 164.43478, mean: 0.09616
[32m[0906 18-54-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18382, current rewards: 169.22833, mean: 0.09615
[32m[0906 18-55-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18381, current rewards: 174.01525, mean: 0.09614
[32m[0906 18-55-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18369, current rewards: 178.80632, mean: 0.09613
[32m[0906 18-55-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18346, current rewards: 183.59654, mean: 0.09612
[32m[0906 18-55-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18324, current rewards: 188.33953, mean: 0.09609
[32m[0906 18-55-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18302, current rewards: 182.12788, mean: 0.09061
[32m[0906 18-55-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18282, current rewards: 187.30295, mean: 0.09092
[32m[0906 18-55-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18263, current rewards: 192.48954, mean: 0.09123
[32m[0906 18-56-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18248, current rewards: 197.67037, mean: 0.09151
[32m[0906 18-56-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18230, current rewards: 202.84915, mean: 0.09179
[32m[0906 18-56-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18217, current rewards: 208.03109, mean: 0.09205
[32m[0906 18-56-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18214, current rewards: 213.21336, mean: 0.09230
[32m[0906 18-56-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18224, current rewards: 218.39745, mean: 0.09254
[32m[0906 18-56-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18229, current rewards: 224.79047, mean: 0.09327
[32m[0906 18-57-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18237, current rewards: 241.51037, mean: 0.09817
[32m[0906 18-57-09 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 18-57-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-57-09 @MBExp.py:227][0m Rewards obtained: [254.62829331366223], Lows: [20], Highs: [31], Total time: 17468.577615999995
[32m[0906 18-58-30 @MBExp.py:144][0m ####################################################################
[32m[0906 18-58-30 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 18-58-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17402, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-58-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17452, current rewards: -5.93079, mean: -0.09885
[32m[0906 18-58-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17447, current rewards: -0.62982, mean: -0.00573
[32m[0906 18-58-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17434, current rewards: 4.66958, mean: 0.02918
[32m[0906 18-59-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17554, current rewards: 9.97246, mean: 0.04749
[32m[0906 18-59-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17652, current rewards: 15.27697, mean: 0.05876
[32m[0906 18-59-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17702, current rewards: 20.45946, mean: 0.06600
[32m[0906 18-59-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17829, current rewards: 25.76274, mean: 0.07156
[32m[0906 18-59-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17924, current rewards: 31.07469, mean: 0.07579
[32m[0906 18-59-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17993, current rewards: 36.38317, mean: 0.07909
[32m[0906 19-00-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18041, current rewards: 41.68868, mean: 0.08174
[32m[0906 19-00-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18085, current rewards: 47.00036, mean: 0.08393
[32m[0906 19-00-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18126, current rewards: 52.31268, mean: 0.08576
[32m[0906 19-00-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18157, current rewards: 36.44795, mean: 0.05522
[32m[0906 19-00-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18188, current rewards: 44.15324, mean: 0.06219
[32m[0906 19-00-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18213, current rewards: 50.03091, mean: 0.06583
[32m[0906 19-00-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18232, current rewards: 55.90236, mean: 0.06902
[32m[0906 19-01-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18249, current rewards: 61.77601, mean: 0.07183
[32m[0906 19-01-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18258, current rewards: 67.64975, mean: 0.07434
[32m[0906 19-01-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18268, current rewards: 73.52117, mean: 0.07658
[32m[0906 19-01-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18282, current rewards: 79.39558, mean: 0.07861
[32m[0906 19-01-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18291, current rewards: 85.26698, mean: 0.08044
[32m[0906 19-01-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18300, current rewards: 79.01799, mean: 0.07119
[32m[0906 19-02-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18310, current rewards: 84.48002, mean: 0.07283
[32m[0906 19-02-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18315, current rewards: 89.70680, mean: 0.07414
[32m[0906 19-02-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18325, current rewards: 94.93467, mean: 0.07534
[32m[0906 19-02-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18331, current rewards: 100.15976, mean: 0.07646
[32m[0906 19-02-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18335, current rewards: 105.39126, mean: 0.07749
[32m[0906 19-02-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18341, current rewards: 110.61926, mean: 0.07845
[32m[0906 19-02-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18345, current rewards: 115.84904, mean: 0.07935
[32m[0906 19-03-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18350, current rewards: 100.13184, mean: 0.06631
[32m[0906 19-03-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18354, current rewards: 105.67869, mean: 0.06774
[32m[0906 19-03-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18356, current rewards: 110.92280, mean: 0.06890
[32m[0906 19-03-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18360, current rewards: 116.16430, mean: 0.06998
[32m[0906 19-03-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18362, current rewards: 121.41204, mean: 0.07100
[32m[0906 19-03-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18367, current rewards: 126.65369, mean: 0.07196
[32m[0906 19-04-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18360, current rewards: 131.89200, mean: 0.07287
[32m[0906 19-04-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18344, current rewards: 137.13663, mean: 0.07373
[32m[0906 19-04-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18322, current rewards: 142.38402, mean: 0.07455
[32m[0906 19-04-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18301, current rewards: 142.90923, mean: 0.07291
[32m[0906 19-04-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18280, current rewards: 131.44689, mean: 0.06540
[32m[0906 19-04-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18260, current rewards: 136.61768, mean: 0.06632
[32m[0906 19-04-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18242, current rewards: 141.78602, mean: 0.06720
[32m[0906 19-05-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18223, current rewards: 146.95491, mean: 0.06803
[32m[0906 19-05-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18207, current rewards: 152.12928, mean: 0.06884
[32m[0906 19-05-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18196, current rewards: 157.30544, mean: 0.06960
[32m[0906 19-05-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18191, current rewards: 162.47815, mean: 0.07034
[32m[0906 19-05-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18199, current rewards: 167.09598, mean: 0.07080
[32m[0906 19-05-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18206, current rewards: 172.19053, mean: 0.07145
[32m[0906 19-05-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18214, current rewards: 177.27761, mean: 0.07206
[32m[0906 19-06-06 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 19-06-06 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-06-06 @MBExp.py:227][0m Rewards obtained: [181.34829899984538], Lows: [30], Highs: [22], Total time: 17924.762828999996
[32m[0906 19-07-29 @MBExp.py:144][0m ####################################################################
[32m[0906 19-07-29 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 19-07-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17523, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-07-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17481, current rewards: -6.52165, mean: -0.10869
[32m[0906 19-07-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17470, current rewards: -1.76594, mean: -0.01605
[32m[0906 19-07-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17470, current rewards: 2.99201, mean: 0.01870
[32m[0906 19-08-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17590, current rewards: 7.75142, mean: 0.03691
[32m[0906 19-08-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17672, current rewards: 12.64178, mean: 0.04862
[32m[0906 19-08-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17720, current rewards: 17.79718, mean: 0.05741
[32m[0906 19-08-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17847, current rewards: 22.58214, mean: 0.06273
[32m[0906 19-08-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17943, current rewards: 0.97207, mean: 0.00237
[32m[0906 19-08-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18000, current rewards: 9.53264, mean: 0.02072
[32m[0906 19-09-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18049, current rewards: 17.18772, mean: 0.03370
[32m[0906 19-09-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18091, current rewards: 24.84280, mean: 0.04436
[32m[0906 19-09-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18126, current rewards: 32.49788, mean: 0.05328
[32m[0906 19-09-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18156, current rewards: 40.15297, mean: 0.06084
[32m[0906 19-09-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18182, current rewards: 45.55724, mean: 0.06417
[32m[0906 19-09-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18204, current rewards: 51.07298, mean: 0.06720
[32m[0906 19-09-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18221, current rewards: 45.61792, mean: 0.05632
[32m[0906 19-10-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18237, current rewards: 49.44162, mean: 0.05749
[32m[0906 19-10-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18256, current rewards: 54.63909, mean: 0.06004
[32m[0906 19-10-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18270, current rewards: 59.83529, mean: 0.06233
[32m[0906 19-10-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18285, current rewards: 65.02945, mean: 0.06439
[32m[0906 19-10-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18304, current rewards: 70.22239, mean: 0.06625
[32m[0906 19-10-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18315, current rewards: 74.98488, mean: 0.06755
[32m[0906 19-11-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18327, current rewards: 81.17139, mean: 0.06998
[32m[0906 19-11-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18335, current rewards: 87.39954, mean: 0.07223
[32m[0906 19-11-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18344, current rewards: 93.65723, mean: 0.07433
[32m[0906 19-11-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18349, current rewards: 99.95079, mean: 0.07630
[32m[0906 19-11-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18357, current rewards: 105.03720, mean: 0.07723
[32m[0906 19-11-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18360, current rewards: 110.02208, mean: 0.07803
[32m[0906 19-11-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18365, current rewards: 115.01261, mean: 0.07878
[32m[0906 19-12-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18370, current rewards: 119.78594, mean: 0.07933
[32m[0906 19-12-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18374, current rewards: 124.78381, mean: 0.07999
[32m[0906 19-12-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18380, current rewards: 129.79218, mean: 0.08062
[32m[0906 19-12-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18380, current rewards: 134.80014, mean: 0.08120
[32m[0906 19-12-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18383, current rewards: 139.80742, mean: 0.08176
[32m[0906 19-12-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18386, current rewards: 144.81620, mean: 0.08228
[32m[0906 19-13-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18376, current rewards: 149.82411, mean: 0.08278
[32m[0906 19-13-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18361, current rewards: 154.82779, mean: 0.08324
[32m[0906 19-13-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18338, current rewards: 140.49606, mean: 0.07356
[32m[0906 19-13-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18315, current rewards: 146.46325, mean: 0.07473
[32m[0906 19-13-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18294, current rewards: 151.63685, mean: 0.07544
[32m[0906 19-13-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18274, current rewards: 156.80647, mean: 0.07612
[32m[0906 19-13-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18255, current rewards: 150.79653, mean: 0.07147
[32m[0906 19-14-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18239, current rewards: 155.88029, mean: 0.07217
[32m[0906 19-14-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18221, current rewards: 160.96349, mean: 0.07283
[32m[0906 19-14-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18213, current rewards: 166.05077, mean: 0.07347
[32m[0906 19-14-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18209, current rewards: 171.13644, mean: 0.07409
[32m[0906 19-14-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18216, current rewards: 175.83452, mean: 0.07451
[32m[0906 19-14-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18225, current rewards: 180.83468, mean: 0.07504
[32m[0906 19-14-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18233, current rewards: 185.83194, mean: 0.07554
[32m[0906 19-15-06 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 19-15-06 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-15-06 @MBExp.py:227][0m Rewards obtained: [169.46678848954838], Lows: [34], Highs: [32], Total time: 18381.417416999997
[32m[0906 19-16-31 @MBExp.py:144][0m ####################################################################
[32m[0906 19-16-31 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 19-16-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17529, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-16-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17499, current rewards: -25.31784, mean: -0.42196
[32m[0906 19-16-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17483, current rewards: -15.98695, mean: -0.14534
[32m[0906 19-16-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17477, current rewards: -6.64053, mean: -0.04150
[32m[0906 19-17-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17596, current rewards: 2.68854, mean: 0.01280
[32m[0906 19-17-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17674, current rewards: 13.73363, mean: 0.05282
[32m[0906 19-17-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17740, current rewards: 21.04395, mean: 0.06788
[32m[0906 19-17-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17854, current rewards: 8.59546, mean: 0.02388
[32m[0906 19-17-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17949, current rewards: 15.52898, mean: 0.03788
[32m[0906 19-17-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18015, current rewards: 22.45818, mean: 0.04882
[32m[0906 19-18-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18063, current rewards: 28.40756, mean: 0.05570
[32m[0906 19-18-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18104, current rewards: 35.52208, mean: 0.06343
[32m[0906 19-18-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18137, current rewards: 42.74624, mean: 0.07008
[32m[0906 19-18-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18170, current rewards: 49.20911, mean: 0.07456
[32m[0906 19-18-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18196, current rewards: 56.82554, mean: 0.08004
[32m[0906 19-18-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18216, current rewards: 65.57568, mean: 0.08628
[32m[0906 19-18-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18236, current rewards: 74.28898, mean: 0.09171
[32m[0906 19-19-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18260, current rewards: 82.99490, mean: 0.09651
[32m[0906 19-19-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18276, current rewards: 91.73957, mean: 0.10081
[32m[0906 19-19-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18288, current rewards: 100.45424, mean: 0.10464
[32m[0906 19-19-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18299, current rewards: 109.21427, mean: 0.10813
[32m[0906 19-19-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18310, current rewards: 117.94336, mean: 0.11127
[32m[0906 19-19-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18318, current rewards: 107.58326, mean: 0.09692
[32m[0906 19-20-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18322, current rewards: 114.90636, mean: 0.09906
[32m[0906 19-20-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18326, current rewards: 100.36835, mean: 0.08295
[32m[0906 19-20-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18334, current rewards: 107.09448, mean: 0.08500
[32m[0906 19-20-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18340, current rewards: 113.82692, mean: 0.08689
[32m[0906 19-20-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18347, current rewards: 120.55937, mean: 0.08865
[32m[0906 19-20-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18354, current rewards: 127.28389, mean: 0.09027
[32m[0906 19-20-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18359, current rewards: 134.00781, mean: 0.09179
[32m[0906 19-21-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18366, current rewards: 140.34115, mean: 0.09294
[32m[0906 19-21-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18373, current rewards: 124.12642, mean: 0.07957
[32m[0906 19-21-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18377, current rewards: 131.21369, mean: 0.08150
[32m[0906 19-21-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18380, current rewards: 138.30020, mean: 0.08331
[32m[0906 19-21-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18382, current rewards: 145.38134, mean: 0.08502
[32m[0906 19-21-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18377, current rewards: 152.46364, mean: 0.08663
[32m[0906 19-22-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18367, current rewards: 159.54663, mean: 0.08815
[32m[0906 19-22-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18350, current rewards: 149.30102, mean: 0.08027
[32m[0906 19-22-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18326, current rewards: 121.79768, mean: 0.06377
[32m[0906 19-22-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18303, current rewards: 82.70343, mean: 0.04220
[32m[0906 19-22-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18283, current rewards: 44.34059, mean: 0.02206
[32m[0906 19-22-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18263, current rewards: 5.41091, mean: 0.00263
[32m[0906 19-22-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18243, current rewards: -32.98490, mean: -0.01563
[32m[0906 19-23-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18224, current rewards: -71.16499, mean: -0.03295
[32m[0906 19-23-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18208, current rewards: -108.91741, mean: -0.04928
[32m[0906 19-23-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18202, current rewards: -146.87876, mean: -0.06499
[32m[0906 19-23-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18198, current rewards: -185.02001, mean: -0.08010
[32m[0906 19-23-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18202, current rewards: -223.48186, mean: -0.09470
[32m[0906 19-23-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18209, current rewards: -261.38709, mean: -0.10846
[32m[0906 19-23-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18217, current rewards: -299.38428, mean: -0.12170
[32m[0906 19-24-07 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 19-24-07 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-24-07 @MBExp.py:227][0m Rewards obtained: [-334.04159588067665], Lows: [334], Highs: [21], Total time: 18837.670145999997
[32m[0906 19-25-34 @MBExp.py:144][0m ####################################################################
[32m[0906 19-25-34 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 19-25-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17292, current rewards: -2.61847, mean: -0.26185
[32m[0906 19-25-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17474, current rewards: 4.84729, mean: 0.08079
[32m[0906 19-25-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17459, current rewards: 10.35230, mean: 0.09411
[32m[0906 19-26-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17477, current rewards: 15.86098, mean: 0.09913
[32m[0906 19-26-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17580, current rewards: 21.36779, mean: 0.10175
[32m[0906 19-26-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17668, current rewards: 28.34513, mean: 0.10902
[32m[0906 19-26-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17734, current rewards: -12.54661, mean: -0.04047
[32m[0906 19-26-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17848, current rewards: -62.54661, mean: -0.17374
[32m[0906 19-26-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17926, current rewards: -112.54661, mean: -0.27450
[32m[0906 19-26-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17994, current rewards: -162.54661, mean: -0.35336
[32m[0906 19-27-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18044, current rewards: -212.54661, mean: -0.41676
[32m[0906 19-27-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18092, current rewards: -262.54661, mean: -0.46883
[32m[0906 19-27-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18130, current rewards: -312.54661, mean: -0.51237
[32m[0906 19-27-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18162, current rewards: -362.54661, mean: -0.54931
[32m[0906 19-27-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18186, current rewards: -412.54661, mean: -0.58105
[32m[0906 19-27-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18205, current rewards: -462.54661, mean: -0.60861
[32m[0906 19-28-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18223, current rewards: -512.54661, mean: -0.63277
[32m[0906 19-28-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18238, current rewards: -562.54661, mean: -0.65412
[32m[0906 19-28-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18251, current rewards: -612.54661, mean: -0.67313
[32m[0906 19-28-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18258, current rewards: -662.54661, mean: -0.69015
[32m[0906 19-28-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18268, current rewards: -712.54661, mean: -0.70549
[32m[0906 19-28-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18278, current rewards: -762.54661, mean: -0.71938
[32m[0906 19-28-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18285, current rewards: -812.54661, mean: -0.73202
[32m[0906 19-29-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18297, current rewards: -862.54661, mean: -0.74357
[32m[0906 19-29-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18303, current rewards: -912.54661, mean: -0.75417
[32m[0906 19-29-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18309, current rewards: -962.54661, mean: -0.76393
[32m[0906 19-29-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18317, current rewards: -1012.54661, mean: -0.77294
[32m[0906 19-29-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18324, current rewards: -1062.54661, mean: -0.78128
[32m[0906 19-29-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18330, current rewards: -1112.54661, mean: -0.78904
[32m[0906 19-30-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18334, current rewards: -1162.54661, mean: -0.79626
[32m[0906 19-30-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18338, current rewards: -1212.54661, mean: -0.80301
[32m[0906 19-30-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18341, current rewards: -1262.54661, mean: -0.80932
[32m[0906 19-30-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18345, current rewards: -1312.54661, mean: -0.81525
[32m[0906 19-30-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18350, current rewards: -1362.54661, mean: -0.82081
[32m[0906 19-30-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18354, current rewards: -1412.54661, mean: -0.82605
[32m[0906 19-30-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18348, current rewards: -1462.54661, mean: -0.83099
[32m[0906 19-31-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18339, current rewards: -1512.54661, mean: -0.83566
[32m[0906 19-31-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18323, current rewards: -1562.54661, mean: -0.84008
[32m[0906 19-31-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18301, current rewards: -1612.54661, mean: -0.84427
[32m[0906 19-31-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18279, current rewards: -1662.54661, mean: -0.84824
[32m[0906 19-31-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18261, current rewards: -1712.54661, mean: -0.85201
[32m[0906 19-31-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18243, current rewards: -1762.54661, mean: -0.85561
[32m[0906 19-31-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18225, current rewards: -1812.54661, mean: -0.85903
[32m[0906 19-32-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18208, current rewards: -1862.54661, mean: -0.86229
[32m[0906 19-32-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18192, current rewards: -1912.54661, mean: -0.86541
[32m[0906 19-32-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18186, current rewards: -1962.54661, mean: -0.86838
[32m[0906 19-32-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18181, current rewards: -2012.54661, mean: -0.87123
[32m[0906 19-32-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18184, current rewards: -2062.54661, mean: -0.87396
[32m[0906 19-32-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18191, current rewards: -2112.54661, mean: -0.87658
[32m[0906 19-33-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18199, current rewards: -2162.54661, mean: -0.87908
[32m[0906 19-33-09 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 19-33-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-33-10 @MBExp.py:227][0m Rewards obtained: [-2202.5466094142726], Lows: [0], Highs: [2235], Total time: 19293.486940999996
[32m[0906 19-34-38 @MBExp.py:144][0m ####################################################################
[32m[0906 19-34-38 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 19-34-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17373, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-34-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17466, current rewards: -107.94400, mean: -1.79907
[32m[0906 19-34-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17468, current rewards: -207.94400, mean: -1.89040
[32m[0906 19-35-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17470, current rewards: -307.94400, mean: -1.92465
[32m[0906 19-35-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17582, current rewards: -407.94400, mean: -1.94259
[32m[0906 19-35-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17674, current rewards: -507.94400, mean: -1.95363
[32m[0906 19-35-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17750, current rewards: -607.94400, mean: -1.96111
[32m[0906 19-35-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17872, current rewards: -707.94400, mean: -1.96651
[32m[0906 19-35-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17964, current rewards: -731.51080, mean: -1.78417
[32m[0906 19-36-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18039, current rewards: -722.45737, mean: -1.57056
[32m[0906 19-36-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18090, current rewards: -713.40394, mean: -1.39883
[32m[0906 19-36-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18127, current rewards: -720.88547, mean: -1.28730
[32m[0906 19-36-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18160, current rewards: -770.88547, mean: -1.26375
[32m[0906 19-36-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18197, current rewards: -820.88547, mean: -1.24377
[32m[0906 19-36-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18221, current rewards: -870.88547, mean: -1.22660
[32m[0906 19-36-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18243, current rewards: -920.88547, mean: -1.21169
[32m[0906 19-37-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18263, current rewards: -970.88547, mean: -1.19862
[32m[0906 19-37-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18281, current rewards: -1020.88547, mean: -1.18708
[32m[0906 19-37-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18296, current rewards: -1070.88547, mean: -1.17680
[32m[0906 19-37-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18309, current rewards: -1120.88547, mean: -1.16759
[32m[0906 19-37-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18325, current rewards: -1170.88547, mean: -1.15929
[32m[0906 19-37-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18334, current rewards: -1220.88547, mean: -1.15178
[32m[0906 19-38-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18348, current rewards: -1270.88547, mean: -1.14494
[32m[0906 19-38-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18354, current rewards: -1320.88547, mean: -1.13869
[32m[0906 19-38-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18360, current rewards: -1370.88547, mean: -1.13296
[32m[0906 19-38-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18366, current rewards: -1420.88547, mean: -1.12769
[32m[0906 19-38-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18372, current rewards: -1470.88547, mean: -1.12281
[32m[0906 19-38-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18377, current rewards: -1520.88547, mean: -1.11830
[32m[0906 19-38-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18380, current rewards: -1570.88547, mean: -1.11410
[32m[0906 19-39-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18384, current rewards: -1620.88547, mean: -1.11020
[32m[0906 19-39-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18389, current rewards: -1670.88547, mean: -1.10655
[32m[0906 19-39-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18393, current rewards: -1720.88547, mean: -1.10313
[32m[0906 19-39-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18397, current rewards: -1770.88547, mean: -1.09993
[32m[0906 19-39-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18402, current rewards: -1820.88547, mean: -1.09692
[32m[0906 19-39-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18403, current rewards: -1870.88547, mean: -1.09409
[32m[0906 19-40-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18394, current rewards: -1920.88547, mean: -1.09141
[32m[0906 19-40-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18387, current rewards: -1970.88547, mean: -1.08889
[32m[0906 19-40-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18369, current rewards: -2020.88547, mean: -1.08650
[32m[0906 19-40-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18346, current rewards: -2070.88547, mean: -1.08423
[32m[0906 19-40-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18324, current rewards: -2120.88547, mean: -1.08208
[32m[0906 19-40-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18303, current rewards: -2170.88547, mean: -1.08004
[32m[0906 19-40-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18282, current rewards: -2220.88547, mean: -1.07810
[32m[0906 19-41-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18263, current rewards: -2270.88547, mean: -1.07625
[32m[0906 19-41-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18244, current rewards: -2320.88547, mean: -1.07448
[32m[0906 19-41-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18227, current rewards: -2370.88547, mean: -1.07280
[32m[0906 19-41-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18222, current rewards: -2420.88547, mean: -1.07119
[32m[0906 19-41-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18219, current rewards: -2470.88547, mean: -1.06965
[32m[0906 19-41-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18221, current rewards: -2520.88547, mean: -1.06817
[32m[0906 19-41-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18228, current rewards: -2570.88547, mean: -1.06676
[32m[0906 19-42-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18235, current rewards: -2620.88547, mean: -1.06540
[32m[0906 19-42-15 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 19-42-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-42-15 @MBExp.py:227][0m Rewards obtained: [-2660.8854665718195], Lows: [364], Highs: [1964], Total time: 19750.232121999994
[32m[0906 19-43-46 @MBExp.py:144][0m ####################################################################
[32m[0906 19-43-46 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 19-43-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17481, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-43-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17487, current rewards: -6.52391, mean: -0.10873
[32m[0906 19-44-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17489, current rewards: -1.34307, mean: -0.01221
[32m[0906 19-44-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17503, current rewards: 4.21886, mean: 0.02637
[32m[0906 19-44-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17634, current rewards: 9.49294, mean: 0.04520
[32m[0906 19-44-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17713, current rewards: 14.64226, mean: 0.05632
[32m[0906 19-44-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17801, current rewards: 19.78089, mean: 0.06381
[32m[0906 19-44-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17912, current rewards: 24.93099, mean: 0.06925
[32m[0906 19-45-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17998, current rewards: 30.07493, mean: 0.07335
[32m[0906 19-45-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18065, current rewards: 35.22247, mean: 0.07657
[32m[0906 19-45-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18116, current rewards: 40.37132, mean: 0.07916
[32m[0906 19-45-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18154, current rewards: 45.58751, mean: 0.08141
[32m[0906 19-45-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18184, current rewards: 40.79392, mean: 0.06688
[32m[0906 19-45-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18209, current rewards: 46.07864, mean: 0.06982
[32m[0906 19-45-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18238, current rewards: 51.36210, mean: 0.07234
[32m[0906 19-46-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18254, current rewards: 56.64580, mean: 0.07453
[32m[0906 19-46-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18273, current rewards: 61.92942, mean: 0.07646
[32m[0906 19-46-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18297, current rewards: 46.86133, mean: 0.05449
[32m[0906 19-46-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18313, current rewards: 52.68304, mean: 0.05789
[32m[0906 19-46-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18326, current rewards: 58.50750, mean: 0.06095
[32m[0906 19-46-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18336, current rewards: 63.48355, mean: 0.06285
[32m[0906 19-47-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18348, current rewards: 69.10218, mean: 0.06519
[32m[0906 19-47-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18356, current rewards: 74.72516, mean: 0.06732
[32m[0906 19-47-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18362, current rewards: 80.35187, mean: 0.06927
[32m[0906 19-47-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18368, current rewards: 85.97665, mean: 0.07106
[32m[0906 19-47-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18373, current rewards: 91.59995, mean: 0.07270
[32m[0906 19-47-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18378, current rewards: 97.22436, mean: 0.07422
[32m[0906 19-47-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18385, current rewards: 102.84812, mean: 0.07562
[32m[0906 19-48-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18386, current rewards: 107.94498, mean: 0.07656
[32m[0906 19-48-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18390, current rewards: 113.18195, mean: 0.07752
[32m[0906 19-48-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18393, current rewards: 118.41166, mean: 0.07842
[32m[0906 19-48-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18399, current rewards: 123.64452, mean: 0.07926
[32m[0906 19-48-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18401, current rewards: 122.56269, mean: 0.07613
[32m[0906 19-48-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18405, current rewards: 113.35383, mean: 0.06829
[32m[0906 19-49-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18400, current rewards: 118.88510, mean: 0.06952
[32m[0906 19-49-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18390, current rewards: 124.41755, mean: 0.07069
[32m[0906 19-49-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18380, current rewards: 129.95080, mean: 0.07180
[32m[0906 19-49-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18360, current rewards: 135.48249, mean: 0.07284
[32m[0906 19-49-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18338, current rewards: 141.01366, mean: 0.07383
[32m[0906 19-49-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18317, current rewards: 146.54426, mean: 0.07477
[32m[0906 19-49-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18296, current rewards: 152.08270, mean: 0.07566
[32m[0906 19-50-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18277, current rewards: 157.60833, mean: 0.07651
[32m[0906 19-50-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18258, current rewards: 163.13916, mean: 0.07732
[32m[0906 19-50-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18241, current rewards: 168.66768, mean: 0.07809
[32m[0906 19-50-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18225, current rewards: 175.35069, mean: 0.07934
[32m[0906 19-50-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18224, current rewards: 158.09915, mean: 0.06996
[32m[0906 19-50-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18220, current rewards: 166.49457, mean: 0.07208
[32m[0906 19-50-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18220, current rewards: 174.23399, mean: 0.07383
[32m[0906 19-51-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18228, current rewards: 181.97307, mean: 0.07551
[32m[0906 19-51-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18236, current rewards: 189.70725, mean: 0.07712
[32m[0906 19-51-22 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 19-51-22 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-51-22 @MBExp.py:227][0m Rewards obtained: [195.89553015100458], Lows: [31], Highs: [21], Total time: 20206.983419999993
[32m[0906 19-52-55 @MBExp.py:144][0m ####################################################################
[32m[0906 19-52-55 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 19-52-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17414, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-53-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17484, current rewards: -6.14331, mean: -0.10239
[32m[0906 19-53-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17514, current rewards: -0.10720, mean: -0.00097
[32m[0906 19-53-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17496, current rewards: 10.39202, mean: 0.06495
[32m[0906 19-53-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17608, current rewards: 16.81281, mean: 0.08006
[32m[0906 19-53-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17693, current rewards: 23.22337, mean: 0.08932
[32m[0906 19-53-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17799, current rewards: 29.63774, mean: 0.09561
[32m[0906 19-54-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17903, current rewards: 36.05921, mean: 0.10016
[32m[0906 19-54-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17998, current rewards: 42.47227, mean: 0.10359
[32m[0906 19-54-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18068, current rewards: 48.88180, mean: 0.10626
[32m[0906 19-54-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18122, current rewards: 55.29899, mean: 0.10843
[32m[0906 19-54-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18159, current rewards: 49.29177, mean: 0.08802
[32m[0906 19-54-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18201, current rewards: 54.98713, mean: 0.09014
[32m[0906 19-54-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18235, current rewards: 60.74154, mean: 0.09203
[32m[0906 19-55-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18262, current rewards: 66.48942, mean: 0.09365
[32m[0906 19-55-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18282, current rewards: 72.24042, mean: 0.09505
[32m[0906 19-55-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18300, current rewards: 77.99907, mean: 0.09630
[32m[0906 19-55-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18316, current rewards: 83.64685, mean: 0.09726
[32m[0906 19-55-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18329, current rewards: 89.56866, mean: 0.09843
[32m[0906 19-55-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18338, current rewards: 95.46854, mean: 0.09945
[32m[0906 19-56-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18347, current rewards: 101.26012, mean: 0.10026
[32m[0906 19-56-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18361, current rewards: 107.17880, mean: 0.10111
[32m[0906 19-56-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18372, current rewards: 113.09448, mean: 0.10189
[32m[0906 19-56-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18384, current rewards: 119.01699, mean: 0.10260
[32m[0906 19-56-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18389, current rewards: 124.92909, mean: 0.10325
[32m[0906 19-56-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18398, current rewards: 130.84406, mean: 0.10384
[32m[0906 19-56-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18407, current rewards: 136.76277, mean: 0.10440
[32m[0906 19-57-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18411, current rewards: 142.66488, mean: 0.10490
[32m[0906 19-57-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18416, current rewards: 150.19287, mean: 0.10652
[32m[0906 19-57-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18420, current rewards: 156.06920, mean: 0.10690
[32m[0906 19-57-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18422, current rewards: 161.93776, mean: 0.10724
[32m[0906 19-57-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18426, current rewards: 167.79708, mean: 0.10756
[32m[0906 19-57-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18430, current rewards: 173.65923, mean: 0.10786
[32m[0906 19-58-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18435, current rewards: 158.34692, mean: 0.09539
[32m[0906 19-58-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18424, current rewards: 164.15408, mean: 0.09600
[32m[0906 19-58-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18414, current rewards: 170.10639, mean: 0.09665
[32m[0906 19-58-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18405, current rewards: 178.77160, mean: 0.09877
[32m[0906 19-58-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18383, current rewards: 184.60914, mean: 0.09925
[32m[0906 19-58-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18360, current rewards: 181.48366, mean: 0.09502
[32m[0906 19-58-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18339, current rewards: 189.64124, mean: 0.09676
[32m[0906 19-59-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18320, current rewards: 197.80336, mean: 0.09841
[32m[0906 19-59-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18301, current rewards: 205.94197, mean: 0.09997
[32m[0906 19-59-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18282, current rewards: 194.67556, mean: 0.09226
[32m[0906 19-59-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18263, current rewards: 202.33064, mean: 0.09367
[32m[0906 19-59-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18249, current rewards: 209.25045, mean: 0.09468
[32m[0906 19-59-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18245, current rewards: 214.84657, mean: 0.09506
[32m[0906 19-59-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18241, current rewards: 221.40558, mean: 0.09585
[32m[0906 20-00-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18241, current rewards: 227.96329, mean: 0.09659
[32m[0906 20-00-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18249, current rewards: 234.52071, mean: 0.09731
[32m[0906 20-00-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18257, current rewards: 241.08077, mean: 0.09800
[32m[0906 20-00-32 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 20-00-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-00-32 @MBExp.py:227][0m Rewards obtained: [242.93593076320127], Lows: [21], Highs: [34], Total time: 20664.315603999992
[32m[0906 20-02-07 @MBExp.py:144][0m ####################################################################
[32m[0906 20-02-07 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 20-02-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17492, current rewards: -4.74076, mean: -0.47408
[32m[0906 20-02-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17498, current rewards: 1.42706, mean: 0.02378
[32m[0906 20-02-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17471, current rewards: 7.19772, mean: 0.06543
[32m[0906 20-02-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17462, current rewards: 12.67405, mean: 0.07921
[32m[0906 20-02-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17605, current rewards: 18.42831, mean: 0.08775
[32m[0906 20-02-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17686, current rewards: 24.17692, mean: 0.09299
[32m[0906 20-03-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17812, current rewards: 29.92943, mean: 0.09655
[32m[0906 20-03-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17941, current rewards: 24.46195, mean: 0.06795
[32m[0906 20-03-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18014, current rewards: 30.18084, mean: 0.07361
[32m[0906 20-03-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18088, current rewards: 35.98443, mean: 0.07823
[32m[0906 20-03-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18129, current rewards: 41.78532, mean: 0.08193
[32m[0906 20-03-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18166, current rewards: 51.51715, mean: 0.09199
[32m[0906 20-03-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18197, current rewards: 57.93671, mean: 0.09498
[32m[0906 20-04-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18218, current rewards: 64.34739, mean: 0.09750
[32m[0906 20-04-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18239, current rewards: 70.75397, mean: 0.09965
[32m[0906 20-04-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18264, current rewards: 77.15915, mean: 0.10153
[32m[0906 20-04-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18285, current rewards: 83.57255, mean: 0.10318
[32m[0906 20-04-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18302, current rewards: 78.11432, mean: 0.09083
[32m[0906 20-04-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18314, current rewards: 83.12592, mean: 0.09135
[32m[0906 20-05-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18328, current rewards: 87.57477, mean: 0.09122
[32m[0906 20-05-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18346, current rewards: 92.20656, mean: 0.09129
[32m[0906 20-05-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18360, current rewards: 76.22000, mean: 0.07191
[32m[0906 20-05-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18368, current rewards: 81.52042, mean: 0.07344
[32m[0906 20-05-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18375, current rewards: 86.82701, mean: 0.07485
[32m[0906 20-05-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18385, current rewards: 92.14188, mean: 0.07615
[32m[0906 20-05-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18391, current rewards: 97.44971, mean: 0.07734
[32m[0906 20-06-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18398, current rewards: 102.76281, mean: 0.07844
[32m[0906 20-06-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18405, current rewards: 108.07403, mean: 0.07947
[32m[0906 20-06-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18410, current rewards: 114.00125, mean: 0.08085
[32m[0906 20-06-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18415, current rewards: 119.51017, mean: 0.08186
[32m[0906 20-06-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18418, current rewards: 125.03749, mean: 0.08281
[32m[0906 20-06-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18423, current rewards: 130.56375, mean: 0.08369
[32m[0906 20-07-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18430, current rewards: 136.08910, mean: 0.08453
[32m[0906 20-07-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18428, current rewards: 141.61395, mean: 0.08531
[32m[0906 20-07-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18421, current rewards: 147.14395, mean: 0.08605
[32m[0906 20-07-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18412, current rewards: 152.67108, mean: 0.08674
[32m[0906 20-07-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18398, current rewards: 158.65002, mean: 0.08765
[32m[0906 20-07-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18374, current rewards: 164.25387, mean: 0.08831
[32m[0906 20-07-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18350, current rewards: 169.85816, mean: 0.08893
[32m[0906 20-08-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18329, current rewards: 156.45374, mean: 0.07982
[32m[0906 20-08-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18308, current rewards: 160.22914, mean: 0.07972
[32m[0906 20-08-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18288, current rewards: 166.10301, mean: 0.08063
[32m[0906 20-08-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18269, current rewards: 171.97638, mean: 0.08151
[32m[0906 20-08-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18251, current rewards: 177.84882, mean: 0.08234
[32m[0906 20-08-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18240, current rewards: 183.72335, mean: 0.08313
[32m[0906 20-09-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18238, current rewards: 189.59879, mean: 0.08389
[32m[0906 20-09-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18235, current rewards: 195.47711, mean: 0.08462
[32m[0906 20-09-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18235, current rewards: 201.35317, mean: 0.08532
[32m[0906 20-09-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18245, current rewards: 207.22806, mean: 0.08599
[32m[0906 20-09-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18252, current rewards: 189.81958, mean: 0.07716
[32m[0906 20-09-44 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 20-09-44 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-09-44 @MBExp.py:227][0m Rewards obtained: [194.8982399948211], Lows: [31], Highs: [25], Total time: 21121.431763999994
[32m[0906 20-11-21 @MBExp.py:144][0m ####################################################################
[32m[0906 20-11-21 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 20-11-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17483, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-11-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17516, current rewards: -1.18062, mean: -0.01968
[32m[0906 20-11-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17508, current rewards: 5.16204, mean: 0.04693
[32m[0906 20-11-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17492, current rewards: 7.73550, mean: 0.04835
[32m[0906 20-11-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17605, current rewards: 16.07238, mean: 0.07654
[32m[0906 20-12-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17698, current rewards: 24.38440, mean: 0.09379
[32m[0906 20-12-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17828, current rewards: 32.64901, mean: 0.10532
[32m[0906 20-12-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17934, current rewards: 27.99542, mean: 0.07777
[32m[0906 20-12-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18005, current rewards: 23.96011, mean: 0.05844
[32m[0906 20-12-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18059, current rewards: 29.88636, mean: 0.06497
[32m[0906 20-12-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18109, current rewards: 37.10767, mean: 0.07276
[32m[0906 20-13-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18145, current rewards: 44.94293, mean: 0.08026
[32m[0906 20-13-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18173, current rewards: 50.98010, mean: 0.08357
[32m[0906 20-13-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18194, current rewards: 57.02700, mean: 0.08640
[32m[0906 20-13-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18221, current rewards: 63.06437, mean: 0.08882
[32m[0906 20-13-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18249, current rewards: 47.87066, mean: 0.06299
[32m[0906 20-13-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18269, current rewards: 53.66588, mean: 0.06625
[32m[0906 20-13-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18284, current rewards: 59.46111, mean: 0.06914
[32m[0906 20-14-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18301, current rewards: 65.25634, mean: 0.07171
[32m[0906 20-14-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18315, current rewards: 69.82568, mean: 0.07274
[32m[0906 20-14-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18320, current rewards: 63.16394, mean: 0.06254
[32m[0906 20-14-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18333, current rewards: 13.16394, mean: 0.01242
[32m[0906 20-14-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18343, current rewards: -36.83606, mean: -0.03319
[32m[0906 20-14-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18352, current rewards: -86.83606, mean: -0.07486
[32m[0906 20-15-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18361, current rewards: -136.83606, mean: -0.11309
[32m[0906 20-15-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18367, current rewards: -186.83606, mean: -0.14828
[32m[0906 20-15-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18373, current rewards: -236.83606, mean: -0.18079
[32m[0906 20-15-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18380, current rewards: -286.83606, mean: -0.21091
[32m[0906 20-15-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18387, current rewards: -336.83606, mean: -0.23889
[32m[0906 20-15-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18393, current rewards: -386.83606, mean: -0.26496
[32m[0906 20-15-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18398, current rewards: -436.83606, mean: -0.28930
[32m[0906 20-16-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18403, current rewards: -486.83606, mean: -0.31207
[32m[0906 20-16-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18404, current rewards: -536.83606, mean: -0.33344
[32m[0906 20-16-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18393, current rewards: -586.83606, mean: -0.35352
[32m[0906 20-16-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18384, current rewards: -636.83606, mean: -0.37242
[32m[0906 20-16-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18374, current rewards: -686.83606, mean: -0.39025
[32m[0906 20-16-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18359, current rewards: -736.83606, mean: -0.40709
[32m[0906 20-17-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18336, current rewards: -786.83606, mean: -0.42303
[32m[0906 20-17-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18314, current rewards: -836.83606, mean: -0.43813
[32m[0906 20-17-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18294, current rewards: -886.83606, mean: -0.45247
[32m[0906 20-17-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18275, current rewards: -936.83606, mean: -0.46609
[32m[0906 20-17-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18257, current rewards: -986.83606, mean: -0.47905
[32m[0906 20-17-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18239, current rewards: -1036.83606, mean: -0.49139
[32m[0906 20-17-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18224, current rewards: -1086.83606, mean: -0.50316
[32m[0906 20-18-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18215, current rewards: -1136.83606, mean: -0.51441
[32m[0906 20-18-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18211, current rewards: -1186.83606, mean: -0.52515
[32m[0906 20-18-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18207, current rewards: -1236.83606, mean: -0.53543
[32m[0906 20-18-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18206, current rewards: -1286.83606, mean: -0.54527
[32m[0906 20-18-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18215, current rewards: -1336.83606, mean: -0.55470
[32m[0906 20-18-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18223, current rewards: -1386.83606, mean: -0.56375
[32m[0906 20-18-58 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 20-18-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-18-58 @MBExp.py:227][0m Rewards obtained: [-1426.8360562059142], Lows: [23], Highs: [1513], Total time: 21577.864896999992
[32m[0906 20-20-36 @MBExp.py:144][0m ####################################################################
[32m[0906 20-20-36 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 20-20-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17376, current rewards: 0.58983, mean: 0.05898
[32m[0906 20-20-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17445, current rewards: 8.45331, mean: 0.14089
[32m[0906 20-20-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17451, current rewards: 9.93133, mean: 0.09028
[32m[0906 20-21-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17464, current rewards: 19.37523, mean: 0.12110
[32m[0906 20-21-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17596, current rewards: 28.80498, mean: 0.13717
[32m[0906 20-21-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17679, current rewards: 38.24522, mean: 0.14710
[32m[0906 20-21-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17820, current rewards: 47.68508, mean: 0.15382
[32m[0906 20-21-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17923, current rewards: 57.12808, mean: 0.15869
[32m[0906 20-21-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18014, current rewards: 53.00978, mean: 0.12929
[32m[0906 20-22-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18085, current rewards: 59.14322, mean: 0.12857
[32m[0906 20-22-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18142, current rewards: 65.75918, mean: 0.12894
[32m[0906 20-22-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18179, current rewards: 72.29967, mean: 0.12911
[32m[0906 20-22-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18208, current rewards: 78.84935, mean: 0.12926
[32m[0906 20-22-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18232, current rewards: 85.39671, mean: 0.12939
[32m[0906 20-22-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18250, current rewards: 70.57526, mean: 0.09940
[32m[0906 20-22-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18263, current rewards: 76.07850, mean: 0.10010
[32m[0906 20-23-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18281, current rewards: 82.09948, mean: 0.10136
[32m[0906 20-23-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18293, current rewards: 88.12136, mean: 0.10247
[32m[0906 20-23-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18305, current rewards: 92.57843, mean: 0.10173
[32m[0906 20-23-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18318, current rewards: 98.18651, mean: 0.10228
[32m[0906 20-23-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18321, current rewards: 103.75345, mean: 0.10273
[32m[0906 20-23-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18329, current rewards: 109.31791, mean: 0.10313
[32m[0906 20-24-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18336, current rewards: 114.88199, mean: 0.10350
[32m[0906 20-24-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18348, current rewards: 120.44790, mean: 0.10383
[32m[0906 20-24-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18356, current rewards: 126.02178, mean: 0.10415
[32m[0906 20-24-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18362, current rewards: 131.58893, mean: 0.10444
[32m[0906 20-24-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18367, current rewards: 137.55129, mean: 0.10500
[32m[0906 20-24-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18368, current rewards: 134.04967, mean: 0.09857
[32m[0906 20-24-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18372, current rewards: 139.49925, mean: 0.09894
[32m[0906 20-25-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18377, current rewards: 144.95666, mean: 0.09929
[32m[0906 20-25-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18380, current rewards: 150.40999, mean: 0.09961
[32m[0906 20-25-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18382, current rewards: 155.86145, mean: 0.09991
[32m[0906 20-25-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18381, current rewards: 161.31592, mean: 0.10020
[32m[0906 20-25-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18372, current rewards: 166.77310, mean: 0.10047
[32m[0906 20-25-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18364, current rewards: 172.31115, mean: 0.10077
[32m[0906 20-26-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18353, current rewards: 178.17118, mean: 0.10123
[32m[0906 20-26-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18336, current rewards: 184.47217, mean: 0.10192
[32m[0906 20-26-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18317, current rewards: 190.76127, mean: 0.10256
[32m[0906 20-26-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18295, current rewards: 197.05218, mean: 0.10317
[32m[0906 20-26-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18274, current rewards: 203.34482, mean: 0.10375
[32m[0906 20-26-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18253, current rewards: 209.63505, mean: 0.10430
[32m[0906 20-26-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18234, current rewards: 195.26621, mean: 0.09479
[32m[0906 20-27-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18216, current rewards: 200.75223, mean: 0.09514
[32m[0906 20-27-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18199, current rewards: 208.16575, mean: 0.09637
[32m[0906 20-27-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18193, current rewards: 213.56499, mean: 0.09664
[32m[0906 20-27-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18190, current rewards: 218.97125, mean: 0.09689
[32m[0906 20-27-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18186, current rewards: 224.37427, mean: 0.09713
[32m[0906 20-27-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18185, current rewards: 229.77649, mean: 0.09736
[32m[0906 20-27-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18196, current rewards: 235.17419, mean: 0.09758
[32m[0906 20-28-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18202, current rewards: 240.57634, mean: 0.09780
[32m[0906 20-28-12 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 20-28-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-28-12 @MBExp.py:227][0m Rewards obtained: [244.89581853752318], Lows: [25], Highs: [21], Total time: 22033.76511599999
[32m[0906 20-29-53 @MBExp.py:144][0m ####################################################################
[32m[0906 20-29-53 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 20-29-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17423, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-30-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17460, current rewards: -12.43763, mean: -0.20729
[32m[0906 20-30-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17472, current rewards: -4.86862, mean: -0.04426
[32m[0906 20-30-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17481, current rewards: 1.30121, mean: 0.00813
[32m[0906 20-30-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17628, current rewards: 7.46614, mean: 0.03555
[32m[0906 20-30-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17710, current rewards: 13.61988, mean: 0.05238
[32m[0906 20-30-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17837, current rewards: 19.78711, mean: 0.06383
[32m[0906 20-30-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17950, current rewards: 25.94221, mean: 0.07206
[32m[0906 20-31-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18034, current rewards: 32.09841, mean: 0.07829
[32m[0906 20-31-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18087, current rewards: 38.26040, mean: 0.08317
[32m[0906 20-31-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18133, current rewards: 47.38501, mean: 0.09291
[32m[0906 20-31-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18169, current rewards: 53.49671, mean: 0.09553
[32m[0906 20-31-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18205, current rewards: 46.24581, mean: 0.07581
[32m[0906 20-31-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18231, current rewards: 50.97253, mean: 0.07723
[32m[0906 20-32-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18259, current rewards: 55.87449, mean: 0.07870
[32m[0906 20-32-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18281, current rewards: 60.77594, mean: 0.07997
[32m[0906 20-32-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18295, current rewards: 65.67549, mean: 0.08108
[32m[0906 20-32-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18318, current rewards: 68.48523, mean: 0.07963
[32m[0906 20-32-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18335, current rewards: 54.12950, mean: 0.05948
[32m[0906 20-32-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18346, current rewards: 58.65371, mean: 0.06110
[32m[0906 20-32-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18360, current rewards: 64.21745, mean: 0.06358
[32m[0906 20-33-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18373, current rewards: 69.78005, mean: 0.06583
[32m[0906 20-33-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18377, current rewards: 75.35214, mean: 0.06788
[32m[0906 20-33-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18384, current rewards: 80.92064, mean: 0.06976
[32m[0906 20-33-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18386, current rewards: 86.48298, mean: 0.07147
[32m[0906 20-33-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18391, current rewards: 92.05531, mean: 0.07306
[32m[0906 20-33-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18396, current rewards: 97.61660, mean: 0.07452
[32m[0906 20-34-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18399, current rewards: 103.56167, mean: 0.07615
[32m[0906 20-34-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18405, current rewards: 109.05823, mean: 0.07735
[32m[0906 20-34-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18408, current rewards: 114.56171, mean: 0.07847
[32m[0906 20-34-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18412, current rewards: 113.40001, mean: 0.07510
[32m[0906 20-34-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18416, current rewards: 104.11382, mean: 0.06674
[32m[0906 20-34-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18409, current rewards: 99.15188, mean: 0.06159
[32m[0906 20-34-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18397, current rewards: 92.02282, mean: 0.05544
[32m[0906 20-35-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18388, current rewards: 84.93192, mean: 0.04967
[32m[0906 20-35-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18378, current rewards: 79.95400, mean: 0.04543
[32m[0906 20-35-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18357, current rewards: 72.87006, mean: 0.04026
[32m[0906 20-35-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18334, current rewards: 66.96143, mean: 0.03600
[32m[0906 20-35-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18311, current rewards: 61.93375, mean: 0.03243
[32m[0906 20-35-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18290, current rewards: 59.02597, mean: 0.03012
[32m[0906 20-36-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18270, current rewards: 50.96757, mean: 0.02536
[32m[0906 20-36-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18252, current rewards: 33.63292, mean: 0.01633
[32m[0906 20-36-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18234, current rewards: 38.88248, mean: 0.01843
[32m[0906 20-36-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18217, current rewards: 44.02216, mean: 0.02038
[32m[0906 20-36-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18214, current rewards: 49.26313, mean: 0.02229
[32m[0906 20-36-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18214, current rewards: 54.50084, mean: 0.02412
[32m[0906 20-36-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18211, current rewards: 59.74159, mean: 0.02586
[32m[0906 20-37-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18209, current rewards: 64.98133, mean: 0.02753
[32m[0906 20-37-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18217, current rewards: 70.22060, mean: 0.02914
[32m[0906 20-37-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18226, current rewards: 75.46130, mean: 0.03068
[32m[0906 20-37-29 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 20-37-29 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-37-30 @MBExp.py:227][0m Rewards obtained: [79.65601707096124], Lows: [21], Highs: [126], Total time: 22490.24974799999
[32m[0906 20-39-12 @MBExp.py:144][0m ####################################################################
[32m[0906 20-39-12 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 20-39-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17496, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-39-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17489, current rewards: -3.93977, mean: -0.06566
[32m[0906 20-39-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17488, current rewards: 2.25544, mean: 0.02050
[32m[0906 20-39-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17485, current rewards: 8.45754, mean: 0.05286
[32m[0906 20-39-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17617, current rewards: 14.66312, mean: 0.06982
[32m[0906 20-39-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17703, current rewards: 20.87389, mean: 0.08028
[32m[0906 20-40-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17857, current rewards: 5.77408, mean: 0.01863
[32m[0906 20-40-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17963, current rewards: 11.67311, mean: 0.03243
[32m[0906 20-40-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18040, current rewards: 17.56333, mean: 0.04284
[32m[0906 20-40-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18096, current rewards: 23.29205, mean: 0.05063
[32m[0906 20-40-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18141, current rewards: 28.50031, mean: 0.05588
[32m[0906 20-40-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18188, current rewards: 34.48403, mean: 0.06158
[32m[0906 20-41-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18221, current rewards: 40.47310, mean: 0.06635
[32m[0906 20-41-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18243, current rewards: 46.46035, mean: 0.07039
[32m[0906 20-41-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18263, current rewards: 52.45046, mean: 0.07387
[32m[0906 20-41-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18281, current rewards: 58.43554, mean: 0.07689
[32m[0906 20-41-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18298, current rewards: 64.42288, mean: 0.07953
[32m[0906 20-41-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18314, current rewards: 70.40621, mean: 0.08187
[32m[0906 20-41-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18326, current rewards: 60.49680, mean: 0.06648
[32m[0906 20-42-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18343, current rewards: 66.53488, mean: 0.06931
[32m[0906 20-42-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18360, current rewards: 72.58190, mean: 0.07186
[32m[0906 20-42-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18370, current rewards: 78.62282, mean: 0.07417
[32m[0906 20-42-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18374, current rewards: 84.66924, mean: 0.07628
[32m[0906 20-42-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18378, current rewards: 90.71308, mean: 0.07820
[32m[0906 20-42-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18383, current rewards: 96.76217, mean: 0.07997
[32m[0906 20-43-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18388, current rewards: 102.80563, mean: 0.08159
[32m[0906 20-43-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18393, current rewards: 108.84656, mean: 0.08309
[32m[0906 20-43-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18394, current rewards: 114.89170, mean: 0.08448
[32m[0906 20-43-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18398, current rewards: 115.33215, mean: 0.08180
[32m[0906 20-43-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18406, current rewards: 122.41073, mean: 0.08384
[32m[0906 20-43-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18409, current rewards: 151.39221, mean: 0.10026
[32m[0906 20-44-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18409, current rewards: 180.59126, mean: 0.11576
[32m[0906 20-44-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18397, current rewards: 209.60029, mean: 0.13019
[32m[0906 20-44-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18388, current rewards: 238.61838, mean: 0.14375
[32m[0906 20-44-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18376, current rewards: 229.52252, mean: 0.13422
[32m[0906 20-44-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18366, current rewards: 129.52252, mean: 0.07359
[32m[0906 20-44-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18341, current rewards: 29.52252, mean: 0.01631
[32m[0906 20-44-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18318, current rewards: -70.47748, mean: -0.03789
[32m[0906 20-45-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18297, current rewards: -88.11850, mean: -0.04614
[32m[0906 20-45-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18275, current rewards: -82.09730, mean: -0.04189
[32m[0906 20-45-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18256, current rewards: -76.06765, mean: -0.03784
[32m[0906 20-45-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18237, current rewards: -70.05606, mean: -0.03401
[32m[0906 20-45-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18218, current rewards: -64.34291, mean: -0.03049
[32m[0906 20-45-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18206, current rewards: -60.12079, mean: -0.02783
[32m[0906 20-45-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18204, current rewards: -55.56335, mean: -0.02514
[32m[0906 20-46-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18201, current rewards: -51.00385, mean: -0.02257
[32m[0906 20-46-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18196, current rewards: -46.44254, mean: -0.02010
[32m[0906 20-46-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18194, current rewards: -41.88609, mean: -0.01775
[32m[0906 20-46-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18203, current rewards: -37.32466, mean: -0.01549
[32m[0906 20-46-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18210, current rewards: -32.76183, mean: -0.01332
[32m[0906 20-46-50 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 20-46-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-46-50 @MBExp.py:227][0m Rewards obtained: [-29.11783784404355], Lows: [197], Highs: [22], Total time: 22947.830800999993
[32m[0906 20-48-35 @MBExp.py:144][0m ####################################################################
[32m[0906 20-48-35 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 20-48-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17344, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-48-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17415, current rewards: -4.50484, mean: -0.07508
[32m[0906 20-48-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17443, current rewards: 0.86473, mean: 0.00786
[32m[0906 20-49-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17447, current rewards: 6.23233, mean: 0.03895
[32m[0906 20-49-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17586, current rewards: 11.59815, mean: 0.05523
[32m[0906 20-49-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17675, current rewards: 16.96304, mean: 0.06524
[32m[0906 20-49-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17824, current rewards: 22.33599, mean: 0.07205
[32m[0906 20-49-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17935, current rewards: 6.26996, mean: 0.01742
[32m[0906 20-49-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18012, current rewards: 11.25279, mean: 0.02745
[32m[0906 20-49-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18077, current rewards: 17.71379, mean: 0.03851
[32m[0906 20-50-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18117, current rewards: 23.23207, mean: 0.04555
[32m[0906 20-50-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18157, current rewards: 28.42719, mean: 0.05076
[32m[0906 20-50-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18189, current rewards: 33.63213, mean: 0.05513
[32m[0906 20-50-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18215, current rewards: 38.83041, mean: 0.05883
[32m[0906 20-50-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18236, current rewards: 44.02770, mean: 0.06201
[32m[0906 20-50-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18254, current rewards: 49.22277, mean: 0.06477
[32m[0906 20-51-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18273, current rewards: 54.41894, mean: 0.06718
[32m[0906 20-51-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18287, current rewards: 58.51853, mean: 0.06804
[32m[0906 20-51-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18301, current rewards: 52.70598, mean: 0.05792
[32m[0906 20-51-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18312, current rewards: 58.27900, mean: 0.06071
[32m[0906 20-51-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18321, current rewards: 63.84464, mean: 0.06321
[32m[0906 20-51-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18329, current rewards: 69.41148, mean: 0.06548
[32m[0906 20-51-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18340, current rewards: 74.98203, mean: 0.06755
[32m[0906 20-52-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18354, current rewards: 80.54861, mean: 0.06944
[32m[0906 20-52-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18362, current rewards: 86.11716, mean: 0.07117
[32m[0906 20-52-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18366, current rewards: 71.38379, mean: 0.05665
[32m[0906 20-52-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18369, current rewards: 75.79251, mean: 0.05786
[32m[0906 20-52-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18373, current rewards: 80.80527, mean: 0.05942
[32m[0906 20-52-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18376, current rewards: 85.82085, mean: 0.06087
[32m[0906 20-53-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18379, current rewards: 90.83590, mean: 0.06222
[32m[0906 20-53-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18386, current rewards: 95.85227, mean: 0.06348
[32m[0906 20-53-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18378, current rewards: 100.86967, mean: 0.06466
[32m[0906 20-53-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18366, current rewards: 105.88485, mean: 0.06577
[32m[0906 20-53-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18357, current rewards: 110.90165, mean: 0.06681
[32m[0906 20-53-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18344, current rewards: 115.97063, mean: 0.06782
[32m[0906 20-53-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18329, current rewards: 120.98684, mean: 0.06874
[32m[0906 20-54-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18306, current rewards: 126.00334, mean: 0.06962
[32m[0906 20-54-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18284, current rewards: 131.01914, mean: 0.07044
[32m[0906 20-54-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18261, current rewards: 115.18469, mean: 0.06031
[32m[0906 20-54-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18240, current rewards: 120.59321, mean: 0.06153
[32m[0906 20-54-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18219, current rewards: 125.80781, mean: 0.06259
[32m[0906 20-54-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18202, current rewards: 131.02557, mean: 0.06360
[32m[0906 20-54-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18183, current rewards: 137.89268, mean: 0.06535
[32m[0906 20-55-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18172, current rewards: 143.18837, mean: 0.06629
[32m[0906 20-55-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18168, current rewards: 148.45372, mean: 0.06717
[32m[0906 20-55-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18164, current rewards: 153.72214, mean: 0.06802
[32m[0906 20-55-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18160, current rewards: 158.99028, mean: 0.06883
[32m[0906 20-55-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18159, current rewards: 164.25848, mean: 0.06960
[32m[0906 20-55-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18168, current rewards: 146.67057, mean: 0.06086
[32m[0906 20-56-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18179, current rewards: 152.80481, mean: 0.06212
[32m[0906 20-56-10 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 20-56-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-56-10 @MBExp.py:227][0m Rewards obtained: [157.1495477142132], Lows: [42], Highs: [20], Total time: 23403.211314999993
[32m[0906 20-57-57 @MBExp.py:144][0m ####################################################################
[32m[0906 20-57-57 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 20-57-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17289, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-58-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17401, current rewards: -5.81275, mean: -0.09688
[32m[0906 20-58-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17444, current rewards: -0.09479, mean: -0.00086
[32m[0906 20-58-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17508, current rewards: 5.62531, mean: 0.03516
[32m[0906 20-58-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17638, current rewards: 11.34790, mean: 0.05404
[32m[0906 20-58-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17740, current rewards: -3.24995, mean: -0.01250
[32m[0906 20-58-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17876, current rewards: 1.57179, mean: 0.00507
[32m[0906 20-59-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17986, current rewards: 6.39823, mean: 0.01777
[32m[0906 20-59-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18043, current rewards: 11.50423, mean: 0.02806
[32m[0906 20-59-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18098, current rewards: 16.68525, mean: 0.03627
[32m[0906 20-59-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18145, current rewards: 21.57995, mean: 0.04231
[32m[0906 20-59-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18175, current rewards: 26.47540, mean: 0.04728
[32m[0906 20-59-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18206, current rewards: 31.37309, mean: 0.05143
[32m[0906 20-59-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18231, current rewards: 36.26999, mean: 0.05495
[32m[0906 21-00-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18254, current rewards: 21.01810, mean: 0.02960
[32m[0906 21-00-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18270, current rewards: 26.99588, mean: 0.03552
[32m[0906 21-00-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18288, current rewards: 32.96168, mean: 0.04069
[32m[0906 21-00-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18302, current rewards: 38.64665, mean: 0.04494
[32m[0906 21-00-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18316, current rewards: 44.58248, mean: 0.04899
[32m[0906 21-00-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18328, current rewards: 30.02783, mean: 0.03128
[32m[0906 21-01-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18339, current rewards: 35.84383, mean: 0.03549
[32m[0906 21-01-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18348, current rewards: 41.66052, mean: 0.03930
[32m[0906 21-01-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18351, current rewards: 47.47682, mean: 0.04277
[32m[0906 21-01-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18355, current rewards: 53.29385, mean: 0.04594
[32m[0906 21-01-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18362, current rewards: 59.11100, mean: 0.04885
[32m[0906 21-01-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18367, current rewards: 64.67208, mean: 0.05133
[32m[0906 21-01-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18372, current rewards: 70.46464, mean: 0.05379
[32m[0906 21-02-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18379, current rewards: 76.25861, mean: 0.05607
[32m[0906 21-02-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18383, current rewards: 82.05432, mean: 0.05819
[32m[0906 21-02-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18387, current rewards: 87.84911, mean: 0.06017
[32m[0906 21-02-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18392, current rewards: 81.13719, mean: 0.05373
[32m[0906 21-02-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18381, current rewards: 86.35392, mean: 0.05536
[32m[0906 21-02-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18371, current rewards: 91.65726, mean: 0.05693
[32m[0906 21-03-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18363, current rewards: 96.66098, mean: 0.05823
[32m[0906 21-03-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18353, current rewards: 101.93198, mean: 0.05961
[32m[0906 21-03-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18334, current rewards: 107.19348, mean: 0.06091
[32m[0906 21-03-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18312, current rewards: 112.46885, mean: 0.06214
[32m[0906 21-03-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18291, current rewards: 117.72973, mean: 0.06330
[32m[0906 21-03-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18269, current rewards: 122.99652, mean: 0.06440
[32m[0906 21-03-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18249, current rewards: 128.26809, mean: 0.06544
[32m[0906 21-04-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18230, current rewards: 133.52956, mean: 0.06643
[32m[0906 21-04-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18212, current rewards: 139.56131, mean: 0.06775
[32m[0906 21-04-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18194, current rewards: 124.82835, mean: 0.05916
[32m[0906 21-04-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18189, current rewards: 130.24666, mean: 0.06030
[32m[0906 21-04-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18189, current rewards: 135.66642, mean: 0.06139
[32m[0906 21-04-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18187, current rewards: 141.08835, mean: 0.06243
[32m[0906 21-04-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18184, current rewards: 146.50892, mean: 0.06342
[32m[0906 21-05-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18183, current rewards: 151.92755, mean: 0.06438
[32m[0906 21-05-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18192, current rewards: 157.34469, mean: 0.06529
[32m[0906 21-05-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18198, current rewards: 162.44678, mean: 0.06604
[32m[0906 21-05-33 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 21-05-33 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-05-33 @MBExp.py:227][0m Rewards obtained: [166.73160961939266], Lows: [40], Highs: [22], Total time: 23859.035967999993
[32m[0906 21-07-21 @MBExp.py:144][0m ####################################################################
[32m[0906 21-07-21 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 21-07-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17306, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-07-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17546, current rewards: -8.95168, mean: -0.14919
[32m[0906 21-07-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17484, current rewards: -4.33319, mean: -0.03939
[32m[0906 21-07-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17492, current rewards: 0.29008, mean: 0.00181
[32m[0906 21-07-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17618, current rewards: 4.91798, mean: 0.02342
[32m[0906 21-08-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17727, current rewards: 9.54141, mean: 0.03670
[32m[0906 21-08-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17867, current rewards: 14.16060, mean: 0.04568
[32m[0906 21-08-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17957, current rewards: 18.78059, mean: 0.05217
[32m[0906 21-08-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18018, current rewards: 24.24916, mean: 0.05914
[32m[0906 21-08-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18067, current rewards: 8.21787, mean: 0.01786
[32m[0906 21-08-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18122, current rewards: 13.80237, mean: 0.02706
[32m[0906 21-09-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18154, current rewards: 19.38414, mean: 0.03461
[32m[0906 21-09-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18177, current rewards: 24.96982, mean: 0.04093
[32m[0906 21-09-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18198, current rewards: 30.55609, mean: 0.04630
[32m[0906 21-09-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18223, current rewards: 36.13990, mean: 0.05090
[32m[0906 21-09-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18237, current rewards: 41.72682, mean: 0.05490
[32m[0906 21-09-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18257, current rewards: 46.94170, mean: 0.05795
[32m[0906 21-09-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18270, current rewards: 52.52000, mean: 0.06107
[32m[0906 21-10-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18285, current rewards: 37.64848, mean: 0.04137
[32m[0906 21-10-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18296, current rewards: 43.37109, mean: 0.04518
[32m[0906 21-10-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18307, current rewards: 49.08934, mean: 0.04860
[32m[0906 21-10-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18318, current rewards: 54.81234, mean: 0.05171
[32m[0906 21-10-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18325, current rewards: 60.53250, mean: 0.05453
[32m[0906 21-10-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18335, current rewards: 66.25278, mean: 0.05711
[32m[0906 21-11-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18345, current rewards: 71.97299, mean: 0.05948
[32m[0906 21-11-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18351, current rewards: 77.69271, mean: 0.06166
[32m[0906 21-11-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18352, current rewards: 83.41131, mean: 0.06367
[32m[0906 21-11-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18355, current rewards: 89.12737, mean: 0.06553
[32m[0906 21-11-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18359, current rewards: 82.25568, mean: 0.05834
[32m[0906 21-11-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18360, current rewards: 87.21197, mean: 0.05973
[32m[0906 21-11-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18355, current rewards: 92.18841, mean: 0.06105
[32m[0906 21-12-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18344, current rewards: 97.16655, mean: 0.06229
[32m[0906 21-12-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18333, current rewards: 80.87967, mean: 0.05024
[32m[0906 21-12-26 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18323, current rewards: 85.90214, mean: 0.05175
[32m[0906 21-12-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18315, current rewards: 91.31502, mean: 0.05340
[32m[0906 21-12-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18293, current rewards: 96.73213, mean: 0.05496
[32m[0906 21-12-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18268, current rewards: 102.14139, mean: 0.05643
[32m[0906 21-13-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18247, current rewards: 107.55566, mean: 0.05783
[32m[0906 21-13-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18228, current rewards: 112.96451, mean: 0.05914
[32m[0906 21-13-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18207, current rewards: 118.37867, mean: 0.06040
[32m[0906 21-13-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18188, current rewards: 123.85828, mean: 0.06162
[32m[0906 21-13-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18170, current rewards: 129.27665, mean: 0.06276
[32m[0906 21-13-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18153, current rewards: 134.68919, mean: 0.06383
[32m[0906 21-13-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18145, current rewards: 140.10625, mean: 0.06486
[32m[0906 21-14-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18142, current rewards: 145.52977, mean: 0.06585
[32m[0906 21-14-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18139, current rewards: 150.22698, mean: 0.06647
[32m[0906 21-14-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18136, current rewards: 154.97013, mean: 0.06709
[32m[0906 21-14-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18135, current rewards: 159.71340, mean: 0.06768
[32m[0906 21-14-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18145, current rewards: 165.71994, mean: 0.06876
[32m[0906 21-14-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18153, current rewards: 170.67022, mean: 0.06938
[32m[0906 21-14-56 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 21-14-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-14-56 @MBExp.py:227][0m Rewards obtained: [154.6829113846787], Lows: [42], Highs: [21], Total time: 24313.75715199999
[32m[0906 21-16-47 @MBExp.py:144][0m ####################################################################
[32m[0906 21-16-47 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 21-16-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17387, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-16-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17441, current rewards: -3.61034, mean: -0.06017
[32m[0906 21-17-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17447, current rewards: 2.20330, mean: 0.02003
[32m[0906 21-17-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17508, current rewards: 8.01617, mean: 0.05010
[32m[0906 21-17-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17635, current rewards: 13.83290, mean: 0.06587
[32m[0906 21-17-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17756, current rewards: 19.64119, mean: 0.07554
[32m[0906 21-17-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17875, current rewards: 25.45580, mean: 0.08212
[32m[0906 21-17-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17964, current rewards: 30.71142, mean: 0.08531
[32m[0906 21-18-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18014, current rewards: 36.33407, mean: 0.08862
[32m[0906 21-18-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18068, current rewards: 41.95290, mean: 0.09120
[32m[0906 21-18-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18119, current rewards: 26.35576, mean: 0.05168
[32m[0906 21-18-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18152, current rewards: 31.78931, mean: 0.05677
[32m[0906 21-18-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18178, current rewards: 37.22416, mean: 0.06102
[32m[0906 21-18-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18203, current rewards: 42.65724, mean: 0.06463
[32m[0906 21-18-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18224, current rewards: 48.08898, mean: 0.06773
[32m[0906 21-19-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18248, current rewards: 53.39985, mean: 0.07026
[32m[0906 21-19-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18269, current rewards: 58.82119, mean: 0.07262
[32m[0906 21-19-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18287, current rewards: 64.24517, mean: 0.07470
[32m[0906 21-19-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18299, current rewards: 69.67168, mean: 0.07656
[32m[0906 21-19-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18309, current rewards: 64.92071, mean: 0.06763
[32m[0906 21-19-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18323, current rewards: 70.67569, mean: 0.06998
[32m[0906 21-20-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18331, current rewards: 75.99560, mean: 0.07169
[32m[0906 21-20-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18335, current rewards: 81.32436, mean: 0.07327
[32m[0906 21-20-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18345, current rewards: 65.53844, mean: 0.05650
[32m[0906 21-20-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18351, current rewards: 71.33299, mean: 0.05895
[32m[0906 21-20-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18359, current rewards: 77.08016, mean: 0.06117
[32m[0906 21-20-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18366, current rewards: 82.83021, mean: 0.06323
[32m[0906 21-20-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18372, current rewards: 88.57827, mean: 0.06513
[32m[0906 21-21-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18375, current rewards: 94.32913, mean: 0.06690
[32m[0906 21-21-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18380, current rewards: 100.07897, mean: 0.06855
[32m[0906 21-21-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18373, current rewards: 105.83188, mean: 0.07009
[32m[0906 21-21-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18364, current rewards: 111.88992, mean: 0.07172
[32m[0906 21-21-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18353, current rewards: 117.67320, mean: 0.07309
[32m[0906 21-21-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18344, current rewards: 123.45122, mean: 0.07437
[32m[0906 21-22-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18333, current rewards: 108.45735, mean: 0.06343
[32m[0906 21-22-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18309, current rewards: 114.45851, mean: 0.06503
[32m[0906 21-22-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18286, current rewards: 120.97252, mean: 0.06684
[32m[0906 21-22-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18264, current rewards: 126.92634, mean: 0.06824
[32m[0906 21-22-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18243, current rewards: 132.84528, mean: 0.06955
[32m[0906 21-22-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18221, current rewards: 140.55301, mean: 0.07171
[32m[0906 21-22-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18202, current rewards: 148.26687, mean: 0.07376
[32m[0906 21-23-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18184, current rewards: 155.92195, mean: 0.07569
[32m[0906 21-23-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18168, current rewards: 163.57703, mean: 0.07752
[32m[0906 21-23-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18165, current rewards: 134.33286, mean: 0.06219
[32m[0906 21-23-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18164, current rewards: 84.33286, mean: 0.03816
[32m[0906 21-23-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18163, current rewards: 34.33286, mean: 0.01519
[32m[0906 21-23-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18158, current rewards: -15.66714, mean: -0.00678
[32m[0906 21-23-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18160, current rewards: -65.66714, mean: -0.02783
[32m[0906 21-24-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18166, current rewards: -115.66714, mean: -0.04799
[32m[0906 21-24-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18173, current rewards: -165.66714, mean: -0.06734
[32m[0906 21-24-22 @Agent.py:117][0m Average action selection time: 0.1818
[32m[0906 21-24-22 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-24-22 @MBExp.py:227][0m Rewards obtained: [-205.66714125080895], Lows: [31], Highs: [392], Total time: 24768.920841999992
[32m[0906 21-26-15 @MBExp.py:144][0m ####################################################################
[32m[0906 21-26-15 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 21-26-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17197, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-26-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17356, current rewards: -5.08121, mean: -0.08469
[32m[0906 21-26-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17371, current rewards: 0.67044, mean: 0.00609
[32m[0906 21-26-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17421, current rewards: 6.41792, mean: 0.04011
[32m[0906 21-26-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17554, current rewards: 12.16868, mean: 0.05795
[32m[0906 21-27-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17700, current rewards: 17.92959, mean: 0.06896
[32m[0906 21-27-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17842, current rewards: 24.36715, mean: 0.07860
[32m[0906 21-27-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17941, current rewards: 30.56065, mean: 0.08489
[32m[0906 21-27-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18002, current rewards: 15.19026, mean: 0.03705
[32m[0906 21-27-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18065, current rewards: 20.97722, mean: 0.04560
[32m[0906 21-27-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18107, current rewards: 26.78016, mean: 0.05251
[32m[0906 21-27-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18148, current rewards: 32.58276, mean: 0.05818
[32m[0906 21-28-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18182, current rewards: 16.62775, mean: 0.02726
[32m[0906 21-28-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18211, current rewards: 24.92787, mean: 0.03777
[32m[0906 21-28-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18232, current rewards: 7.85984, mean: 0.01107
[32m[0906 21-28-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18253, current rewards: -42.14016, mean: -0.05545
[32m[0906 21-28-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18269, current rewards: -69.38586, mean: -0.08566
[32m[0906 21-28-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18281, current rewards: -63.83260, mean: -0.07422
[32m[0906 21-29-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18292, current rewards: -58.29111, mean: -0.06406
[32m[0906 21-29-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18304, current rewards: -52.75653, mean: -0.05495
[32m[0906 21-29-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18314, current rewards: -47.22699, mean: -0.04676
[32m[0906 21-29-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18319, current rewards: -41.69108, mean: -0.03933
[32m[0906 21-29-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18327, current rewards: -34.61688, mean: -0.03119
[32m[0906 21-29-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18337, current rewards: -28.81953, mean: -0.02484
[32m[0906 21-29-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18348, current rewards: -23.19081, mean: -0.01917
[32m[0906 21-30-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18354, current rewards: -28.72709, mean: -0.02280
[32m[0906 21-30-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18360, current rewards: -23.49803, mean: -0.01794
[32m[0906 21-30-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18362, current rewards: -17.91249, mean: -0.01317
[32m[0906 21-30-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18367, current rewards: -12.32951, mean: -0.00874
[32m[0906 21-30-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18364, current rewards: -6.74481, mean: -0.00462
[32m[0906 21-30-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18351, current rewards: -1.14116, mean: -0.00076
[32m[0906 21-31-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18339, current rewards: -7.40692, mean: -0.00475
[32m[0906 21-31-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18330, current rewards: -2.05382, mean: -0.00128
[32m[0906 21-31-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18320, current rewards: 3.61522, mean: 0.00218
[32m[0906 21-31-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18306, current rewards: 9.28611, mean: 0.00543
[32m[0906 21-31-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18282, current rewards: 1.68423, mean: 0.00096
[32m[0906 21-31-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18259, current rewards: 7.30233, mean: 0.00403
[32m[0906 21-31-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18239, current rewards: 12.94020, mean: 0.00696
[32m[0906 21-32-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18218, current rewards: 18.57625, mean: 0.00973
[32m[0906 21-32-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18198, current rewards: 2.90502, mean: 0.00148
[32m[0906 21-32-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18178, current rewards: 8.24706, mean: 0.00410
[32m[0906 21-32-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18160, current rewards: 13.97350, mean: 0.00678
[32m[0906 21-32-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18147, current rewards: 19.69918, mean: 0.00934
[32m[0906 21-32-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18143, current rewards: 25.41914, mean: 0.01177
[32m[0906 21-32-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18140, current rewards: 31.14297, mean: 0.01409
[32m[0906 21-33-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18136, current rewards: 36.86952, mean: 0.01631
[32m[0906 21-33-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18134, current rewards: 42.59526, mean: 0.01844
[32m[0906 21-33-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18135, current rewards: 47.24897, mean: 0.02002
[32m[0906 21-33-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18144, current rewards: 52.83430, mean: 0.02192
[32m[0906 21-33-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18152, current rewards: 58.42417, mean: 0.02375
[32m[0906 21-33-49 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 21-33-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-33-50 @MBExp.py:227][0m Rewards obtained: [41.40424386432221], Lows: [43], Highs: [139], Total time: 25223.597664999994
[32m[0906 21-35-44 @MBExp.py:144][0m ####################################################################
[32m[0906 21-35-44 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 21-35-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17378, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-35-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17398, current rewards: -16.14867, mean: -0.26914
[32m[0906 21-36-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17428, current rewards: -10.71155, mean: -0.09738
[32m[0906 21-36-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17477, current rewards: -5.26847, mean: -0.03293
[32m[0906 21-36-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17601, current rewards: 0.16374, mean: 0.00078
[32m[0906 21-36-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17749, current rewards: 5.61085, mean: 0.02158
[32m[0906 21-36-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17884, current rewards: -12.72620, mean: -0.04105
[32m[0906 21-36-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17966, current rewards: -112.72620, mean: -0.31313
[32m[0906 21-36-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18032, current rewards: -212.72620, mean: -0.51884
[32m[0906 21-37-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18081, current rewards: -312.72620, mean: -0.67984
[32m[0906 21-37-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18123, current rewards: -412.72620, mean: -0.80927
[32m[0906 21-37-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18154, current rewards: -512.72620, mean: -0.91558
[32m[0906 21-37-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18178, current rewards: -612.72620, mean: -1.00447
[32m[0906 21-37-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18204, current rewards: -702.74978, mean: -1.06477
[32m[0906 21-37-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18222, current rewards: -793.56203, mean: -1.11769
[32m[0906 21-38-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18237, current rewards: -862.24577, mean: -1.13453
[32m[0906 21-38-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18260, current rewards: -938.42449, mean: -1.15855
[32m[0906 21-38-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18277, current rewards: -1038.42449, mean: -1.20747
[32m[0906 21-38-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18286, current rewards: -1138.42449, mean: -1.25102
[32m[0906 21-38-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18297, current rewards: -1233.65421, mean: -1.28506
[32m[0906 21-38-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18306, current rewards: -1302.96689, mean: -1.29007
[32m[0906 21-38-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18315, current rewards: -1293.65416, mean: -1.22043
[32m[0906 21-39-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18323, current rewards: -1286.48709, mean: -1.15900
[32m[0906 21-39-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18331, current rewards: -1278.52581, mean: -1.10218
[32m[0906 21-39-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18338, current rewards: -1270.28213, mean: -1.04982
[32m[0906 21-39-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18345, current rewards: -1265.03895, mean: -1.00400
[32m[0906 21-39-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18393, current rewards: -1286.67941, mean: -0.98220
[32m[0906 21-39-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18505, current rewards: -1313.88776, mean: -0.96609
[32m[0906 21-40-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18569, current rewards: -1340.84922, mean: -0.95096
[32m[0906 21-40-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18573, current rewards: -1372.39834, mean: -0.94000
[32m[0906 21-40-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18623, current rewards: -1397.76884, mean: -0.92567
[32m[0906 21-40-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18685, current rewards: -1418.19375, mean: -0.90910
[32m[0906 21-40-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18723, current rewards: -1434.93053, mean: -0.89126
[32m[0906 21-40-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18737, current rewards: -1466.23656, mean: -0.88328
[32m[0906 21-41-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18763, current rewards: -1482.34762, mean: -0.86687
[32m[0906 21-41-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18771, current rewards: -1508.50693, mean: -0.85711
[32m[0906 21-41-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18756, current rewards: -1540.41213, mean: -0.85106
[32m[0906 21-41-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18722, current rewards: -1561.70615, mean: -0.83963
[32m[0906 21-41-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18687, current rewards: -1584.15429, mean: -0.82940
[32m[0906 21-41-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18655, current rewards: -1605.39433, mean: -0.81908
[32m[0906 21-41-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18624, current rewards: -1627.83687, mean: -0.80987
[32m[0906 21-42-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18603, current rewards: -1651.28490, mean: -0.80159
[32m[0906 21-42-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18590, current rewards: -1674.71388, mean: -0.79370
[32m[0906 21-42-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18578, current rewards: -1698.14661, mean: -0.78618
[32m[0906 21-42-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18565, current rewards: -1721.54781, mean: -0.77898
[32m[0906 21-42-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18552, current rewards: -1744.99310, mean: -0.77212
[32m[0906 21-42-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18545, current rewards: -1770.61930, mean: -0.76650
[32m[0906 21-43-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18544, current rewards: -1774.82473, mean: -0.75204
[32m[0906 21-43-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18542, current rewards: -1768.71849, mean: -0.73391
[32m[0906 21-43-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18540, current rewards: -1762.40726, mean: -0.71643
[32m[0906 21-43-28 @Agent.py:117][0m Average action selection time: 0.1854
[32m[0906 21-43-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-43-28 @MBExp.py:227][0m Rewards obtained: [-1757.3552440270269], Lows: [856], Highs: [242], Total time: 25687.778318999994
[32m[0906 21-45-24 @MBExp.py:144][0m ####################################################################
[32m[0906 21-45-24 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 21-45-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17323, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-45-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17401, current rewards: -9.00211, mean: -0.15004
[32m[0906 21-45-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17491, current rewards: -3.15403, mean: -0.02867
[32m[0906 21-45-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17653, current rewards: 2.69541, mean: 0.01685
[32m[0906 21-46-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17839, current rewards: 8.54864, mean: 0.04071
[32m[0906 21-46-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17987, current rewards: 14.32047, mean: 0.05508
[32m[0906 21-46-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18093, current rewards: -3.87565, mean: -0.01250
[32m[0906 21-46-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18150, current rewards: 2.75136, mean: 0.00764
[32m[0906 21-46-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18208, current rewards: 9.65218, mean: 0.02354
[32m[0906 21-46-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18243, current rewards: 16.55539, mean: 0.03599
[32m[0906 21-46-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18266, current rewards: 23.46922, mean: 0.04602
[32m[0906 21-47-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18284, current rewards: 30.37581, mean: 0.05424
[32m[0906 21-47-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18305, current rewards: 37.28005, mean: 0.06111
[32m[0906 21-47-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18318, current rewards: 44.17339, mean: 0.06693
[32m[0906 21-47-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18324, current rewards: 43.82220, mean: 0.06172
[32m[0906 21-47-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18333, current rewards: 10.88464, mean: 0.01432
[32m[0906 21-47-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18337, current rewards: 5.52145, mean: 0.00682
[32m[0906 21-48-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18341, current rewards: 4.17893, mean: 0.00486
[32m[0906 21-48-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18348, current rewards: -0.04248, mean: -0.00005
[32m[0906 21-48-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18351, current rewards: -2.32820, mean: -0.00243
[32m[0906 21-48-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18356, current rewards: -6.63715, mean: -0.00657
[32m[0906 21-48-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18367, current rewards: -8.67844, mean: -0.00819
[32m[0906 21-48-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18374, current rewards: -13.59889, mean: -0.01225
[32m[0906 21-48-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18377, current rewards: -13.72187, mean: -0.01183
[32m[0906 21-49-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18381, current rewards: -7.91759, mean: -0.00654
[32m[0906 21-49-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18384, current rewards: -2.10180, mean: -0.00167
[32m[0906 21-49-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18384, current rewards: 3.72377, mean: 0.00284
[32m[0906 21-49-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18378, current rewards: -17.74143, mean: -0.01305
[32m[0906 21-49-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18365, current rewards: -58.53007, mean: -0.04151
[32m[0906 21-49-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18357, current rewards: -91.37549, mean: -0.06259
[32m[0906 21-50-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18347, current rewards: -109.63440, mean: -0.07261
[32m[0906 21-50-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18335, current rewards: -105.15187, mean: -0.06741
[32m[0906 21-50-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18325, current rewards: -99.31712, mean: -0.06169
[32m[0906 21-50-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18299, current rewards: -93.47811, mean: -0.05631
[32m[0906 21-50-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18273, current rewards: -87.63912, mean: -0.05125
[32m[0906 21-50-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18251, current rewards: -81.80066, mean: -0.04648
[32m[0906 21-50-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18229, current rewards: -75.96152, mean: -0.04197
[32m[0906 21-51-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18208, current rewards: -70.12751, mean: -0.03770
[32m[0906 21-51-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18186, current rewards: -64.40758, mean: -0.03372
[32m[0906 21-51-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18166, current rewards: -78.73956, mean: -0.04017
[32m[0906 21-51-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18148, current rewards: -72.55287, mean: -0.03610
[32m[0906 21-51-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18142, current rewards: -66.37658, mean: -0.03222
[32m[0906 21-51-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18138, current rewards: -60.20774, mean: -0.02853
[32m[0906 21-51-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18135, current rewards: -54.03991, mean: -0.02502
[32m[0906 21-52-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18132, current rewards: -47.86191, mean: -0.02166
[32m[0906 21-52-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18129, current rewards: -41.69086, mean: -0.01845
[32m[0906 21-52-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18131, current rewards: -35.44924, mean: -0.01535
[32m[0906 21-52-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18140, current rewards: -40.27230, mean: -0.01706
[32m[0906 21-52-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18147, current rewards: -34.28335, mean: -0.01423
[32m[0906 21-52-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18157, current rewards: -28.28340, mean: -0.01150
[32m[0906 21-52-59 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 21-52-59 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-52-59 @MBExp.py:227][0m Rewards obtained: [-23.48273594161404], Lows: [153], Highs: [20], Total time: 26142.573385999993
[32m[0906 21-54-57 @MBExp.py:144][0m ####################################################################
[32m[0906 21-54-57 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 21-54-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17407, current rewards: 0.59416, mean: 0.05942
[32m[0906 21-55-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17503, current rewards: -3.91296, mean: -0.06522
[32m[0906 21-55-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17587, current rewards: 1.65474, mean: 0.01504
[32m[0906 21-55-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17734, current rewards: 7.22528, mean: 0.04516
[32m[0906 21-55-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17912, current rewards: 12.79387, mean: 0.06092
[32m[0906 21-55-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18014, current rewards: 6.51540, mean: 0.02506
[32m[0906 21-55-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18095, current rewards: 11.35258, mean: 0.03662
[32m[0906 21-56-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18153, current rewards: 16.18870, mean: 0.04497
[32m[0906 21-56-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18195, current rewards: 21.03000, mean: 0.05129
[32m[0906 21-56-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18226, current rewards: 25.86552, mean: 0.05623
[32m[0906 21-56-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18257, current rewards: 19.08092, mean: 0.03741
[32m[0906 21-56-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18275, current rewards: 22.94678, mean: 0.04098
[32m[0906 21-56-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18290, current rewards: 26.81003, mean: 0.04395
[32m[0906 21-56-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18312, current rewards: 31.03753, mean: 0.04703
[32m[0906 21-57-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18329, current rewards: 36.45580, mean: 0.05135
[32m[0906 21-57-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18338, current rewards: 41.09390, mean: 0.05407
[32m[0906 21-57-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18351, current rewards: 45.15852, mean: 0.05575
[32m[0906 21-57-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18359, current rewards: 49.06446, mean: 0.05705
[32m[0906 21-57-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18365, current rewards: 52.93680, mean: 0.05817
[32m[0906 21-57-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18373, current rewards: 56.80150, mean: 0.05917
[32m[0906 21-58-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18378, current rewards: 60.67096, mean: 0.06007
[32m[0906 21-58-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18379, current rewards: 64.37718, mean: 0.06073
[32m[0906 21-58-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18388, current rewards: 70.41914, mean: 0.06344
[32m[0906 21-58-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18393, current rewards: 74.55578, mean: 0.06427
[32m[0906 21-58-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18397, current rewards: 78.69133, mean: 0.06503
[32m[0906 21-58-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18401, current rewards: 82.82882, mean: 0.06574
[32m[0906 21-58-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18400, current rewards: 86.96309, mean: 0.06638
[32m[0906 21-59-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18390, current rewards: 91.10037, mean: 0.06699
[32m[0906 21-59-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18377, current rewards: 95.23717, mean: 0.06754
[32m[0906 21-59-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18363, current rewards: 99.44393, mean: 0.06811
[32m[0906 21-59-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18350, current rewards: 103.59257, mean: 0.06860
[32m[0906 21-59-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18339, current rewards: 107.74174, mean: 0.06907
[32m[0906 21-59-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18323, current rewards: 117.42897, mean: 0.07294
[32m[0906 22-00-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18295, current rewards: 122.29916, mean: 0.07367
[32m[0906 22-00-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18270, current rewards: 127.16523, mean: 0.07437
[32m[0906 22-00-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18246, current rewards: 132.02402, mean: 0.07501
[32m[0906 22-00-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18222, current rewards: 136.88415, mean: 0.07563
[32m[0906 22-00-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18201, current rewards: 141.58138, mean: 0.07612
[32m[0906 22-00-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18182, current rewards: 146.56238, mean: 0.07673
[32m[0906 22-00-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18163, current rewards: 151.56004, mean: 0.07733
[32m[0906 22-01-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18147, current rewards: 156.55997, mean: 0.07789
[32m[0906 22-01-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18146, current rewards: 150.06098, mean: 0.07285
[32m[0906 22-01-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18146, current rewards: 154.18249, mean: 0.07307
[32m[0906 22-01-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18144, current rewards: 158.31315, mean: 0.07329
[32m[0906 22-01-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18142, current rewards: 162.44428, mean: 0.07350
[32m[0906 22-01-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18137, current rewards: 144.02413, mean: 0.06373
[32m[0906 22-01-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18140, current rewards: 148.86569, mean: 0.06444
[32m[0906 22-02-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18151, current rewards: 153.65343, mean: 0.06511
[32m[0906 22-02-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18159, current rewards: 158.44377, mean: 0.06574
[32m[0906 22-02-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18166, current rewards: 163.23535, mean: 0.06636
[32m[0906 22-02-32 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0906 22-02-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-02-32 @MBExp.py:227][0m Rewards obtained: [167.06483591761517], Lows: [16], Highs: [30], Total time: 26597.565294999993
[32m[0906 22-04-32 @MBExp.py:144][0m ####################################################################
[32m[0906 22-04-32 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 22-04-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17321, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-04-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17418, current rewards: -18.18880, mean: -0.30315
[32m[0906 22-04-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17569, current rewards: -11.64165, mean: -0.10583
[32m[0906 22-05-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17722, current rewards: -4.45586, mean: -0.02785
[32m[0906 22-05-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17903, current rewards: 2.92387, mean: 0.01392
[32m[0906 22-05-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18021, current rewards: 9.86106, mean: 0.03793
[32m[0906 22-05-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18134, current rewards: 16.82795, mean: 0.05428
[32m[0906 22-05-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18188, current rewards: 23.75676, mean: 0.06599
[32m[0906 22-05-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18218, current rewards: 30.64525, mean: 0.07474
[32m[0906 22-05-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18259, current rewards: 37.51140, mean: 0.08155
[32m[0906 22-06-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18285, current rewards: 44.37210, mean: 0.08700
[32m[0906 22-06-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18305, current rewards: 12.40677, mean: 0.02215
[32m[0906 22-06-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18325, current rewards: -51.32416, mean: -0.08414
[32m[0906 22-06-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18337, current rewards: -93.36528, mean: -0.14146
[32m[0906 22-06-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18349, current rewards: -151.88675, mean: -0.21393
[32m[0906 22-06-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18359, current rewards: -188.32994, mean: -0.24780
[32m[0906 22-07-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18372, current rewards: -215.89430, mean: -0.26654
[32m[0906 22-07-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18376, current rewards: -240.23950, mean: -0.27935
[32m[0906 22-07-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18382, current rewards: -266.73292, mean: -0.29311
[32m[0906 22-07-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18393, current rewards: -291.10762, mean: -0.30324
[32m[0906 22-07-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18409, current rewards: -323.98448, mean: -0.32078
[32m[0906 22-07-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18413, current rewards: -360.00626, mean: -0.33963
[32m[0906 22-07-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18416, current rewards: -394.93434, mean: -0.35580
[32m[0906 22-08-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18420, current rewards: -430.95492, mean: -0.37151
[32m[0906 22-08-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18443, current rewards: -465.68491, mean: -0.38486
[32m[0906 22-08-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18444, current rewards: -468.92504, mean: -0.37216
[32m[0906 22-08-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18437, current rewards: -469.57611, mean: -0.35846
[32m[0906 22-08-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18419, current rewards: -472.46836, mean: -0.34740
[32m[0906 22-08-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18404, current rewards: -469.52925, mean: -0.33300
[32m[0906 22-09-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18389, current rewards: -463.95177, mean: -0.31778
[32m[0906 22-09-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18379, current rewards: -458.36070, mean: -0.30355
[32m[0906 22-09-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18366, current rewards: -452.77800, mean: -0.29024
[32m[0906 22-09-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18346, current rewards: -447.19834, mean: -0.27776
[32m[0906 22-09-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18321, current rewards: -441.60546, mean: -0.26603
[32m[0906 22-09-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18297, current rewards: -436.01772, mean: -0.25498
[32m[0906 22-09-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18271, current rewards: -451.18855, mean: -0.25636
[32m[0906 22-10-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18248, current rewards: -470.06252, mean: -0.25970
[32m[0906 22-10-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18226, current rewards: -473.73226, mean: -0.25469
[32m[0906 22-10-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18205, current rewards: -468.02134, mean: -0.24504
[32m[0906 22-10-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18186, current rewards: -462.22143, mean: -0.23583
[32m[0906 22-10-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18175, current rewards: -456.42062, mean: -0.22707
[32m[0906 22-10-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18170, current rewards: -450.61854, mean: -0.21875
[32m[0906 22-10-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18167, current rewards: -444.81646, mean: -0.21081
[32m[0906 22-11-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18164, current rewards: -439.01336, mean: -0.20325
[32m[0906 22-11-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18161, current rewards: -433.58428, mean: -0.19619
[32m[0906 22-11-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18158, current rewards: -428.02608, mean: -0.18939
[32m[0906 22-11-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18161, current rewards: -422.32923, mean: -0.18283
[32m[0906 22-11-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18170, current rewards: -416.64033, mean: -0.17654
[32m[0906 22-11-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18180, current rewards: -411.79853, mean: -0.17087
[32m[0906 22-12-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18186, current rewards: -406.94959, mean: -0.16543
[32m[0906 22-12-07 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 22-12-07 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-12-07 @MBExp.py:227][0m Rewards obtained: [-403.06821956848233], Lows: [171], Highs: [325], Total time: 27053.081214999995
[32m[0906 22-14-09 @MBExp.py:144][0m ####################################################################
[32m[0906 22-14-09 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 22-14-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17210, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-14-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17378, current rewards: -99.86792, mean: -1.66447
[32m[0906 22-14-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17559, current rewards: -189.14455, mean: -1.71950
[32m[0906 22-14-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17697, current rewards: -240.46381, mean: -1.50290
[32m[0906 22-14-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17896, current rewards: -234.50344, mean: -1.11668
[32m[0906 22-14-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18018, current rewards: -228.02178, mean: -0.87701
[32m[0906 22-15-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18093, current rewards: -221.54522, mean: -0.71466
[32m[0906 22-15-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18135, current rewards: -215.06471, mean: -0.59740
[32m[0906 22-15-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18177, current rewards: -208.58564, mean: -0.50875
[32m[0906 22-15-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18222, current rewards: -202.09367, mean: -0.43933
[32m[0906 22-15-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18244, current rewards: -195.62425, mean: -0.38358
[32m[0906 22-15-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18282, current rewards: -189.13260, mean: -0.33774
[32m[0906 22-16-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18307, current rewards: -180.95734, mean: -0.29665
[32m[0906 22-16-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18321, current rewards: -174.83486, mean: -0.26490
[32m[0906 22-16-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18336, current rewards: -188.39033, mean: -0.26534
[32m[0906 22-16-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18345, current rewards: -180.03417, mean: -0.23689
[32m[0906 22-16-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18347, current rewards: -173.41525, mean: -0.21409
[32m[0906 22-16-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18353, current rewards: -166.80091, mean: -0.19395
[32m[0906 22-16-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18359, current rewards: -160.19219, mean: -0.17604
[32m[0906 22-17-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18363, current rewards: -153.58040, mean: -0.15998
[32m[0906 22-17-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18372, current rewards: -147.38954, mean: -0.14593
[32m[0906 22-17-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18375, current rewards: -140.76978, mean: -0.13280
[32m[0906 22-17-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18379, current rewards: -134.15004, mean: -0.12086
[32m[0906 22-17-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18381, current rewards: -127.52485, mean: -0.10994
[32m[0906 22-17-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18383, current rewards: -135.83080, mean: -0.11226
[32m[0906 22-18-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18389, current rewards: -136.90868, mean: -0.10866
[32m[0906 22-18-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18374, current rewards: -131.63580, mean: -0.10049
[32m[0906 22-18-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18358, current rewards: -126.36576, mean: -0.09292
[32m[0906 22-18-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18343, current rewards: -119.51341, mean: -0.08476
[32m[0906 22-18-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18329, current rewards: -114.01596, mean: -0.07809
[32m[0906 22-18-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18317, current rewards: -108.66235, mean: -0.07196
[32m[0906 22-18-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18304, current rewards: -103.30926, mean: -0.06622
[32m[0906 22-19-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18280, current rewards: -97.95698, mean: -0.06084
[32m[0906 22-19-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18254, current rewards: -92.60462, mean: -0.05579
[32m[0906 22-19-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18229, current rewards: -87.24943, mean: -0.05102
[32m[0906 22-19-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18204, current rewards: -81.89500, mean: -0.04653
[32m[0906 22-19-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18185, current rewards: -96.32162, mean: -0.05322
[32m[0906 22-19-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18163, current rewards: -91.93029, mean: -0.04942
[32m[0906 22-19-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18144, current rewards: -86.90134, mean: -0.04550
[32m[0906 22-20-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18126, current rewards: -81.86988, mean: -0.04177
[32m[0906 22-20-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18120, current rewards: -76.83560, mean: -0.03823
[32m[0906 22-20-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18117, current rewards: -71.80120, mean: -0.03485
[32m[0906 22-20-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18114, current rewards: -86.91745, mean: -0.04119
[32m[0906 22-20-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18110, current rewards: -81.31806, mean: -0.03765
[32m[0906 22-20-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18106, current rewards: -75.71780, mean: -0.03426
[32m[0906 22-20-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18103, current rewards: -66.33694, mean: -0.02935
[32m[0906 22-21-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18108, current rewards: -60.91502, mean: -0.02637
[32m[0906 22-21-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18118, current rewards: -55.47221, mean: -0.02351
[32m[0906 22-21-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18125, current rewards: -50.02723, mean: -0.02076
[32m[0906 22-21-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18132, current rewards: -44.58264, mean: -0.01812
[32m[0906 22-21-43 @Agent.py:117][0m Average action selection time: 0.1814
[32m[0906 22-21-43 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-21-43 @MBExp.py:227][0m Rewards obtained: [-40.226517405913434], Lows: [159], Highs: [11], Total time: 27507.310810999996
[32m[0906 22-23-47 @MBExp.py:144][0m ####################################################################
[32m[0906 22-23-47 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 22-23-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17350, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-23-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17402, current rewards: -29.77571, mean: -0.49626
[32m[0906 22-24-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17572, current rewards: -49.29961, mean: -0.44818
[32m[0906 22-24-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17742, current rewards: -69.80482, mean: -0.43628
[32m[0906 22-24-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17950, current rewards: -80.06918, mean: -0.38128
[32m[0906 22-24-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18062, current rewards: -74.72386, mean: -0.28740
[32m[0906 22-24-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18121, current rewards: -75.88828, mean: -0.24480
[32m[0906 22-24-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18164, current rewards: -85.16470, mean: -0.23657
[32m[0906 22-25-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18208, current rewards: -79.43912, mean: -0.19375
[32m[0906 22-25-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18226, current rewards: -74.17140, mean: -0.16124
[32m[0906 22-25-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18248, current rewards: -68.89986, mean: -0.13510
[32m[0906 22-25-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18260, current rewards: -63.63044, mean: -0.11363
[32m[0906 22-25-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18270, current rewards: -58.60988, mean: -0.09608
[32m[0906 22-25-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18280, current rewards: -70.08795, mean: -0.10619
[32m[0906 22-25-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18296, current rewards: -72.39234, mean: -0.10196
[32m[0906 22-26-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18305, current rewards: -68.59487, mean: -0.09026
[32m[0906 22-26-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18310, current rewards: -64.79772, mean: -0.08000
[32m[0906 22-26-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18323, current rewards: -60.99846, mean: -0.07093
[32m[0906 22-26-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18337, current rewards: -57.20182, mean: -0.06286
[32m[0906 22-26-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18342, current rewards: -53.40462, mean: -0.05563
[32m[0906 22-26-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18347, current rewards: -49.30743, mean: -0.04882
[32m[0906 22-27-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18350, current rewards: -43.47500, mean: -0.04101
[32m[0906 22-27-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18355, current rewards: -38.77859, mean: -0.03494
[32m[0906 22-27-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18357, current rewards: -34.08218, mean: -0.02938
[32m[0906 22-27-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18359, current rewards: -29.38577, mean: -0.02429
[32m[0906 22-27-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18357, current rewards: -40.00435, mean: -0.03175
[32m[0906 22-27-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18340, current rewards: -90.00435, mean: -0.06871
[32m[0906 22-27-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18327, current rewards: -140.00435, mean: -0.10294
[32m[0906 22-28-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18315, current rewards: -190.00435, mean: -0.13475
[32m[0906 22-28-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18304, current rewards: -240.00435, mean: -0.16439
[32m[0906 22-28-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18292, current rewards: -290.00435, mean: -0.19206
[32m[0906 22-28-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18284, current rewards: -340.00435, mean: -0.21795
[32m[0906 22-28-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18258, current rewards: -390.00435, mean: -0.24224
[32m[0906 22-28-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18234, current rewards: -440.00435, mean: -0.26506
[32m[0906 22-28-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18209, current rewards: -490.00435, mean: -0.28655
[32m[0906 22-29-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18188, current rewards: -540.00435, mean: -0.30682
[32m[0906 22-29-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18166, current rewards: -590.00435, mean: -0.32597
[32m[0906 22-29-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18145, current rewards: -640.00435, mean: -0.34409
[32m[0906 22-29-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18126, current rewards: -690.00435, mean: -0.36126
[32m[0906 22-29-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18108, current rewards: -740.00435, mean: -0.37755
[32m[0906 22-29-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18105, current rewards: -790.00435, mean: -0.39304
[32m[0906 22-30-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18101, current rewards: -840.00435, mean: -0.40777
[32m[0906 22-30-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18099, current rewards: -890.00435, mean: -0.42180
[32m[0906 22-30-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18096, current rewards: -940.00435, mean: -0.43519
[32m[0906 22-30-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18093, current rewards: -990.00435, mean: -0.44797
[32m[0906 22-30-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18092, current rewards: -1040.00435, mean: -0.46018
[32m[0906 22-30-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18098, current rewards: -1090.00435, mean: -0.47186
[32m[0906 22-30-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18107, current rewards: -1140.00435, mean: -0.48305
[32m[0906 22-31-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18115, current rewards: -1190.00435, mean: -0.49378
[32m[0906 22-31-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18125, current rewards: -1240.00435, mean: -0.50407
[32m[0906 22-31-21 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0906 22-31-21 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-31-21 @MBExp.py:227][0m Rewards obtained: [-1280.0043547204168], Lows: [66], Highs: [1275], Total time: 27961.312926999995
[32m[0906 22-33-27 @MBExp.py:144][0m ####################################################################
[32m[0906 22-33-27 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 22-33-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18486, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-33-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17603, current rewards: -27.30826, mean: -0.45514
[32m[0906 22-33-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17709, current rewards: -21.20477, mean: -0.19277
[32m[0906 22-33-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17778, current rewards: -15.09994, mean: -0.09437
[32m[0906 22-34-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17964, current rewards: -9.25186, mean: -0.04406
[32m[0906 22-34-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18052, current rewards: -3.07403, mean: -0.01182
[32m[0906 22-34-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18119, current rewards: 3.14652, mean: 0.01015
[32m[0906 22-34-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18164, current rewards: 8.07719, mean: 0.02244
[32m[0906 22-34-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18202, current rewards: 13.89763, mean: 0.03390
[32m[0906 22-34-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18244, current rewards: 19.72873, mean: 0.04289
[32m[0906 22-35-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18265, current rewards: 25.54958, mean: 0.05010
[32m[0906 22-35-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18281, current rewards: 31.37570, mean: 0.05603
[32m[0906 22-35-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18296, current rewards: 6.54286, mean: 0.01073
[32m[0906 22-35-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18304, current rewards: 12.39520, mean: 0.01878
[32m[0906 22-35-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18317, current rewards: 18.14800, mean: 0.02556
[32m[0906 22-35-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18326, current rewards: 23.90134, mean: 0.03145
[32m[0906 22-35-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18335, current rewards: 29.65357, mean: 0.03661
[32m[0906 22-36-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18342, current rewards: 35.41024, mean: 0.04117
[32m[0906 22-36-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18348, current rewards: 41.15937, mean: 0.04523
[32m[0906 22-36-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18356, current rewards: 46.91709, mean: 0.04887
[32m[0906 22-36-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18362, current rewards: 52.64824, mean: 0.05213
[32m[0906 22-36-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18363, current rewards: 58.14938, mean: 0.05486
[32m[0906 22-36-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18373, current rewards: 63.86753, mean: 0.05754
[32m[0906 22-37-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18379, current rewards: 69.58342, mean: 0.05999
[32m[0906 22-37-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18382, current rewards: 57.84514, mean: 0.04781
[32m[0906 22-37-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18365, current rewards: 63.12503, mean: 0.05010
[32m[0906 22-37-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18350, current rewards: 68.39128, mean: 0.05221
[32m[0906 22-37-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18335, current rewards: 73.66810, mean: 0.05417
[32m[0906 22-37-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18324, current rewards: 74.73190, mean: 0.05300
[32m[0906 22-37-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18314, current rewards: 57.50788, mean: 0.03939
[32m[0906 22-38-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18302, current rewards: 63.42660, mean: 0.04200
[32m[0906 22-38-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18292, current rewards: 69.33136, mean: 0.04444
[32m[0906 22-38-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18266, current rewards: 75.24103, mean: 0.04673
[32m[0906 22-38-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18240, current rewards: 81.14599, mean: 0.04888
[32m[0906 22-38-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18216, current rewards: 87.05319, mean: 0.05091
[32m[0906 22-38-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18193, current rewards: 92.95748, mean: 0.05282
[32m[0906 22-38-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18172, current rewards: 98.86334, mean: 0.05462
[32m[0906 22-39-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18154, current rewards: 106.18249, mean: 0.05709
[32m[0906 22-39-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18134, current rewards: 88.60242, mean: 0.04639
[32m[0906 22-39-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18121, current rewards: 95.60974, mean: 0.04878
[32m[0906 22-39-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18116, current rewards: 102.80041, mean: 0.05114
[32m[0906 22-39-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18113, current rewards: 109.98943, mean: 0.05339
[32m[0906 22-39-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18111, current rewards: 117.18229, mean: 0.05554
[32m[0906 22-39-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18108, current rewards: 124.37170, mean: 0.05758
[32m[0906 22-40-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18107, current rewards: 131.56064, mean: 0.05953
[32m[0906 22-40-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18103, current rewards: 141.15174, mean: 0.06246
[32m[0906 22-40-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18103, current rewards: 148.07766, mean: 0.06410
[32m[0906 22-40-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18113, current rewards: 141.24979, mean: 0.05985
[32m[0906 22-40-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18124, current rewards: 147.63216, mean: 0.06126
[32m[0906 22-40-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18130, current rewards: 154.02066, mean: 0.06261
[32m[0906 22-41-01 @Agent.py:117][0m Average action selection time: 0.1814
[32m[0906 22-41-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-41-01 @MBExp.py:227][0m Rewards obtained: [159.1333425546805], Lows: [51], Highs: [37], Total time: 28415.499519999994
[32m[0906 22-43-09 @MBExp.py:144][0m ####################################################################
[32m[0906 22-43-09 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 22-43-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17346, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-43-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17459, current rewards: -29.90498, mean: -0.49842
[32m[0906 22-43-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17649, current rewards: -35.89525, mean: -0.32632
[32m[0906 22-43-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17795, current rewards: -45.29498, mean: -0.28309
[32m[0906 22-43-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17959, current rewards: -64.04903, mean: -0.30500
[32m[0906 22-43-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18087, current rewards: -87.23020, mean: -0.33550
[32m[0906 22-44-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18165, current rewards: -104.49414, mean: -0.33708
[32m[0906 22-44-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18197, current rewards: -132.14962, mean: -0.36708
[32m[0906 22-44-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18231, current rewards: -128.53576, mean: -0.31350
[32m[0906 22-44-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18257, current rewards: -124.92769, mean: -0.27158
[32m[0906 22-44-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18280, current rewards: -121.32099, mean: -0.23788
[32m[0906 22-44-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18295, current rewards: -117.72336, mean: -0.21022
[32m[0906 22-45-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18309, current rewards: -114.06976, mean: -0.18700
[32m[0906 22-45-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18325, current rewards: -110.14593, mean: -0.16689
[32m[0906 22-45-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18341, current rewards: -106.22131, mean: -0.14961
[32m[0906 22-45-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18352, current rewards: -102.29524, mean: -0.13460
[32m[0906 22-45-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18355, current rewards: -112.28603, mean: -0.13862
[32m[0906 22-45-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18360, current rewards: -127.36222, mean: -0.14810
[32m[0906 22-45-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18368, current rewards: -134.04741, mean: -0.14730
[32m[0906 22-46-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18371, current rewards: -140.64610, mean: -0.14651
[32m[0906 22-46-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18379, current rewards: -141.63977, mean: -0.14024
[32m[0906 22-46-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18381, current rewards: -138.58434, mean: -0.13074
[32m[0906 22-46-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18384, current rewards: -135.52055, mean: -0.12209
[32m[0906 22-46-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18387, current rewards: -132.44328, mean: -0.11418
[32m[0906 22-46-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18382, current rewards: -129.37085, mean: -0.10692
[32m[0906 22-47-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18365, current rewards: -126.30058, mean: -0.10024
[32m[0906 22-47-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18349, current rewards: -123.23557, mean: -0.09407
[32m[0906 22-47-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18338, current rewards: -120.17779, mean: -0.08837
[32m[0906 22-47-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18329, current rewards: -135.63820, mean: -0.09620
[32m[0906 22-47-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18318, current rewards: -146.43077, mean: -0.10030
[32m[0906 22-47-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18308, current rewards: -173.11439, mean: -0.11465
[32m[0906 22-47-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18293, current rewards: -200.44479, mean: -0.12849
[32m[0906 22-48-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18268, current rewards: -215.45720, mean: -0.13382
[32m[0906 22-48-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18243, current rewards: -215.58207, mean: -0.12987
[32m[0906 22-48-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18218, current rewards: -216.80979, mean: -0.12679
[32m[0906 22-48-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18195, current rewards: -220.17710, mean: -0.12510
[32m[0906 22-48-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18174, current rewards: -236.32311, mean: -0.13057
[32m[0906 22-48-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18153, current rewards: -247.68175, mean: -0.13316
[32m[0906 22-48-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18135, current rewards: -242.13574, mean: -0.12677
[32m[0906 22-49-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18126, current rewards: -236.58807, mean: -0.12071
[32m[0906 22-49-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18121, current rewards: -231.03995, mean: -0.11495
[32m[0906 22-49-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18119, current rewards: -225.49316, mean: -0.10946
[32m[0906 22-49-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18119, current rewards: -241.22472, mean: -0.11432
[32m[0906 22-49-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18116, current rewards: -235.62054, mean: -0.10908
[32m[0906 22-49-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18113, current rewards: -230.28461, mean: -0.10420
[32m[0906 22-49-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18110, current rewards: -224.78251, mean: -0.09946
[32m[0906 22-50-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18111, current rewards: -219.20942, mean: -0.09490
[32m[0906 22-50-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18119, current rewards: -213.64798, mean: -0.09053
[32m[0906 22-50-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18128, current rewards: -235.83688, mean: -0.09786
[32m[0906 22-50-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18137, current rewards: -283.68186, mean: -0.11532
[32m[0906 22-50-43 @Agent.py:117][0m Average action selection time: 0.1814
[32m[0906 22-50-43 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-50-43 @MBExp.py:227][0m Rewards obtained: [-305.174572236317], Lows: [57], Highs: [362], Total time: 28869.812418999994
[32m[0906 22-52-52 @MBExp.py:144][0m ####################################################################
[32m[0906 22-52-52 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 22-52-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17367, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-53-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17410, current rewards: -46.64145, mean: -0.77736
[32m[0906 22-53-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17599, current rewards: -41.30175, mean: -0.37547
[32m[0906 22-53-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17781, current rewards: -35.96525, mean: -0.22478
[32m[0906 22-53-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17957, current rewards: -30.62862, mean: -0.14585
[32m[0906 22-53-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18075, current rewards: -25.28962, mean: -0.09727
[32m[0906 22-53-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18155, current rewards: -19.95059, mean: -0.06436
[32m[0906 22-53-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18204, current rewards: -14.61590, mean: -0.04060
[32m[0906 22-54-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18233, current rewards: -9.27842, mean: -0.02263
[32m[0906 22-54-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18256, current rewards: -3.94738, mean: -0.00858
[32m[0906 22-54-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18278, current rewards: 1.51359, mean: 0.00297
[32m[0906 22-54-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18297, current rewards: 7.34055, mean: 0.01311
[32m[0906 22-54-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18307, current rewards: 12.71454, mean: 0.02084
[32m[0906 22-54-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18321, current rewards: 18.09471, mean: 0.02742
[32m[0906 22-55-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18350, current rewards: -4.23671, mean: -0.00597
[32m[0906 22-55-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18356, current rewards: -0.36998, mean: -0.00049
[32m[0906 22-55-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18365, current rewards: 5.11331, mean: 0.00631
[32m[0906 22-55-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18367, current rewards: 10.59836, mean: 0.01232
[32m[0906 22-55-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18373, current rewards: 16.08117, mean: 0.01767
[32m[0906 22-55-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18384, current rewards: 26.01282, mean: 0.02710
[32m[0906 22-55-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18388, current rewards: -2.15231, mean: -0.00213
[32m[0906 22-56-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18393, current rewards: -52.15231, mean: -0.04920
[32m[0906 22-56-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18398, current rewards: -102.15231, mean: -0.09203
[32m[0906 22-56-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18395, current rewards: -152.15231, mean: -0.13117
[32m[0906 22-56-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18376, current rewards: -202.15231, mean: -0.16707
[32m[0906 22-56-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18359, current rewards: -252.15231, mean: -0.20012
[32m[0906 22-56-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18343, current rewards: -302.15231, mean: -0.23065
[32m[0906 22-57-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18330, current rewards: -352.15231, mean: -0.25894
[32m[0906 22-57-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18317, current rewards: -402.15231, mean: -0.28521
[32m[0906 22-57-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18304, current rewards: -452.15231, mean: -0.30969
[32m[0906 22-57-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18292, current rewards: -502.15231, mean: -0.33255
[32m[0906 22-57-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18269, current rewards: -552.15231, mean: -0.35394
[32m[0906 22-57-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18242, current rewards: -602.15231, mean: -0.37401
[32m[0906 22-57-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18220, current rewards: -652.15231, mean: -0.39286
[32m[0906 22-58-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18196, current rewards: -702.15231, mean: -0.41062
[32m[0906 22-58-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18174, current rewards: -752.15231, mean: -0.42736
[32m[0906 22-58-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18153, current rewards: -802.15231, mean: -0.44318
[32m[0906 22-58-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18132, current rewards: -852.15231, mean: -0.45815
[32m[0906 22-58-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18114, current rewards: -902.15231, mean: -0.47233
[32m[0906 22-58-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18109, current rewards: -952.15231, mean: -0.48579
[32m[0906 22-58-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18106, current rewards: -1002.15231, mean: -0.49858
[32m[0906 22-59-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18102, current rewards: -1052.15231, mean: -0.51075
[32m[0906 22-59-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18099, current rewards: -1102.15231, mean: -0.52235
[32m[0906 22-59-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18096, current rewards: -1152.15231, mean: -0.53340
[32m[0906 22-59-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18095, current rewards: -1202.15231, mean: -0.54396
[32m[0906 22-59-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18091, current rewards: -1252.15231, mean: -0.55405
[32m[0906 22-59-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18095, current rewards: -1302.15231, mean: -0.56370
[32m[0906 23-00-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18107, current rewards: -1352.15231, mean: -0.57295
[32m[0906 23-00-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18116, current rewards: -1402.15231, mean: -0.58181
[32m[0906 23-00-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18123, current rewards: -1452.15231, mean: -0.59031
[32m[0906 23-00-26 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0906 23-00-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-00-26 @MBExp.py:227][0m Rewards obtained: [-1492.1523103602203], Lows: [30], Highs: [1538], Total time: 29323.816161999996
[32m[0906 23-02-38 @MBExp.py:144][0m ####################################################################
[32m[0906 23-02-38 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 23-02-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17307, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-02-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17406, current rewards: -5.88645, mean: -0.09811
[32m[0906 23-02-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17595, current rewards: -2.29188, mean: -0.02084
[32m[0906 23-03-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17796, current rewards: 1.42195, mean: 0.00889
[32m[0906 23-03-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17960, current rewards: 5.08282, mean: 0.02420
[32m[0906 23-03-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18065, current rewards: 8.74261, mean: 0.03363
[32m[0906 23-03-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18125, current rewards: 12.40267, mean: 0.04001
[32m[0906 23-03-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18181, current rewards: 16.06294, mean: 0.04462
[32m[0906 23-03-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18212, current rewards: 19.72021, mean: 0.04810
[32m[0906 23-04-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18244, current rewards: 23.37863, mean: 0.05082
[32m[0906 23-04-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18278, current rewards: 27.12678, mean: 0.05319
[32m[0906 23-04-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18295, current rewards: 31.15370, mean: 0.05563
[32m[0906 23-04-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18311, current rewards: 34.58156, mean: 0.05669
[32m[0906 23-04-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18319, current rewards: 38.00467, mean: 0.05758
[32m[0906 23-04-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18327, current rewards: 41.42476, mean: 0.05834
[32m[0906 23-04-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18331, current rewards: 44.83827, mean: 0.05900
[32m[0906 23-05-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18339, current rewards: 48.24735, mean: 0.05956
[32m[0906 23-05-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18344, current rewards: 51.65652, mean: 0.06007
[32m[0906 23-05-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18350, current rewards: 55.06916, mean: 0.06052
[32m[0906 23-05-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18356, current rewards: 41.86071, mean: 0.04360
[32m[0906 23-05-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18364, current rewards: 46.11889, mean: 0.04566
[32m[0906 23-05-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18367, current rewards: 50.27865, mean: 0.04743
[32m[0906 23-06-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18367, current rewards: 54.44163, mean: 0.04905
[32m[0906 23-06-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18358, current rewards: 58.60652, mean: 0.05052
[32m[0906 23-06-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18344, current rewards: 62.76812, mean: 0.05187
[32m[0906 23-06-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18329, current rewards: 66.92814, mean: 0.05312
[32m[0906 23-06-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18313, current rewards: 71.08423, mean: 0.05426
[32m[0906 23-06-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18300, current rewards: 47.10316, mean: 0.03463
[32m[0906 23-06-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18288, current rewards: 49.37709, mean: 0.03502
[32m[0906 23-07-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18276, current rewards: 55.29496, mean: 0.03787
[32m[0906 23-07-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18264, current rewards: 61.21284, mean: 0.04054
[32m[0906 23-07-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18240, current rewards: 67.13071, mean: 0.04303
[32m[0906 23-07-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18214, current rewards: 45.08965, mean: 0.02801
[32m[0906 23-07-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18189, current rewards: -4.91035, mean: -0.00296
[32m[0906 23-07-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18166, current rewards: -54.91035, mean: -0.03211
[32m[0906 23-07-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18143, current rewards: -104.91035, mean: -0.05961
[32m[0906 23-08-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18122, current rewards: -154.91035, mean: -0.08559
[32m[0906 23-08-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18104, current rewards: -204.91035, mean: -0.11017
[32m[0906 23-08-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18091, current rewards: -254.91035, mean: -0.13346
[32m[0906 23-08-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18088, current rewards: -304.91035, mean: -0.15557
[32m[0906 23-08-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18084, current rewards: -354.91035, mean: -0.17657
[32m[0906 23-08-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18082, current rewards: -404.91035, mean: -0.19656
[32m[0906 23-09-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18079, current rewards: -454.91035, mean: -0.21560
[32m[0906 23-09-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18077, current rewards: -504.91035, mean: -0.23375
[32m[0906 23-09-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18073, current rewards: -554.91035, mean: -0.25109
[32m[0906 23-09-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18070, current rewards: -604.91035, mean: -0.26766
[32m[0906 23-09-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18075, current rewards: -654.91035, mean: -0.28351
[32m[0906 23-09-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18084, current rewards: -704.91035, mean: -0.29869
[32m[0906 23-09-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18094, current rewards: -754.91035, mean: -0.31324
[32m[0906 23-10-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18103, current rewards: -804.91035, mean: -0.32720
[32m[0906 23-10-11 @Agent.py:117][0m Average action selection time: 0.1811
[32m[0906 23-10-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-10-11 @MBExp.py:227][0m Rewards obtained: [-844.9103532391082], Lows: [24], Highs: [926], Total time: 29777.282027999994
[32m[0906 23-12-24 @MBExp.py:144][0m ####################################################################
[32m[0906 23-12-24 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 23-12-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17599, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-12-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17539, current rewards: -5.29024, mean: -0.08817
[32m[0906 23-12-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17665, current rewards: 0.18188, mean: 0.00165
[32m[0906 23-12-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17840, current rewards: 5.73308, mean: 0.03583
[32m[0906 23-13-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17994, current rewards: 11.29165, mean: 0.05377
[32m[0906 23-13-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18077, current rewards: 16.83460, mean: 0.06475
[32m[0906 23-13-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18137, current rewards: 22.38068, mean: 0.07220
[32m[0906 23-13-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18184, current rewards: 27.94294, mean: 0.07762
[32m[0906 23-13-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18249, current rewards: 14.48997, mean: 0.03534
[32m[0906 23-13-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18270, current rewards: 15.89288, mean: 0.03455
[32m[0906 23-13-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18292, current rewards: 24.76910, mean: 0.04857
[32m[0906 23-14-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18316, current rewards: 30.79503, mean: 0.05499
[32m[0906 23-14-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18335, current rewards: 36.81676, mean: 0.06036
[32m[0906 23-14-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18346, current rewards: 42.83738, mean: 0.06491
[32m[0906 23-14-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18354, current rewards: 42.49944, mean: 0.05986
[32m[0906 23-14-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18368, current rewards: 32.85111, mean: 0.04323
[32m[0906 23-14-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18365, current rewards: 38.96418, mean: 0.04810
[32m[0906 23-15-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18366, current rewards: 45.07684, mean: 0.05241
[32m[0906 23-15-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18364, current rewards: 51.19735, mean: 0.05626
[32m[0906 23-15-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18365, current rewards: 57.31231, mean: 0.05970
[32m[0906 23-15-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18370, current rewards: 63.42387, mean: 0.06280
[32m[0906 23-15-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18373, current rewards: 69.53771, mean: 0.06560
[32m[0906 23-15-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18368, current rewards: 75.65223, mean: 0.06816
[32m[0906 23-15-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18350, current rewards: 81.76633, mean: 0.07049
[32m[0906 23-16-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18335, current rewards: 75.15829, mean: 0.06211
[32m[0906 23-16-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18324, current rewards: 81.05333, mean: 0.06433
[32m[0906 23-16-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18309, current rewards: 86.54638, mean: 0.06607
[32m[0906 23-16-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18294, current rewards: 92.46654, mean: 0.06799
[32m[0906 23-16-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18287, current rewards: 98.37943, mean: 0.06977
[32m[0906 23-16-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18277, current rewards: 104.28892, mean: 0.07143
[32m[0906 23-17-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18268, current rewards: 110.19856, mean: 0.07298
[32m[0906 23-17-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18244, current rewards: 116.11081, mean: 0.07443
[32m[0906 23-17-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18217, current rewards: 122.03605, mean: 0.07580
[32m[0906 23-17-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18194, current rewards: 127.93930, mean: 0.07707
[32m[0906 23-17-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18170, current rewards: 135.92768, mean: 0.07949
[32m[0906 23-17-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18148, current rewards: 141.84513, mean: 0.08059
[32m[0906 23-17-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18135, current rewards: 126.09647, mean: 0.06967
[32m[0906 23-18-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18115, current rewards: 132.97794, mean: 0.07149
[32m[0906 23-18-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18106, current rewards: 139.64313, mean: 0.07311
[32m[0906 23-18-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18103, current rewards: 146.31431, mean: 0.07465
[32m[0906 23-18-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18099, current rewards: 152.98359, mean: 0.07611
[32m[0906 23-18-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18096, current rewards: 159.65280, mean: 0.07750
[32m[0906 23-18-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18094, current rewards: 154.23147, mean: 0.07310
[32m[0906 23-18-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18093, current rewards: 159.25852, mean: 0.07373
[32m[0906 23-19-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18090, current rewards: 164.68876, mean: 0.07452
[32m[0906 23-19-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18088, current rewards: 170.11728, mean: 0.07527
[32m[0906 23-19-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18087, current rewards: 175.52777, mean: 0.07599
[32m[0906 23-19-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18096, current rewards: 180.96243, mean: 0.07668
[32m[0906 23-19-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18103, current rewards: 186.38677, mean: 0.07734
[32m[0906 23-19-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18112, current rewards: 191.80527, mean: 0.07797
[32m[0906 23-19-58 @Agent.py:117][0m Average action selection time: 0.1812
[32m[0906 23-19-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-19-58 @MBExp.py:227][0m Rewards obtained: [196.14496809035504], Lows: [33], Highs: [31], Total time: 30231.004260999995
[32m[0906 23-22-14 @MBExp.py:144][0m ####################################################################
[32m[0906 23-22-14 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 23-22-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.27606, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-22-25 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19097, current rewards: -10.37791, mean: -0.17297
[32m[0906 23-22-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18594, current rewards: -13.30399, mean: -0.12095
[32m[0906 23-22-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18395, current rewards: -16.11323, mean: -0.10071
[32m[0906 23-22-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18428, current rewards: -16.86763, mean: -0.08032
[32m[0906 23-23-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18481, current rewards: -19.73100, mean: -0.07589
[32m[0906 23-23-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18480, current rewards: -20.41565, mean: -0.06586
[32m[0906 23-23-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18477, current rewards: -23.30136, mean: -0.06473
[32m[0906 23-23-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18475, current rewards: -23.98257, mean: -0.05849
[32m[0906 23-23-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18477, current rewards: -20.84845, mean: -0.04532
[32m[0906 23-23-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18477, current rewards: -20.02304, mean: -0.03926
[32m[0906 23-23-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18480, current rewards: -20.31679, mean: -0.03628
[32m[0906 23-24-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18478, current rewards: -15.50698, mean: -0.02542
[32m[0906 23-24-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18479, current rewards: -10.69930, mean: -0.01621
[32m[0906 23-24-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18476, current rewards: -5.89432, mean: -0.00830
[32m[0906 23-24-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18474, current rewards: -1.08672, mean: -0.00143
[32m[0906 23-24-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18477, current rewards: 3.71792, mean: 0.00459
[32m[0906 23-24-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18483, current rewards: 8.37792, mean: 0.00974
[32m[0906 23-25-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18487, current rewards: 13.20927, mean: 0.01452
[32m[0906 23-25-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18492, current rewards: 18.04497, mean: 0.01880
[32m[0906 23-25-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18491, current rewards: 22.87810, mean: 0.02265
[32m[0906 23-25-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18487, current rewards: 23.69978, mean: 0.02236
[32m[0906 23-25-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18462, current rewards: 18.62253, mean: 0.01678
[32m[0906 23-25-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18437, current rewards: 15.65886, mean: 0.01350
[32m[0906 23-25-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18417, current rewards: 10.57640, mean: 0.00874
[32m[0906 23-26-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18398, current rewards: 7.25020, mean: 0.00575
[32m[0906 23-26-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18382, current rewards: -3.94857, mean: -0.00301
[32m[0906 23-26-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18365, current rewards: -22.49456, mean: -0.01654
[32m[0906 23-26-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18354, current rewards: -108.72765, mean: -0.07711
[32m[0906 23-26-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18342, current rewards: -200.09502, mean: -0.13705
[32m[0906 23-26-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18325, current rewards: -289.30940, mean: -0.19160
[32m[0906 23-27-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18294, current rewards: -378.53944, mean: -0.24265
[32m[0906 23-27-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18268, current rewards: -469.92113, mean: -0.29188
[32m[0906 23-27-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18244, current rewards: -559.14929, mean: -0.33684
[32m[0906 23-27-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18220, current rewards: -616.25185, mean: -0.36038
[32m[0906 23-27-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18197, current rewards: -635.20426, mean: -0.36091
[32m[0906 23-27-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18174, current rewards: -660.61067, mean: -0.36498
[32m[0906 23-27-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18155, current rewards: -681.67280, mean: -0.36649
[32m[0906 23-28-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18149, current rewards: -704.93495, mean: -0.36908
[32m[0906 23-28-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18144, current rewards: -726.00218, mean: -0.37041
[32m[0906 23-28-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18140, current rewards: -749.22609, mean: -0.37275
[32m[0906 23-28-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18135, current rewards: -770.29418, mean: -0.37393
[32m[0906 23-28-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18131, current rewards: -792.64229, mean: -0.37566
[32m[0906 23-28-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18144, current rewards: -832.55417, mean: -0.38544
[32m[0906 23-28-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18146, current rewards: -846.33983, mean: -0.38296
[32m[0906 23-29-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18142, current rewards: -839.24328, mean: -0.37135
[32m[0906 23-29-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18146, current rewards: -832.14672, mean: -0.36024
[32m[0906 23-29-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18156, current rewards: -825.05017, mean: -0.34960
[32m[0906 23-29-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18163, current rewards: -817.95361, mean: -0.33940
[32m[0906 23-29-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18169, current rewards: -810.85706, mean: -0.32962
[32m[0906 23-29-49 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0906 23-29-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-29-49 @MBExp.py:227][0m Rewards obtained: [-805.3917399157408], Lows: [533], Highs: [10], Total time: 30686.100957999995
[32m[0906 23-32-06 @MBExp.py:144][0m ####################################################################
[32m[0906 23-32-06 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 23-32-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17294, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-32-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17335, current rewards: -5.78666, mean: -0.09644
[32m[0906 23-32-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17597, current rewards: -0.00502, mean: -0.00005
[32m[0906 23-32-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17729, current rewards: 5.77100, mean: 0.03607
[32m[0906 23-32-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17914, current rewards: 11.55590, mean: 0.05503
[32m[0906 23-32-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18040, current rewards: 17.33382, mean: 0.06667
[32m[0906 23-33-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18119, current rewards: 23.10756, mean: 0.07454
[32m[0906 23-33-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18160, current rewards: 28.88383, mean: 0.08023
[32m[0906 23-33-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18202, current rewards: 34.24462, mean: 0.08352
[32m[0906 23-33-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18251, current rewards: 40.02989, mean: 0.08702
[32m[0906 23-33-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18276, current rewards: 36.89150, mean: 0.07234
[32m[0906 23-33-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18290, current rewards: 37.22085, mean: 0.06647
[32m[0906 23-33-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18298, current rewards: 42.39403, mean: 0.06950
[32m[0906 23-34-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18311, current rewards: 47.55865, mean: 0.07206
[32m[0906 23-34-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18320, current rewards: 52.72351, mean: 0.07426
[32m[0906 23-34-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18330, current rewards: 57.88944, mean: 0.07617
[32m[0906 23-34-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18333, current rewards: 63.19291, mean: 0.07802
[32m[0906 23-34-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18338, current rewards: 68.58068, mean: 0.07974
[32m[0906 23-34-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18343, current rewards: 73.88165, mean: 0.08119
[32m[0906 23-35-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18347, current rewards: 79.17364, mean: 0.08247
[32m[0906 23-35-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18350, current rewards: 84.47256, mean: 0.08364
[32m[0906 23-35-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18341, current rewards: 89.76518, mean: 0.08468
[32m[0906 23-35-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18324, current rewards: 95.05791, mean: 0.08564
[32m[0906 23-35-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18312, current rewards: 100.35202, mean: 0.08651
[32m[0906 23-35-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18307, current rewards: 86.68291, mean: 0.07164
[32m[0906 23-35-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18308, current rewards: 88.22532, mean: 0.07002
[32m[0906 23-36-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18296, current rewards: 94.28978, mean: 0.07198
[32m[0906 23-36-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18281, current rewards: 100.35673, mean: 0.07379
[32m[0906 23-36-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18269, current rewards: 106.42368, mean: 0.07548
[32m[0906 23-36-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18256, current rewards: 112.49022, mean: 0.07705
[32m[0906 23-36-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18233, current rewards: 118.55702, mean: 0.07851
[32m[0906 23-36-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18206, current rewards: 124.62358, mean: 0.07989
[32m[0906 23-36-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18180, current rewards: 130.69015, mean: 0.08117
[32m[0906 23-37-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18156, current rewards: 125.08615, mean: 0.07535
[32m[0906 23-37-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18134, current rewards: 130.74763, mean: 0.07646
[32m[0906 23-37-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18114, current rewards: 136.41575, mean: 0.07751
[32m[0906 23-37-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18094, current rewards: 142.07861, mean: 0.07850
[32m[0906 23-37-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18084, current rewards: 147.74769, mean: 0.07943
[32m[0906 23-37-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18082, current rewards: 153.41248, mean: 0.08032
[32m[0906 23-38-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18080, current rewards: 157.96201, mean: 0.08059
[32m[0906 23-38-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18077, current rewards: 153.19237, mean: 0.07622
[32m[0906 23-38-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18074, current rewards: 158.09391, mean: 0.07674
[32m[0906 23-38-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18071, current rewards: 163.27655, mean: 0.07738
[32m[0906 23-38-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18069, current rewards: 168.46309, mean: 0.07799
[32m[0906 23-38-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18066, current rewards: 173.57593, mean: 0.07854
[32m[0906 23-38-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18064, current rewards: 179.77181, mean: 0.07955
[32m[0906 23-39-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18069, current rewards: 185.96523, mean: 0.08050
[32m[0906 23-39-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18079, current rewards: 192.15620, mean: 0.08142
[32m[0906 23-39-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18089, current rewards: 198.35527, mean: 0.08231
[32m[0906 23-39-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18098, current rewards: 204.34372, mean: 0.08307
[32m[0906 23-39-39 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0906 23-39-39 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-39-39 @MBExp.py:227][0m Rewards obtained: [209.20895793328822], Lows: [14], Highs: [41], Total time: 31139.477855999994
[32m[0906 23-41-59 @MBExp.py:144][0m ####################################################################
[32m[0906 23-41-59 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 23-42-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17279, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-42-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17442, current rewards: -32.41834, mean: -0.54031
[32m[0906 23-42-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17688, current rewards: -26.12475, mean: -0.23750
[32m[0906 23-42-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17822, current rewards: -19.83458, mean: -0.12397
[32m[0906 23-42-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17997, current rewards: -13.53264, mean: -0.06444
[32m[0906 23-42-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18089, current rewards: -7.24319, mean: -0.02786
[32m[0906 23-42-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18145, current rewards: -0.95172, mean: -0.00307
[32m[0906 23-43-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18197, current rewards: 5.95774, mean: 0.01655
[32m[0906 23-43-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18225, current rewards: 12.62312, mean: 0.03079
[32m[0906 23-43-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18252, current rewards: 19.22136, mean: 0.04179
[32m[0906 23-43-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18275, current rewards: 25.82347, mean: 0.05063
[32m[0906 23-43-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18297, current rewards: 8.97480, mean: 0.01603
[32m[0906 23-43-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18314, current rewards: -32.96182, mean: -0.05404
[32m[0906 23-44-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18336, current rewards: -76.93830, mean: -0.11657
[32m[0906 23-44-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18346, current rewards: -120.42591, mean: -0.16961
[32m[0906 23-44-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18354, current rewards: -116.67925, mean: -0.15353
[32m[0906 23-44-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18359, current rewards: -110.97212, mean: -0.13700
[32m[0906 23-44-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18360, current rewards: -105.79273, mean: -0.12301
[32m[0906 23-44-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18364, current rewards: -100.60715, mean: -0.11056
[32m[0906 23-44-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18368, current rewards: -95.42796, mean: -0.09940
[32m[0906 23-45-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18370, current rewards: -99.22018, mean: -0.09824
[32m[0906 23-45-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18351, current rewards: -105.03546, mean: -0.09909
[32m[0906 23-45-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18334, current rewards: -98.67780, mean: -0.08890
[32m[0906 23-45-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18319, current rewards: -92.32220, mean: -0.07959
[32m[0906 23-45-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18306, current rewards: -86.22816, mean: -0.07126
[32m[0906 23-45-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18292, current rewards: -103.64368, mean: -0.08226
[32m[0906 23-45-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18281, current rewards: -125.48622, mean: -0.09579
[32m[0906 23-46-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18273, current rewards: -120.24109, mean: -0.08841
[32m[0906 23-46-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18262, current rewards: -114.97678, mean: -0.08154
[32m[0906 23-46-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18251, current rewards: -109.72543, mean: -0.07515
[32m[0906 23-46-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18223, current rewards: -104.47208, mean: -0.06919
[32m[0906 23-46-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18196, current rewards: -99.22483, mean: -0.06361
[32m[0906 23-46-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18172, current rewards: -92.70101, mean: -0.05758
[32m[0906 23-47-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18148, current rewards: -87.03312, mean: -0.05243
[32m[0906 23-47-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18127, current rewards: -81.36387, mean: -0.04758
[32m[0906 23-47-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18106, current rewards: -75.69423, mean: -0.04301
[32m[0906 23-47-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18087, current rewards: -70.02856, mean: -0.03869
[32m[0906 23-47-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18080, current rewards: -64.36487, mean: -0.03460
[32m[0906 23-47-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18078, current rewards: -58.70127, mean: -0.03073
[32m[0906 23-47-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18075, current rewards: -74.82597, mean: -0.03818
[32m[0906 23-48-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18073, current rewards: -67.41666, mean: -0.03354
[32m[0906 23-48-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18073, current rewards: -59.31898, mean: -0.02880
[32m[0906 23-48-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18071, current rewards: -51.23845, mean: -0.02428
[32m[0906 23-48-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18068, current rewards: -43.15378, mean: -0.01998
[32m[0906 23-48-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18065, current rewards: -60.06280, mean: -0.02718
[32m[0906 23-48-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18063, current rewards: -52.21229, mean: -0.02310
[32m[0906 23-48-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18070, current rewards: -44.30616, mean: -0.01918
[32m[0906 23-49-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18081, current rewards: -36.40716, mean: -0.01543
[32m[0906 23-49-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18088, current rewards: -25.85306, mean: -0.01073
[32m[0906 23-49-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18095, current rewards: -12.62135, mean: -0.00513
[32m[0906 23-49-32 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0906 23-49-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-49-32 @MBExp.py:227][0m Rewards obtained: [-4.51706188360014], Lows: [147], Highs: [21], Total time: 31592.777156999993
[32m[0906 23-51-53 @MBExp.py:144][0m ####################################################################
[32m[0906 23-51-53 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 23-51-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17315, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-52-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17423, current rewards: -5.79312, mean: -0.09655
[32m[0906 23-52-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17654, current rewards: 1.87725, mean: 0.01707
[32m[0906 23-52-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17790, current rewards: 9.54516, mean: 0.05966
[32m[0906 23-52-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17949, current rewards: 17.21610, mean: 0.08198
[32m[0906 23-52-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18059, current rewards: 24.88662, mean: 0.09572
[32m[0906 23-52-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18123, current rewards: 32.56264, mean: 0.10504
[32m[0906 23-52-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18185, current rewards: 39.18842, mean: 0.10886
[32m[0906 23-53-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18215, current rewards: 46.71647, mean: 0.11394
[32m[0906 23-53-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18238, current rewards: 54.22737, mean: 0.11789
[32m[0906 23-53-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18252, current rewards: 39.46474, mean: 0.07738
[32m[0906 23-53-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18269, current rewards: 45.11191, mean: 0.08056
[32m[0906 23-53-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18289, current rewards: 50.75755, mean: 0.08321
[32m[0906 23-53-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18300, current rewards: 56.39678, mean: 0.08545
[32m[0906 23-54-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18318, current rewards: 62.03939, mean: 0.08738
[32m[0906 23-54-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18326, current rewards: 71.77491, mean: 0.09444
[32m[0906 23-54-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18337, current rewards: 78.55823, mean: 0.09699
[32m[0906 23-54-31 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18355, current rewards: 84.22334, mean: 0.09793
[32m[0906 23-54-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18366, current rewards: 89.89154, mean: 0.09878
[32m[0906 23-54-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18372, current rewards: 95.55818, mean: 0.09954
[32m[0906 23-54-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18355, current rewards: 89.82375, mean: 0.08893
[32m[0906 23-55-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18338, current rewards: 98.05058, mean: 0.09250
[32m[0906 23-55-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18319, current rewards: 106.37383, mean: 0.09583
[32m[0906 23-55-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18303, current rewards: 114.50593, mean: 0.09871
[32m[0906 23-55-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18287, current rewards: 124.54449, mean: 0.10293
[32m[0906 23-55-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18274, current rewards: 131.82892, mean: 0.10463
[32m[0906 23-55-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18261, current rewards: 139.25319, mean: 0.10630
[32m[0906 23-56-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18250, current rewards: 146.68707, mean: 0.10786
[32m[0906 23-56-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18240, current rewards: 154.11282, mean: 0.10930
[32m[0906 23-56-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18230, current rewards: 161.54055, mean: 0.11064
[32m[0906 23-56-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18208, current rewards: 168.97633, mean: 0.11190
[32m[0906 23-56-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18183, current rewards: 176.40450, mean: 0.11308
[32m[0906 23-56-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18158, current rewards: 182.51338, mean: 0.11336
[32m[0906 23-56-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18142, current rewards: 181.31587, mean: 0.10923
[32m[0906 23-57-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18120, current rewards: 172.20150, mean: 0.10070
[32m[0906 23-57-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18100, current rewards: 178.24084, mean: 0.10127
[32m[0906 23-57-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18083, current rewards: 184.29027, mean: 0.10182
[32m[0906 23-57-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18079, current rewards: 190.33889, mean: 0.10233
[32m[0906 23-57-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18075, current rewards: 196.38783, mean: 0.10282
[32m[0906 23-57-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18073, current rewards: 202.43006, mean: 0.10328
[32m[0906 23-57-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18070, current rewards: 211.00711, mean: 0.10498
[32m[0906 23-58-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18067, current rewards: 205.99051, mean: 0.10000
[32m[0906 23-58-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18065, current rewards: 167.83966, mean: 0.07954
[32m[0906 23-58-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18061, current rewards: 137.13744, mean: 0.06349
[32m[0906 23-58-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18059, current rewards: 101.19484, mean: 0.04579
[32m[0906 23-58-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18060, current rewards: 70.14138, mean: 0.03104
[32m[0906 23-58-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18060, current rewards: 36.70352, mean: 0.01589
[32m[0906 23-59-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18069, current rewards: 3.34609, mean: 0.00142
[32m[0906 23-59-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18077, current rewards: -38.73716, mean: -0.01607
[32m[0906 23-59-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18086, current rewards: -32.23272, mean: -0.01310
[32m[0906 23-59-26 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0906 23-59-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-59-26 @MBExp.py:227][0m Rewards obtained: [-25.668071728410418], Lows: [189], Highs: [31], Total time: 32045.866397999995
[32m[0907 00-01-50 @MBExp.py:144][0m ####################################################################
[32m[0907 00-01-50 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 00-01-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17249, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-02-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17459, current rewards: -9.49779, mean: -0.15830
[32m[0907 00-02-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17687, current rewards: -5.93001, mean: -0.05391
[32m[0907 00-02-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17798, current rewards: -2.35831, mean: -0.01474
[32m[0907 00-02-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17977, current rewards: 1.21467, mean: 0.00578
[32m[0907 00-02-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18064, current rewards: 4.78718, mean: 0.01841
[32m[0907 00-02-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18116, current rewards: 8.35889, mean: 0.02696
[32m[0907 00-02-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18190, current rewards: 11.86237, mean: 0.03295
[32m[0907 00-03-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18226, current rewards: 15.43449, mean: 0.03765
[32m[0907 00-03-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18244, current rewards: -1.23345, mean: -0.00268
[32m[0907 00-03-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18264, current rewards: 4.39772, mean: 0.00862
[32m[0907 00-03-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18282, current rewards: 9.08241, mean: 0.01622
[32m[0907 00-03-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18291, current rewards: 13.76308, mean: 0.02256
[32m[0907 00-03-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18306, current rewards: 18.43860, mean: 0.02794
[32m[0907 00-04-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18317, current rewards: 3.74562, mean: 0.00528
[32m[0907 00-04-09 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18323, current rewards: 9.24864, mean: 0.01217
[32m[0907 00-04-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18328, current rewards: 13.78423, mean: 0.01702
[32m[0907 00-04-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18340, current rewards: 18.31982, mean: 0.02130
[32m[0907 00-04-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18347, current rewards: 22.85541, mean: 0.02512
[32m[0907 00-04-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18346, current rewards: 27.39100, mean: 0.02853
[32m[0907 00-04-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18332, current rewards: 31.92658, mean: 0.03161
[32m[0907 00-05-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18319, current rewards: -7.16630, mean: -0.00676
[32m[0907 00-05-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18304, current rewards: -57.16630, mean: -0.05150
[32m[0907 00-05-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18290, current rewards: -107.16630, mean: -0.09238
[32m[0907 00-05-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18275, current rewards: -157.16630, mean: -0.12989
[32m[0907 00-05-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18260, current rewards: -207.16630, mean: -0.16442
[32m[0907 00-05-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18248, current rewards: -257.16630, mean: -0.19631
[32m[0907 00-05-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18238, current rewards: -307.16630, mean: -0.22586
[32m[0907 00-06-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18228, current rewards: -357.16630, mean: -0.25331
[32m[0907 00-06-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18218, current rewards: -407.16630, mean: -0.27888
[32m[0907 00-06-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18196, current rewards: -457.16630, mean: -0.30276
[32m[0907 00-06-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18172, current rewards: -507.16630, mean: -0.32511
[32m[0907 00-06-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18147, current rewards: -557.16630, mean: -0.34607
[32m[0907 00-06-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18126, current rewards: -607.16630, mean: -0.36576
[32m[0907 00-07-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18106, current rewards: -657.16630, mean: -0.38431
[32m[0907 00-07-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18090, current rewards: -707.16630, mean: -0.40180
[32m[0907 00-07-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18075, current rewards: -757.16630, mean: -0.41832
[32m[0907 00-07-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18071, current rewards: -807.16630, mean: -0.43396
[32m[0907 00-07-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18067, current rewards: -857.16630, mean: -0.44878
[32m[0907 00-07-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18065, current rewards: -907.16630, mean: -0.46284
[32m[0907 00-07-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18062, current rewards: -957.16630, mean: -0.47620
[32m[0907 00-08-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18061, current rewards: -1007.16630, mean: -0.48892
[32m[0907 00-08-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18058, current rewards: -1057.16630, mean: -0.50103
[32m[0907 00-08-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18055, current rewards: -1107.16630, mean: -0.51258
[32m[0907 00-08-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18053, current rewards: -1157.16630, mean: -0.52360
[32m[0907 00-08-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18052, current rewards: -1207.16630, mean: -0.53414
[32m[0907 00-08-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18051, current rewards: -1257.16630, mean: -0.54423
[32m[0907 00-08-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18061, current rewards: -1307.16630, mean: -0.55388
[32m[0907 00-09-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18071, current rewards: -1357.16630, mean: -0.56314
[32m[0907 00-09-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18082, current rewards: -1407.16630, mean: -0.57202
[32m[0907 00-09-22 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0907 00-09-22 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-09-23 @MBExp.py:227][0m Rewards obtained: [-1447.1662984000723], Lows: [20], Highs: [1493], Total time: 32498.832112999993
[32m[0907 00-11-47 @MBExp.py:144][0m ####################################################################
[32m[0907 00-11-47 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 00-11-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.23093, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-11-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18495, current rewards: -5.61329, mean: -0.09355
[32m[0907 00-12-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18242, current rewards: -2.77110, mean: -0.02519
[32m[0907 00-12-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18179, current rewards: 0.07254, mean: 0.00045
[32m[0907 00-12-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18252, current rewards: 2.91678, mean: 0.01389
[32m[0907 00-12-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18301, current rewards: 5.75768, mean: 0.02214
[32m[0907 00-12-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18332, current rewards: 8.60254, mean: 0.02775
[32m[0907 00-12-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18367, current rewards: 0.16188, mean: 0.00045
[32m[0907 00-13-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18382, current rewards: 3.02174, mean: 0.00737
[32m[0907 00-13-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18391, current rewards: 5.88849, mean: 0.01280
[32m[0907 00-13-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18413, current rewards: 8.75123, mean: 0.01716
[32m[0907 00-13-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18413, current rewards: 11.61823, mean: 0.02075
[32m[0907 00-13-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18416, current rewards: 14.48470, mean: 0.02375
[32m[0907 00-13-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18411, current rewards: 17.35084, mean: 0.02629
[32m[0907 00-13-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18411, current rewards: 5.81167, mean: 0.00819
[32m[0907 00-14-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18412, current rewards: 3.49600, mean: 0.00460
[32m[0907 00-14-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18410, current rewards: 8.05719, mean: 0.00995
[32m[0907 00-14-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18409, current rewards: 11.39716, mean: 0.01325
[32m[0907 00-14-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18406, current rewards: 14.73243, mean: 0.01619
[32m[0907 00-14-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18408, current rewards: 18.06821, mean: 0.01882
[32m[0907 00-14-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18390, current rewards: 21.40582, mean: 0.02119
[32m[0907 00-15-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18371, current rewards: 24.73953, mean: 0.02334
[32m[0907 00-15-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18353, current rewards: 28.07456, mean: 0.02529
[32m[0907 00-15-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18335, current rewards: 27.14467, mean: 0.02340
[32m[0907 00-15-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18323, current rewards: 24.74611, mean: 0.02045
[32m[0907 00-15-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18308, current rewards: 28.76735, mean: 0.02283
[32m[0907 00-15-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18294, current rewards: 32.78924, mean: 0.02503
[32m[0907 00-15-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18281, current rewards: 36.81064, mean: 0.02707
[32m[0907 00-16-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18269, current rewards: 40.83038, mean: 0.02896
[32m[0907 00-16-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18257, current rewards: 44.85167, mean: 0.03072
[32m[0907 00-16-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18226, current rewards: 48.87362, mean: 0.03237
[32m[0907 00-16-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18199, current rewards: 52.89234, mean: 0.03391
[32m[0907 00-16-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18175, current rewards: 56.54079, mean: 0.03512
[32m[0907 00-16-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18150, current rewards: 60.46881, mean: 0.03643
[32m[0907 00-16-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18128, current rewards: 43.58330, mean: 0.02549
[32m[0907 00-17-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18108, current rewards: 49.43668, mean: 0.02809
[32m[0907 00-17-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18089, current rewards: 55.40001, mean: 0.03061
[32m[0907 00-17-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18083, current rewards: 61.36730, mean: 0.03299
[32m[0907 00-17-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18084, current rewards: 67.33113, mean: 0.03525
[32m[0907 00-17-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18081, current rewards: 73.28876, mean: 0.03739
[32m[0907 00-17-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18078, current rewards: 79.33933, mean: 0.03947
[32m[0907 00-18-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18074, current rewards: 67.28685, mean: 0.03266
[32m[0907 00-18-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18071, current rewards: 72.56950, mean: 0.03439
[32m[0907 00-18-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18068, current rewards: 78.54554, mean: 0.03636
[32m[0907 00-18-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18067, current rewards: 84.51879, mean: 0.03824
[32m[0907 00-18-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18064, current rewards: 90.49516, mean: 0.04004
[32m[0907 00-18-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18062, current rewards: 96.46712, mean: 0.04176
[32m[0907 00-18-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18072, current rewards: 102.44862, mean: 0.04341
[32m[0907 00-19-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18079, current rewards: 108.42577, mean: 0.04499
[32m[0907 00-19-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18085, current rewards: 117.23160, mean: 0.04766
[32m[0907 00-19-20 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0907 00-19-20 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-19-20 @MBExp.py:227][0m Rewards obtained: [101.21214874913719], Lows: [30], Highs: [50], Total time: 32951.908620999995
[32m[0907 00-21-47 @MBExp.py:144][0m ####################################################################
[32m[0907 00-21-47 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 00-21-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17377, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-21-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17446, current rewards: -10.20352, mean: -0.17006
[32m[0907 00-22-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17677, current rewards: -4.62736, mean: -0.04207
[32m[0907 00-22-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17814, current rewards: 0.92533, mean: 0.00578
[32m[0907 00-22-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17981, current rewards: 6.48997, mean: 0.03090
[32m[0907 00-22-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18082, current rewards: 12.04883, mean: 0.04634
[32m[0907 00-22-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18125, current rewards: 17.60538, mean: 0.05679
[32m[0907 00-22-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18166, current rewards: 23.20768, mean: 0.06447
[32m[0907 00-23-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18206, current rewards: 30.88746, mean: 0.07534
[32m[0907 00-23-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18228, current rewards: 36.30777, mean: 0.07893
[32m[0907 00-23-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18256, current rewards: 41.73076, mean: 0.08183
[32m[0907 00-23-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18267, current rewards: 25.70547, mean: 0.04590
[32m[0907 00-23-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18276, current rewards: 31.26348, mean: 0.05125
[32m[0907 00-23-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18296, current rewards: 36.87332, mean: 0.05587
[32m[0907 00-23-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18306, current rewards: 42.48478, mean: 0.05984
[32m[0907 00-24-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18312, current rewards: 36.25775, mean: 0.04771
[32m[0907 00-24-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18316, current rewards: 41.23478, mean: 0.05091
[32m[0907 00-24-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18322, current rewards: 46.56848, mean: 0.05415
[32m[0907 00-24-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18328, current rewards: 51.90674, mean: 0.05704
[32m[0907 00-24-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18360, current rewards: 36.74005, mean: 0.03827
[32m[0907 00-24-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18345, current rewards: 40.97284, mean: 0.04057
[32m[0907 00-25-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18327, current rewards: 45.01437, mean: 0.04247
[32m[0907 00-25-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18310, current rewards: 49.05591, mean: 0.04419
[32m[0907 00-25-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18294, current rewards: 53.09744, mean: 0.04577
[32m[0907 00-25-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18283, current rewards: 56.71574, mean: 0.04687
[32m[0907 00-25-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18269, current rewards: 17.31542, mean: 0.01374
[32m[0907 00-25-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18257, current rewards: -32.68458, mean: -0.02495
[32m[0907 00-25-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18250, current rewards: -82.68458, mean: -0.06080
[32m[0907 00-26-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18241, current rewards: -132.68458, mean: -0.09410
[32m[0907 00-26-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18231, current rewards: -182.68458, mean: -0.12513
[32m[0907 00-26-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18221, current rewards: -232.68458, mean: -0.15410
[32m[0907 00-26-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18196, current rewards: -282.68458, mean: -0.18121
[32m[0907 00-26-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18172, current rewards: -332.68458, mean: -0.20664
[32m[0907 00-26-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18148, current rewards: -382.68458, mean: -0.23053
[32m[0907 00-26-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18125, current rewards: -432.68458, mean: -0.25303
[32m[0907 00-27-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18105, current rewards: -482.68458, mean: -0.27425
[32m[0907 00-27-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18085, current rewards: -532.68458, mean: -0.29430
[32m[0907 00-27-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18073, current rewards: -582.68458, mean: -0.31327
[32m[0907 00-27-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18071, current rewards: -632.68458, mean: -0.33125
[32m[0907 00-27-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18067, current rewards: -682.68458, mean: -0.34831
[32m[0907 00-27-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18064, current rewards: -732.68458, mean: -0.36452
[32m[0907 00-28-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18064, current rewards: -782.68458, mean: -0.37994
[32m[0907 00-28-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18064, current rewards: -826.17563, mean: -0.39155
[32m[0907 00-28-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18060, current rewards: -821.93435, mean: -0.38053
[32m[0907 00-28-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18056, current rewards: -817.69308, mean: -0.37000
[32m[0907 00-28-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18053, current rewards: -813.45180, mean: -0.35993
[32m[0907 00-28-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18050, current rewards: -809.21053, mean: -0.35031
[32m[0907 00-28-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18048, current rewards: -804.96926, mean: -0.34109
[32m[0907 00-29-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18054, current rewards: -800.72798, mean: -0.33225
[32m[0907 00-29-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18063, current rewards: -796.48671, mean: -0.32378
[32m[0907 00-29-20 @Agent.py:117][0m Average action selection time: 0.1807
[32m[0907 00-29-20 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-29-20 @MBExp.py:227][0m Rewards obtained: [-793.0936850923938], Lows: [23], Highs: [904], Total time: 33404.426287999995
[32m[0907 00-31-48 @MBExp.py:144][0m ####################################################################
[32m[0907 00-31-48 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 00-31-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17262, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-31-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17308, current rewards: -13.73472, mean: -0.22891
[32m[0907 00-32-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17633, current rewards: -7.42773, mean: -0.06752
[32m[0907 00-32-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17842, current rewards: -1.12453, mean: -0.00703
[32m[0907 00-32-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17995, current rewards: 5.18793, mean: 0.02470
[32m[0907 00-32-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18093, current rewards: 11.06537, mean: 0.04256
[32m[0907 00-32-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18157, current rewards: 17.84900, mean: 0.05758
[32m[0907 00-32-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18200, current rewards: 23.48576, mean: 0.06524
[32m[0907 00-33-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18231, current rewards: 29.92085, mean: 0.07298
[32m[0907 00-33-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18251, current rewards: 36.34440, mean: 0.07901
[32m[0907 00-33-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18274, current rewards: 42.77488, mean: 0.08387
[32m[0907 00-33-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18289, current rewards: 49.19241, mean: 0.08784
[32m[0907 00-33-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18302, current rewards: 55.60957, mean: 0.09116
[32m[0907 00-33-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18318, current rewards: 62.03158, mean: 0.09399
[32m[0907 00-33-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18329, current rewards: 68.45491, mean: 0.09642
[32m[0907 00-34-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18353, current rewards: 62.56978, mean: 0.08233
[32m[0907 00-34-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18365, current rewards: 46.76397, mean: 0.05773
[32m[0907 00-34-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18370, current rewards: 34.25432, mean: 0.03983
[32m[0907 00-34-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18372, current rewards: 43.63830, mean: 0.04795
[32m[0907 00-34-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18507, current rewards: 3.14607, mean: 0.00328
[32m[0907 00-34-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18637, current rewards: -45.90741, mean: -0.04545
[32m[0907 00-35-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18761, current rewards: -88.57262, mean: -0.08356
[32m[0907 00-35-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18723, current rewards: -89.19127, mean: -0.08035
[32m[0907 00-35-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18689, current rewards: -75.97343, mean: -0.06549
[32m[0907 00-35-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18656, current rewards: -66.43404, mean: -0.05490
[32m[0907 00-35-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18629, current rewards: -55.15240, mean: -0.04377
[32m[0907 00-35-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18605, current rewards: -85.86407, mean: -0.06555
[32m[0907 00-36-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18583, current rewards: -143.07487, mean: -0.10520
[32m[0907 00-36-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18559, current rewards: -192.34106, mean: -0.13641
[32m[0907 00-36-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18541, current rewards: -258.91077, mean: -0.17734
[32m[0907 00-36-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18512, current rewards: -311.17429, mean: -0.20608
[32m[0907 00-36-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18476, current rewards: -358.90237, mean: -0.23007
[32m[0907 00-36-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18456, current rewards: -423.70826, mean: -0.26317
[32m[0907 00-36-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18424, current rewards: -429.52848, mean: -0.25875
[32m[0907 00-37-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18395, current rewards: -423.17863, mean: -0.24747
[32m[0907 00-37-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18369, current rewards: -416.82320, mean: -0.23683
[32m[0907 00-37-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18342, current rewards: -410.47834, mean: -0.22678
[32m[0907 00-37-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18332, current rewards: -404.13330, mean: -0.21728
[32m[0907 00-37-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18323, current rewards: -397.77890, mean: -0.20826
[32m[0907 00-37-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18315, current rewards: -391.43074, mean: -0.19971
[32m[0907 00-37-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18307, current rewards: -386.13456, mean: -0.19211
[32m[0907 00-38-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18300, current rewards: -379.00055, mean: -0.18398
[32m[0907 00-38-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18292, current rewards: -371.76460, mean: -0.17619
[32m[0907 00-38-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18286, current rewards: -364.55060, mean: -0.16877
[32m[0907 00-38-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18280, current rewards: -357.91357, mean: -0.16195
[32m[0907 00-38-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18277, current rewards: -383.18455, mean: -0.16955
[32m[0907 00-38-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18270, current rewards: -416.52095, mean: -0.18031
[32m[0907 00-39-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18266, current rewards: -420.76801, mean: -0.17829
[32m[0907 00-39-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18272, current rewards: -410.03998, mean: -0.17014
[32m[0907 00-39-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18277, current rewards: -398.50156, mean: -0.16199
[32m[0907 00-39-26 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0907 00-39-26 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-39-26 @MBExp.py:227][0m Rewards obtained: [-394.98912012898506], Lows: [371], Highs: [40], Total time: 33862.21840799999
[32m[0907 00-41-57 @MBExp.py:144][0m ####################################################################
[32m[0907 00-41-57 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 00-42-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.25252, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-42-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18973, current rewards: -21.39434, mean: -0.35657
[32m[0907 00-42-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18538, current rewards: -16.21873, mean: -0.14744
[32m[0907 00-42-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18545, current rewards: -11.04046, mean: -0.06900
[32m[0907 00-42-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18536, current rewards: -5.85879, mean: -0.02790
[32m[0907 00-42-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18537, current rewards: -0.67569, mean: -0.00260
[32m[0907 00-42-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18534, current rewards: 4.50828, mean: 0.01454
[32m[0907 00-43-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18515, current rewards: 10.28427, mean: 0.02857
[32m[0907 00-43-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18514, current rewards: 15.47486, mean: 0.03774
[32m[0907 00-43-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18510, current rewards: 20.66012, mean: 0.04491
[32m[0907 00-43-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18507, current rewards: 25.84993, mean: 0.05069
[32m[0907 00-43-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18510, current rewards: 31.03414, mean: 0.05542
[32m[0907 00-43-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18505, current rewards: 36.22185, mean: 0.05938
[32m[0907 00-43-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18494, current rewards: 31.33267, mean: 0.04747
[32m[0907 00-44-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18491, current rewards: 35.62280, mean: 0.05017
[32m[0907 00-44-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18493, current rewards: 39.70581, mean: 0.05224
[32m[0907 00-44-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18494, current rewards: 43.95354, mean: 0.05426
[32m[0907 00-44-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18489, current rewards: 48.19923, mean: 0.05605
[32m[0907 00-44-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18494, current rewards: 52.44749, mean: 0.05763
[32m[0907 00-44-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18493, current rewards: 56.69225, mean: 0.05905
[32m[0907 00-45-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18491, current rewards: 60.93765, mean: 0.06033
[32m[0907 00-45-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18485, current rewards: 65.18240, mean: 0.06149
[32m[0907 00-45-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18458, current rewards: 69.42878, mean: 0.06255
[32m[0907 00-45-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18438, current rewards: 74.77685, mean: 0.06446
[32m[0907 00-45-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18416, current rewards: 79.54440, mean: 0.06574
[32m[0907 00-45-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18396, current rewards: 83.99639, mean: 0.06666
[32m[0907 00-45-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18378, current rewards: 49.33264, mean: 0.03766
[32m[0907 00-46-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18416, current rewards: 23.53816, mean: 0.01731
[32m[0907 00-46-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18399, current rewards: 29.58954, mean: 0.02099
[32m[0907 00-46-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18386, current rewards: 35.08102, mean: 0.02403
[32m[0907 00-46-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18356, current rewards: 40.57203, mean: 0.02687
[32m[0907 00-46-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18325, current rewards: 46.06109, mean: 0.02953
[32m[0907 00-46-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18297, current rewards: 50.24315, mean: 0.03121
[32m[0907 00-47-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18270, current rewards: 55.75806, mean: 0.03359
[32m[0907 00-47-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18243, current rewards: 49.90937, mean: 0.02919
[32m[0907 00-47-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18218, current rewards: 55.16990, mean: 0.03135
[32m[0907 00-47-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18195, current rewards: 60.42136, mean: 0.03338
[32m[0907 00-47-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18173, current rewards: 65.66292, mean: 0.03530
[32m[0907 00-47-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18152, current rewards: 70.91354, mean: 0.03713
[32m[0907 00-47-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18138, current rewards: 76.15922, mean: 0.03886
[32m[0907 00-48-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18133, current rewards: 81.13600, mean: 0.04037
[32m[0907 00-48-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18128, current rewards: 86.53426, mean: 0.04201
[32m[0907 00-48-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18124, current rewards: 91.85860, mean: 0.04353
[32m[0907 00-48-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18121, current rewards: 97.18515, mean: 0.04499
[32m[0907 00-48-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18116, current rewards: 102.51035, mean: 0.04638
[32m[0907 00-48-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18111, current rewards: 107.83148, mean: 0.04771
[32m[0907 00-48-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18109, current rewards: 113.15398, mean: 0.04898
[32m[0907 00-49-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18107, current rewards: 118.47221, mean: 0.05020
[32m[0907 00-49-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18117, current rewards: 124.32529, mean: 0.05159
[32m[0907 00-49-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18124, current rewards: 131.14855, mean: 0.05331
[32m[0907 00-49-31 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0907 00-49-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-49-31 @MBExp.py:227][0m Rewards obtained: [93.17619179999235], Lows: [66], Highs: [31], Total time: 34316.27722499999
[32m[0907 00-52-04 @MBExp.py:144][0m ####################################################################
[32m[0907 00-52-04 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 00-52-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17392, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-52-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17744, current rewards: -109.00000, mean: -1.81667
[32m[0907 00-52-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17885, current rewards: -209.00000, mean: -1.90000
[32m[0907 00-52-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18086, current rewards: -309.00000, mean: -1.93125
[32m[0907 00-52-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18199, current rewards: -409.00000, mean: -1.94762
[32m[0907 00-52-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18244, current rewards: -509.00000, mean: -1.95769
[32m[0907 00-53-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18270, current rewards: -609.00000, mean: -1.96452
[32m[0907 00-53-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18303, current rewards: -709.00000, mean: -1.96944
[32m[0907 00-53-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18321, current rewards: -809.00000, mean: -1.97317
[32m[0907 00-53-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18331, current rewards: -909.00000, mean: -1.97609
[32m[0907 00-53-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18334, current rewards: -1009.00000, mean: -1.97843
[32m[0907 00-53-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18343, current rewards: -1109.00000, mean: -1.98036
[32m[0907 00-53-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18349, current rewards: -1209.00000, mean: -1.98197
[32m[0907 00-54-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18363, current rewards: -1309.00000, mean: -1.98333
[32m[0907 00-54-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18368, current rewards: -1409.00000, mean: -1.98451
[32m[0907 00-54-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18371, current rewards: -1509.00000, mean: -1.98553
[32m[0907 00-54-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18379, current rewards: -1609.00000, mean: -1.98642
[32m[0907 00-54-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18381, current rewards: -1709.00000, mean: -1.98721
[32m[0907 00-54-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18383, current rewards: -1809.00000, mean: -1.98791
[32m[0907 00-55-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18383, current rewards: -1909.00000, mean: -1.98854
[32m[0907 00-55-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18388, current rewards: -2009.00000, mean: -1.98911
[32m[0907 00-55-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18376, current rewards: -2109.00000, mean: -1.98962
[32m[0907 00-55-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18359, current rewards: -2209.00000, mean: -1.99009
[32m[0907 00-55-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18341, current rewards: -2309.00000, mean: -1.99052
[32m[0907 00-55-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18324, current rewards: -2409.00000, mean: -1.99091
[32m[0907 00-55-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18309, current rewards: -2509.00000, mean: -1.99127
[32m[0907 00-56-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18296, current rewards: -2609.00000, mean: -1.99160
[32m[0907 00-56-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18284, current rewards: -2709.00000, mean: -1.99191
[32m[0907 00-56-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18272, current rewards: -2809.00000, mean: -1.99220
[32m[0907 00-56-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18257, current rewards: -2909.00000, mean: -1.99247
[32m[0907 00-56-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18227, current rewards: -3009.00000, mean: -1.99272
[32m[0907 00-56-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18198, current rewards: -3109.00000, mean: -1.99295
[32m[0907 00-56-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18174, current rewards: -3209.00000, mean: -1.99317
[32m[0907 00-57-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18148, current rewards: -3309.00000, mean: -1.99337
[32m[0907 00-57-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18125, current rewards: -3409.00000, mean: -1.99357
[32m[0907 00-57-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18106, current rewards: -3509.00000, mean: -1.99375
[32m[0907 00-57-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18086, current rewards: -3609.00000, mean: -1.99392
[32m[0907 00-57-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18067, current rewards: -3709.00000, mean: -1.99409
[32m[0907 00-57-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18049, current rewards: -3809.00000, mean: -1.99424
[32m[0907 00-57-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18043, current rewards: -3909.00000, mean: -1.99439
[32m[0907 00-58-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18040, current rewards: -4009.00000, mean: -1.99453
[32m[0907 00-58-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18038, current rewards: -4109.00000, mean: -1.99466
[32m[0907 00-58-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18035, current rewards: -4209.00000, mean: -1.99479
[32m[0907 00-58-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18032, current rewards: -4309.00000, mean: -1.99491
[32m[0907 00-58-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18029, current rewards: -4409.00000, mean: -1.99502
[32m[0907 00-58-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18027, current rewards: -4509.00000, mean: -1.99513
[32m[0907 00-59-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18025, current rewards: -4609.00000, mean: -1.99524
[32m[0907 00-59-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18026, current rewards: -4709.00000, mean: -1.99534
[32m[0907 00-59-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18036, current rewards: -4809.00000, mean: -1.99544
[32m[0907 00-59-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18050, current rewards: -4909.00000, mean: -1.99553
[32m[0907 00-59-36 @Agent.py:117][0m Average action selection time: 0.1806
[32m[0907 00-59-36 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-59-36 @MBExp.py:227][0m Rewards obtained: [-4989], Lows: [2489], Highs: [11], Total time: 34768.48351499999
[32m[0907 01-02-11 @MBExp.py:144][0m ####################################################################
[32m[0907 01-02-11 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 01-02-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18488, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-02-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17854, current rewards: -9.94849, mean: -0.16581
[32m[0907 01-02-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17898, current rewards: -4.54930, mean: -0.04136
[32m[0907 01-02-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17910, current rewards: 0.83582, mean: 0.00522
[32m[0907 01-02-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18016, current rewards: 6.21309, mean: 0.02959
[32m[0907 01-02-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18115, current rewards: 11.58734, mean: 0.04457
[32m[0907 01-03-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18173, current rewards: 16.96158, mean: 0.05471
[32m[0907 01-03-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18213, current rewards: 22.35633, mean: 0.06210
[32m[0907 01-03-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18238, current rewards: 27.65244, mean: 0.06744
[32m[0907 01-03-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18262, current rewards: 32.51442, mean: 0.07068
[32m[0907 01-03-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18287, current rewards: 37.35200, mean: 0.07324
[32m[0907 01-03-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18302, current rewards: 42.21314, mean: 0.07538
[32m[0907 01-04-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18310, current rewards: 24.15917, mean: 0.03961
[32m[0907 01-04-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18321, current rewards: 28.70715, mean: 0.04350
[32m[0907 01-04-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18328, current rewards: 33.25364, mean: 0.04684
[32m[0907 01-04-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18337, current rewards: 37.80356, mean: 0.04974
[32m[0907 01-04-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18344, current rewards: 42.22591, mean: 0.05213
[32m[0907 01-04-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18353, current rewards: 23.75991, mean: 0.02763
[32m[0907 01-04-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18358, current rewards: 28.05342, mean: 0.03083
[32m[0907 01-05-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18367, current rewards: 32.33996, mean: 0.03369
[32m[0907 01-05-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18371, current rewards: 36.62670, mean: 0.03626
[32m[0907 01-05-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18349, current rewards: 40.91612, mean: 0.03860
[32m[0907 01-05-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18329, current rewards: 45.20273, mean: 0.04072
[32m[0907 01-05-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18318, current rewards: 49.49046, mean: 0.04266
[32m[0907 01-05-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18302, current rewards: 53.77889, mean: 0.04445
[32m[0907 01-06-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18287, current rewards: 58.06766, mean: 0.04609
[32m[0907 01-06-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18274, current rewards: 62.35435, mean: 0.04760
[32m[0907 01-06-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18260, current rewards: 66.64331, mean: 0.04900
[32m[0907 01-06-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18247, current rewards: 70.93202, mean: 0.05031
[32m[0907 01-06-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18224, current rewards: 75.22123, mean: 0.05152
[32m[0907 01-06-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18196, current rewards: 79.50814, mean: 0.05265
[32m[0907 01-06-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18167, current rewards: 83.79634, mean: 0.05372
[32m[0907 01-07-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18143, current rewards: 88.72401, mean: 0.05511
[32m[0907 01-07-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18123, current rewards: 79.82369, mean: 0.04809
[32m[0907 01-07-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18104, current rewards: 86.14568, mean: 0.05038
[32m[0907 01-07-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18084, current rewards: 92.48495, mean: 0.05255
[32m[0907 01-07-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18064, current rewards: 98.81563, mean: 0.05459
[32m[0907 01-07-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18047, current rewards: 105.14712, mean: 0.05653
[32m[0907 01-07-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18033, current rewards: 111.47454, mean: 0.05836
[32m[0907 01-08-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18031, current rewards: 117.80463, mean: 0.06010
[32m[0907 01-08-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18029, current rewards: 126.10521, mean: 0.06274
[32m[0907 01-08-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18028, current rewards: 128.39472, mean: 0.06233
[32m[0907 01-08-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18026, current rewards: 82.08684, mean: 0.03890
[32m[0907 01-08-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18025, current rewards: 46.31899, mean: 0.02144
[32m[0907 01-08-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18023, current rewards: 15.44104, mean: 0.00699
[32m[0907 01-08-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18021, current rewards: -5.06754, mean: -0.00224
[32m[0907 01-09-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18021, current rewards: -37.12261, mean: -0.01607
[32m[0907 01-09-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18026, current rewards: -80.92036, mean: -0.03429
[32m[0907 01-09-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18036, current rewards: -93.74572, mean: -0.03890
[32m[0907 01-09-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18044, current rewards: -87.31572, mean: -0.03549
[32m[0907 01-09-43 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 01-09-43 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-09-43 @MBExp.py:227][0m Rewards obtained: [-81.6725231947273], Lows: [160], Highs: [30], Total time: 35220.537549999994
[32m[0907 01-12-20 @MBExp.py:144][0m ####################################################################
[32m[0907 01-12-20 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 01-12-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17912, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-12-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18579, current rewards: -52.78952, mean: -0.87983
[32m[0907 01-12-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18672, current rewards: -94.77719, mean: -0.86161
[32m[0907 01-12-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18439, current rewards: -132.37272, mean: -0.82733
[32m[0907 01-12-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18453, current rewards: -154.71390, mean: -0.73673
[32m[0907 01-13-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18458, current rewards: -149.42729, mean: -0.57472
[32m[0907 01-13-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18458, current rewards: -144.13942, mean: -0.46497
[32m[0907 01-13-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18477, current rewards: -164.04757, mean: -0.45569
[32m[0907 01-13-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18628, current rewards: -206.90479, mean: -0.50465
[32m[0907 01-13-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18607, current rewards: -231.45484, mean: -0.50316
[32m[0907 01-13-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18591, current rewards: -225.99138, mean: -0.44312
[32m[0907 01-14-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18587, current rewards: -220.51904, mean: -0.39378
[32m[0907 01-14-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18575, current rewards: -215.04321, mean: -0.35253
[32m[0907 01-14-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18565, current rewards: -209.57115, mean: -0.31753
[32m[0907 01-14-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18554, current rewards: -204.09222, mean: -0.28745
[32m[0907 01-14-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18547, current rewards: -198.26895, mean: -0.26088
[32m[0907 01-14-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18541, current rewards: -192.76138, mean: -0.23798
[32m[0907 01-15-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18533, current rewards: -187.25724, mean: -0.21774
[32m[0907 01-15-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18526, current rewards: -191.68216, mean: -0.21064
[32m[0907 01-15-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18515, current rewards: -206.31530, mean: -0.21491
[32m[0907 01-15-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18486, current rewards: -199.67382, mean: -0.19770
[32m[0907 01-15-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18463, current rewards: -192.95596, mean: -0.18203
[32m[0907 01-15-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18442, current rewards: -186.29726, mean: -0.16784
[32m[0907 01-15-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18418, current rewards: -179.09306, mean: -0.15439
[32m[0907 01-16-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18399, current rewards: -172.63370, mean: -0.14267
[32m[0907 01-16-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18384, current rewards: -166.20266, mean: -0.13191
[32m[0907 01-16-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18370, current rewards: -159.77162, mean: -0.12196
[32m[0907 01-16-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18353, current rewards: -153.36039, mean: -0.11276
[32m[0907 01-16-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18334, current rewards: -184.79394, mean: -0.13106
[32m[0907 01-16-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18300, current rewards: -177.94552, mean: -0.12188
[32m[0907 01-16-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18268, current rewards: -171.76783, mean: -0.11375
[32m[0907 01-17-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18241, current rewards: -165.59015, mean: -0.10615
[32m[0907 01-17-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18214, current rewards: -166.69003, mean: -0.10353
[32m[0907 01-17-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18189, current rewards: -216.69003, mean: -0.13054
[32m[0907 01-17-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18167, current rewards: -266.69003, mean: -0.15596
[32m[0907 01-17-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18144, current rewards: -316.69003, mean: -0.17994
[32m[0907 01-17-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18123, current rewards: -366.69003, mean: -0.20259
[32m[0907 01-17-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18102, current rewards: -416.69003, mean: -0.22403
[32m[0907 01-18-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18092, current rewards: -466.69003, mean: -0.24434
[32m[0907 01-18-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18089, current rewards: -516.69003, mean: -0.26362
[32m[0907 01-18-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18087, current rewards: -566.69003, mean: -0.28194
[32m[0907 01-18-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18084, current rewards: -616.69003, mean: -0.29936
[32m[0907 01-18-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18079, current rewards: -666.69003, mean: -0.31597
[32m[0907 01-18-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18075, current rewards: -716.69003, mean: -0.33180
[32m[0907 01-19-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18071, current rewards: -766.69003, mean: -0.34692
[32m[0907 01-19-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18069, current rewards: -816.69003, mean: -0.36137
[32m[0907 01-19-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18064, current rewards: -866.69003, mean: -0.37519
[32m[0907 01-19-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18072, current rewards: -916.69003, mean: -0.38843
[32m[0907 01-19-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18082, current rewards: -966.69003, mean: -0.40112
[32m[0907 01-19-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18091, current rewards: -1016.69003, mean: -0.41329
[32m[0907 01-19-53 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0907 01-19-53 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-19-53 @MBExp.py:227][0m Rewards obtained: [-1056.690034022977], Lows: [105], Highs: [1012], Total time: 35673.75273099999
[32m[0907 01-22-33 @MBExp.py:144][0m ####################################################################
[32m[0907 01-22-33 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 01-22-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17280, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-22-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17378, current rewards: -42.15162, mean: -0.70253
[32m[0907 01-22-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17386, current rewards: -72.82337, mean: -0.66203
[32m[0907 01-23-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17441, current rewards: -83.77380, mean: -0.52359
[32m[0907 01-23-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17649, current rewards: -90.21929, mean: -0.42962
[32m[0907 01-23-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17801, current rewards: -115.70058, mean: -0.44500
[32m[0907 01-23-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17908, current rewards: -136.72111, mean: -0.44104
[32m[0907 01-23-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17976, current rewards: -184.23150, mean: -0.51175
[32m[0907 01-23-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18041, current rewards: -230.73363, mean: -0.56276
[32m[0907 01-23-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18083, current rewards: -267.60367, mean: -0.58175
[32m[0907 01-24-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18116, current rewards: -327.90722, mean: -0.64296
[32m[0907 01-24-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18152, current rewards: -363.56594, mean: -0.64922
[32m[0907 01-24-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18170, current rewards: -412.72276, mean: -0.67659
[32m[0907 01-24-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18195, current rewards: -463.89028, mean: -0.70286
[32m[0907 01-24-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18214, current rewards: -530.99788, mean: -0.74788
[32m[0907 01-24-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18227, current rewards: -630.99788, mean: -0.83026
[32m[0907 01-25-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18235, current rewards: -730.99788, mean: -0.90247
[32m[0907 01-25-10 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18252, current rewards: -830.99788, mean: -0.96628
[32m[0907 01-25-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18257, current rewards: -930.99788, mean: -1.02307
[32m[0907 01-25-28 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18266, current rewards: -1030.99788, mean: -1.07396
[32m[0907 01-25-37 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18258, current rewards: -1130.99788, mean: -1.11980
[32m[0907 01-25-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18242, current rewards: -1230.99788, mean: -1.16132
[32m[0907 01-25-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18228, current rewards: -1330.99788, mean: -1.19910
[32m[0907 01-26-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18214, current rewards: -1430.99788, mean: -1.23362
[32m[0907 01-26-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18204, current rewards: -1530.99788, mean: -1.26529
[32m[0907 01-26-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18193, current rewards: -1630.99788, mean: -1.29444
[32m[0907 01-26-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18185, current rewards: -1730.99788, mean: -1.32137
[32m[0907 01-26-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18178, current rewards: -1830.99788, mean: -1.34632
[32m[0907 01-26-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18164, current rewards: -1930.99788, mean: -1.36950
[32m[0907 01-26-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18137, current rewards: -2030.99788, mean: -1.39109
[32m[0907 01-27-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18110, current rewards: -2130.99788, mean: -1.41126
[32m[0907 01-27-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18085, current rewards: -2230.99788, mean: -1.43013
[32m[0907 01-27-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18063, current rewards: -2330.99788, mean: -1.44782
[32m[0907 01-27-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18044, current rewards: -2430.99788, mean: -1.46446
[32m[0907 01-27-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18025, current rewards: -2530.99788, mean: -1.48012
[32m[0907 01-27-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18009, current rewards: -2630.99788, mean: -1.49489
[32m[0907 01-27-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17996, current rewards: -2730.99788, mean: -1.50884
[32m[0907 01-28-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17982, current rewards: -2830.99788, mean: -1.52204
[32m[0907 01-28-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17969, current rewards: -2930.99788, mean: -1.53455
[32m[0907 01-28-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17971, current rewards: -3030.99788, mean: -1.54643
[32m[0907 01-28-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17972, current rewards: -3130.99788, mean: -1.55771
[32m[0907 01-28-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17976, current rewards: -3230.99788, mean: -1.56845
[32m[0907 01-28-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17980, current rewards: -3330.99788, mean: -1.57867
[32m[0907 01-29-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17983, current rewards: -3430.99788, mean: -1.58842
[32m[0907 01-29-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17985, current rewards: -3530.99788, mean: -1.59774
[32m[0907 01-29-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17987, current rewards: -3630.99788, mean: -1.60664
[32m[0907 01-29-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17988, current rewards: -3730.99788, mean: -1.61515
[32m[0907 01-29-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17999, current rewards: -3830.99788, mean: -1.62330
[32m[0907 01-29-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18012, current rewards: -3930.99788, mean: -1.63112
[32m[0907 01-29-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18023, current rewards: -4030.99788, mean: -1.63862
[32m[0907 01-30-04 @Agent.py:117][0m Average action selection time: 0.1803
[32m[0907 01-30-04 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-30-04 @MBExp.py:227][0m Rewards obtained: [-4110.997877413245], Lows: [1996], Highs: [172], Total time: 36125.34109899999
[32m[0907 01-32-46 @MBExp.py:144][0m ####################################################################
[32m[0907 01-32-46 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 01-32-48 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18372, current rewards: -2.62307, mean: -0.26231
[32m[0907 01-32-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17615, current rewards: -22.92069, mean: -0.38201
[32m[0907 01-33-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17647, current rewards: -20.20723, mean: -0.18370
[32m[0907 01-33-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17565, current rewards: -16.41427, mean: -0.10259
[32m[0907 01-33-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17617, current rewards: -12.62029, mean: -0.06010
[32m[0907 01-33-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17757, current rewards: -8.82612, mean: -0.03395
[32m[0907 01-33-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17885, current rewards: -5.03297, mean: -0.01624
[32m[0907 01-33-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17972, current rewards: 0.54146, mean: 0.00150
[32m[0907 01-34-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18020, current rewards: 6.09420, mean: 0.01486
[32m[0907 01-34-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18066, current rewards: 11.33889, mean: 0.02465
[32m[0907 01-34-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18102, current rewards: 16.58358, mean: 0.03252
[32m[0907 01-34-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18133, current rewards: -15.73812, mean: -0.02810
[32m[0907 01-34-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18161, current rewards: -65.73812, mean: -0.10777
[32m[0907 01-34-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18182, current rewards: -115.73812, mean: -0.17536
[32m[0907 01-34-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18203, current rewards: -165.73812, mean: -0.23343
[32m[0907 01-35-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18226, current rewards: -215.73812, mean: -0.28387
[32m[0907 01-35-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18237, current rewards: -265.73812, mean: -0.32807
[32m[0907 01-35-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18247, current rewards: -315.73812, mean: -0.36714
[32m[0907 01-35-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18252, current rewards: -365.73812, mean: -0.40191
[32m[0907 01-35-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18251, current rewards: -415.73812, mean: -0.43306
[32m[0907 01-35-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18236, current rewards: -465.73812, mean: -0.46113
[32m[0907 01-36-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18224, current rewards: -515.73812, mean: -0.48655
[32m[0907 01-36-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18212, current rewards: -565.73812, mean: -0.50967
[32m[0907 01-36-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18199, current rewards: -615.73812, mean: -0.53081
[32m[0907 01-36-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18188, current rewards: -665.73812, mean: -0.55020
[32m[0907 01-36-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18178, current rewards: -715.73812, mean: -0.56805
[32m[0907 01-36-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18171, current rewards: -765.73812, mean: -0.58453
[32m[0907 01-36-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18162, current rewards: -815.73812, mean: -0.59981
[32m[0907 01-37-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18139, current rewards: -865.73812, mean: -0.61400
[32m[0907 01-37-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18115, current rewards: -915.73812, mean: -0.62722
[32m[0907 01-37-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18092, current rewards: -965.73812, mean: -0.63956
[32m[0907 01-37-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18067, current rewards: -1015.73812, mean: -0.65111
[32m[0907 01-37-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18044, current rewards: -1065.73812, mean: -0.66195
[32m[0907 01-37-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18024, current rewards: -1115.73812, mean: -0.67213
[32m[0907 01-37-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18005, current rewards: -1165.73812, mean: -0.68172
[32m[0907 01-38-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17987, current rewards: -1215.73812, mean: -0.69076
[32m[0907 01-38-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17970, current rewards: -1265.73812, mean: -0.69930
[32m[0907 01-38-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17953, current rewards: -1315.73812, mean: -0.70739
[32m[0907 01-38-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17941, current rewards: -1365.73812, mean: -0.71505
[32m[0907 01-38-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17940, current rewards: -1415.73812, mean: -0.72232
[32m[0907 01-38-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17941, current rewards: -1465.73812, mean: -0.72922
[32m[0907 01-38-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17940, current rewards: -1515.73812, mean: -0.73580
[32m[0907 01-39-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17939, current rewards: -1565.73812, mean: -0.74206
[32m[0907 01-39-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17941, current rewards: -1615.73812, mean: -0.74803
[32m[0907 01-39-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17942, current rewards: -1665.73812, mean: -0.75373
[32m[0907 01-39-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17942, current rewards: -1715.73812, mean: -0.75918
[32m[0907 01-39-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17941, current rewards: -1765.73812, mean: -0.76439
[32m[0907 01-39-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17953, current rewards: -1815.73812, mean: -0.76938
[32m[0907 01-40-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17963, current rewards: -1865.73812, mean: -0.77417
[32m[0907 01-40-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17974, current rewards: -1915.73812, mean: -0.77876
[32m[0907 01-40-16 @Agent.py:117][0m Average action selection time: 0.1798
[32m[0907 01-40-16 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-40-17 @MBExp.py:227][0m Rewards obtained: [-1955.7381229227126], Lows: [11], Highs: [1980], Total time: 36575.67294099999
[32m[0907 01-43-01 @MBExp.py:144][0m ####################################################################
[32m[0907 01-43-01 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 01-43-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17334, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-43-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17354, current rewards: -110.00000, mean: -1.83333
[32m[0907 01-43-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17354, current rewards: -210.00000, mean: -1.90909
[32m[0907 01-43-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17405, current rewards: -310.00000, mean: -1.93750
[32m[0907 01-43-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17517, current rewards: -410.00000, mean: -1.95238
[32m[0907 01-43-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17594, current rewards: -510.00000, mean: -1.96154
[32m[0907 01-43-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17646, current rewards: -610.00000, mean: -1.96774
[32m[0907 01-44-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17695, current rewards: -710.00000, mean: -1.97222
[32m[0907 01-44-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17789, current rewards: -810.00000, mean: -1.97561
[32m[0907 01-44-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17863, current rewards: -910.00000, mean: -1.97826
[32m[0907 01-44-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17924, current rewards: -1010.00000, mean: -1.98039
[32m[0907 01-44-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17969, current rewards: -1110.00000, mean: -1.98214
[32m[0907 01-44-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18016, current rewards: -1210.00000, mean: -1.98361
[32m[0907 01-45-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18047, current rewards: -1310.00000, mean: -1.98485
[32m[0907 01-45-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18073, current rewards: -1410.00000, mean: -1.98592
[32m[0907 01-45-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18102, current rewards: -1510.00000, mean: -1.98684
[32m[0907 01-45-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18124, current rewards: -1610.00000, mean: -1.98765
[32m[0907 01-45-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18152, current rewards: -1710.00000, mean: -1.98837
[32m[0907 01-45-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18172, current rewards: -1810.00000, mean: -1.98901
[32m[0907 01-45-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18188, current rewards: -1910.00000, mean: -1.98958
[32m[0907 01-46-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18200, current rewards: -2010.00000, mean: -1.99010
[32m[0907 01-46-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18187, current rewards: -2110.00000, mean: -1.99057
[32m[0907 01-46-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18171, current rewards: -2210.00000, mean: -1.99099
[32m[0907 01-46-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18159, current rewards: -2310.00000, mean: -1.99138
[32m[0907 01-46-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18147, current rewards: -2410.00000, mean: -1.99174
[32m[0907 01-46-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18137, current rewards: -2510.00000, mean: -1.99206
[32m[0907 01-46-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18129, current rewards: -2610.00000, mean: -1.99237
[32m[0907 01-47-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18122, current rewards: -2710.00000, mean: -1.99265
[32m[0907 01-47-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18097, current rewards: -2810.00000, mean: -1.99291
[32m[0907 01-47-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18072, current rewards: -2910.00000, mean: -1.99315
[32m[0907 01-47-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18049, current rewards: -3010.00000, mean: -1.99338
[32m[0907 01-47-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18029, current rewards: -3110.00000, mean: -1.99359
[32m[0907 01-47-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18006, current rewards: -3210.00000, mean: -1.99379
[32m[0907 01-48-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17987, current rewards: -3310.00000, mean: -1.99398
[32m[0907 01-48-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17969, current rewards: -3410.00000, mean: -1.99415
[32m[0907 01-48-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17950, current rewards: -3510.00000, mean: -1.99432
[32m[0907 01-48-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17933, current rewards: -3610.00000, mean: -1.99448
[32m[0907 01-48-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17916, current rewards: -3710.00000, mean: -1.99462
[32m[0907 01-48-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17901, current rewards: -3810.00000, mean: -1.99476
[32m[0907 01-48-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17887, current rewards: -3910.00000, mean: -1.99490
[32m[0907 01-49-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17885, current rewards: -4010.00000, mean: -1.99502
[32m[0907 01-49-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17887, current rewards: -4110.00000, mean: -1.99515
[32m[0907 01-49-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17888, current rewards: -4210.00000, mean: -1.99526
[32m[0907 01-49-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17888, current rewards: -4310.00000, mean: -1.99537
[32m[0907 01-49-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17889, current rewards: -4410.00000, mean: -1.99548
[32m[0907 01-49-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17892, current rewards: -4510.00000, mean: -1.99558
[32m[0907 01-49-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17893, current rewards: -4610.00000, mean: -1.99567
[32m[0907 01-50-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17904, current rewards: -4710.00000, mean: -1.99576
[32m[0907 01-50-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17919, current rewards: -4810.00000, mean: -1.99585
[32m[0907 01-50-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17931, current rewards: -4910.00000, mean: -1.99593
[32m[0907 01-50-30 @Agent.py:117][0m Average action selection time: 0.1794
[32m[0907 01-50-30 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-50-30 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 37024.98518499999
[32m[0907 01-53-16 @MBExp.py:144][0m ####################################################################
[32m[0907 01-53-16 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 01-53-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.22545, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-53-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18349, current rewards: -17.39506, mean: -0.28992
[32m[0907 01-53-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17906, current rewards: -11.81633, mean: -0.10742
[32m[0907 01-53-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17737, current rewards: -6.23975, mean: -0.03900
[32m[0907 01-53-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17793, current rewards: -0.66367, mean: -0.00316
[32m[0907 01-54-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17853, current rewards: 4.91125, mean: 0.01889
[32m[0907 01-54-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17875, current rewards: 10.48559, mean: 0.03382
[32m[0907 01-54-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17882, current rewards: 16.06172, mean: 0.04462
[32m[0907 01-54-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17890, current rewards: 21.63590, mean: 0.05277
[32m[0907 01-54-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17941, current rewards: 27.21549, mean: 0.05916
[32m[0907 01-54-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18054, current rewards: 10.70373, mean: 0.02099
[32m[0907 01-54-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18184, current rewards: -49.47418, mean: -0.08835
[32m[0907 01-55-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18277, current rewards: -89.08570, mean: -0.14604
[32m[0907 01-55-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18419, current rewards: -134.08707, mean: -0.20316
[32m[0907 01-55-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18475, current rewards: -183.66232, mean: -0.25868
[32m[0907 01-55-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18650, current rewards: -262.26405, mean: -0.34508
[32m[0907 01-55-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18704, current rewards: -297.93462, mean: -0.36782
[32m[0907 01-55-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18752, current rewards: -363.34474, mean: -0.42249
[32m[0907 01-56-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18807, current rewards: -411.23626, mean: -0.45191
[32m[0907 01-56-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18828, current rewards: -474.64076, mean: -0.49442
[32m[0907 01-56-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18878, current rewards: -539.26762, mean: -0.53393
[32m[0907 01-56-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18897, current rewards: -602.30605, mean: -0.56821
[32m[0907 01-56-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18929, current rewards: -663.18137, mean: -0.59746
[32m[0907 01-56-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18937, current rewards: -709.04192, mean: -0.61124
[32m[0907 01-57-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18986, current rewards: -746.51408, mean: -0.61695
[32m[0907 01-57-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19000, current rewards: -793.47362, mean: -0.62974
[32m[0907 01-57-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18979, current rewards: -850.16858, mean: -0.64898
[32m[0907 01-57-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18958, current rewards: -899.95352, mean: -0.66173
[32m[0907 01-57-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18916, current rewards: -929.73234, mean: -0.65938
[32m[0907 01-57-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18864, current rewards: -924.24183, mean: -0.63304
[32m[0907 01-58-00 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18813, current rewards: -931.31523, mean: -0.61677
[32m[0907 01-58-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18772, current rewards: -927.09195, mean: -0.59429
[32m[0907 01-58-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18730, current rewards: -922.23154, mean: -0.57281
[32m[0907 01-58-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18690, current rewards: -917.36950, mean: -0.55263
[32m[0907 01-58-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18651, current rewards: -912.50849, mean: -0.53363
[32m[0907 01-58-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18615, current rewards: -907.64819, mean: -0.51571
[32m[0907 01-58-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18579, current rewards: -902.78852, mean: -0.49878
[32m[0907 01-59-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18546, current rewards: -897.93286, mean: -0.48276
[32m[0907 01-59-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18523, current rewards: -893.07437, mean: -0.46758
[32m[0907 01-59-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18507, current rewards: -887.98314, mean: -0.45305
[32m[0907 01-59-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18492, current rewards: -883.11172, mean: -0.43936
[32m[0907 01-59-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18478, current rewards: -890.13738, mean: -0.43211
[32m[0907 01-59-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18466, current rewards: -885.78841, mean: -0.41980
[32m[0907 01-59-55 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18454, current rewards: -881.43289, mean: -0.40807
[32m[0907 02-00-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18443, current rewards: -877.07425, mean: -0.39687
[32m[0907 02-00-13 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18438, current rewards: -872.71427, mean: -0.38616
[32m[0907 02-00-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18441, current rewards: -868.35922, mean: -0.37591
[32m[0907 02-00-32 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18443, current rewards: -864.05783, mean: -0.36613
[32m[0907 02-00-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18444, current rewards: -859.33951, mean: -0.35657
[32m[0907 02-00-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18445, current rewards: -851.88046, mean: -0.34629
[32m[0907 02-00-58 @Agent.py:117][0m Average action selection time: 0.1844
[32m[0907 02-00-58 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-00-58 @MBExp.py:227][0m Rewards obtained: [-847.7511794637273], Lows: [505], Highs: [70], Total time: 37486.87846099999
[32m[0907 02-03-46 @MBExp.py:144][0m ####################################################################
[32m[0907 02-03-46 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 02-03-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17425, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-03-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17440, current rewards: -7.22649, mean: -0.12044
[32m[0907 02-04-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17503, current rewards: -0.63044, mean: -0.00573
[32m[0907 02-04-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17634, current rewards: 5.96411, mean: 0.03728
[32m[0907 02-04-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17716, current rewards: 12.55989, mean: 0.05981
[32m[0907 02-04-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17777, current rewards: 21.00991, mean: 0.08081
[32m[0907 02-04-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17797, current rewards: 5.41767, mean: 0.01748
[32m[0907 02-04-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17821, current rewards: 9.66969, mean: 0.02686
[32m[0907 02-04-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17891, current rewards: 13.91709, mean: 0.03394
[32m[0907 02-05-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17958, current rewards: 18.16636, mean: 0.03949
[32m[0907 02-05-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18004, current rewards: 22.41555, mean: 0.04395
[32m[0907 02-05-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18048, current rewards: 26.66339, mean: 0.04761
[32m[0907 02-05-36 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18082, current rewards: 30.91151, mean: 0.05067
[32m[0907 02-05-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18117, current rewards: 15.34688, mean: 0.02325
[32m[0907 02-05-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18142, current rewards: 19.57973, mean: 0.02758
[32m[0907 02-06-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18171, current rewards: 23.74777, mean: 0.03125
[32m[0907 02-06-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18185, current rewards: 27.92241, mean: 0.03447
[32m[0907 02-06-22 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18195, current rewards: 32.09231, mean: 0.03732
[32m[0907 02-06-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18203, current rewards: 36.26168, mean: 0.03985
[32m[0907 02-06-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18195, current rewards: 40.42630, mean: 0.04211
[32m[0907 02-06-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18183, current rewards: 35.93733, mean: 0.03558
[32m[0907 02-06-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18224, current rewards: -11.64805, mean: -0.01099
[32m[0907 02-07-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18240, current rewards: -70.08572, mean: -0.06314
[32m[0907 02-07-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18225, current rewards: -134.61448, mean: -0.11605
[32m[0907 02-07-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18234, current rewards: -181.13446, mean: -0.14970
[32m[0907 02-07-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18226, current rewards: -245.03287, mean: -0.19447
[32m[0907 02-07-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18194, current rewards: -305.76176, mean: -0.23341
[32m[0907 02-07-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18167, current rewards: -374.49612, mean: -0.27536
[32m[0907 02-08-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18179, current rewards: -434.68865, mean: -0.30829
[32m[0907 02-08-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18153, current rewards: -442.48073, mean: -0.30307
[32m[0907 02-08-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18127, current rewards: -435.13237, mean: -0.28817
[32m[0907 02-08-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18104, current rewards: -429.62626, mean: -0.27540
[32m[0907 02-08-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18085, current rewards: -424.58309, mean: -0.26372
[32m[0907 02-08-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18065, current rewards: -419.79274, mean: -0.25289
[32m[0907 02-08-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18046, current rewards: -415.09781, mean: -0.24275
[32m[0907 02-09-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18028, current rewards: -421.16822, mean: -0.23930
[32m[0907 02-09-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18011, current rewards: -414.61218, mean: -0.22907
[32m[0907 02-09-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17994, current rewards: -409.78753, mean: -0.22032
[32m[0907 02-09-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17991, current rewards: -404.99046, mean: -0.21204
[32m[0907 02-09-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17990, current rewards: -400.88048, mean: -0.20453
[32m[0907 02-09-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17987, current rewards: -396.08273, mean: -0.19706
[32m[0907 02-09-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17986, current rewards: -391.28633, mean: -0.18994
[32m[0907 02-10-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17984, current rewards: -407.55674, mean: -0.19315
[32m[0907 02-10-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17983, current rewards: -402.80116, mean: -0.18648
[32m[0907 02-10-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17983, current rewards: -398.04013, mean: -0.18011
[32m[0907 02-10-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17990, current rewards: -393.28268, mean: -0.17402
[32m[0907 02-10-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18004, current rewards: -388.52638, mean: -0.16819
[32m[0907 02-10-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18014, current rewards: -383.76356, mean: -0.16261
[32m[0907 02-11-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18021, current rewards: -379.00615, mean: -0.15726
[32m[0907 02-11-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18028, current rewards: -374.24625, mean: -0.15213
[32m[0907 02-11-17 @Agent.py:117][0m Average action selection time: 0.1803
[32m[0907 02-11-17 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-11-17 @MBExp.py:227][0m Rewards obtained: [-370.43674144168403], Lows: [269], Highs: [57], Total time: 37938.530844999994
[32m[0907 02-14-07 @MBExp.py:144][0m ####################################################################
[32m[0907 02-14-07 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 02-14-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17322, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-14-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17653, current rewards: -21.96619, mean: -0.36610
[32m[0907 02-14-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18092, current rewards: -32.72906, mean: -0.29754
[32m[0907 02-14-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18333, current rewards: -54.74118, mean: -0.34213
[32m[0907 02-14-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18415, current rewards: -86.46999, mean: -0.41176
[32m[0907 02-14-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18463, current rewards: -112.65513, mean: -0.43329
[32m[0907 02-15-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18428, current rewards: -104.37514, mean: -0.33669
[32m[0907 02-15-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18481, current rewards: -119.76265, mean: -0.33267
[32m[0907 02-15-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18603, current rewards: -133.69625, mean: -0.32609
[32m[0907 02-15-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18694, current rewards: -162.55969, mean: -0.35339
[32m[0907 02-15-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18731, current rewards: -178.07907, mean: -0.34917
[32m[0907 02-15-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18768, current rewards: -195.86368, mean: -0.34976
[32m[0907 02-16-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18812, current rewards: -213.28340, mean: -0.34964
[32m[0907 02-16-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18852, current rewards: -236.27826, mean: -0.35800
[32m[0907 02-16-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18819, current rewards: -295.73122, mean: -0.41652
[32m[0907 02-16-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18797, current rewards: -361.64203, mean: -0.47584
[32m[0907 02-16-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18778, current rewards: -427.91995, mean: -0.52830
[32m[0907 02-16-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18753, current rewards: -493.68464, mean: -0.57405
[32m[0907 02-16-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18714, current rewards: -571.10520, mean: -0.62759
[32m[0907 02-17-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18678, current rewards: -595.48829, mean: -0.62030
[32m[0907 02-17-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18642, current rewards: -631.82780, mean: -0.62557
[32m[0907 02-17-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18608, current rewards: -696.33384, mean: -0.65692
[32m[0907 02-17-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18579, current rewards: -744.92873, mean: -0.67111
[32m[0907 02-17-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18551, current rewards: -798.51418, mean: -0.68837
[32m[0907 02-17-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18527, current rewards: -847.49301, mean: -0.70041
[32m[0907 02-18-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18482, current rewards: -917.29296, mean: -0.72801
[32m[0907 02-18-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18440, current rewards: -980.69644, mean: -0.74862
[32m[0907 02-18-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18401, current rewards: -1067.27791, mean: -0.78476
[32m[0907 02-18-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18364, current rewards: -1141.50804, mean: -0.80958
[32m[0907 02-18-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18330, current rewards: -1221.04663, mean: -0.83633
[32m[0907 02-18-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18300, current rewards: -1307.68343, mean: -0.86602
[32m[0907 02-18-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18271, current rewards: -1378.20416, mean: -0.88346
[32m[0907 02-19-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18250, current rewards: -1404.18121, mean: -0.87216
[32m[0907 02-19-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18228, current rewards: -1459.06435, mean: -0.87895
[32m[0907 02-19-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18210, current rewards: -1469.19707, mean: -0.85918
[32m[0907 02-19-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18186, current rewards: -1494.40733, mean: -0.84910
[32m[0907 02-19-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18166, current rewards: -1524.73382, mean: -0.84239
[32m[0907 02-19-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18151, current rewards: -1546.55820, mean: -0.83148
[32m[0907 02-19-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18145, current rewards: -1619.46516, mean: -0.84789
[32m[0907 02-20-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18141, current rewards: -1711.49767, mean: -0.87321
[32m[0907 02-20-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18136, current rewards: -1798.12464, mean: -0.89459
[32m[0907 02-20-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18131, current rewards: -1888.38303, mean: -0.91669
[32m[0907 02-20-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18125, current rewards: -1975.09339, mean: -0.93606
[32m[0907 02-20-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18122, current rewards: -2009.70076, mean: -0.93042
[32m[0907 02-20-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18122, current rewards: -1995.02009, mean: -0.90272
[32m[0907 02-20-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18130, current rewards: -1979.68494, mean: -0.87597
[32m[0907 02-21-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18138, current rewards: -1977.58315, mean: -0.85610
[32m[0907 02-21-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18147, current rewards: -1968.94111, mean: -0.83430
[32m[0907 02-21-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18156, current rewards: -1976.97839, mean: -0.82032
[32m[0907 02-21-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18161, current rewards: -1965.33458, mean: -0.79892
[32m[0907 02-21-41 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0907 02-21-41 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-21-42 @MBExp.py:227][0m Rewards obtained: [-1962.3180796094605], Lows: [992], Highs: [296], Total time: 38393.50154799999
[32m[0907 02-24-33 @MBExp.py:144][0m ####################################################################
[32m[0907 02-24-33 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 02-24-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17718, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-24-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17577, current rewards: -41.42096, mean: -0.69035
[32m[0907 02-24-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17772, current rewards: -34.04729, mean: -0.30952
[32m[0907 02-25-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17837, current rewards: -26.71152, mean: -0.16695
[32m[0907 02-25-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17870, current rewards: -20.17843, mean: -0.09609
[32m[0907 02-25-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17894, current rewards: -34.04403, mean: -0.13094
[32m[0907 02-25-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17987, current rewards: -55.18261, mean: -0.17801
[32m[0907 02-25-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18038, current rewards: -49.91258, mean: -0.13865
[32m[0907 02-25-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18097, current rewards: -44.63722, mean: -0.10887
[32m[0907 02-25-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18143, current rewards: -39.36378, mean: -0.08557
[32m[0907 02-26-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18202, current rewards: -34.08519, mean: -0.06683
[32m[0907 02-26-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18255, current rewards: -28.81340, mean: -0.05145
[32m[0907 02-26-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18301, current rewards: -23.46737, mean: -0.03847
[32m[0907 02-26-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18334, current rewards: -16.16059, mean: -0.02449
[32m[0907 02-26-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18367, current rewards: -19.61831, mean: -0.02763
[32m[0907 02-26-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18397, current rewards: -17.53309, mean: -0.02307
[32m[0907 02-27-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18423, current rewards: -11.98603, mean: -0.01480
[32m[0907 02-27-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18441, current rewards: -6.43976, mean: -0.00749
[32m[0907 02-27-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18436, current rewards: -0.89349, mean: -0.00098
[32m[0907 02-27-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18429, current rewards: 4.65170, mean: 0.00485
[32m[0907 02-27-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18424, current rewards: 10.20276, mean: 0.01010
[32m[0907 02-27-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18421, current rewards: 15.31573, mean: 0.01445
[32m[0907 02-27-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18415, current rewards: 20.68295, mean: 0.01863
[32m[0907 02-28-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18411, current rewards: 26.05704, mean: 0.02246
[32m[0907 02-28-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18408, current rewards: 31.42777, mean: 0.02597
[32m[0907 02-28-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18395, current rewards: 36.79772, mean: 0.02920
[32m[0907 02-28-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18370, current rewards: 26.21689, mean: 0.02001
[32m[0907 02-28-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18346, current rewards: -2.07947, mean: -0.00153
[32m[0907 02-28-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18324, current rewards: -43.04479, mean: -0.03053
[32m[0907 02-29-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18305, current rewards: -84.04399, mean: -0.05756
[32m[0907 02-29-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18287, current rewards: -129.75103, mean: -0.08593
[32m[0907 02-29-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18270, current rewards: -192.79355, mean: -0.12359
[32m[0907 02-29-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18254, current rewards: -186.98601, mean: -0.11614
[32m[0907 02-29-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18236, current rewards: -225.73307, mean: -0.13598
[32m[0907 02-29-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18220, current rewards: -205.46932, mean: -0.12016
[32m[0907 02-29-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18207, current rewards: -211.66278, mean: -0.12026
[32m[0907 02-30-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18237, current rewards: -202.82477, mean: -0.11206
[32m[0907 02-30-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18253, current rewards: -240.23450, mean: -0.12916
[32m[0907 02-30-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18286, current rewards: -285.18384, mean: -0.14931
[32m[0907 02-30-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18317, current rewards: -343.67919, mean: -0.17535
[32m[0907 02-30-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18350, current rewards: -392.80399, mean: -0.19542
[32m[0907 02-30-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18384, current rewards: -460.86190, mean: -0.22372
[32m[0907 02-31-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18394, current rewards: -507.46048, mean: -0.24050
[32m[0907 02-31-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18407, current rewards: -562.67124, mean: -0.26050
[32m[0907 02-31-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18419, current rewards: -623.66773, mean: -0.28220
[32m[0907 02-31-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18435, current rewards: -679.71911, mean: -0.30076
[32m[0907 02-31-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18455, current rewards: -728.52353, mean: -0.31538
[32m[0907 02-31-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18476, current rewards: -782.29523, mean: -0.33148
[32m[0907 02-31-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18488, current rewards: -827.66807, mean: -0.34343
[32m[0907 02-32-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18505, current rewards: -874.77449, mean: -0.35560
[32m[0907 02-32-16 @Agent.py:117][0m Average action selection time: 0.1851
[32m[0907 02-32-16 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-32-17 @MBExp.py:227][0m Rewards obtained: [-900.6535122071507], Lows: [585], Highs: [71], Total time: 38857.099603999995
[32m[0907 02-35-14 @MBExp.py:144][0m ####################################################################
[32m[0907 02-35-14 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 02-35-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17632, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-35-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18214, current rewards: -38.73105, mean: -0.64552
[32m[0907 02-35-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18272, current rewards: -33.89192, mean: -0.30811
[32m[0907 02-35-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18301, current rewards: -28.57442, mean: -0.17859
[32m[0907 02-35-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18318, current rewards: -35.06320, mean: -0.16697
[32m[0907 02-36-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18316, current rewards: -30.90346, mean: -0.11886
[32m[0907 02-36-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18317, current rewards: -26.74424, mean: -0.08627
[32m[0907 02-36-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18332, current rewards: -22.58307, mean: -0.06273
[32m[0907 02-36-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18345, current rewards: -18.42265, mean: -0.04493
[32m[0907 02-36-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18390, current rewards: -14.26197, mean: -0.03100
[32m[0907 02-36-48 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18431, current rewards: -10.10251, mean: -0.01981
[32m[0907 02-36-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18465, current rewards: -6.04085, mean: -0.01079
[32m[0907 02-37-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18496, current rewards: -2.26167, mean: -0.00371
[32m[0907 02-37-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18519, current rewards: 1.75492, mean: 0.00266
[32m[0907 02-37-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18543, current rewards: 5.77289, mean: 0.00813
[32m[0907 02-37-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18566, current rewards: -14.13527, mean: -0.01860
[32m[0907 02-37-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18574, current rewards: -9.71373, mean: -0.01199
[32m[0907 02-37-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18558, current rewards: -5.31439, mean: -0.00618
[32m[0907 02-38-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18547, current rewards: -0.91171, mean: -0.00100
[32m[0907 02-38-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18534, current rewards: 3.49172, mean: 0.00364
[32m[0907 02-38-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18525, current rewards: 3.14993, mean: 0.00312
[32m[0907 02-38-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18516, current rewards: 2.53775, mean: 0.00239
[32m[0907 02-38-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18505, current rewards: 8.24854, mean: 0.00743
[32m[0907 02-38-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18496, current rewards: 13.96406, mean: 0.01204
[32m[0907 02-38-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18490, current rewards: 19.67818, mean: 0.01626
[32m[0907 02-39-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18459, current rewards: 25.38859, mean: 0.02015
[32m[0907 02-39-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18430, current rewards: 31.10409, mean: 0.02374
[32m[0907 02-39-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18404, current rewards: 36.81393, mean: 0.02707
[32m[0907 02-39-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18407, current rewards: 17.26329, mean: 0.01224
[32m[0907 02-39-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18385, current rewards: 27.43699, mean: 0.01879
[32m[0907 02-39-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18361, current rewards: 37.27793, mean: 0.02469
[32m[0907 02-40-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18339, current rewards: 47.11064, mean: 0.03020
[32m[0907 02-40-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18322, current rewards: 56.94214, mean: 0.03537
[32m[0907 02-40-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18305, current rewards: 66.77828, mean: 0.04023
[32m[0907 02-40-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18288, current rewards: 76.63225, mean: 0.04481
[32m[0907 02-40-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18271, current rewards: 86.47347, mean: 0.04913
[32m[0907 02-40-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18257, current rewards: 75.84177, mean: 0.04190
[32m[0907 02-40-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18256, current rewards: 80.58787, mean: 0.04333
[32m[0907 02-41-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18258, current rewards: 89.50335, mean: 0.04686
[32m[0907 02-41-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18259, current rewards: 98.42680, mean: 0.05022
[32m[0907 02-41-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18261, current rewards: 107.34793, mean: 0.05341
[32m[0907 02-41-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18261, current rewards: 110.37975, mean: 0.05358
[32m[0907 02-41-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18263, current rewards: 111.96727, mean: 0.05307
[32m[0907 02-41-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18264, current rewards: 125.89724, mean: 0.05829
[32m[0907 02-41-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18265, current rewards: 140.11517, mean: 0.06340
[32m[0907 02-42-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18276, current rewards: 126.04239, mean: 0.05577
[32m[0907 02-42-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18287, current rewards: 139.38840, mean: 0.06034
[32m[0907 02-42-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18298, current rewards: 152.79179, mean: 0.06474
[32m[0907 02-42-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18309, current rewards: 143.36643, mean: 0.05949
[32m[0907 02-42-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18320, current rewards: 148.46707, mean: 0.06035
[32m[0907 02-42-52 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0907 02-42-52 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-42-53 @MBExp.py:227][0m Rewards obtained: [152.1878812693836], Lows: [53], Highs: [75], Total time: 39316.137784
[32m[0907 02-45-52 @MBExp.py:144][0m ####################################################################
[32m[0907 02-45-52 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 02-45-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18193, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-46-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18324, current rewards: -110.00000, mean: -1.83333
[32m[0907 02-46-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18302, current rewards: -210.00000, mean: -1.90909
[32m[0907 02-46-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18285, current rewards: -310.00000, mean: -1.93750
[32m[0907 02-46-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18292, current rewards: -410.00000, mean: -1.95238
[32m[0907 02-46-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18291, current rewards: -510.00000, mean: -1.96154
[32m[0907 02-46-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18287, current rewards: -610.00000, mean: -1.96774
[32m[0907 02-46-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18287, current rewards: -710.00000, mean: -1.97222
[32m[0907 02-47-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18367, current rewards: -807.68211, mean: -1.96996
[32m[0907 02-47-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18474, current rewards: -900.95587, mean: -1.95860
[32m[0907 02-47-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18674, current rewards: -986.01228, mean: -1.93336
[32m[0907 02-47-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18684, current rewards: -982.25497, mean: -1.75403
[32m[0907 02-47-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18691, current rewards: -978.36689, mean: -1.60388
[32m[0907 02-47-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18698, current rewards: -974.54079, mean: -1.47658
[32m[0907 02-48-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18706, current rewards: -970.68306, mean: -1.36716
[32m[0907 02-48-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18714, current rewards: -966.65727, mean: -1.27192
[32m[0907 02-48-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18688, current rewards: -962.79937, mean: -1.18864
[32m[0907 02-48-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18666, current rewards: -958.82825, mean: -1.11492
[32m[0907 02-48-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18648, current rewards: -971.11477, mean: -1.06716
[32m[0907 02-48-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18631, current rewards: -1064.90747, mean: -1.10928
[32m[0907 02-49-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18613, current rewards: -1164.90747, mean: -1.15337
[32m[0907 02-49-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18598, current rewards: -1264.90747, mean: -1.19331
[32m[0907 02-49-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18584, current rewards: -1364.90747, mean: -1.22965
[32m[0907 02-49-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18571, current rewards: -1464.90747, mean: -1.26285
[32m[0907 02-49-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18562, current rewards: -1564.90747, mean: -1.29331
[32m[0907 02-49-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18534, current rewards: -1664.90747, mean: -1.32136
[32m[0907 02-49-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18501, current rewards: -1764.90747, mean: -1.34726
[32m[0907 02-50-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18473, current rewards: -1864.90747, mean: -1.37126
[32m[0907 02-50-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18446, current rewards: -1964.90747, mean: -1.39355
[32m[0907 02-50-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18422, current rewards: -2064.90747, mean: -1.41432
[32m[0907 02-50-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18399, current rewards: -2164.90747, mean: -1.43371
[32m[0907 02-50-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18379, current rewards: -2264.90747, mean: -1.45186
[32m[0907 02-50-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18357, current rewards: -2364.90747, mean: -1.46889
[32m[0907 02-50-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18338, current rewards: -2464.90747, mean: -1.48488
[32m[0907 02-51-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18319, current rewards: -2564.90747, mean: -1.49995
[32m[0907 02-51-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18303, current rewards: -2664.90747, mean: -1.51415
[32m[0907 02-51-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18293, current rewards: -2764.90747, mean: -1.52757
[32m[0907 02-51-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18294, current rewards: -2864.90747, mean: -1.54027
[32m[0907 02-51-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18295, current rewards: -2964.90747, mean: -1.55231
[32m[0907 02-51-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18295, current rewards: -3064.90747, mean: -1.56373
[32m[0907 02-52-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18294, current rewards: -3164.90747, mean: -1.57458
[32m[0907 02-52-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18295, current rewards: -3264.90747, mean: -1.58491
[32m[0907 02-52-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18296, current rewards: -3364.90747, mean: -1.59474
[32m[0907 02-52-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18296, current rewards: -3464.90747, mean: -1.60412
[32m[0907 02-52-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18297, current rewards: -3564.90747, mean: -1.61308
[32m[0907 02-52-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18302, current rewards: -3664.90747, mean: -1.62164
[32m[0907 02-52-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18312, current rewards: -3764.90747, mean: -1.62983
[32m[0907 02-53-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18324, current rewards: -3864.90747, mean: -1.63767
[32m[0907 02-53-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18335, current rewards: -3964.90747, mean: -1.64519
[32m[0907 02-53-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18346, current rewards: -4064.90747, mean: -1.65240
[32m[0907 02-53-31 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0907 02-53-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-53-31 @MBExp.py:227][0m Rewards obtained: [-4144.907468230289], Lows: [2075], Highs: [27], Total time: 39775.80661
[32m[0907 02-56-33 @MBExp.py:144][0m ####################################################################
[32m[0907 02-56-33 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 02-56-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29360, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-56-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20928, current rewards: -88.97277, mean: -1.48288
[32m[0907 02-56-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19680, current rewards: -153.49736, mean: -1.39543
[32m[0907 02-57-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19146, current rewards: -176.95019, mean: -1.10594
[32m[0907 02-57-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19379, current rewards: -215.57085, mean: -1.02653
[32m[0907 02-57-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19213, current rewards: -299.53090, mean: -1.15204
[32m[0907 02-57-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19217, current rewards: -383.96699, mean: -1.23860
[32m[0907 02-57-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19303, current rewards: -466.46428, mean: -1.29573
[32m[0907 02-57-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19371, current rewards: -547.47886, mean: -1.33531
[32m[0907 02-58-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19270, current rewards: -592.12488, mean: -1.28723
[32m[0907 02-58-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19239, current rewards: -624.07842, mean: -1.22368
[32m[0907 02-58-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19275, current rewards: -661.01093, mean: -1.18038
[32m[0907 02-58-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19281, current rewards: -752.67372, mean: -1.23389
[32m[0907 02-58-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19269, current rewards: -842.73798, mean: -1.27688
[32m[0907 02-58-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19275, current rewards: -931.70610, mean: -1.31226
[32m[0907 02-59-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19241, current rewards: -1029.30882, mean: -1.35435
[32m[0907 02-59-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19213, current rewards: -1123.04417, mean: -1.38647
[32m[0907 02-59-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19193, current rewards: -1216.61293, mean: -1.41467
[32m[0907 02-59-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19191, current rewards: -1300.55751, mean: -1.42918
[32m[0907 02-59-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19178, current rewards: -1390.32860, mean: -1.44826
[32m[0907 02-59-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19134, current rewards: -1484.13687, mean: -1.46944
[32m[0907 02-59-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19094, current rewards: -1584.13687, mean: -1.49447
[32m[0907 03-00-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19055, current rewards: -1684.13687, mean: -1.51724
[32m[0907 03-00-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19021, current rewards: -1784.13687, mean: -1.53805
[32m[0907 03-00-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18984, current rewards: -1884.13687, mean: -1.55714
[32m[0907 03-00-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18933, current rewards: -1984.13687, mean: -1.57471
[32m[0907 03-00-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18888, current rewards: -2084.13687, mean: -1.59094
[32m[0907 03-00-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18845, current rewards: -2184.13687, mean: -1.60598
[32m[0907 03-00-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18804, current rewards: -2284.13687, mean: -1.61996
[32m[0907 03-01-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18767, current rewards: -2384.13687, mean: -1.63297
[32m[0907 03-01-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18731, current rewards: -2484.13687, mean: -1.64512
[32m[0907 03-01-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18699, current rewards: -2584.13687, mean: -1.65650
[32m[0907 03-01-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18669, current rewards: -2684.13687, mean: -1.66717
[32m[0907 03-01-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18640, current rewards: -2784.13687, mean: -1.67719
[32m[0907 03-01-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18614, current rewards: -2884.13687, mean: -1.68663
[32m[0907 03-02-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18590, current rewards: -2984.13687, mean: -1.69553
[32m[0907 03-02-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18580, current rewards: -3084.13687, mean: -1.70394
[32m[0907 03-02-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18571, current rewards: -3184.13687, mean: -1.71190
[32m[0907 03-02-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18564, current rewards: -3284.13687, mean: -1.71944
[32m[0907 03-02-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18558, current rewards: -3384.13687, mean: -1.72660
[32m[0907 03-02-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18551, current rewards: -3484.13687, mean: -1.73340
[32m[0907 03-02-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18545, current rewards: -3584.13687, mean: -1.73987
[32m[0907 03-03-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18541, current rewards: -3684.13687, mean: -1.74604
[32m[0907 03-03-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18535, current rewards: -3784.13687, mean: -1.75192
[32m[0907 03-03-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18529, current rewards: -3884.13687, mean: -1.75753
[32m[0907 03-03-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18529, current rewards: -3984.13687, mean: -1.76289
[32m[0907 03-03-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18535, current rewards: -4084.13687, mean: -1.76802
[32m[0907 03-03-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18541, current rewards: -4184.13687, mean: -1.77294
[32m[0907 03-04-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18548, current rewards: -4284.13687, mean: -1.77765
[32m[0907 03-04-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18553, current rewards: -4384.13687, mean: -1.78217
[32m[0907 03-04-18 @Agent.py:117][0m Average action selection time: 0.1856
[32m[0907 03-04-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-04-18 @MBExp.py:227][0m Rewards obtained: [-4464.136866727786], Lows: [2173], Highs: [147], Total time: 40240.534338
[32m[0907 03-07-22 @MBExp.py:144][0m ####################################################################
[32m[0907 03-07-22 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 03-07-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18771, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-07-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17956, current rewards: -33.73850, mean: -0.56231
[32m[0907 03-07-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17877, current rewards: -37.44675, mean: -0.34043
[32m[0907 03-07-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17835, current rewards: -35.36826, mean: -0.22105
[32m[0907 03-08-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17815, current rewards: -30.79374, mean: -0.14664
[32m[0907 03-08-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17849, current rewards: -30.10277, mean: -0.11578
[32m[0907 03-08-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17932, current rewards: -27.60669, mean: -0.08905
[32m[0907 03-08-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17986, current rewards: -27.10845, mean: -0.07530
[32m[0907 03-08-36 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18036, current rewards: -24.44482, mean: -0.05962
[32m[0907 03-08-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18068, current rewards: -22.10106, mean: -0.04805
[32m[0907 03-08-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18141, current rewards: -23.58497, mean: -0.04625
[32m[0907 03-09-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18207, current rewards: -27.23382, mean: -0.04863
[32m[0907 03-09-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18258, current rewards: -43.39072, mean: -0.07113
[32m[0907 03-09-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18297, current rewards: -43.42459, mean: -0.06579
[32m[0907 03-09-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18333, current rewards: -36.90707, mean: -0.05198
[32m[0907 03-09-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18364, current rewards: -30.42412, mean: -0.04003
[32m[0907 03-09-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18385, current rewards: -23.85259, mean: -0.02945
[32m[0907 03-10-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18383, current rewards: -17.34343, mean: -0.02017
[32m[0907 03-10-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18382, current rewards: -10.40557, mean: -0.01143
[32m[0907 03-10-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18380, current rewards: -4.04924, mean: -0.00422
[32m[0907 03-10-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18375, current rewards: 2.30488, mean: 0.00228
[32m[0907 03-10-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18373, current rewards: 8.64841, mean: 0.00816
[32m[0907 03-10-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18368, current rewards: 14.98439, mean: 0.01350
[32m[0907 03-10-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18366, current rewards: 21.33221, mean: 0.01839
[32m[0907 03-11-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18357, current rewards: 27.68968, mean: 0.02288
[32m[0907 03-11-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18332, current rewards: 34.03603, mean: 0.02701
[32m[0907 03-11-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18312, current rewards: 43.08104, mean: 0.03289
[32m[0907 03-11-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18293, current rewards: 29.01347, mean: 0.02133
[32m[0907 03-11-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18273, current rewards: 37.55140, mean: 0.02663
[32m[0907 03-11-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18253, current rewards: 46.08932, mean: 0.03157
[32m[0907 03-11-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18235, current rewards: 33.55359, mean: 0.02222
[32m[0907 03-12-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18219, current rewards: -16.44641, mean: -0.01054
[32m[0907 03-12-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18203, current rewards: -62.12930, mean: -0.03859
[32m[0907 03-12-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18189, current rewards: -81.41706, mean: -0.04905
[32m[0907 03-12-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18177, current rewards: -96.85855, mean: -0.05664
[32m[0907 03-12-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18165, current rewards: -110.51338, mean: -0.06279
[32m[0907 03-12-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18153, current rewards: -134.79565, mean: -0.07447
[32m[0907 03-13-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18147, current rewards: -133.59516, mean: -0.07183
[32m[0907 03-13-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18151, current rewards: -126.65388, mean: -0.06631
[32m[0907 03-13-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18155, current rewards: -119.46201, mean: -0.06095
[32m[0907 03-13-28 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18158, current rewards: -120.34879, mean: -0.05988
[32m[0907 03-13-37 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18162, current rewards: -136.24966, mean: -0.06614
[32m[0907 03-13-46 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18165, current rewards: -178.87601, mean: -0.08478
[32m[0907 03-13-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18205, current rewards: -206.81445, mean: -0.09575
[32m[0907 03-14-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18207, current rewards: -226.61704, mean: -0.10254
[32m[0907 03-14-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18213, current rewards: -220.75507, mean: -0.09768
[32m[0907 03-14-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18227, current rewards: -214.86093, mean: -0.09301
[32m[0907 03-14-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18240, current rewards: -220.41469, mean: -0.09340
[32m[0907 03-14-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18252, current rewards: -240.57429, mean: -0.09982
[32m[0907 03-14-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18263, current rewards: -264.34812, mean: -0.10746
[32m[0907 03-15-00 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0907 03-15-00 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-15-00 @MBExp.py:227][0m Rewards obtained: [-288.09394347303515], Lows: [35], Highs: [447], Total time: 40698.169730999994
[32m[0907 03-18-06 @MBExp.py:144][0m ####################################################################
[32m[0907 03-18-06 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 03-18-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19899, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-18-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18046, current rewards: -88.00000, mean: -1.46667
[32m[0907 03-18-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18008, current rewards: -183.88795, mean: -1.67171
[32m[0907 03-18-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17908, current rewards: -272.78349, mean: -1.70490
[32m[0907 03-18-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17989, current rewards: -344.98528, mean: -1.64279
[32m[0907 03-18-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18088, current rewards: -434.21306, mean: -1.67005
[32m[0907 03-19-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18165, current rewards: -530.21306, mean: -1.71036
[32m[0907 03-19-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18289, current rewards: -600.91337, mean: -1.66920
[32m[0907 03-19-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18293, current rewards: -689.71661, mean: -1.68224
[32m[0907 03-19-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18349, current rewards: -761.47365, mean: -1.65538
[32m[0907 03-19-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18395, current rewards: -861.47365, mean: -1.68916
[32m[0907 03-19-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18431, current rewards: -961.47365, mean: -1.71692
[32m[0907 03-19-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18453, current rewards: -1061.47365, mean: -1.74012
[32m[0907 03-20-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18479, current rewards: -1161.47365, mean: -1.75981
[32m[0907 03-20-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18519, current rewards: -1257.28040, mean: -1.77082
[32m[0907 03-20-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18578, current rewards: -1331.97301, mean: -1.75260
[32m[0907 03-20-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18576, current rewards: -1424.90892, mean: -1.75915
[32m[0907 03-20-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18683, current rewards: -1489.18925, mean: -1.73162
[32m[0907 03-20-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18675, current rewards: -1582.93840, mean: -1.73949
[32m[0907 03-21-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18657, current rewards: -1644.84446, mean: -1.71338
[32m[0907 03-21-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18637, current rewards: -1694.84446, mean: -1.67806
[32m[0907 03-21-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18620, current rewards: -1744.84446, mean: -1.64608
[32m[0907 03-21-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18605, current rewards: -1794.84446, mean: -1.61698
[32m[0907 03-21-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18591, current rewards: -1844.84446, mean: -1.59038
[32m[0907 03-21-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18556, current rewards: -1894.84446, mean: -1.56599
[32m[0907 03-22-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18521, current rewards: -1944.84446, mean: -1.54353
[32m[0907 03-22-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18492, current rewards: -1994.84446, mean: -1.52278
[32m[0907 03-22-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18463, current rewards: -2044.84446, mean: -1.50356
[32m[0907 03-22-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18437, current rewards: -2094.84446, mean: -1.48571
[32m[0907 03-22-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18413, current rewards: -2144.84446, mean: -1.46907
[32m[0907 03-22-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18390, current rewards: -2194.84446, mean: -1.45354
[32m[0907 03-22-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18370, current rewards: -2244.84446, mean: -1.43900
[32m[0907 03-23-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18350, current rewards: -2294.84446, mean: -1.42537
[32m[0907 03-23-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18330, current rewards: -2344.84446, mean: -1.41256
[32m[0907 03-23-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18313, current rewards: -2394.84446, mean: -1.40049
[32m[0907 03-23-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18296, current rewards: -2444.84446, mean: -1.38912
[32m[0907 03-23-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18279, current rewards: -2494.84446, mean: -1.37837
[32m[0907 03-23-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18280, current rewards: -2540.19852, mean: -1.36570
[32m[0907 03-23-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18279, current rewards: -2532.12423, mean: -1.32572
[32m[0907 03-24-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18280, current rewards: -2524.04994, mean: -1.28778
[32m[0907 03-24-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18280, current rewards: -2515.97566, mean: -1.25173
[32m[0907 03-24-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18282, current rewards: -2507.90137, mean: -1.21743
[32m[0907 03-24-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18284, current rewards: -2514.46116, mean: -1.19169
[32m[0907 03-24-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18284, current rewards: -2564.46116, mean: -1.18725
[32m[0907 03-24-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18286, current rewards: -2614.46116, mean: -1.18301
[32m[0907 03-25-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18296, current rewards: -2664.46116, mean: -1.17897
[32m[0907 03-25-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18310, current rewards: -2714.46116, mean: -1.17509
[32m[0907 03-25-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18321, current rewards: -2764.46116, mean: -1.17138
[32m[0907 03-25-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18331, current rewards: -2814.46116, mean: -1.16783
[32m[0907 03-25-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18340, current rewards: -2864.46116, mean: -1.16442
[32m[0907 03-25-45 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0907 03-25-45 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-25-45 @MBExp.py:227][0m Rewards obtained: [-2904.4611550948134], Lows: [716], Highs: [1514], Total time: 41157.696564
[32m[0907 03-28-54 @MBExp.py:144][0m ####################################################################
[32m[0907 03-28-54 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 03-28-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18835, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-29-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18095, current rewards: -98.32241, mean: -1.63871
[32m[0907 03-29-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17936, current rewards: -198.32241, mean: -1.80293
[32m[0907 03-29-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17879, current rewards: -298.32241, mean: -1.86452
[32m[0907 03-29-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17862, current rewards: -398.32241, mean: -1.89677
[32m[0907 03-29-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17838, current rewards: -498.32241, mean: -1.91662
[32m[0907 03-29-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17907, current rewards: -598.32241, mean: -1.93007
[32m[0907 03-29-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17965, current rewards: -698.32241, mean: -1.93978
[32m[0907 03-30-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18012, current rewards: -798.32241, mean: -1.94713
[32m[0907 03-30-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18043, current rewards: -898.32241, mean: -1.95287
[32m[0907 03-30-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18070, current rewards: -998.32241, mean: -1.95749
[32m[0907 03-30-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18133, current rewards: -1098.32241, mean: -1.96129
[32m[0907 03-30-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18201, current rewards: -1198.32241, mean: -1.96446
[32m[0907 03-30-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18242, current rewards: -1298.32241, mean: -1.96716
[32m[0907 03-31-04 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18286, current rewards: -1398.32241, mean: -1.96947
[32m[0907 03-31-13 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18297, current rewards: -1498.32241, mean: -1.97148
[32m[0907 03-31-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18365, current rewards: -1593.91364, mean: -1.96779
[32m[0907 03-31-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18486, current rewards: -1681.15018, mean: -1.95483
[32m[0907 03-31-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18485, current rewards: -1778.98602, mean: -1.95493
[32m[0907 03-31-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18527, current rewards: -1874.61147, mean: -1.95272
[32m[0907 03-32-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18515, current rewards: -1923.21435, mean: -1.90417
[32m[0907 03-32-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18505, current rewards: -1973.21435, mean: -1.86152
[32m[0907 03-32-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18495, current rewards: -2023.21435, mean: -1.82272
[32m[0907 03-32-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18475, current rewards: -2073.21435, mean: -1.78725
[32m[0907 03-32-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18443, current rewards: -2123.21435, mean: -1.75472
[32m[0907 03-32-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18414, current rewards: -2173.21435, mean: -1.72477
[32m[0907 03-32-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18387, current rewards: -2223.21435, mean: -1.69711
[32m[0907 03-33-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18362, current rewards: -2273.21435, mean: -1.67148
[32m[0907 03-33-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18337, current rewards: -2323.21435, mean: -1.64767
[32m[0907 03-33-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18314, current rewards: -2373.21435, mean: -1.62549
[32m[0907 03-33-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18294, current rewards: -2423.21435, mean: -1.60478
[32m[0907 03-33-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18275, current rewards: -2473.21435, mean: -1.58539
[32m[0907 03-33-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18256, current rewards: -2523.21435, mean: -1.56721
[32m[0907 03-33-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18240, current rewards: -2573.21435, mean: -1.55013
[32m[0907 03-34-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18223, current rewards: -2623.21435, mean: -1.53404
[32m[0907 03-34-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18209, current rewards: -2673.21435, mean: -1.51887
[32m[0907 03-34-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18203, current rewards: -2723.21435, mean: -1.50454
[32m[0907 03-34-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18206, current rewards: -2773.21435, mean: -1.49098
[32m[0907 03-34-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18207, current rewards: -2823.21435, mean: -1.47812
[32m[0907 03-34-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18210, current rewards: -2873.21435, mean: -1.46593
[32m[0907 03-35-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18211, current rewards: -2923.21435, mean: -1.45434
[32m[0907 03-35-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18214, current rewards: -2973.21435, mean: -1.44331
[32m[0907 03-35-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18217, current rewards: -3023.21435, mean: -1.43280
[32m[0907 03-35-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18219, current rewards: -3073.21435, mean: -1.42278
[32m[0907 03-35-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18221, current rewards: -3123.21435, mean: -1.41322
[32m[0907 03-35-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18237, current rewards: -3173.21435, mean: -1.40408
[32m[0907 03-35-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18249, current rewards: -3223.21435, mean: -1.39533
[32m[0907 03-36-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18263, current rewards: -3273.21435, mean: -1.38696
[32m[0907 03-36-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18274, current rewards: -3323.21435, mean: -1.37893
[32m[0907 03-36-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18283, current rewards: -3373.21435, mean: -1.37123
[32m[0907 03-36-32 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 03-36-32 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-36-32 @MBExp.py:227][0m Rewards obtained: [-3413.214352175506], Lows: [934], Highs: [1548], Total time: 41615.812301
[32m[0907 03-39-42 @MBExp.py:144][0m ####################################################################
[32m[0907 03-39-42 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 03-39-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19333, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-39-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18375, current rewards: -36.70835, mean: -0.61181
[32m[0907 03-40-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18955, current rewards: -67.49742, mean: -0.61361
[32m[0907 03-40-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18832, current rewards: -102.47244, mean: -0.64045
[32m[0907 03-40-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18799, current rewards: -138.12839, mean: -0.65775
[32m[0907 03-40-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18887, current rewards: -168.78713, mean: -0.64918
[32m[0907 03-40-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18813, current rewards: -203.88213, mean: -0.65768
[32m[0907 03-40-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18751, current rewards: -245.70277, mean: -0.68251
[32m[0907 03-40-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18697, current rewards: -249.59435, mean: -0.60877
[32m[0907 03-41-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18656, current rewards: -244.71442, mean: -0.53199
[32m[0907 03-41-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18637, current rewards: -238.77593, mean: -0.46819
[32m[0907 03-41-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18727, current rewards: -259.88386, mean: -0.46408
[32m[0907 03-41-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18799, current rewards: -275.41058, mean: -0.45149
[32m[0907 03-41-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18848, current rewards: -303.02519, mean: -0.45913
[32m[0907 03-41-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18945, current rewards: -330.94948, mean: -0.46613
[32m[0907 03-42-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18902, current rewards: -325.85646, mean: -0.42876
[32m[0907 03-42-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18866, current rewards: -321.22745, mean: -0.39658
[32m[0907 03-42-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18834, current rewards: -316.60696, mean: -0.36815
[32m[0907 03-42-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18805, current rewards: -311.98076, mean: -0.34284
[32m[0907 03-42-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18781, current rewards: -328.01129, mean: -0.34168
[32m[0907 03-42-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18757, current rewards: -321.86179, mean: -0.31868
[32m[0907 03-43-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18739, current rewards: -315.85717, mean: -0.29798
[32m[0907 03-43-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18721, current rewards: -309.83195, mean: -0.27913
[32m[0907 03-43-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18703, current rewards: -303.81206, mean: -0.26191
[32m[0907 03-43-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18677, current rewards: -297.78678, mean: -0.24610
[32m[0907 03-43-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18640, current rewards: -289.19215, mean: -0.22952
[32m[0907 03-43-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18607, current rewards: -288.45568, mean: -0.22020
[32m[0907 03-43-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18575, current rewards: -338.45568, mean: -0.24886
[32m[0907 03-44-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18545, current rewards: -388.45568, mean: -0.27550
[32m[0907 03-44-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18520, current rewards: -434.81202, mean: -0.29782
[32m[0907 03-44-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18494, current rewards: -478.48200, mean: -0.31688
[32m[0907 03-44-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18538, current rewards: -499.15720, mean: -0.31997
[32m[0907 03-44-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18576, current rewards: -526.96707, mean: -0.32731
[32m[0907 03-44-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18599, current rewards: -550.73199, mean: -0.33177
[32m[0907 03-45-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18588, current rewards: -571.84757, mean: -0.33441
[32m[0907 03-45-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18576, current rewards: -569.66754, mean: -0.32367
[32m[0907 03-45-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18585, current rewards: -578.42044, mean: -0.31957
[32m[0907 03-45-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18579, current rewards: -574.21155, mean: -0.30872
[32m[0907 03-45-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18572, current rewards: -570.04811, mean: -0.29845
[32m[0907 03-45-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18567, current rewards: -565.88376, mean: -0.28872
[32m[0907 03-45-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18570, current rewards: -584.96797, mean: -0.29103
[32m[0907 03-46-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18610, current rewards: -618.99912, mean: -0.30049
[32m[0907 03-46-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18617, current rewards: -657.96359, mean: -0.31183
[32m[0907 03-46-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18623, current rewards: -700.60422, mean: -0.32435
[32m[0907 03-46-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18630, current rewards: -745.33391, mean: -0.33726
[32m[0907 03-46-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18637, current rewards: -789.00988, mean: -0.34912
[32m[0907 03-46-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18656, current rewards: -834.80928, mean: -0.36139
[32m[0907 03-47-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18679, current rewards: -880.57647, mean: -0.37313
[32m[0907 03-47-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18706, current rewards: -925.99658, mean: -0.38423
[32m[0907 03-47-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18723, current rewards: -974.94849, mean: -0.39632
[32m[0907 03-47-31 @Agent.py:117][0m Average action selection time: 0.1874
[32m[0907 03-47-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-47-32 @MBExp.py:227][0m Rewards obtained: [-1014.9484859840197], Lows: [125], Highs: [926], Total time: 42085.152690999996
[32m[0907 03-50-44 @MBExp.py:144][0m ####################################################################
[32m[0907 03-50-44 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 03-50-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17373, current rewards: 1.18103, mean: 0.11810
[32m[0907 03-50-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17691, current rewards: -98.81897, mean: -1.64698
[32m[0907 03-51-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17697, current rewards: -198.81897, mean: -1.80745
[32m[0907 03-51-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17707, current rewards: -298.81897, mean: -1.86762
[32m[0907 03-51-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17712, current rewards: -398.81897, mean: -1.89914
[32m[0907 03-51-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17715, current rewards: -498.81897, mean: -1.91853
[32m[0907 03-51-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17813, current rewards: -598.81897, mean: -1.93167
[32m[0907 03-51-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17879, current rewards: -698.81897, mean: -1.94116
[32m[0907 03-51-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17932, current rewards: -798.81897, mean: -1.94834
[32m[0907 03-52-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18004, current rewards: -898.81897, mean: -1.95395
[32m[0907 03-52-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18089, current rewards: -998.81897, mean: -1.95847
[32m[0907 03-52-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18162, current rewards: -1098.81897, mean: -1.96218
[32m[0907 03-52-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18198, current rewards: -1198.81897, mean: -1.96528
[32m[0907 03-52-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18207, current rewards: -1298.81897, mean: -1.96791
[32m[0907 03-52-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18211, current rewards: -1398.81897, mean: -1.97017
[32m[0907 03-53-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18220, current rewards: -1498.81897, mean: -1.97213
[32m[0907 03-53-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18224, current rewards: -1598.81897, mean: -1.97385
[32m[0907 03-53-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18230, current rewards: -1698.81897, mean: -1.97537
[32m[0907 03-53-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18234, current rewards: -1798.81897, mean: -1.97672
[32m[0907 03-53-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18237, current rewards: -1898.81897, mean: -1.97794
[32m[0907 03-53-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18243, current rewards: -1998.81897, mean: -1.97903
[32m[0907 03-53-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18244, current rewards: -2098.81897, mean: -1.98002
[32m[0907 03-54-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18248, current rewards: -2198.81897, mean: -1.98092
[32m[0907 03-54-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18236, current rewards: -2298.81897, mean: -1.98174
[32m[0907 03-54-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18217, current rewards: -2398.81897, mean: -1.98250
[32m[0907 03-54-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18199, current rewards: -2498.81897, mean: -1.98319
[32m[0907 03-54-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18182, current rewards: -2598.81897, mean: -1.98383
[32m[0907 03-54-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18165, current rewards: -2698.81897, mean: -1.98443
[32m[0907 03-55-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18149, current rewards: -2798.81897, mean: -1.98498
[32m[0907 03-55-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18136, current rewards: -2898.81897, mean: -1.98549
[32m[0907 03-55-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18121, current rewards: -2998.81897, mean: -1.98597
[32m[0907 03-55-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18110, current rewards: -3098.81897, mean: -1.98642
[32m[0907 03-55-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18098, current rewards: -3198.81897, mean: -1.98684
[32m[0907 03-55-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18087, current rewards: -3298.81897, mean: -1.98724
[32m[0907 03-55-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18082, current rewards: -3398.81897, mean: -1.98761
[32m[0907 03-56-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18090, current rewards: -3498.81897, mean: -1.98797
[32m[0907 03-56-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18095, current rewards: -3598.81897, mean: -1.98830
[32m[0907 03-56-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18100, current rewards: -3698.81897, mean: -1.98861
[32m[0907 03-56-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18105, current rewards: -3798.81897, mean: -1.98891
[32m[0907 03-56-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18111, current rewards: -3898.81897, mean: -1.98919
[32m[0907 03-56-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18115, current rewards: -3998.81897, mean: -1.98946
[32m[0907 03-56-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18121, current rewards: -4098.81897, mean: -1.98972
[32m[0907 03-57-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18126, current rewards: -4198.81897, mean: -1.98996
[32m[0907 03-57-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18131, current rewards: -4298.81897, mean: -1.99019
[32m[0907 03-57-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18134, current rewards: -4398.81897, mean: -1.99042
[32m[0907 03-57-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18148, current rewards: -4498.81897, mean: -1.99063
[32m[0907 03-57-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18165, current rewards: -4598.81897, mean: -1.99083
[32m[0907 03-57-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18181, current rewards: -4698.81897, mean: -1.99102
[32m[0907 03-58-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18194, current rewards: -4798.81897, mean: -1.99121
[32m[0907 03-58-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18208, current rewards: -4898.81897, mean: -1.99139
[32m[0907 03-58-20 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0907 03-58-20 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-58-21 @MBExp.py:227][0m Rewards obtained: [-4978.818974237204], Lows: [2490], Highs: [0], Total time: 42541.435423999996
[32m[0907 04-01-35 @MBExp.py:144][0m ####################################################################
[32m[0907 04-01-35 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 04-01-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.26968, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-01-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19238, current rewards: -60.00000, mean: -1.00000
[32m[0907 04-01-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18524, current rewards: -110.00000, mean: -1.00000
[32m[0907 04-02-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18263, current rewards: -160.00000, mean: -1.00000
[32m[0907 04-02-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18133, current rewards: -210.00000, mean: -1.00000
[32m[0907 04-02-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18051, current rewards: -260.00000, mean: -1.00000
[32m[0907 04-02-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18057, current rewards: -310.00000, mean: -1.00000
[32m[0907 04-02-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18087, current rewards: -360.00000, mean: -1.00000
[32m[0907 04-02-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18114, current rewards: -410.00000, mean: -1.00000
[32m[0907 04-02-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18134, current rewards: -460.00000, mean: -1.00000
[32m[0907 04-03-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18148, current rewards: -510.00000, mean: -1.00000
[32m[0907 04-03-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18209, current rewards: -560.00000, mean: -1.00000
[32m[0907 04-03-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18263, current rewards: -610.00000, mean: -1.00000
[32m[0907 04-03-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18324, current rewards: -660.00000, mean: -1.00000
[32m[0907 04-03-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18361, current rewards: -710.00000, mean: -1.00000
[32m[0907 04-03-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18384, current rewards: -760.00000, mean: -1.00000
[32m[0907 04-04-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18416, current rewards: -810.00000, mean: -1.00000
[32m[0907 04-04-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18444, current rewards: -817.97795, mean: -0.95114
[32m[0907 04-04-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18464, current rewards: -815.45038, mean: -0.89610
[32m[0907 04-04-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18463, current rewards: -812.92281, mean: -0.84679
[32m[0907 04-04-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18453, current rewards: -810.39525, mean: -0.80237
[32m[0907 04-04-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18448, current rewards: -807.86768, mean: -0.76214
[32m[0907 04-05-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18440, current rewards: -814.79508, mean: -0.73405
[32m[0907 04-05-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18407, current rewards: -864.79508, mean: -0.74551
[32m[0907 04-05-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18381, current rewards: -914.79508, mean: -0.75603
[32m[0907 04-05-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18356, current rewards: -964.79508, mean: -0.76571
[32m[0907 04-05-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18333, current rewards: -1014.79508, mean: -0.77465
[32m[0907 04-05-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18313, current rewards: -1064.79508, mean: -0.78294
[32m[0907 04-05-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18292, current rewards: -1114.79508, mean: -0.79063
[32m[0907 04-06-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18273, current rewards: -1164.79508, mean: -0.79780
[32m[0907 04-06-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18256, current rewards: -1214.79508, mean: -0.80450
[32m[0907 04-06-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18268, current rewards: -1267.79508, mean: -0.81269
[32m[0907 04-06-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18292, current rewards: -1330.22641, mean: -0.82623
[32m[0907 04-06-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18275, current rewards: -1380.22641, mean: -0.83146
[32m[0907 04-06-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18259, current rewards: -1430.22641, mean: -0.83639
[32m[0907 04-06-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18245, current rewards: -1480.22641, mean: -0.84104
[32m[0907 04-07-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18231, current rewards: -1530.22641, mean: -0.84543
[32m[0907 04-07-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18220, current rewards: -1580.22641, mean: -0.84958
[32m[0907 04-07-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18208, current rewards: -1630.22641, mean: -0.85352
[32m[0907 04-07-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18196, current rewards: -1680.22641, mean: -0.85726
[32m[0907 04-07-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18190, current rewards: -1746.80717, mean: -0.86906
[32m[0907 04-07-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18188, current rewards: -1796.80717, mean: -0.87224
[32m[0907 04-08-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18191, current rewards: -1846.80717, mean: -0.87526
[32m[0907 04-08-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18194, current rewards: -1896.80717, mean: -0.87815
[32m[0907 04-08-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18196, current rewards: -1946.80717, mean: -0.88091
[32m[0907 04-08-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18212, current rewards: -1996.80717, mean: -0.88354
[32m[0907 04-08-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18228, current rewards: -2046.80717, mean: -0.88606
[32m[0907 04-08-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18241, current rewards: -2096.80717, mean: -0.88848
[32m[0907 04-08-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18253, current rewards: -2146.80717, mean: -0.89079
[32m[0907 04-09-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18264, current rewards: -2196.80717, mean: -0.89301
[32m[0907 04-09-13 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0907 04-09-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-09-13 @MBExp.py:227][0m Rewards obtained: [-2236.8071702717502], Lows: [41], Highs: [2170], Total time: 42999.074703
[32m[0907 04-12-31 @MBExp.py:144][0m ####################################################################
[32m[0907 04-12-31 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 04-12-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18855, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-12-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17907, current rewards: -88.77621, mean: -1.47960
[32m[0907 04-12-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17812, current rewards: -175.49737, mean: -1.59543
[32m[0907 04-12-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17774, current rewards: -252.61759, mean: -1.57886
[32m[0907 04-13-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17753, current rewards: -332.20098, mean: -1.58191
[32m[0907 04-13-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17744, current rewards: -409.70753, mean: -1.57580
[32m[0907 04-13-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17737, current rewards: -496.09931, mean: -1.60032
[32m[0907 04-13-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17734, current rewards: -576.34882, mean: -1.60097
[32m[0907 04-13-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17787, current rewards: -648.46159, mean: -1.58161
[32m[0907 04-13-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17848, current rewards: -722.33572, mean: -1.57030
[32m[0907 04-14-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17905, current rewards: -801.68708, mean: -1.57194
[32m[0907 04-14-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17990, current rewards: -883.50596, mean: -1.57769
[32m[0907 04-14-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18065, current rewards: -957.11887, mean: -1.56905
[32m[0907 04-14-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18117, current rewards: -1033.09573, mean: -1.56530
[32m[0907 04-14-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18167, current rewards: -1104.75922, mean: -1.55600
[32m[0907 04-14-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18229, current rewards: -1202.64592, mean: -1.58243
[32m[0907 04-14-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18321, current rewards: -1302.64592, mean: -1.60820
[32m[0907 04-15-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18393, current rewards: -1402.64592, mean: -1.63098
[32m[0907 04-15-19 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18458, current rewards: -1497.73161, mean: -1.64586
[32m[0907 04-15-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18512, current rewards: -1590.39026, mean: -1.65666
[32m[0907 04-15-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18572, current rewards: -1687.83734, mean: -1.67113
[32m[0907 04-15-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18620, current rewards: -1787.83734, mean: -1.68664
[32m[0907 04-15-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18604, current rewards: -1887.83734, mean: -1.70075
[32m[0907 04-16-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18578, current rewards: -1987.83734, mean: -1.71365
[32m[0907 04-16-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18566, current rewards: -2087.83734, mean: -1.72549
[32m[0907 04-16-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18540, current rewards: -2187.83734, mean: -1.73638
[32m[0907 04-16-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18580, current rewards: -2287.83734, mean: -1.74644
[32m[0907 04-16-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18570, current rewards: -2387.83734, mean: -1.75576
[32m[0907 04-16-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18553, current rewards: -2487.83734, mean: -1.76442
[32m[0907 04-17-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18525, current rewards: -2585.28479, mean: -1.77074
[32m[0907 04-17-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18505, current rewards: -2680.36788, mean: -1.77508
[32m[0907 04-17-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18491, current rewards: -2780.36788, mean: -1.78229
[32m[0907 04-17-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18495, current rewards: -2877.50573, mean: -1.78727
[32m[0907 04-17-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18494, current rewards: -2974.96660, mean: -1.79215
[32m[0907 04-17-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18495, current rewards: -3072.83872, mean: -1.79698
[32m[0907 04-17-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18480, current rewards: -3170.68957, mean: -1.80153
[32m[0907 04-18-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18458, current rewards: -3268.45540, mean: -1.80578
[32m[0907 04-18-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18442, current rewards: -3368.45540, mean: -1.81100
[32m[0907 04-18-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18437, current rewards: -3466.02032, mean: -1.81467
[32m[0907 04-18-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18426, current rewards: -3561.69370, mean: -1.81719
[32m[0907 04-18-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18414, current rewards: -3611.41227, mean: -1.79672
[32m[0907 04-18-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18399, current rewards: -3699.06964, mean: -1.79566
[32m[0907 04-18-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18383, current rewards: -3785.44509, mean: -1.79405
[32m[0907 04-19-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18369, current rewards: -3880.37138, mean: -1.79647
[32m[0907 04-19-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18378, current rewards: -3968.95235, mean: -1.79591
[32m[0907 04-19-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18390, current rewards: -4054.25610, mean: -1.79392
[32m[0907 04-19-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18409, current rewards: -4139.72577, mean: -1.79209
[32m[0907 04-19-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18430, current rewards: -4226.33646, mean: -1.79082
[32m[0907 04-19-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18439, current rewards: -4306.19183, mean: -1.78680
[32m[0907 04-20-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18480, current rewards: -4373.51621, mean: -1.77785
[32m[0907 04-20-13 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0907 04-20-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-20-14 @MBExp.py:227][0m Rewards obtained: [-4440.875648680127], Lows: [2234], Highs: [30], Total time: 43462.044171
[32m[0907 04-23-33 @MBExp.py:144][0m ####################################################################
[32m[0907 04-23-33 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 04-23-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20468, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-23-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18226, current rewards: -101.30790, mean: -1.68846
[32m[0907 04-23-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18011, current rewards: -201.30790, mean: -1.83007
[32m[0907 04-24-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17921, current rewards: -301.30790, mean: -1.88317
[32m[0907 04-24-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17880, current rewards: -401.30790, mean: -1.91099
[32m[0907 04-24-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17848, current rewards: -501.30790, mean: -1.92811
[32m[0907 04-24-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17829, current rewards: -601.30790, mean: -1.93970
[32m[0907 04-24-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17817, current rewards: -701.30790, mean: -1.94808
[32m[0907 04-24-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17878, current rewards: -801.30790, mean: -1.95441
[32m[0907 04-24-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17932, current rewards: -901.30790, mean: -1.95936
[32m[0907 04-25-05 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18020, current rewards: -1001.30790, mean: -1.96335
[32m[0907 04-25-14 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18096, current rewards: -1101.30790, mean: -1.96662
[32m[0907 04-25-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18152, current rewards: -1201.30790, mean: -1.96936
[32m[0907 04-25-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18197, current rewards: -1301.30790, mean: -1.97168
[32m[0907 04-25-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18239, current rewards: -1401.30790, mean: -1.97367
[32m[0907 04-25-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18274, current rewards: -1501.30790, mean: -1.97541
[32m[0907 04-26-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18306, current rewards: -1601.30790, mean: -1.97692
[32m[0907 04-26-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18336, current rewards: -1701.30790, mean: -1.97826
[32m[0907 04-26-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18359, current rewards: -1801.30790, mean: -1.97946
[32m[0907 04-26-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18379, current rewards: -1901.30790, mean: -1.98053
[32m[0907 04-26-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18401, current rewards: -2001.30790, mean: -1.98149
[32m[0907 04-26-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18421, current rewards: -2101.30790, mean: -1.98237
[32m[0907 04-26-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18407, current rewards: -2201.30790, mean: -1.98316
[32m[0907 04-27-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18377, current rewards: -2301.30790, mean: -1.98389
[32m[0907 04-27-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18352, current rewards: -2401.30790, mean: -1.98455
[32m[0907 04-27-24 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18326, current rewards: -2501.30790, mean: -1.98516
[32m[0907 04-27-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18302, current rewards: -2601.30790, mean: -1.98573
[32m[0907 04-27-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18281, current rewards: -2701.30790, mean: -1.98626
[32m[0907 04-27-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18261, current rewards: -2801.30790, mean: -1.98674
[32m[0907 04-27-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18242, current rewards: -2901.30790, mean: -1.98720
[32m[0907 04-28-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18225, current rewards: -3001.30790, mean: -1.98762
[32m[0907 04-28-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18210, current rewards: -3101.30790, mean: -1.98802
[32m[0907 04-28-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18196, current rewards: -3201.30790, mean: -1.98839
[32m[0907 04-28-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18184, current rewards: -3301.30790, mean: -1.98874
[32m[0907 04-28-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18171, current rewards: -3401.30790, mean: -1.98907
[32m[0907 04-28-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18157, current rewards: -3501.30790, mean: -1.98938
[32m[0907 04-29-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18146, current rewards: -3601.30790, mean: -1.98967
[32m[0907 04-29-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18135, current rewards: -3701.30790, mean: -1.98995
[32m[0907 04-29-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18125, current rewards: -3801.30790, mean: -1.99021
[32m[0907 04-29-28 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18116, current rewards: -3901.30790, mean: -1.99046
[32m[0907 04-29-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18106, current rewards: -4001.30790, mean: -1.99070
[32m[0907 04-29-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18098, current rewards: -4101.30790, mean: -1.99093
[32m[0907 04-29-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18089, current rewards: -4201.30790, mean: -1.99114
[32m[0907 04-30-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18082, current rewards: -4301.30790, mean: -1.99135
[32m[0907 04-30-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18077, current rewards: -4401.30790, mean: -1.99154
[32m[0907 04-30-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18091, current rewards: -4501.30790, mean: -1.99173
[32m[0907 04-30-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18109, current rewards: -4601.30790, mean: -1.99191
[32m[0907 04-30-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18126, current rewards: -4701.30790, mean: -1.99208
[32m[0907 04-30-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18141, current rewards: -4801.30790, mean: -1.99224
[32m[0907 04-31-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18155, current rewards: -4901.30790, mean: -1.99240
[32m[0907 04-31-08 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0907 04-31-08 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-31-08 @MBExp.py:227][0m Rewards obtained: [-4981.307897657076], Lows: [2485], Highs: [12], Total time: 43917.088042
[32m[0907 04-34-29 @MBExp.py:144][0m ####################################################################
[32m[0907 04-34-29 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 04-34-32 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28418, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-34-41 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19920, current rewards: -75.07315, mean: -1.25122
[32m[0907 04-34-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19339, current rewards: -119.23672, mean: -1.08397
[32m[0907 04-35-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18878, current rewards: -156.50149, mean: -0.97813
[32m[0907 04-35-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19002, current rewards: -209.45844, mean: -0.99742
[32m[0907 04-35-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18887, current rewards: -275.20883, mean: -1.05850
[32m[0907 04-35-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18872, current rewards: -312.52248, mean: -1.00814
[32m[0907 04-35-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18938, current rewards: -373.63911, mean: -1.03789
[32m[0907 04-35-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18940, current rewards: -423.98095, mean: -1.03410
[32m[0907 04-35-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19115, current rewards: -490.89443, mean: -1.06716
[32m[0907 04-36-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19325, current rewards: -538.52204, mean: -1.05593
[32m[0907 04-36-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19444, current rewards: -610.55456, mean: -1.09028
[32m[0907 04-36-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19561, current rewards: -647.75271, mean: -1.06189
[32m[0907 04-36-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19605, current rewards: -717.50808, mean: -1.08713
[32m[0907 04-36-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19649, current rewards: -810.89355, mean: -1.14210
[32m[0907 04-36-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19716, current rewards: -862.92188, mean: -1.13542
[32m[0907 04-37-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19735, current rewards: -896.49010, mean: -1.10678
[32m[0907 04-37-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19868, current rewards: -957.86821, mean: -1.11380
[32m[0907 04-37-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19928, current rewards: -1048.73568, mean: -1.15246
[32m[0907 04-37-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19928, current rewards: -1088.98836, mean: -1.13436
[32m[0907 04-37-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19967, current rewards: -1173.92189, mean: -1.16230
[32m[0907 04-38-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19900, current rewards: -1262.93156, mean: -1.19144
[32m[0907 04-38-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19912, current rewards: -1347.84230, mean: -1.21427
[32m[0907 04-38-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19819, current rewards: -1436.23205, mean: -1.23813
[32m[0907 04-38-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19734, current rewards: -1522.42427, mean: -1.25820
[32m[0907 04-38-37 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19657, current rewards: -1622.42427, mean: -1.28764
[32m[0907 04-38-46 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19585, current rewards: -1722.42427, mean: -1.31483
[32m[0907 04-38-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19517, current rewards: -1822.42427, mean: -1.34002
[32m[0907 04-39-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19455, current rewards: -1922.42427, mean: -1.36342
[32m[0907 04-39-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19394, current rewards: -2022.42427, mean: -1.38522
[32m[0907 04-39-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19342, current rewards: -2122.42427, mean: -1.40558
[32m[0907 04-39-31 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19290, current rewards: -2222.42427, mean: -1.42463
[32m[0907 04-39-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19244, current rewards: -2322.42427, mean: -1.44250
[32m[0907 04-39-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19199, current rewards: -2422.42427, mean: -1.45929
[32m[0907 04-39-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19155, current rewards: -2522.42427, mean: -1.47510
[32m[0907 04-40-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19116, current rewards: -2622.42427, mean: -1.49001
[32m[0907 04-40-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19079, current rewards: -2722.42427, mean: -1.50410
[32m[0907 04-40-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.19042, current rewards: -2822.42427, mean: -1.51743
[32m[0907 04-40-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19006, current rewards: -2922.42427, mean: -1.53007
[32m[0907 04-40-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18973, current rewards: -3022.42427, mean: -1.54205
[32m[0907 04-40-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18944, current rewards: -3122.42427, mean: -1.55344
[32m[0907 04-41-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18915, current rewards: -3222.42427, mean: -1.56428
[32m[0907 04-41-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18892, current rewards: -3322.42427, mean: -1.57461
[32m[0907 04-41-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18887, current rewards: -3422.42427, mean: -1.58446
[32m[0907 04-41-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18888, current rewards: -3522.42427, mean: -1.59386
[32m[0907 04-41-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18888, current rewards: -3622.42427, mean: -1.60284
[32m[0907 04-41-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18888, current rewards: -3722.42427, mean: -1.61144
[32m[0907 04-41-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18887, current rewards: -3822.42427, mean: -1.61967
[32m[0907 04-42-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18887, current rewards: -3922.42427, mean: -1.62756
[32m[0907 04-42-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18886, current rewards: -4022.42427, mean: -1.63513
[32m[0907 04-42-22 @Agent.py:117][0m Average action selection time: 0.1888
[32m[0907 04-42-22 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-42-22 @MBExp.py:227][0m Rewards obtained: [-4102.42427419421], Lows: [1982], Highs: [191], Total time: 44390.035774
[32m[0907 04-45-45 @MBExp.py:144][0m ####################################################################
[32m[0907 04-45-45 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 04-45-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.23518, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-45-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20799, current rewards: -99.58079, mean: -1.65968
[32m[0907 04-46-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20439, current rewards: -199.58079, mean: -1.81437
[32m[0907 04-46-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20438, current rewards: -299.58079, mean: -1.87238
[32m[0907 04-46-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20383, current rewards: -399.58079, mean: -1.90277
[32m[0907 04-46-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19981, current rewards: -499.58079, mean: -1.92146
[32m[0907 04-46-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19721, current rewards: -599.58079, mean: -1.93413
[32m[0907 04-46-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19589, current rewards: -699.58079, mean: -1.94328
[32m[0907 04-47-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19501, current rewards: -799.58079, mean: -1.95020
[32m[0907 04-47-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19434, current rewards: -899.58079, mean: -1.95561
[32m[0907 04-47-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19380, current rewards: -999.58079, mean: -1.95996
[32m[0907 04-47-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19340, current rewards: -1099.58079, mean: -1.96354
[32m[0907 04-47-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19296, current rewards: -1199.58079, mean: -1.96653
[32m[0907 04-47-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19267, current rewards: -1299.58079, mean: -1.96906
[32m[0907 04-48-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19236, current rewards: -1379.01149, mean: -1.94227
[32m[0907 04-48-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19212, current rewards: -1479.01149, mean: -1.94607
[32m[0907 04-48-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19190, current rewards: -1579.01149, mean: -1.94940
[32m[0907 04-48-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19171, current rewards: -1679.01149, mean: -1.95234
[32m[0907 04-48-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19141, current rewards: -1779.01149, mean: -1.95496
[32m[0907 04-48-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19101, current rewards: -1879.01149, mean: -1.95730
[32m[0907 04-48-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19033, current rewards: -1979.01149, mean: -1.95942
[32m[0907 04-49-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18973, current rewards: -2079.01149, mean: -1.96133
[32m[0907 04-49-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18919, current rewards: -2179.01149, mean: -1.96307
[32m[0907 04-49-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18869, current rewards: -2279.01149, mean: -1.96467
[32m[0907 04-49-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18823, current rewards: -2379.01149, mean: -1.96613
[32m[0907 04-49-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18782, current rewards: -2479.01149, mean: -1.96747
[32m[0907 04-49-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18744, current rewards: -2579.01149, mean: -1.96871
[32m[0907 04-50-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18706, current rewards: -2679.01149, mean: -1.96986
[32m[0907 04-50-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18675, current rewards: -2779.01149, mean: -1.97093
[32m[0907 04-50-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18643, current rewards: -2879.01149, mean: -1.97193
[32m[0907 04-50-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18615, current rewards: -2979.01149, mean: -1.97286
[32m[0907 04-50-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18590, current rewards: -3079.01149, mean: -1.97373
[32m[0907 04-50-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18564, current rewards: -3179.01149, mean: -1.97454
[32m[0907 04-50-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18542, current rewards: -3279.01149, mean: -1.97531
[32m[0907 04-51-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18521, current rewards: -3379.01149, mean: -1.97603
[32m[0907 04-51-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18499, current rewards: -3479.01149, mean: -1.97671
[32m[0907 04-51-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18479, current rewards: -3579.01149, mean: -1.97735
[32m[0907 04-51-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18459, current rewards: -3679.01149, mean: -1.97796
[32m[0907 04-51-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18440, current rewards: -3779.01149, mean: -1.97854
[32m[0907 04-51-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18424, current rewards: -3879.01149, mean: -1.97909
[32m[0907 04-51-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18407, current rewards: -3979.01149, mean: -1.97961
[32m[0907 04-52-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18394, current rewards: -4079.01149, mean: -1.98010
[32m[0907 04-52-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18393, current rewards: -4179.01149, mean: -1.98057
[32m[0907 04-52-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18404, current rewards: -4279.01149, mean: -1.98102
[32m[0907 04-52-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18416, current rewards: -4379.01149, mean: -1.98145
[32m[0907 04-52-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18427, current rewards: -4479.01149, mean: -1.98186
[32m[0907 04-52-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18437, current rewards: -4579.01149, mean: -1.98226
[32m[0907 04-53-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18445, current rewards: -4679.01149, mean: -1.98263
[32m[0907 04-53-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18454, current rewards: -4779.01149, mean: -1.98299
[32m[0907 04-53-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18463, current rewards: -4879.01149, mean: -1.98334
[32m[0907 04-53-27 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0907 04-53-27 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-53-28 @MBExp.py:227][0m Rewards obtained: [-4959.011493355614], Lows: [2475], Highs: [10], Total time: 44852.567824000005
[32m[0907 04-56-53 @MBExp.py:144][0m ####################################################################
[32m[0907 04-56-53 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 04-56-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28217, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-57-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20619, current rewards: -64.13995, mean: -1.06900
[32m[0907 04-57-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19763, current rewards: -131.00905, mean: -1.19099
[32m[0907 04-57-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19303, current rewards: -161.75384, mean: -1.01096
[32m[0907 04-57-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18996, current rewards: -172.63156, mean: -0.82206
[32m[0907 04-57-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18899, current rewards: -227.29532, mean: -0.87421
[32m[0907 04-57-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18937, current rewards: -296.49584, mean: -0.95644
[32m[0907 04-58-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19144, current rewards: -341.63880, mean: -0.94900
[32m[0907 04-58-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19134, current rewards: -407.29134, mean: -0.99339
[32m[0907 04-58-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19187, current rewards: -489.90217, mean: -1.06500
[32m[0907 04-58-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19236, current rewards: -572.33029, mean: -1.12222
[32m[0907 04-58-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19260, current rewards: -665.74034, mean: -1.18882
[32m[0907 04-58-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19229, current rewards: -765.74034, mean: -1.25531
[32m[0907 04-59-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19198, current rewards: -865.74034, mean: -1.31173
[32m[0907 04-59-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19174, current rewards: -965.74034, mean: -1.36020
[32m[0907 04-59-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19152, current rewards: -1065.74034, mean: -1.40229
[32m[0907 04-59-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19133, current rewards: -1165.74034, mean: -1.43919
[32m[0907 04-59-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19111, current rewards: -1265.74034, mean: -1.47179
[32m[0907 04-59-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19068, current rewards: -1365.74034, mean: -1.50081
[32m[0907 04-59-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19009, current rewards: -1465.74034, mean: -1.52681
[32m[0907 05-00-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18950, current rewards: -1565.74034, mean: -1.55024
[32m[0907 05-00-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18894, current rewards: -1665.74034, mean: -1.57145
[32m[0907 05-00-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18845, current rewards: -1765.74034, mean: -1.59076
[32m[0907 05-00-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18799, current rewards: -1865.74034, mean: -1.60840
[32m[0907 05-00-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18756, current rewards: -1965.74034, mean: -1.62458
[32m[0907 05-00-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18719, current rewards: -2065.74034, mean: -1.63948
[32m[0907 05-00-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18685, current rewards: -2165.74034, mean: -1.65324
[32m[0907 05-01-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18650, current rewards: -2265.74034, mean: -1.66599
[32m[0907 05-01-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18621, current rewards: -2365.74034, mean: -1.67783
[32m[0907 05-01-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18591, current rewards: -2465.74034, mean: -1.68886
[32m[0907 05-01-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18565, current rewards: -2565.74034, mean: -1.69917
[32m[0907 05-01-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18539, current rewards: -2665.74034, mean: -1.70881
[32m[0907 05-01-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18516, current rewards: -2765.74034, mean: -1.71785
[32m[0907 05-02-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18493, current rewards: -2865.74034, mean: -1.72635
[32m[0907 05-02-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18472, current rewards: -2965.74034, mean: -1.73435
[32m[0907 05-02-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18451, current rewards: -3065.74034, mean: -1.74190
[32m[0907 05-02-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18431, current rewards: -3165.74034, mean: -1.74903
[32m[0907 05-02-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18414, current rewards: -3265.74034, mean: -1.75577
[32m[0907 05-02-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18397, current rewards: -3365.74034, mean: -1.76217
[32m[0907 05-02-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18383, current rewards: -3465.74034, mean: -1.76823
[32m[0907 05-03-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18369, current rewards: -3565.74034, mean: -1.77400
[32m[0907 05-03-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18364, current rewards: -3665.74034, mean: -1.77949
[32m[0907 05-03-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18369, current rewards: -3765.74034, mean: -1.78471
[32m[0907 05-03-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18381, current rewards: -3865.74034, mean: -1.78969
[32m[0907 05-03-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18391, current rewards: -3965.74034, mean: -1.79445
[32m[0907 05-03-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18401, current rewards: -4065.74034, mean: -1.79900
[32m[0907 05-03-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18413, current rewards: -4165.74034, mean: -1.80335
[32m[0907 05-04-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18424, current rewards: -4265.74034, mean: -1.80752
[32m[0907 05-04-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18433, current rewards: -4365.74034, mean: -1.81151
[32m[0907 05-04-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18443, current rewards: -4465.74034, mean: -1.81534
[32m[0907 05-04-35 @Agent.py:117][0m Average action selection time: 0.1845
[32m[0907 05-04-35 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-04-35 @MBExp.py:227][0m Rewards obtained: [-4545.740342656278], Lows: [2246], Highs: [76], Total time: 45314.659589
[32m[0907 05-08-03 @MBExp.py:144][0m ####################################################################
[32m[0907 05-08-03 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 05-08-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29301, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-08-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.24660, current rewards: -56.47085, mean: -0.94118
[32m[0907 05-08-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.23343, current rewards: -124.40247, mean: -1.13093
[32m[0907 05-08-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.23587, current rewards: -149.39725, mean: -0.93373
[32m[0907 05-08-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.22253, current rewards: -199.39725, mean: -0.94951
[32m[0907 05-08-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.21493, current rewards: -249.39725, mean: -0.95922
[32m[0907 05-09-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20991, current rewards: -299.39725, mean: -0.96580
[32m[0907 05-09-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20622, current rewards: -349.39725, mean: -0.97055
[32m[0907 05-09-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20347, current rewards: -399.39725, mean: -0.97414
[32m[0907 05-09-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20151, current rewards: -449.39725, mean: -0.97695
[32m[0907 05-09-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20026, current rewards: -499.39725, mean: -0.97921
[32m[0907 05-09-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19923, current rewards: -549.39725, mean: -0.98107
[32m[0907 05-10-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19838, current rewards: -599.39725, mean: -0.98262
[32m[0907 05-10-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19767, current rewards: -649.39725, mean: -0.98394
[32m[0907 05-10-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19702, current rewards: -699.39725, mean: -0.98507
[32m[0907 05-10-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19651, current rewards: -749.39725, mean: -0.98605
[32m[0907 05-10-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19590, current rewards: -799.39725, mean: -0.98691
[32m[0907 05-10-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19517, current rewards: -849.39725, mean: -0.98767
[32m[0907 05-11-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19420, current rewards: -899.39725, mean: -0.98835
[32m[0907 05-11-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19334, current rewards: -949.39725, mean: -0.98896
[32m[0907 05-11-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19256, current rewards: -999.39725, mean: -0.98950
[32m[0907 05-11-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19185, current rewards: -1049.39725, mean: -0.99000
[32m[0907 05-11-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19122, current rewards: -1099.39725, mean: -0.99045
[32m[0907 05-11-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19062, current rewards: -1149.39725, mean: -0.99086
[32m[0907 05-11-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19007, current rewards: -1199.39725, mean: -0.99124
[32m[0907 05-12-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18959, current rewards: -1249.39725, mean: -0.99159
[32m[0907 05-12-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18911, current rewards: -1299.39725, mean: -0.99191
[32m[0907 05-12-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18868, current rewards: -1349.39725, mean: -0.99220
[32m[0907 05-12-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18829, current rewards: -1399.39725, mean: -0.99248
[32m[0907 05-12-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18794, current rewards: -1449.39725, mean: -0.99274
[32m[0907 05-12-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18760, current rewards: -1499.39725, mean: -0.99298
[32m[0907 05-12-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18725, current rewards: -1549.39725, mean: -0.99320
[32m[0907 05-13-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18695, current rewards: -1599.39725, mean: -0.99341
[32m[0907 05-13-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18668, current rewards: -1649.39725, mean: -0.99361
[32m[0907 05-13-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18640, current rewards: -1690.06923, mean: -0.98834
[32m[0907 05-13-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18614, current rewards: -1681.76912, mean: -0.95555
[32m[0907 05-13-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18590, current rewards: -1675.39710, mean: -0.92563
[32m[0907 05-13-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18568, current rewards: -1672.83999, mean: -0.89938
[32m[0907 05-13-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18549, current rewards: -1670.28287, mean: -0.87449
[32m[0907 05-14-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18531, current rewards: -1712.92487, mean: -0.87394
[32m[0907 05-14-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18520, current rewards: -1762.92487, mean: -0.87708
[32m[0907 05-14-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18519, current rewards: -1812.92487, mean: -0.88006
[32m[0907 05-14-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18530, current rewards: -1862.92487, mean: -0.88290
[32m[0907 05-14-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18540, current rewards: -1912.92487, mean: -0.88561
[32m[0907 05-14-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18546, current rewards: -1962.92487, mean: -0.88820
[32m[0907 05-15-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18557, current rewards: -2012.92487, mean: -0.89067
[32m[0907 05-15-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18565, current rewards: -2062.92487, mean: -0.89304
[32m[0907 05-15-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18574, current rewards: -2112.92487, mean: -0.89531
[32m[0907 05-15-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18582, current rewards: -2162.92487, mean: -0.89748
[32m[0907 05-15-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18588, current rewards: -2212.92487, mean: -0.89956
[32m[0907 05-15-48 @Agent.py:117][0m Average action selection time: 0.1859
[32m[0907 05-15-48 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-15-48 @MBExp.py:227][0m Rewards obtained: [-2252.924873606975], Lows: [57], Highs: [2167], Total time: 45780.320553000005
[32m[0907 05-19-19 @MBExp.py:144][0m ####################################################################
[32m[0907 05-19-19 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 05-19-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18796, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-19-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18218, current rewards: -95.18940, mean: -1.58649
[32m[0907 05-19-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18010, current rewards: -195.18940, mean: -1.77445
[32m[0907 05-19-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17913, current rewards: -295.18940, mean: -1.84493
[32m[0907 05-19-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17942, current rewards: -395.18940, mean: -1.88185
[32m[0907 05-20-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18015, current rewards: -495.18940, mean: -1.90457
[32m[0907 05-20-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18078, current rewards: -595.18940, mean: -1.91997
[32m[0907 05-20-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18111, current rewards: -695.18940, mean: -1.93108
[32m[0907 05-20-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18142, current rewards: -795.18940, mean: -1.93949
[32m[0907 05-20-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18163, current rewards: -895.18940, mean: -1.94606
[32m[0907 05-20-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18227, current rewards: -995.18940, mean: -1.95135
[32m[0907 05-21-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18290, current rewards: -1095.18940, mean: -1.95570
[32m[0907 05-21-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18333, current rewards: -1195.18940, mean: -1.95933
[32m[0907 05-21-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18373, current rewards: -1295.18940, mean: -1.96241
[32m[0907 05-21-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18405, current rewards: -1395.18940, mean: -1.96506
[32m[0907 05-21-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18432, current rewards: -1495.18940, mean: -1.96735
[32m[0907 05-21-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18458, current rewards: -1595.18940, mean: -1.96937
[32m[0907 05-21-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18468, current rewards: -1695.18940, mean: -1.97115
[32m[0907 05-22-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18466, current rewards: -1795.18940, mean: -1.97274
[32m[0907 05-22-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18460, current rewards: -1895.18940, mean: -1.97416
[32m[0907 05-22-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18439, current rewards: -1995.18940, mean: -1.97544
[32m[0907 05-22-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18411, current rewards: -2095.18940, mean: -1.97659
[32m[0907 05-22-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18380, current rewards: -2195.18940, mean: -1.97765
[32m[0907 05-22-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18356, current rewards: -2295.18940, mean: -1.97861
[32m[0907 05-23-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18332, current rewards: -2395.18940, mean: -1.97950
[32m[0907 05-23-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18313, current rewards: -2495.18940, mean: -1.98031
[32m[0907 05-23-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18294, current rewards: -2595.18940, mean: -1.98106
[32m[0907 05-23-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18275, current rewards: -2695.18940, mean: -1.98176
[32m[0907 05-23-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18259, current rewards: -2795.18940, mean: -1.98240
[32m[0907 05-23-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18244, current rewards: -2895.18940, mean: -1.98301
[32m[0907 05-23-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18229, current rewards: -2995.18940, mean: -1.98357
[32m[0907 05-24-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18216, current rewards: -3095.18940, mean: -1.98410
[32m[0907 05-24-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18200, current rewards: -3195.18940, mean: -1.98459
[32m[0907 05-24-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18189, current rewards: -3295.18940, mean: -1.98505
[32m[0907 05-24-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18176, current rewards: -3395.18940, mean: -1.98549
[32m[0907 05-24-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18163, current rewards: -3495.18940, mean: -1.98590
[32m[0907 05-24-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18153, current rewards: -3595.18940, mean: -1.98629
[32m[0907 05-24-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18143, current rewards: -3695.18940, mean: -1.98666
[32m[0907 05-25-05 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18133, current rewards: -3795.18940, mean: -1.98701
[32m[0907 05-25-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18123, current rewards: -3895.18940, mean: -1.98734
[32m[0907 05-25-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18113, current rewards: -3995.18940, mean: -1.98766
[32m[0907 05-25-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18113, current rewards: -4095.18940, mean: -1.98796
[32m[0907 05-25-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18119, current rewards: -4195.18940, mean: -1.98824
[32m[0907 05-25-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18125, current rewards: -4295.18940, mean: -1.98851
[32m[0907 05-26-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18136, current rewards: -4395.18940, mean: -1.98877
[32m[0907 05-26-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18155, current rewards: -4495.18940, mean: -1.98902
[32m[0907 05-26-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18173, current rewards: -4595.18940, mean: -1.98926
[32m[0907 05-26-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18188, current rewards: -4695.18940, mean: -1.98949
[32m[0907 05-26-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18203, current rewards: -4795.18940, mean: -1.98971
[32m[0907 05-26-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18219, current rewards: -4895.18940, mean: -1.98991
[32m[0907 05-26-55 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0907 05-26-55 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-26-55 @MBExp.py:227][0m Rewards obtained: [-4975.189401558048], Lows: [2483], Highs: [11], Total time: 46236.92834400001
[32m[0907 05-30-28 @MBExp.py:144][0m ####################################################################
[32m[0907 05-30-28 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 05-30-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17535, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-30-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17948, current rewards: -92.11262, mean: -1.53521
[32m[0907 05-30-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17860, current rewards: -189.64075, mean: -1.72401
[32m[0907 05-30-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17832, current rewards: -269.11444, mean: -1.68197
[32m[0907 05-31-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17836, current rewards: -345.90366, mean: -1.64716
[32m[0907 05-31-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17858, current rewards: -435.74242, mean: -1.67593
[32m[0907 05-31-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17946, current rewards: -526.23479, mean: -1.69753
[32m[0907 05-31-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18034, current rewards: -619.20902, mean: -1.72003
[32m[0907 05-31-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18072, current rewards: -709.49266, mean: -1.73047
[32m[0907 05-31-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18103, current rewards: -791.29262, mean: -1.72020
[32m[0907 05-32-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18119, current rewards: -879.59350, mean: -1.72469
[32m[0907 05-32-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18173, current rewards: -971.76924, mean: -1.73530
[32m[0907 05-32-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18235, current rewards: -1064.16706, mean: -1.74454
[32m[0907 05-32-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18284, current rewards: -1157.03478, mean: -1.75308
[32m[0907 05-32-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18327, current rewards: -1249.86251, mean: -1.76037
[32m[0907 05-32-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18365, current rewards: -1337.66428, mean: -1.76008
[32m[0907 05-32-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18398, current rewards: -1437.66428, mean: -1.77489
[32m[0907 05-33-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18405, current rewards: -1524.91432, mean: -1.77316
[32m[0907 05-33-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18408, current rewards: -1611.87140, mean: -1.77129
[32m[0907 05-33-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18416, current rewards: -1696.06974, mean: -1.76674
[32m[0907 05-33-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18432, current rewards: -1783.11101, mean: -1.76546
[32m[0907 05-33-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18408, current rewards: -1859.33247, mean: -1.75409
[32m[0907 05-33-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18392, current rewards: -1957.00401, mean: -1.76307
[32m[0907 05-34-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18366, current rewards: -2051.86785, mean: -1.76885
[32m[0907 05-34-10 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18343, current rewards: -2122.18433, mean: -1.75387
[32m[0907 05-34-19 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18321, current rewards: -2188.27117, mean: -1.73672
[32m[0907 05-34-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18299, current rewards: -2278.91629, mean: -1.73963
[32m[0907 05-34-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18280, current rewards: -2336.59155, mean: -1.71808
[32m[0907 05-34-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18274, current rewards: -2425.93534, mean: -1.72052
[32m[0907 05-34-55 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18258, current rewards: -2523.78236, mean: -1.72862
[32m[0907 05-35-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18243, current rewards: -2623.78236, mean: -1.73760
[32m[0907 05-35-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18228, current rewards: -2723.78236, mean: -1.74601
[32m[0907 05-35-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18215, current rewards: -2823.78236, mean: -1.75390
[32m[0907 05-35-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18202, current rewards: -2923.78236, mean: -1.76131
[32m[0907 05-35-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18190, current rewards: -3023.78236, mean: -1.76829
[32m[0907 05-35-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18177, current rewards: -3123.78236, mean: -1.77488
[32m[0907 05-35-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18166, current rewards: -3218.75418, mean: -1.77832
[32m[0907 05-36-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18157, current rewards: -3313.56291, mean: -1.78149
[32m[0907 05-36-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18148, current rewards: -3410.91331, mean: -1.78582
[32m[0907 05-36-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18140, current rewards: -3510.91331, mean: -1.79128
[32m[0907 05-36-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18130, current rewards: -3610.91331, mean: -1.79647
[32m[0907 05-36-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18132, current rewards: -3710.91331, mean: -1.80141
[32m[0907 05-36-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18139, current rewards: -3810.91331, mean: -1.80612
[32m[0907 05-37-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18143, current rewards: -3895.47842, mean: -1.80346
[32m[0907 05-37-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18148, current rewards: -3986.30230, mean: -1.80376
[32m[0907 05-37-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18166, current rewards: -4074.33889, mean: -1.80280
[32m[0907 05-37-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18186, current rewards: -4159.57439, mean: -1.80068
[32m[0907 05-37-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18204, current rewards: -4254.96087, mean: -1.80295
[32m[0907 05-37-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18235, current rewards: -4343.40664, mean: -1.80224
[32m[0907 05-37-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18257, current rewards: -4436.55946, mean: -1.80348
[32m[0907 05-38-05 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0907 05-38-05 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-38-05 @MBExp.py:227][0m Rewards obtained: [-4512.0808220662175], Lows: [2284], Highs: [31], Total time: 46694.50286500001
[32m[0907 05-41-40 @MBExp.py:144][0m ####################################################################
[32m[0907 05-41-40 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 05-41-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.23469, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-41-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21390, current rewards: -39.23709, mean: -0.65395
[32m[0907 05-42-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19805, current rewards: -121.56795, mean: -1.10516
[32m[0907 05-42-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19153, current rewards: -221.56795, mean: -1.38480
[32m[0907 05-42-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18826, current rewards: -321.56795, mean: -1.53128
[32m[0907 05-42-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18709, current rewards: -421.56795, mean: -1.62142
[32m[0907 05-42-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18650, current rewards: -521.56795, mean: -1.68248
[32m[0907 05-42-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18613, current rewards: -621.56795, mean: -1.72658
[32m[0907 05-42-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18579, current rewards: -721.56795, mean: -1.75992
[32m[0907 05-43-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18555, current rewards: -821.56795, mean: -1.78602
[32m[0907 05-43-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18537, current rewards: -921.56795, mean: -1.80700
[32m[0907 05-43-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18573, current rewards: -1021.56795, mean: -1.82423
[32m[0907 05-43-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18599, current rewards: -1121.56795, mean: -1.83864
[32m[0907 05-43-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18618, current rewards: -1221.56795, mean: -1.85086
[32m[0907 05-43-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18645, current rewards: -1321.56795, mean: -1.86136
[32m[0907 05-44-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18662, current rewards: -1421.56795, mean: -1.87048
[32m[0907 05-44-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18654, current rewards: -1521.56795, mean: -1.87848
[32m[0907 05-44-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18640, current rewards: -1621.56795, mean: -1.88554
[32m[0907 05-44-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18627, current rewards: -1721.56795, mean: -1.89183
[32m[0907 05-44-39 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18614, current rewards: -1821.56795, mean: -1.89747
[32m[0907 05-44-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18601, current rewards: -1921.56795, mean: -1.90254
[32m[0907 05-44-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18563, current rewards: -2021.56795, mean: -1.90714
[32m[0907 05-45-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18529, current rewards: -2121.56795, mean: -1.91132
[32m[0907 05-45-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18500, current rewards: -2221.56795, mean: -1.91514
[32m[0907 05-45-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18471, current rewards: -2321.56795, mean: -1.91865
[32m[0907 05-45-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18443, current rewards: -2421.56795, mean: -1.92188
[32m[0907 05-45-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18415, current rewards: -2521.56795, mean: -1.92486
[32m[0907 05-45-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18394, current rewards: -2621.56795, mean: -1.92762
[32m[0907 05-46-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18373, current rewards: -2721.56795, mean: -1.93019
[32m[0907 05-46-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18356, current rewards: -2821.56795, mean: -1.93258
[32m[0907 05-46-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18338, current rewards: -2921.56795, mean: -1.93481
[32m[0907 05-46-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18320, current rewards: -3021.56795, mean: -1.93690
[32m[0907 05-46-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18305, current rewards: -3121.56795, mean: -1.93886
[32m[0907 05-46-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18290, current rewards: -3221.56795, mean: -1.94070
[32m[0907 05-46-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18276, current rewards: -3321.56795, mean: -1.94244
[32m[0907 05-47-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18263, current rewards: -3421.56795, mean: -1.94407
[32m[0907 05-47-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18252, current rewards: -3521.56795, mean: -1.94562
[32m[0907 05-47-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18240, current rewards: -3621.56795, mean: -1.94708
[32m[0907 05-47-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18227, current rewards: -3721.56795, mean: -1.94846
[32m[0907 05-47-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18218, current rewards: -3821.56795, mean: -1.94978
[32m[0907 05-47-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18211, current rewards: -3921.56795, mean: -1.95103
[32m[0907 05-47-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18215, current rewards: -4021.56795, mean: -1.95222
[32m[0907 05-48-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18220, current rewards: -4121.56795, mean: -1.95335
[32m[0907 05-48-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18224, current rewards: -4221.56795, mean: -1.95443
[32m[0907 05-48-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18226, current rewards: -4321.56795, mean: -1.95546
[32m[0907 05-48-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18240, current rewards: -4421.56795, mean: -1.95645
[32m[0907 05-48-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18257, current rewards: -4521.56795, mean: -1.95739
[32m[0907 05-48-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18269, current rewards: -4621.56795, mean: -1.95829
[32m[0907 05-49-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18283, current rewards: -4721.56795, mean: -1.95916
[32m[0907 05-49-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18297, current rewards: -4821.56795, mean: -1.95999
[32m[0907 05-49-19 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0907 05-49-19 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-49-19 @MBExp.py:227][0m Rewards obtained: [-4901.567952300855], Lows: [2446], Highs: [16], Total time: 47153.04370100001
[32m[0907 05-52-56 @MBExp.py:144][0m ####################################################################
[32m[0907 05-52-56 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 05-52-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17638, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-53-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17716, current rewards: -64.00000, mean: -1.06667
[32m[0907 05-53-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17737, current rewards: -114.00000, mean: -1.03636
[32m[0907 05-53-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17734, current rewards: -164.00000, mean: -1.02500
[32m[0907 05-53-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17738, current rewards: -214.00000, mean: -1.01905
[32m[0907 05-53-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17757, current rewards: -264.00000, mean: -1.01538
[32m[0907 05-53-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17848, current rewards: -314.00000, mean: -1.01290
[32m[0907 05-54-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17910, current rewards: -364.00000, mean: -1.01111
[32m[0907 05-54-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17965, current rewards: -414.00000, mean: -1.00976
[32m[0907 05-54-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18006, current rewards: -464.00000, mean: -1.00870
[32m[0907 05-54-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18050, current rewards: -514.00000, mean: -1.00784
[32m[0907 05-54-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18126, current rewards: -564.00000, mean: -1.00714
[32m[0907 05-54-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18197, current rewards: -614.00000, mean: -1.00656
[32m[0907 05-54-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18253, current rewards: -664.00000, mean: -1.00606
[32m[0907 05-55-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18288, current rewards: -714.00000, mean: -1.00563
[32m[0907 05-55-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18331, current rewards: -764.00000, mean: -1.00526
[32m[0907 05-55-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18335, current rewards: -814.00000, mean: -1.00494
[32m[0907 05-55-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18336, current rewards: -864.00000, mean: -1.00465
[32m[0907 05-55-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18338, current rewards: -914.00000, mean: -1.00440
[32m[0907 05-55-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18337, current rewards: -964.00000, mean: -1.00417
[32m[0907 05-56-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18320, current rewards: -1014.00000, mean: -1.00396
[32m[0907 05-56-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18296, current rewards: -1064.00000, mean: -1.00377
[32m[0907 05-56-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18273, current rewards: -1114.00000, mean: -1.00360
[32m[0907 05-56-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18252, current rewards: -1164.00000, mean: -1.00345
[32m[0907 05-56-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18232, current rewards: -1214.00000, mean: -1.00331
[32m[0907 05-56-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18212, current rewards: -1264.00000, mean: -1.00317
[32m[0907 05-56-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18197, current rewards: -1314.00000, mean: -1.00305
[32m[0907 05-57-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18183, current rewards: -1364.00000, mean: -1.00294
[32m[0907 05-57-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18171, current rewards: -1414.00000, mean: -1.00284
[32m[0907 05-57-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18158, current rewards: -1464.00000, mean: -1.00274
[32m[0907 05-57-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18145, current rewards: -1514.00000, mean: -1.00265
[32m[0907 05-57-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18136, current rewards: -1564.00000, mean: -1.00256
[32m[0907 05-57-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18126, current rewards: -1614.00000, mean: -1.00248
[32m[0907 05-57-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18117, current rewards: -1664.00000, mean: -1.00241
[32m[0907 05-58-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18110, current rewards: -1714.00000, mean: -1.00234
[32m[0907 05-58-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18100, current rewards: -1764.00000, mean: -1.00227
[32m[0907 05-58-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18092, current rewards: -1814.00000, mean: -1.00221
[32m[0907 05-58-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18084, current rewards: -1864.00000, mean: -1.00215
[32m[0907 05-58-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18077, current rewards: -1914.00000, mean: -1.00209
[32m[0907 05-58-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18070, current rewards: -1964.00000, mean: -1.00204
[32m[0907 05-58-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18068, current rewards: -2014.00000, mean: -1.00199
[32m[0907 05-59-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18075, current rewards: -2064.00000, mean: -1.00194
[32m[0907 05-59-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18084, current rewards: -2114.00000, mean: -1.00190
[32m[0907 05-59-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18091, current rewards: -2164.00000, mean: -1.00185
[32m[0907 05-59-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18097, current rewards: -2214.00000, mean: -1.00181
[32m[0907 05-59-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18116, current rewards: -2264.00000, mean: -1.00177
[32m[0907 05-59-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18134, current rewards: -2314.00000, mean: -1.00173
[32m[0907 06-00-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18152, current rewards: -2364.00000, mean: -1.00169
[32m[0907 06-00-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18167, current rewards: -2414.00000, mean: -1.00166
[32m[0907 06-00-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18182, current rewards: -2464.00000, mean: -1.00163
[32m[0907 06-00-31 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0907 06-00-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-00-31 @MBExp.py:227][0m Rewards obtained: [-2504], Lows: [4], Highs: [2496], Total time: 47608.75970700001
[32m[0907 06-04-11 @MBExp.py:144][0m ####################################################################
[32m[0907 06-04-11 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 06-04-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18851, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-04-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18866, current rewards: -58.76112, mean: -0.97935
[32m[0907 06-04-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18476, current rewards: -103.34016, mean: -0.93946
[32m[0907 06-04-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18338, current rewards: -149.03833, mean: -0.93149
[32m[0907 06-04-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18264, current rewards: -196.73937, mean: -0.93685
[32m[0907 06-04-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18250, current rewards: -242.26904, mean: -0.93180
[32m[0907 06-05-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18287, current rewards: -286.79821, mean: -0.92516
[32m[0907 06-05-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18308, current rewards: -336.79821, mean: -0.93555
[32m[0907 06-05-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18346, current rewards: -384.69158, mean: -0.93827
[32m[0907 06-05-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18346, current rewards: -433.63308, mean: -0.94268
[32m[0907 06-05-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18345, current rewards: -481.32801, mean: -0.94378
[32m[0907 06-05-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18381, current rewards: -529.21244, mean: -0.94502
[32m[0907 06-06-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18429, current rewards: -576.05304, mean: -0.94435
[32m[0907 06-06-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18514, current rewards: -621.85282, mean: -0.94220
[32m[0907 06-06-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18554, current rewards: -670.65805, mean: -0.94459
[32m[0907 06-06-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18570, current rewards: -718.55453, mean: -0.94547
[32m[0907 06-06-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18670, current rewards: -773.55453, mean: -0.95501
[32m[0907 06-06-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18780, current rewards: -829.39919, mean: -0.96442
[32m[0907 06-07-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18810, current rewards: -885.62481, mean: -0.97321
[32m[0907 06-07-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18850, current rewards: -940.01766, mean: -0.97919
[32m[0907 06-07-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18842, current rewards: -1027.32287, mean: -1.01715
[32m[0907 06-07-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18915, current rewards: -1085.42813, mean: -1.02399
[32m[0907 06-07-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18915, current rewards: -1156.99785, mean: -1.04234
[32m[0907 06-07-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18867, current rewards: -1256.99785, mean: -1.08362
[32m[0907 06-07-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18821, current rewards: -1356.99785, mean: -1.12149
[32m[0907 06-08-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18781, current rewards: -1456.99785, mean: -1.15635
[32m[0907 06-08-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18744, current rewards: -1556.99785, mean: -1.18855
[32m[0907 06-08-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18710, current rewards: -1656.99785, mean: -1.21838
[32m[0907 06-08-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18675, current rewards: -1756.99785, mean: -1.24610
[32m[0907 06-08-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18646, current rewards: -1856.99785, mean: -1.27192
[32m[0907 06-08-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18617, current rewards: -1956.99785, mean: -1.29603
[32m[0907 06-09-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18590, current rewards: -2056.99785, mean: -1.31859
[32m[0907 06-09-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18565, current rewards: -2156.99785, mean: -1.33975
[32m[0907 06-09-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18540, current rewards: -2256.99785, mean: -1.35964
[32m[0907 06-09-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18518, current rewards: -2356.99785, mean: -1.37836
[32m[0907 06-09-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18498, current rewards: -2456.99785, mean: -1.39602
[32m[0907 06-09-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18479, current rewards: -2556.99785, mean: -1.41271
[32m[0907 06-09-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18461, current rewards: -2656.99785, mean: -1.42849
[32m[0907 06-10-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18443, current rewards: -2756.99785, mean: -1.44345
[32m[0907 06-10-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18435, current rewards: -2856.99785, mean: -1.45765
[32m[0907 06-10-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18433, current rewards: -2956.99785, mean: -1.47114
[32m[0907 06-10-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18431, current rewards: -3056.99785, mean: -1.48398
[32m[0907 06-10-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18429, current rewards: -3156.99785, mean: -1.49621
[32m[0907 06-10-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18430, current rewards: -3256.99785, mean: -1.50787
[32m[0907 06-10-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18441, current rewards: -3356.99785, mean: -1.51900
[32m[0907 06-11-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18452, current rewards: -3456.99785, mean: -1.52965
[32m[0907 06-11-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18462, current rewards: -3556.99785, mean: -1.53983
[32m[0907 06-11-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18470, current rewards: -3656.99785, mean: -1.54958
[32m[0907 06-11-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18479, current rewards: -3756.99785, mean: -1.55892
[32m[0907 06-11-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18486, current rewards: -3856.99785, mean: -1.56789
[32m[0907 06-11-54 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0907 06-11-54 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-11-54 @MBExp.py:227][0m Rewards obtained: [-3936.9978534043285], Lows: [1531], Highs: [884], Total time: 48071.94370600001
[32m[0907 06-15-35 @MBExp.py:144][0m ####################################################################
[32m[0907 06-15-35 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 06-15-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.21132, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-15-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19310, current rewards: -68.96378, mean: -1.14940
[32m[0907 06-15-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18635, current rewards: -168.96378, mean: -1.53603
[32m[0907 06-16-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18368, current rewards: -268.96378, mean: -1.68102
[32m[0907 06-16-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18249, current rewards: -368.96378, mean: -1.75697
[32m[0907 06-16-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18273, current rewards: -468.96378, mean: -1.80371
[32m[0907 06-16-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18288, current rewards: -568.96378, mean: -1.83537
[32m[0907 06-16-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18292, current rewards: -668.96378, mean: -1.85823
[32m[0907 06-16-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18303, current rewards: -768.96378, mean: -1.87552
[32m[0907 06-17-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18318, current rewards: -868.96378, mean: -1.88905
[32m[0907 06-17-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18323, current rewards: -968.96378, mean: -1.89993
[32m[0907 06-17-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18373, current rewards: -1068.96378, mean: -1.90886
[32m[0907 06-17-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18425, current rewards: -1168.96378, mean: -1.91633
[32m[0907 06-17-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18461, current rewards: -1268.96378, mean: -1.92267
[32m[0907 06-17-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18466, current rewards: -1368.96378, mean: -1.92812
[32m[0907 06-17-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18461, current rewards: -1468.96378, mean: -1.93285
[32m[0907 06-18-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18459, current rewards: -1568.96378, mean: -1.93699
[32m[0907 06-18-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18452, current rewards: -1668.96378, mean: -1.94066
[32m[0907 06-18-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18426, current rewards: -1768.96378, mean: -1.94392
[32m[0907 06-18-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18395, current rewards: -1868.96378, mean: -1.94684
[32m[0907 06-18-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18368, current rewards: -1968.96378, mean: -1.94947
[32m[0907 06-18-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18341, current rewards: -2068.96378, mean: -1.95185
[32m[0907 06-18-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18317, current rewards: -2168.96378, mean: -1.95402
[32m[0907 06-19-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18295, current rewards: -2268.96378, mean: -1.95600
[32m[0907 06-19-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18276, current rewards: -2368.96378, mean: -1.95782
[32m[0907 06-19-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18257, current rewards: -2468.96378, mean: -1.95950
[32m[0907 06-19-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18239, current rewards: -2568.96378, mean: -1.96104
[32m[0907 06-19-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18223, current rewards: -2668.96378, mean: -1.96247
[32m[0907 06-19-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18207, current rewards: -2768.96378, mean: -1.96380
[32m[0907 06-20-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18192, current rewards: -2868.96378, mean: -1.96504
[32m[0907 06-20-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18179, current rewards: -2968.96378, mean: -1.96620
[32m[0907 06-20-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18166, current rewards: -3068.96378, mean: -1.96728
[32m[0907 06-20-28 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18154, current rewards: -3168.96378, mean: -1.96830
[32m[0907 06-20-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18143, current rewards: -3268.96378, mean: -1.96926
[32m[0907 06-20-46 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18134, current rewards: -3368.96378, mean: -1.97015
[32m[0907 06-20-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18124, current rewards: -3468.96378, mean: -1.97100
[32m[0907 06-21-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18116, current rewards: -3568.96378, mean: -1.97180
[32m[0907 06-21-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18107, current rewards: -3668.96378, mean: -1.97256
[32m[0907 06-21-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18099, current rewards: -3768.96378, mean: -1.97328
[32m[0907 06-21-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18098, current rewards: -3868.96378, mean: -1.97396
[32m[0907 06-21-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18105, current rewards: -3968.96378, mean: -1.97461
[32m[0907 06-21-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18111, current rewards: -4068.96378, mean: -1.97523
[32m[0907 06-21-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18118, current rewards: -4168.96378, mean: -1.97581
[32m[0907 06-22-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18130, current rewards: -4268.96378, mean: -1.97637
[32m[0907 06-22-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18149, current rewards: -4368.96378, mean: -1.97691
[32m[0907 06-22-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18167, current rewards: -4468.96378, mean: -1.97742
[32m[0907 06-22-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18183, current rewards: -4568.96378, mean: -1.97791
[32m[0907 06-22-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18199, current rewards: -4668.96378, mean: -1.97837
[32m[0907 06-22-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18213, current rewards: -4768.96378, mean: -1.97882
[32m[0907 06-23-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18226, current rewards: -4868.96378, mean: -1.97925
[32m[0907 06-23-12 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0907 06-23-12 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-23-12 @MBExp.py:227][0m Rewards obtained: [-4948.963781450817], Lows: [2461], Highs: [28], Total time: 48528.75147400001
[32m[0907 06-26-56 @MBExp.py:144][0m ####################################################################
[32m[0907 06-26-56 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 06-26-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19414, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-27-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19447, current rewards: -45.09072, mean: -0.75151
[32m[0907 06-27-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20429, current rewards: -80.27419, mean: -0.72977
[32m[0907 06-27-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20372, current rewards: -115.47071, mean: -0.72169
[32m[0907 06-27-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20686, current rewards: -149.56547, mean: -0.71222
[32m[0907 06-27-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20858, current rewards: -184.78443, mean: -0.71071
[32m[0907 06-28-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20757, current rewards: -218.81481, mean: -0.70585
[32m[0907 06-28-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20801, current rewards: -251.91180, mean: -0.69976
[32m[0907 06-28-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20779, current rewards: -298.07392, mean: -0.72701
[32m[0907 06-28-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20525, current rewards: -341.78344, mean: -0.74301
[32m[0907 06-28-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20368, current rewards: -384.44588, mean: -0.75382
[32m[0907 06-28-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20243, current rewards: -434.44588, mean: -0.77580
[32m[0907 06-28-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20119, current rewards: -484.44588, mean: -0.79417
[32m[0907 06-29-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19991, current rewards: -534.44588, mean: -0.80977
[32m[0907 06-29-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19875, current rewards: -584.44588, mean: -0.82316
[32m[0907 06-29-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19776, current rewards: -588.97422, mean: -0.77497
[32m[0907 06-29-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19679, current rewards: -583.63170, mean: -0.72053
[32m[0907 06-29-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19569, current rewards: -578.48605, mean: -0.67266
[32m[0907 06-29-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19476, current rewards: -573.34040, mean: -0.63004
[32m[0907 06-30-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19389, current rewards: -568.19476, mean: -0.59187
[32m[0907 06-30-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19311, current rewards: -563.04911, mean: -0.55747
[32m[0907 06-30-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19238, current rewards: -557.90346, mean: -0.52632
[32m[0907 06-30-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19175, current rewards: -552.75781, mean: -0.49798
[32m[0907 06-30-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19119, current rewards: -547.61216, mean: -0.47208
[32m[0907 06-30-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19062, current rewards: -542.46651, mean: -0.44832
[32m[0907 06-30-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19013, current rewards: -585.84903, mean: -0.46496
[32m[0907 06-31-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18967, current rewards: -635.84903, mean: -0.48538
[32m[0907 06-31-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18925, current rewards: -685.84903, mean: -0.50430
[32m[0907 06-31-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18886, current rewards: -735.84903, mean: -0.52188
[32m[0907 06-31-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18849, current rewards: -785.84903, mean: -0.53825
[32m[0907 06-31-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18815, current rewards: -835.84903, mean: -0.55354
[32m[0907 06-31-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18784, current rewards: -885.84903, mean: -0.56785
[32m[0907 06-31-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18755, current rewards: -935.84903, mean: -0.58127
[32m[0907 06-32-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18728, current rewards: -985.84903, mean: -0.59388
[32m[0907 06-32-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18701, current rewards: -1035.84903, mean: -0.60576
[32m[0907 06-32-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18676, current rewards: -1085.84903, mean: -0.61696
[32m[0907 06-32-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18652, current rewards: -1135.84903, mean: -0.62754
[32m[0907 06-32-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18630, current rewards: -1185.84903, mean: -0.63755
[32m[0907 06-32-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18624, current rewards: -1235.84903, mean: -0.64704
[32m[0907 06-33-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18620, current rewards: -1285.84903, mean: -0.65605
[32m[0907 06-33-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18615, current rewards: -1335.84903, mean: -0.66460
[32m[0907 06-33-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18610, current rewards: -1385.84903, mean: -0.67274
[32m[0907 06-33-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18616, current rewards: -1435.84903, mean: -0.68050
[32m[0907 06-33-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18623, current rewards: -1485.84903, mean: -0.68789
[32m[0907 06-33-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18630, current rewards: -1535.84903, mean: -0.69495
[32m[0907 06-33-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18634, current rewards: -1585.84903, mean: -0.70170
[32m[0907 06-34-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18639, current rewards: -1635.84903, mean: -0.70816
[32m[0907 06-34-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18644, current rewards: -1685.84903, mean: -0.71434
[32m[0907 06-34-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18649, current rewards: -1735.84903, mean: -0.72027
[32m[0907 06-34-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18652, current rewards: -1785.84903, mean: -0.72595
[32m[0907 06-34-43 @Agent.py:117][0m Average action selection time: 0.1866
[32m[0907 06-34-43 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-34-43 @MBExp.py:227][0m Rewards obtained: [-1825.8490309573717], Lows: [17], Highs: [1852], Total time: 48996.01299200001
[32m[0907 06-38-29 @MBExp.py:144][0m ####################################################################
[32m[0907 06-38-29 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 06-38-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18890, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-38-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18732, current rewards: -92.26727, mean: -1.53779
[32m[0907 06-38-50 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18690, current rewards: -170.99296, mean: -1.55448
[32m[0907 06-38-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18750, current rewards: -248.21347, mean: -1.55133
[32m[0907 06-39-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18611, current rewards: -336.28853, mean: -1.60137
[32m[0907 06-39-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18498, current rewards: -417.59499, mean: -1.60613
[32m[0907 06-39-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18490, current rewards: -503.58606, mean: -1.62447
[32m[0907 06-39-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18678, current rewards: -593.03681, mean: -1.64732
[32m[0907 06-39-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18808, current rewards: -679.89813, mean: -1.65829
[32m[0907 06-39-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18864, current rewards: -761.74178, mean: -1.65596
[32m[0907 06-40-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18948, current rewards: -850.94339, mean: -1.66852
[32m[0907 06-40-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19080, current rewards: -933.09256, mean: -1.66624
[32m[0907 06-40-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19082, current rewards: -1028.54782, mean: -1.68614
[32m[0907 06-40-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19027, current rewards: -1128.54782, mean: -1.70992
[32m[0907 06-40-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18991, current rewards: -1228.54782, mean: -1.73035
[32m[0907 06-40-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18943, current rewards: -1328.54782, mean: -1.74809
[32m[0907 06-41-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18902, current rewards: -1428.54782, mean: -1.76364
[32m[0907 06-41-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18840, current rewards: -1528.54782, mean: -1.77738
[32m[0907 06-41-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18785, current rewards: -1628.54782, mean: -1.78961
[32m[0907 06-41-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18754, current rewards: -1728.54782, mean: -1.80057
[32m[0907 06-41-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18718, current rewards: -1828.54782, mean: -1.81044
[32m[0907 06-41-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18737, current rewards: -1924.08934, mean: -1.81518
[32m[0907 06-41-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18786, current rewards: -2014.74316, mean: -1.81508
[32m[0907 06-42-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18782, current rewards: -2107.90590, mean: -1.81716
[32m[0907 06-42-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18771, current rewards: -2194.22001, mean: -1.81340
[32m[0907 06-42-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18752, current rewards: -2278.96396, mean: -1.80870
[32m[0907 06-42-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18761, current rewards: -2372.61597, mean: -1.81116
[32m[0907 06-42-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18769, current rewards: -2453.73348, mean: -1.80422
[32m[0907 06-42-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18769, current rewards: -2533.51572, mean: -1.79682
[32m[0907 06-43-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18775, current rewards: -2621.14196, mean: -1.79530
[32m[0907 06-43-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18774, current rewards: -2690.38606, mean: -1.78171
[32m[0907 06-43-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18776, current rewards: -2775.89063, mean: -1.77942
[32m[0907 06-43-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18791, current rewards: -2858.68421, mean: -1.77558
[32m[0907 06-43-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18789, current rewards: -2942.03419, mean: -1.77231
[32m[0907 06-43-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18762, current rewards: -3042.03419, mean: -1.77897
[32m[0907 06-43-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18735, current rewards: -3142.03419, mean: -1.78525
[32m[0907 06-44-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18712, current rewards: -3242.03419, mean: -1.79118
[32m[0907 06-44-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18703, current rewards: -3342.03419, mean: -1.79679
[32m[0907 06-44-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18696, current rewards: -3442.03419, mean: -1.80211
[32m[0907 06-44-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18688, current rewards: -3542.03419, mean: -1.80716
[32m[0907 06-44-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18686, current rewards: -3642.03419, mean: -1.81196
[32m[0907 06-44-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18692, current rewards: -3742.03419, mean: -1.81652
[32m[0907 06-45-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18697, current rewards: -3842.03419, mean: -1.82087
[32m[0907 06-45-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18700, current rewards: -3942.03419, mean: -1.82502
[32m[0907 06-45-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18704, current rewards: -4042.03419, mean: -1.82897
[32m[0907 06-45-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18709, current rewards: -4142.03419, mean: -1.83276
[32m[0907 06-45-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18713, current rewards: -4242.03419, mean: -1.83638
[32m[0907 06-45-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18718, current rewards: -4342.03419, mean: -1.83984
[32m[0907 06-46-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18721, current rewards: -4442.03419, mean: -1.84317
[32m[0907 06-46-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18724, current rewards: -4542.03419, mean: -1.84636
[32m[0907 06-46-18 @Agent.py:117][0m Average action selection time: 0.1873
[32m[0907 06-46-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-46-18 @MBExp.py:227][0m Rewards obtained: [-4622.034190458151], Lows: [2313], Highs: [32], Total time: 49465.03595100001
[32m[0907 06-50-06 @MBExp.py:144][0m ####################################################################
[32m[0907 06-50-06 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 06-50-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17644, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-50-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17779, current rewards: -104.67880, mean: -1.74465
[32m[0907 06-50-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17798, current rewards: -204.67880, mean: -1.86072
[32m[0907 06-50-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17793, current rewards: -304.67880, mean: -1.90424
[32m[0907 06-50-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17785, current rewards: -402.56686, mean: -1.91699
[32m[0907 06-50-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17859, current rewards: -489.36568, mean: -1.88218
[32m[0907 06-51-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17947, current rewards: -578.60889, mean: -1.86648
[32m[0907 06-51-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18010, current rewards: -665.30677, mean: -1.84807
[32m[0907 06-51-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18144, current rewards: -749.41015, mean: -1.82783
[32m[0907 06-51-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18248, current rewards: -840.45279, mean: -1.82707
[32m[0907 06-51-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18304, current rewards: -924.92027, mean: -1.81357
[32m[0907 06-51-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18309, current rewards: -990.50054, mean: -1.76875
[32m[0907 06-51-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18314, current rewards: -1067.53621, mean: -1.75006
[32m[0907 06-52-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18321, current rewards: -1148.25323, mean: -1.73978
[32m[0907 06-52-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18300, current rewards: -1229.69418, mean: -1.73196
[32m[0907 06-52-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18265, current rewards: -1307.74033, mean: -1.72071
[32m[0907 06-52-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18236, current rewards: -1392.28589, mean: -1.71887
[32m[0907 06-52-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18214, current rewards: -1473.35154, mean: -1.71320
[32m[0907 06-52-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18191, current rewards: -1558.38088, mean: -1.71251
[32m[0907 06-53-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18172, current rewards: -1645.45576, mean: -1.71402
[32m[0907 06-53-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18154, current rewards: -1721.13024, mean: -1.70409
[32m[0907 06-53-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18137, current rewards: -1803.33286, mean: -1.70126
[32m[0907 06-53-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18124, current rewards: -1882.81929, mean: -1.69623
[32m[0907 06-53-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18110, current rewards: -1959.76826, mean: -1.68946
[32m[0907 06-53-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18097, current rewards: -2037.83121, mean: -1.68416
[32m[0907 06-53-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18087, current rewards: -2108.51991, mean: -1.67343
[32m[0907 06-54-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18076, current rewards: -2169.44101, mean: -1.65606
[32m[0907 06-54-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18067, current rewards: -2243.38471, mean: -1.64955
[32m[0907 06-54-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18057, current rewards: -2320.03792, mean: -1.64542
[32m[0907 06-54-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18047, current rewards: -2382.74941, mean: -1.63202
[32m[0907 06-54-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18042, current rewards: -2450.83949, mean: -1.62307
[32m[0907 06-54-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18033, current rewards: -2514.33884, mean: -1.61176
[32m[0907 06-54-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18026, current rewards: -2578.71283, mean: -1.60168
[32m[0907 06-55-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18019, current rewards: -2636.92859, mean: -1.58851
[32m[0907 06-55-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18012, current rewards: -2697.16552, mean: -1.57729
[32m[0907 06-55-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18006, current rewards: -2759.82518, mean: -1.56808
[32m[0907 06-55-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18007, current rewards: -2822.32858, mean: -1.55930
[32m[0907 06-55-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18018, current rewards: -2883.05895, mean: -1.55003
[32m[0907 06-55-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18030, current rewards: -2939.68264, mean: -1.53910
[32m[0907 06-56-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18039, current rewards: -3004.38626, mean: -1.53285
[32m[0907 06-56-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18057, current rewards: -3066.02269, mean: -1.52538
[32m[0907 06-56-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18079, current rewards: -3126.32096, mean: -1.51763
[32m[0907 06-56-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18101, current rewards: -3189.78258, mean: -1.51175
[32m[0907 06-56-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18126, current rewards: -3261.01757, mean: -1.50973
[32m[0907 06-56-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18143, current rewards: -3354.25500, mean: -1.51776
[32m[0907 06-56-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18161, current rewards: -3445.01545, mean: -1.52434
[32m[0907 06-57-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18179, current rewards: -3535.06568, mean: -1.53033
[32m[0907 06-57-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18197, current rewards: -3625.89221, mean: -1.53640
[32m[0907 06-57-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18217, current rewards: -3718.61799, mean: -1.54300
[32m[0907 06-57-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18231, current rewards: -3807.47038, mean: -1.54775
[32m[0907 06-57-43 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0907 06-57-43 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-57-43 @MBExp.py:227][0m Rewards obtained: [-3878.3734922475915], Lows: [1981], Highs: [25], Total time: 49921.899397000016
[32m[0907 07-01-32 @MBExp.py:144][0m ####################################################################
[32m[0907 07-01-32 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 07-01-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.21794, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-01-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18859, current rewards: -68.75679, mean: -1.14595
[32m[0907 07-01-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18913, current rewards: -108.94542, mean: -0.99041
[32m[0907 07-02-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18744, current rewards: -149.47440, mean: -0.93421
[32m[0907 07-02-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18802, current rewards: -172.98869, mean: -0.82376
[32m[0907 07-02-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18809, current rewards: -228.08145, mean: -0.87724
[32m[0907 07-02-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18763, current rewards: -292.43756, mean: -0.94335
[32m[0907 07-02-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18724, current rewards: -392.43756, mean: -1.09010
[32m[0907 07-02-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18754, current rewards: -492.43756, mean: -1.20107
[32m[0907 07-02-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18780, current rewards: -592.43756, mean: -1.28791
[32m[0907 07-03-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18746, current rewards: -692.43756, mean: -1.35772
[32m[0907 07-03-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18714, current rewards: -792.43756, mean: -1.41507
[32m[0907 07-03-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18684, current rewards: -892.43756, mean: -1.46301
[32m[0907 07-03-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18660, current rewards: -992.43756, mean: -1.50369
[32m[0907 07-03-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18638, current rewards: -1092.43756, mean: -1.53864
[32m[0907 07-03-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18621, current rewards: -1192.43756, mean: -1.56900
[32m[0907 07-04-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18607, current rewards: -1292.43756, mean: -1.59560
[32m[0907 07-04-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18556, current rewards: -1392.43756, mean: -1.61911
[32m[0907 07-04-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18516, current rewards: -1492.43756, mean: -1.64004
[32m[0907 07-04-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18476, current rewards: -1592.43756, mean: -1.65879
[32m[0907 07-04-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18441, current rewards: -1692.43756, mean: -1.67568
[32m[0907 07-04-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18411, current rewards: -1792.43756, mean: -1.69098
[32m[0907 07-04-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18383, current rewards: -1892.43756, mean: -1.70490
[32m[0907 07-05-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18359, current rewards: -1992.43756, mean: -1.71762
[32m[0907 07-05-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18336, current rewards: -2092.43756, mean: -1.72929
[32m[0907 07-05-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18314, current rewards: -2192.43756, mean: -1.74003
[32m[0907 07-05-32 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18296, current rewards: -2292.43756, mean: -1.74995
[32m[0907 07-05-41 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18279, current rewards: -2392.43756, mean: -1.75915
[32m[0907 07-05-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18261, current rewards: -2492.43756, mean: -1.76769
[32m[0907 07-05-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18245, current rewards: -2592.43756, mean: -1.77564
[32m[0907 07-06-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18229, current rewards: -2692.43756, mean: -1.78307
[32m[0907 07-06-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18216, current rewards: -2792.43756, mean: -1.79002
[32m[0907 07-06-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18202, current rewards: -2892.43756, mean: -1.79655
[32m[0907 07-06-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18189, current rewards: -2992.43756, mean: -1.80267
[32m[0907 07-06-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18179, current rewards: -3092.43756, mean: -1.80844
[32m[0907 07-06-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18168, current rewards: -3192.43756, mean: -1.81388
[32m[0907 07-07-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18175, current rewards: -3292.43756, mean: -1.81903
[32m[0907 07-07-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18180, current rewards: -3392.43756, mean: -1.82389
[32m[0907 07-07-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18185, current rewards: -3492.43756, mean: -1.82850
[32m[0907 07-07-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18190, current rewards: -3592.43756, mean: -1.83288
[32m[0907 07-07-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18196, current rewards: -3692.43756, mean: -1.83703
[32m[0907 07-07-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18199, current rewards: -3792.43756, mean: -1.84099
[32m[0907 07-07-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18204, current rewards: -3892.43756, mean: -1.84476
[32m[0907 07-08-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18221, current rewards: -3992.43756, mean: -1.84835
[32m[0907 07-08-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18238, current rewards: -4092.43756, mean: -1.85178
[32m[0907 07-08-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18251, current rewards: -4192.43756, mean: -1.85506
[32m[0907 07-08-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18262, current rewards: -4292.43756, mean: -1.85820
[32m[0907 07-08-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18275, current rewards: -4392.43756, mean: -1.86120
[32m[0907 07-08-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18290, current rewards: -4492.43756, mean: -1.86408
[32m[0907 07-09-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18304, current rewards: -4592.43756, mean: -1.86684
[32m[0907 07-09-10 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0907 07-09-10 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-09-11 @MBExp.py:227][0m Rewards obtained: [-4672.437560623876], Lows: [2324], Highs: [44], Total time: 50380.64068000002
[32m[0907 07-13-02 @MBExp.py:144][0m ####################################################################
[32m[0907 07-13-02 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 07-13-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18874, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-13-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17938, current rewards: -71.87688, mean: -1.19795
[32m[0907 07-13-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17888, current rewards: -171.87688, mean: -1.56252
[32m[0907 07-13-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17956, current rewards: -223.48400, mean: -1.39677
[32m[0907 07-13-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18046, current rewards: -296.95276, mean: -1.41406
[32m[0907 07-13-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18042, current rewards: -378.40754, mean: -1.45541
[32m[0907 07-13-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18094, current rewards: -478.40754, mean: -1.54325
[32m[0907 07-14-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18160, current rewards: -571.67952, mean: -1.58800
[32m[0907 07-14-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18256, current rewards: -671.67952, mean: -1.63824
[32m[0907 07-14-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18288, current rewards: -771.67952, mean: -1.67756
[32m[0907 07-14-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18297, current rewards: -871.67952, mean: -1.70918
[32m[0907 07-14-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18303, current rewards: -971.67952, mean: -1.73514
[32m[0907 07-14-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18307, current rewards: -1071.67952, mean: -1.75685
[32m[0907 07-15-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18313, current rewards: -1171.67952, mean: -1.77527
[32m[0907 07-15-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18315, current rewards: -1271.67952, mean: -1.79110
[32m[0907 07-15-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18319, current rewards: -1344.19065, mean: -1.76867
[32m[0907 07-15-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18301, current rewards: -1428.91069, mean: -1.76409
[32m[0907 07-15-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18272, current rewards: -1474.34373, mean: -1.71435
[32m[0907 07-15-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18246, current rewards: -1524.34373, mean: -1.67510
[32m[0907 07-15-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18226, current rewards: -1574.34373, mean: -1.63994
[32m[0907 07-16-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18206, current rewards: -1624.34373, mean: -1.60826
[32m[0907 07-16-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18187, current rewards: -1674.34373, mean: -1.57957
[32m[0907 07-16-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18172, current rewards: -1724.34373, mean: -1.55346
[32m[0907 07-16-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18156, current rewards: -1725.75038, mean: -1.48772
[32m[0907 07-16-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18143, current rewards: -1722.90020, mean: -1.42388
[32m[0907 07-16-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18131, current rewards: -1720.05003, mean: -1.36512
[32m[0907 07-17-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18120, current rewards: -1717.19986, mean: -1.31084
[32m[0907 07-17-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18111, current rewards: -1717.52070, mean: -1.26288
[32m[0907 07-17-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18100, current rewards: -1767.52070, mean: -1.25356
[32m[0907 07-17-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18090, current rewards: -1817.52070, mean: -1.24488
[32m[0907 07-17-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18081, current rewards: -1867.52070, mean: -1.23677
[32m[0907 07-17-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18073, current rewards: -1917.52070, mean: -1.22918
[32m[0907 07-17-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18063, current rewards: -1967.52070, mean: -1.22206
[32m[0907 07-18-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18057, current rewards: -2017.52070, mean: -1.21537
[32m[0907 07-18-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18050, current rewards: -2067.52070, mean: -1.20908
[32m[0907 07-18-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18051, current rewards: -2117.52070, mean: -1.20314
[32m[0907 07-18-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18064, current rewards: -2167.52070, mean: -1.19753
[32m[0907 07-18-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18074, current rewards: -2225.52070, mean: -1.19652
[32m[0907 07-18-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18141, current rewards: -2292.99361, mean: -1.20052
[32m[0907 07-19-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18230, current rewards: -2347.14991, mean: -1.19753
[32m[0907 07-19-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18238, current rewards: -2391.35013, mean: -1.18973
[32m[0907 07-19-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18247, current rewards: -2452.12012, mean: -1.19035
[32m[0907 07-19-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18259, current rewards: -2542.06886, mean: -1.20477
[32m[0907 07-19-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18274, current rewards: -2592.06886, mean: -1.20003
[32m[0907 07-19-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18290, current rewards: -2642.06886, mean: -1.19551
[32m[0907 07-19-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18304, current rewards: -2692.06886, mean: -1.19118
[32m[0907 07-20-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18317, current rewards: -2742.06886, mean: -1.18704
[32m[0907 07-20-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18330, current rewards: -2792.06886, mean: -1.18308
[32m[0907 07-20-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18343, current rewards: -2842.06886, mean: -1.17928
[32m[0907 07-20-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18353, current rewards: -2892.06886, mean: -1.17564
[32m[0907 07-20-42 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0907 07-20-42 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-20-42 @MBExp.py:227][0m Rewards obtained: [-2932.0688550507257], Lows: [841], Highs: [1294], Total time: 50840.54487100002
[32m[0907 07-24-35 @MBExp.py:144][0m ####################################################################
[32m[0907 07-24-35 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 07-24-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17649, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-24-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17939, current rewards: -80.04176, mean: -1.33403
[32m[0907 07-24-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18085, current rewards: -108.82014, mean: -0.98927
[32m[0907 07-25-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18163, current rewards: -124.19920, mean: -0.77624
[32m[0907 07-25-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18135, current rewards: -172.26231, mean: -0.82030
[32m[0907 07-25-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18117, current rewards: -157.02203, mean: -0.60393
[32m[0907 07-25-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18162, current rewards: -143.64793, mean: -0.46338
[32m[0907 07-25-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18283, current rewards: -185.40839, mean: -0.51502
[32m[0907 07-25-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18349, current rewards: -235.34616, mean: -0.57402
[32m[0907 07-26-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18358, current rewards: -296.58518, mean: -0.64475
[32m[0907 07-26-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18382, current rewards: -362.17910, mean: -0.71016
[32m[0907 07-26-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18384, current rewards: -389.72557, mean: -0.69594
[32m[0907 07-26-28 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18411, current rewards: -413.29331, mean: -0.67753
[32m[0907 07-26-37 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18406, current rewards: -454.55970, mean: -0.68873
[32m[0907 07-26-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18406, current rewards: -491.48091, mean: -0.69223
[32m[0907 07-26-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18372, current rewards: -535.20218, mean: -0.70421
[32m[0907 07-27-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18341, current rewards: -584.35457, mean: -0.72143
[32m[0907 07-27-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18311, current rewards: -632.77094, mean: -0.73578
[32m[0907 07-27-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18284, current rewards: -681.13168, mean: -0.74850
[32m[0907 07-27-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18259, current rewards: -726.34954, mean: -0.75661
[32m[0907 07-27-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18236, current rewards: -773.75095, mean: -0.76609
[32m[0907 07-27-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18224, current rewards: -815.60166, mean: -0.76944
[32m[0907 07-27-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18206, current rewards: -847.95494, mean: -0.76392
[32m[0907 07-28-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18190, current rewards: -883.10677, mean: -0.76130
[32m[0907 07-28-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18174, current rewards: -921.19429, mean: -0.76132
[32m[0907 07-28-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18160, current rewards: -962.65347, mean: -0.76401
[32m[0907 07-28-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18147, current rewards: -991.43086, mean: -0.75682
[32m[0907 07-28-42 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18138, current rewards: -1038.46284, mean: -0.76358
[32m[0907 07-28-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18261, current rewards: -1074.54332, mean: -0.76209
[32m[0907 07-29-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18442, current rewards: -1100.48832, mean: -0.75376
[32m[0907 07-29-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18642, current rewards: -1110.62444, mean: -0.73551
[32m[0907 07-29-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18847, current rewards: -1117.74119, mean: -0.71650
[32m[0907 07-29-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19038, current rewards: -1127.39248, mean: -0.70024
[32m[0907 07-29-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19188, current rewards: -1141.83442, mean: -0.68785
[32m[0907 07-30-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19363, current rewards: -1150.62219, mean: -0.67288
[32m[0907 07-30-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19470, current rewards: -1180.79000, mean: -0.67090
[32m[0907 07-30-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19498, current rewards: -1236.24055, mean: -0.68301
[32m[0907 07-30-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.19556, current rewards: -1306.64311, mean: -0.70250
[32m[0907 07-30-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19667, current rewards: -1328.37630, mean: -0.69548
[32m[0907 07-31-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.19700, current rewards: -1395.40737, mean: -0.71194
[32m[0907 07-31-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.19680, current rewards: -1495.40737, mean: -0.74398
[32m[0907 07-31-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19663, current rewards: -1595.40737, mean: -0.77447
[32m[0907 07-31-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19645, current rewards: -1695.40737, mean: -0.80351
[32m[0907 07-31-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19628, current rewards: -1795.40737, mean: -0.83121
[32m[0907 07-31-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19612, current rewards: -1895.40737, mean: -0.85765
[32m[0907 07-31-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19598, current rewards: -1995.40737, mean: -0.88292
[32m[0907 07-32-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19594, current rewards: -2049.44349, mean: -0.88720
[32m[0907 07-32-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19586, current rewards: -2116.70532, mean: -0.89691
[32m[0907 07-32-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19572, current rewards: -2174.70196, mean: -0.90237
[32m[0907 07-32-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19557, current rewards: -2251.76092, mean: -0.91535
[32m[0907 07-32-45 @Agent.py:117][0m Average action selection time: 0.1955
[32m[0907 07-32-45 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-32-45 @MBExp.py:227][0m Rewards obtained: [-2312.699442874163], Lows: [1147], Highs: [243], Total time: 51330.11534700002
[32m[0907 07-36-40 @MBExp.py:144][0m ####################################################################
[32m[0907 07-36-40 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 07-36-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17663, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-36-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17736, current rewards: -110.00000, mean: -1.83333
[32m[0907 07-37-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17927, current rewards: -210.00000, mean: -1.90909
[32m[0907 07-37-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18136, current rewards: -310.00000, mean: -1.93750
[32m[0907 07-37-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18282, current rewards: -410.00000, mean: -1.95238
[32m[0907 07-37-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18310, current rewards: -510.00000, mean: -1.96154
[32m[0907 07-37-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18328, current rewards: -610.00000, mean: -1.96774
[32m[0907 07-37-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18341, current rewards: -710.00000, mean: -1.97222
[32m[0907 07-37-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18346, current rewards: -810.00000, mean: -1.97561
[32m[0907 07-38-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18350, current rewards: -910.00000, mean: -1.97826
[32m[0907 07-38-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18356, current rewards: -1010.00000, mean: -1.98039
[32m[0907 07-38-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18342, current rewards: -1107.61335, mean: -1.97788
[32m[0907 07-38-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18298, current rewards: -1205.27517, mean: -1.97586
[32m[0907 07-38-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18260, current rewards: -1305.27517, mean: -1.97769
[32m[0907 07-38-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18232, current rewards: -1405.27517, mean: -1.97926
[32m[0907 07-38-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18201, current rewards: -1505.27517, mean: -1.98063
[32m[0907 07-39-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18180, current rewards: -1605.27517, mean: -1.98182
[32m[0907 07-39-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18158, current rewards: -1705.27517, mean: -1.98288
[32m[0907 07-39-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18140, current rewards: -1805.27517, mean: -1.98382
[32m[0907 07-39-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18125, current rewards: -1905.27517, mean: -1.98466
[32m[0907 07-39-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18107, current rewards: -2005.27517, mean: -1.98542
[32m[0907 07-39-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18093, current rewards: -2105.27517, mean: -1.98611
[32m[0907 07-40-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18081, current rewards: -2205.27517, mean: -1.98673
[32m[0907 07-40-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18070, current rewards: -2305.27517, mean: -1.98731
[32m[0907 07-40-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18061, current rewards: -2405.27517, mean: -1.98783
[32m[0907 07-40-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18052, current rewards: -2505.27517, mean: -1.98831
[32m[0907 07-40-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18043, current rewards: -2605.27517, mean: -1.98876
[32m[0907 07-40-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18035, current rewards: -2705.27517, mean: -1.98917
[32m[0907 07-40-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18029, current rewards: -2805.27517, mean: -1.98956
[32m[0907 07-41-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18022, current rewards: -2905.27517, mean: -1.98991
[32m[0907 07-41-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18014, current rewards: -3005.27517, mean: -1.99025
[32m[0907 07-41-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18021, current rewards: -3105.27517, mean: -1.99056
[32m[0907 07-41-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18033, current rewards: -3205.27517, mean: -1.99085
[32m[0907 07-41-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18043, current rewards: -3305.27517, mean: -1.99113
[32m[0907 07-41-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18054, current rewards: -3405.27517, mean: -1.99139
[32m[0907 07-41-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18066, current rewards: -3505.27517, mean: -1.99163
[32m[0907 07-42-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18074, current rewards: -3605.27517, mean: -1.99186
[32m[0907 07-42-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18085, current rewards: -3705.27517, mean: -1.99208
[32m[0907 07-42-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18101, current rewards: -3805.27517, mean: -1.99229
[32m[0907 07-42-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18122, current rewards: -3905.27517, mean: -1.99249
[32m[0907 07-42-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18144, current rewards: -4005.27517, mean: -1.99267
[32m[0907 07-42-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18161, current rewards: -4105.27517, mean: -1.99285
[32m[0907 07-43-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18178, current rewards: -4205.27517, mean: -1.99302
[32m[0907 07-43-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18193, current rewards: -4305.27517, mean: -1.99318
[32m[0907 07-43-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18208, current rewards: -4405.27517, mean: -1.99334
[32m[0907 07-43-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18221, current rewards: -4505.27517, mean: -1.99348
[32m[0907 07-43-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18235, current rewards: -4605.27517, mean: -1.99363
[32m[0907 07-43-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18250, current rewards: -4705.27517, mean: -1.99376
[32m[0907 07-44-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18263, current rewards: -4805.27517, mean: -1.99389
[32m[0907 07-44-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18277, current rewards: -4905.27517, mean: -1.99401
[32m[0907 07-44-18 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 07-44-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-44-18 @MBExp.py:227][0m Rewards obtained: [-4985.275172506601], Lows: [2488], Highs: [10], Total time: 51788.12550300002
[32m[0907 07-48-14 @MBExp.py:144][0m ####################################################################
[32m[0907 07-48-14 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 07-48-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18750, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-48-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19021, current rewards: -68.03746, mean: -1.13396
[32m[0907 07-48-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18774, current rewards: -152.64576, mean: -1.38769
[32m[0907 07-48-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19186, current rewards: -230.80300, mean: -1.44252
[32m[0907 07-48-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19355, current rewards: -269.41698, mean: -1.28294
[32m[0907 07-49-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19217, current rewards: -309.48888, mean: -1.19034
[32m[0907 07-49-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19078, current rewards: -356.49553, mean: -1.14999
[32m[0907 07-49-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19070, current rewards: -399.69614, mean: -1.11027
[32m[0907 07-49-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19019, current rewards: -448.33836, mean: -1.09351
[32m[0907 07-49-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18977, current rewards: -486.84858, mean: -1.05837
[32m[0907 07-49-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18933, current rewards: -531.20278, mean: -1.04157
[32m[0907 07-50-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18837, current rewards: -631.20278, mean: -1.12715
[32m[0907 07-50-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18754, current rewards: -731.20278, mean: -1.19869
[32m[0907 07-50-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18684, current rewards: -831.20278, mean: -1.25940
[32m[0907 07-50-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18624, current rewards: -931.20278, mean: -1.31155
[32m[0907 07-50-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18569, current rewards: -1031.20278, mean: -1.35685
[32m[0907 07-50-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18523, current rewards: -1131.20278, mean: -1.39655
[32m[0907 07-50-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18486, current rewards: -1231.20278, mean: -1.43163
[32m[0907 07-51-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18451, current rewards: -1331.20278, mean: -1.46286
[32m[0907 07-51-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18419, current rewards: -1431.20278, mean: -1.49084
[32m[0907 07-51-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18388, current rewards: -1531.20278, mean: -1.51604
[32m[0907 07-51-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18363, current rewards: -1631.20278, mean: -1.53887
[32m[0907 07-51-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18337, current rewards: -1731.20278, mean: -1.55964
[32m[0907 07-51-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18314, current rewards: -1831.20278, mean: -1.57862
[32m[0907 07-51-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18296, current rewards: -1931.20278, mean: -1.59604
[32m[0907 07-52-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18276, current rewards: -2031.20278, mean: -1.61207
[32m[0907 07-52-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18258, current rewards: -2131.20278, mean: -1.62687
[32m[0907 07-52-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18243, current rewards: -2231.20278, mean: -1.64059
[32m[0907 07-52-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18228, current rewards: -2331.20278, mean: -1.65334
[32m[0907 07-52-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18214, current rewards: -2431.20278, mean: -1.66521
[32m[0907 07-52-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18208, current rewards: -2531.20278, mean: -1.67629
[32m[0907 07-52-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18213, current rewards: -2631.20278, mean: -1.68667
[32m[0907 07-53-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18217, current rewards: -2731.20278, mean: -1.69640
[32m[0907 07-53-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18221, current rewards: -2831.20278, mean: -1.70554
[32m[0907 07-53-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18233, current rewards: -2875.35120, mean: -1.68149
[32m[0907 07-53-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18241, current rewards: -2895.26907, mean: -1.64504
[32m[0907 07-53-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18244, current rewards: -2906.62691, mean: -1.60587
[32m[0907 07-53-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18261, current rewards: -2923.08891, mean: -1.57155
[32m[0907 07-54-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18280, current rewards: -2936.82257, mean: -1.53760
[32m[0907 07-54-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18309, current rewards: -2949.19806, mean: -1.50469
[32m[0907 07-54-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18348, current rewards: -2969.37367, mean: -1.47730
[32m[0907 07-54-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18398, current rewards: -3039.86999, mean: -1.47567
[32m[0907 07-54-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18454, current rewards: -3087.60865, mean: -1.46332
[32m[0907 07-54-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18482, current rewards: -3161.55265, mean: -1.46368
[32m[0907 07-55-04 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18511, current rewards: -3232.19731, mean: -1.46253
[32m[0907 07-55-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18553, current rewards: -3296.84659, mean: -1.45878
[32m[0907 07-55-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18576, current rewards: -3364.64354, mean: -1.45656
[32m[0907 07-55-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18609, current rewards: -3417.18625, mean: -1.44796
[32m[0907 07-55-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18631, current rewards: -3486.21730, mean: -1.44656
[32m[0907 07-55-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18651, current rewards: -3555.41839, mean: -1.44529
[32m[0907 07-56-01 @Agent.py:117][0m Average action selection time: 0.1866
[32m[0907 07-56-01 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-56-02 @MBExp.py:227][0m Rewards obtained: [-3624.6290432481037], Lows: [1880], Highs: [34], Total time: 52255.482316000016
[32m[0907 08-00-00 @MBExp.py:144][0m ####################################################################
[32m[0907 08-00-00 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 08-00-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18971, current rewards: 1.20711, mean: 0.12071
[32m[0907 08-00-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17990, current rewards: -59.47098, mean: -0.99118
[32m[0907 08-00-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18088, current rewards: -159.47098, mean: -1.44974
[32m[0907 08-00-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18182, current rewards: -259.47098, mean: -1.62169
[32m[0907 08-00-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18239, current rewards: -359.47098, mean: -1.71177
[32m[0907 08-00-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18257, current rewards: -459.47098, mean: -1.76720
[32m[0907 08-00-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18287, current rewards: -559.47098, mean: -1.80475
[32m[0907 08-01-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18309, current rewards: -659.47098, mean: -1.83186
[32m[0907 08-01-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18323, current rewards: -759.47098, mean: -1.85237
[32m[0907 08-01-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18302, current rewards: -859.47098, mean: -1.86842
[32m[0907 08-01-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18256, current rewards: -959.47098, mean: -1.88132
[32m[0907 08-01-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18216, current rewards: -1059.47098, mean: -1.89191
[32m[0907 08-01-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18186, current rewards: -1159.47098, mean: -1.90077
[32m[0907 08-02-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18159, current rewards: -1259.47098, mean: -1.90829
[32m[0907 08-02-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18137, current rewards: -1359.47098, mean: -1.91475
[32m[0907 08-02-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18118, current rewards: -1459.47098, mean: -1.92036
[32m[0907 08-02-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18102, current rewards: -1559.47098, mean: -1.92527
[32m[0907 08-02-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18087, current rewards: -1659.47098, mean: -1.92962
[32m[0907 08-02-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18072, current rewards: -1759.47098, mean: -1.93348
[32m[0907 08-02-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18060, current rewards: -1859.47098, mean: -1.93695
[32m[0907 08-03-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18046, current rewards: -1959.47098, mean: -1.94007
[32m[0907 08-03-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18036, current rewards: -2059.47098, mean: -1.94290
[32m[0907 08-03-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18026, current rewards: -2159.47098, mean: -1.94547
[32m[0907 08-03-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18017, current rewards: -2259.47098, mean: -1.94782
[32m[0907 08-03-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18009, current rewards: -2359.47098, mean: -1.94998
[32m[0907 08-03-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17999, current rewards: -2459.47098, mean: -1.95196
[32m[0907 08-03-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17992, current rewards: -2559.47098, mean: -1.95379
[32m[0907 08-04-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17987, current rewards: -2659.47098, mean: -1.95549
[32m[0907 08-04-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17983, current rewards: -2759.47098, mean: -1.95707
[32m[0907 08-04-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17987, current rewards: -2859.47098, mean: -1.95854
[32m[0907 08-04-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18001, current rewards: -2959.47098, mean: -1.95991
[32m[0907 08-04-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18014, current rewards: -3059.47098, mean: -1.96120
[32m[0907 08-04-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18026, current rewards: -3159.47098, mean: -1.96240
[32m[0907 08-05-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18035, current rewards: -3259.47098, mean: -1.96354
[32m[0907 08-05-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18045, current rewards: -3359.47098, mean: -1.96460
[32m[0907 08-05-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18059, current rewards: -3459.47098, mean: -1.96561
[32m[0907 08-05-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18071, current rewards: -3559.47098, mean: -1.96656
[32m[0907 08-05-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18096, current rewards: -3659.47098, mean: -1.96746
[32m[0907 08-05-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18119, current rewards: -3759.47098, mean: -1.96831
[32m[0907 08-05-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18138, current rewards: -3859.47098, mean: -1.96912
[32m[0907 08-06-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18158, current rewards: -3959.47098, mean: -1.96989
[32m[0907 08-06-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18175, current rewards: -4059.47098, mean: -1.97062
[32m[0907 08-06-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18193, current rewards: -4159.47098, mean: -1.97131
[32m[0907 08-06-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18212, current rewards: -4259.47098, mean: -1.97198
[32m[0907 08-06-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18229, current rewards: -4359.47098, mean: -1.97261
[32m[0907 08-06-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18243, current rewards: -4459.47098, mean: -1.97322
[32m[0907 08-07-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18256, current rewards: -4559.47098, mean: -1.97380
[32m[0907 08-07-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18272, current rewards: -4659.47098, mean: -1.97435
[32m[0907 08-07-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18285, current rewards: -4759.47098, mean: -1.97488
[32m[0907 08-07-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18299, current rewards: -4859.47098, mean: -1.97539
[32m[0907 08-07-38 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0907 08-07-38 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-07-39 @MBExp.py:227][0m Rewards obtained: [-4939.470981289408], Lows: [2471], Highs: [0], Total time: 52714.041911000015
[32m[0907 08-11-39 @MBExp.py:144][0m ####################################################################
[32m[0907 08-11-39 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 08-11-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18762, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-11-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19059, current rewards: -78.37932, mean: -1.30632
[32m[0907 08-12-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18662, current rewards: -153.05707, mean: -1.39143
[32m[0907 08-12-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18650, current rewards: -228.42870, mean: -1.42768
[32m[0907 08-12-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18457, current rewards: -328.42870, mean: -1.56395
[32m[0907 08-12-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18433, current rewards: -428.42870, mean: -1.64780
[32m[0907 08-12-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18428, current rewards: -528.42870, mean: -1.70461
[32m[0907 08-12-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18425, current rewards: -628.42870, mean: -1.74564
[32m[0907 08-12-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18421, current rewards: -728.42870, mean: -1.77666
[32m[0907 08-13-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18374, current rewards: -828.42870, mean: -1.80093
[32m[0907 08-13-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18319, current rewards: -928.42870, mean: -1.82045
[32m[0907 08-13-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18277, current rewards: -1028.42870, mean: -1.83648
[32m[0907 08-13-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18240, current rewards: -1128.42870, mean: -1.84988
[32m[0907 08-13-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18213, current rewards: -1228.42870, mean: -1.86126
[32m[0907 08-13-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18185, current rewards: -1328.42870, mean: -1.87103
[32m[0907 08-13-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18165, current rewards: -1428.42870, mean: -1.87951
[32m[0907 08-14-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18146, current rewards: -1528.42870, mean: -1.88695
[32m[0907 08-14-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18129, current rewards: -1628.42870, mean: -1.89352
[32m[0907 08-14-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18110, current rewards: -1728.42870, mean: -1.89937
[32m[0907 08-14-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18095, current rewards: -1828.42870, mean: -1.90461
[32m[0907 08-14-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18083, current rewards: -1928.42870, mean: -1.90934
[32m[0907 08-14-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18072, current rewards: -2028.42870, mean: -1.91361
[32m[0907 08-15-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18061, current rewards: -2128.42870, mean: -1.91750
[32m[0907 08-15-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18053, current rewards: -2228.42870, mean: -1.92106
[32m[0907 08-15-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18044, current rewards: -2328.42870, mean: -1.92432
[32m[0907 08-15-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18034, current rewards: -2428.42870, mean: -1.92732
[32m[0907 08-15-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18025, current rewards: -2528.42870, mean: -1.93010
[32m[0907 08-15-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18017, current rewards: -2628.42870, mean: -1.93267
[32m[0907 08-15-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18009, current rewards: -2728.42870, mean: -1.93506
[32m[0907 08-16-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18018, current rewards: -2828.42870, mean: -1.93728
[32m[0907 08-16-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18031, current rewards: -2928.42870, mean: -1.93936
[32m[0907 08-16-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18044, current rewards: -3028.42870, mean: -1.94130
[32m[0907 08-16-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18055, current rewards: -3128.42870, mean: -1.94312
[32m[0907 08-16-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18066, current rewards: -3228.42870, mean: -1.94484
[32m[0907 08-16-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18076, current rewards: -3328.42870, mean: -1.94645
[32m[0907 08-16-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18087, current rewards: -3428.42870, mean: -1.94797
[32m[0907 08-17-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18099, current rewards: -3528.42870, mean: -1.94941
[32m[0907 08-17-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18123, current rewards: -3628.42870, mean: -1.95077
[32m[0907 08-17-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18146, current rewards: -3728.42870, mean: -1.95206
[32m[0907 08-17-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18167, current rewards: -3828.42870, mean: -1.95328
[32m[0907 08-17-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18186, current rewards: -3928.42870, mean: -1.95444
[32m[0907 08-17-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18206, current rewards: -4028.42870, mean: -1.95555
[32m[0907 08-18-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18222, current rewards: -4128.42870, mean: -1.95660
[32m[0907 08-18-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18238, current rewards: -4228.42870, mean: -1.95761
[32m[0907 08-18-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18253, current rewards: -4328.42870, mean: -1.95857
[32m[0907 08-18-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18267, current rewards: -4428.42870, mean: -1.95948
[32m[0907 08-18-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18281, current rewards: -4528.42870, mean: -1.96036
[32m[0907 08-18-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18294, current rewards: -4628.42870, mean: -1.96120
[32m[0907 08-19-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18306, current rewards: -4728.42870, mean: -1.96200
[32m[0907 08-19-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18318, current rewards: -4828.42870, mean: -1.96278
[32m[0907 08-19-18 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0907 08-19-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-19-18 @MBExp.py:227][0m Rewards obtained: [-4908.4287044072535], Lows: [2432], Highs: [47], Total time: 53173.09434800001
[32m[0907 08-23-21 @MBExp.py:144][0m ####################################################################
[32m[0907 08-23-21 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 08-23-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17569, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-23-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17870, current rewards: -78.65597, mean: -1.31093
[32m[0907 08-23-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18117, current rewards: -130.31603, mean: -1.18469
[32m[0907 08-23-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18190, current rewards: -199.88167, mean: -1.24926
[32m[0907 08-23-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18204, current rewards: -261.11414, mean: -1.24340
[32m[0907 08-24-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18391, current rewards: -326.41656, mean: -1.25545
[32m[0907 08-24-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18499, current rewards: -381.30791, mean: -1.23003
[32m[0907 08-24-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18561, current rewards: -447.73680, mean: -1.24371
[32m[0907 08-24-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18580, current rewards: -514.01894, mean: -1.25370
[32m[0907 08-24-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18498, current rewards: -586.33336, mean: -1.27464
[32m[0907 08-24-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18499, current rewards: -655.90242, mean: -1.28608
[32m[0907 08-25-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18458, current rewards: -730.69717, mean: -1.30482
[32m[0907 08-25-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18415, current rewards: -809.12102, mean: -1.32643
[32m[0907 08-25-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18431, current rewards: -878.18642, mean: -1.33059
[32m[0907 08-25-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18422, current rewards: -959.52907, mean: -1.35145
[32m[0907 08-25-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18444, current rewards: -1031.09293, mean: -1.35670
[32m[0907 08-25-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18418, current rewards: -1108.66181, mean: -1.36872
[32m[0907 08-25-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18381, current rewards: -1208.66181, mean: -1.40542
[32m[0907 08-26-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18347, current rewards: -1308.66181, mean: -1.43809
[32m[0907 08-26-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18319, current rewards: -1408.66181, mean: -1.46736
[32m[0907 08-26-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18293, current rewards: -1508.66181, mean: -1.49372
[32m[0907 08-26-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18270, current rewards: -1608.66181, mean: -1.51761
[32m[0907 08-26-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18249, current rewards: -1708.66181, mean: -1.53933
[32m[0907 08-26-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18228, current rewards: -1808.66181, mean: -1.55919
[32m[0907 08-27-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18208, current rewards: -1908.66181, mean: -1.57741
[32m[0907 08-27-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18192, current rewards: -2008.66181, mean: -1.59418
[32m[0907 08-27-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18178, current rewards: -2108.66181, mean: -1.60967
[32m[0907 08-27-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18162, current rewards: -2208.66181, mean: -1.62402
[32m[0907 08-27-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18149, current rewards: -2308.66181, mean: -1.63735
[32m[0907 08-27-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18140, current rewards: -2408.66181, mean: -1.64977
[32m[0907 08-27-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18148, current rewards: -2508.66181, mean: -1.66137
[32m[0907 08-28-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18154, current rewards: -2608.66181, mean: -1.67222
[32m[0907 08-28-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18162, current rewards: -2708.66181, mean: -1.68240
[32m[0907 08-28-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18167, current rewards: -2808.66181, mean: -1.69196
[32m[0907 08-28-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18173, current rewards: -2908.66181, mean: -1.70097
[32m[0907 08-28-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18183, current rewards: -3008.66181, mean: -1.70947
[32m[0907 08-28-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18206, current rewards: -3108.66181, mean: -1.71749
[32m[0907 08-29-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18225, current rewards: -3208.66181, mean: -1.72509
[32m[0907 08-29-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18242, current rewards: -3308.66181, mean: -1.73228
[32m[0907 08-29-19 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18259, current rewards: -3408.66181, mean: -1.73911
[32m[0907 08-29-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18274, current rewards: -3508.66181, mean: -1.74560
[32m[0907 08-29-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18289, current rewards: -3608.66181, mean: -1.75178
[32m[0907 08-29-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18304, current rewards: -3708.66181, mean: -1.75766
[32m[0907 08-29-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18319, current rewards: -3808.66181, mean: -1.76327
[32m[0907 08-30-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18330, current rewards: -3908.66181, mean: -1.76863
[32m[0907 08-30-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18342, current rewards: -4008.66181, mean: -1.77374
[32m[0907 08-30-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18353, current rewards: -4108.66181, mean: -1.77864
[32m[0907 08-30-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18362, current rewards: -4208.66181, mean: -1.78333
[32m[0907 08-30-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18373, current rewards: -4308.66181, mean: -1.78783
[32m[0907 08-30-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18383, current rewards: -4408.66181, mean: -1.79214
[32m[0907 08-31-02 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0907 08-31-02 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-31-02 @MBExp.py:227][0m Rewards obtained: [-4488.661807599277], Lows: [2104], Highs: [291], Total time: 53633.784433000015
[32m[0907 08-35-06 @MBExp.py:144][0m ####################################################################
[32m[0907 08-35-06 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 08-35-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17697, current rewards: 1.46936, mean: 0.14694
[32m[0907 08-35-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17759, current rewards: -98.53064, mean: -1.64218
[32m[0907 08-35-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17807, current rewards: -198.53064, mean: -1.80482
[32m[0907 08-35-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17789, current rewards: -298.53064, mean: -1.86582
[32m[0907 08-35-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17830, current rewards: -398.53064, mean: -1.89776
[32m[0907 08-35-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17926, current rewards: -498.53064, mean: -1.91743
[32m[0907 08-36-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18006, current rewards: -598.53064, mean: -1.93074
[32m[0907 08-36-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17993, current rewards: -698.53064, mean: -1.94036
[32m[0907 08-36-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17979, current rewards: -798.53064, mean: -1.94764
[32m[0907 08-36-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17967, current rewards: -898.53064, mean: -1.95333
[32m[0907 08-36-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17957, current rewards: -981.65023, mean: -1.92480
[32m[0907 08-36-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17946, current rewards: -1067.20301, mean: -1.90572
[32m[0907 08-36-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17936, current rewards: -1153.74268, mean: -1.89138
[32m[0907 08-37-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17927, current rewards: -1227.18663, mean: -1.85937
[32m[0907 08-37-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17921, current rewards: -1304.90517, mean: -1.83789
[32m[0907 08-37-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17916, current rewards: -1386.87370, mean: -1.82483
[32m[0907 08-37-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17911, current rewards: -1486.87370, mean: -1.83565
[32m[0907 08-37-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17907, current rewards: -1586.87370, mean: -1.84520
[32m[0907 08-37-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17901, current rewards: -1686.87370, mean: -1.85371
[32m[0907 08-37-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17899, current rewards: -1786.87370, mean: -1.86133
[32m[0907 08-38-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17895, current rewards: -1886.87370, mean: -1.86819
[32m[0907 08-38-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17892, current rewards: -1986.87370, mean: -1.87441
[32m[0907 08-38-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17891, current rewards: -2086.87370, mean: -1.88007
[32m[0907 08-38-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17888, current rewards: -2186.87370, mean: -1.88524
[32m[0907 08-38-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17884, current rewards: -2286.87370, mean: -1.88998
[32m[0907 08-38-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17882, current rewards: -2386.87370, mean: -1.89434
[32m[0907 08-39-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17880, current rewards: -2486.87370, mean: -1.89838
[32m[0907 08-39-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17880, current rewards: -2586.87370, mean: -1.90211
[32m[0907 08-39-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17878, current rewards: -2686.87370, mean: -1.90558
[32m[0907 08-39-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17888, current rewards: -2786.87370, mean: -1.90882
[32m[0907 08-39-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17906, current rewards: -2886.87370, mean: -1.91184
[32m[0907 08-39-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17920, current rewards: -2986.87370, mean: -1.91466
[32m[0907 08-39-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17935, current rewards: -3086.87370, mean: -1.91731
[32m[0907 08-40-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17951, current rewards: -3186.87370, mean: -1.91980
[32m[0907 08-40-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17963, current rewards: -3286.87370, mean: -1.92215
[32m[0907 08-40-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17986, current rewards: -3386.87370, mean: -1.92436
[32m[0907 08-40-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18014, current rewards: -3486.87370, mean: -1.92645
[32m[0907 08-40-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18038, current rewards: -3586.87370, mean: -1.92843
[32m[0907 08-40-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18061, current rewards: -3686.87370, mean: -1.93030
[32m[0907 08-41-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18082, current rewards: -3786.87370, mean: -1.93208
[32m[0907 08-41-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18101, current rewards: -3886.87370, mean: -1.93377
[32m[0907 08-41-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18122, current rewards: -3986.87370, mean: -1.93538
[32m[0907 08-41-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18140, current rewards: -4086.87370, mean: -1.93691
[32m[0907 08-41-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18160, current rewards: -4186.87370, mean: -1.93837
[32m[0907 08-41-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18176, current rewards: -4286.87370, mean: -1.93976
[32m[0907 08-41-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18191, current rewards: -4386.87370, mean: -1.94109
[32m[0907 08-42-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18207, current rewards: -4486.87370, mean: -1.94237
[32m[0907 08-42-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18222, current rewards: -4586.87370, mean: -1.94359
[32m[0907 08-42-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18236, current rewards: -4686.87370, mean: -1.94476
[32m[0907 08-42-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18249, current rewards: -4786.87370, mean: -1.94588
[32m[0907 08-42-43 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0907 08-42-43 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-42-44 @MBExp.py:227][0m Rewards obtained: [-4866.873703365526], Lows: [2427], Highs: [23], Total time: 54091.138368000014
[32m[0907 08-46-50 @MBExp.py:144][0m ####################################################################
[32m[0907 08-46-50 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 08-46-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20248, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-47-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17922, current rewards: -56.82871, mean: -0.94715
[32m[0907 08-47-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17876, current rewards: -106.82871, mean: -0.97117
[32m[0907 08-47-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17864, current rewards: -156.82871, mean: -0.98018
[32m[0907 08-47-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17909, current rewards: -206.82871, mean: -0.98490
[32m[0907 08-47-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18005, current rewards: -256.82871, mean: -0.98780
[32m[0907 08-47-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18049, current rewards: -306.82871, mean: -0.98977
[32m[0907 08-47-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18020, current rewards: -356.82871, mean: -0.99119
[32m[0907 08-48-04 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18003, current rewards: -406.82871, mean: -0.99227
[32m[0907 08-48-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17985, current rewards: -456.82871, mean: -0.99311
[32m[0907 08-48-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17969, current rewards: -506.82871, mean: -0.99378
[32m[0907 08-48-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17957, current rewards: -556.82871, mean: -0.99434
[32m[0907 08-48-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17945, current rewards: -606.82871, mean: -0.99480
[32m[0907 08-48-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17937, current rewards: -656.82871, mean: -0.99520
[32m[0907 08-48-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17931, current rewards: -706.82871, mean: -0.99553
[32m[0907 08-49-07 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17927, current rewards: -756.82871, mean: -0.99583
[32m[0907 08-49-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17916, current rewards: -806.82871, mean: -0.99608
[32m[0907 08-49-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17908, current rewards: -856.82871, mean: -0.99631
[32m[0907 08-49-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17902, current rewards: -906.82871, mean: -0.99652
[32m[0907 08-49-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17897, current rewards: -956.82871, mean: -0.99670
[32m[0907 08-49-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17892, current rewards: -1006.82871, mean: -0.99686
[32m[0907 08-50-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17889, current rewards: -1056.82871, mean: -0.99701
[32m[0907 08-50-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17887, current rewards: -1106.82871, mean: -0.99714
[32m[0907 08-50-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17882, current rewards: -1156.82871, mean: -0.99727
[32m[0907 08-50-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17879, current rewards: -1206.82871, mean: -0.99738
[32m[0907 08-50-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17878, current rewards: -1256.82871, mean: -0.99748
[32m[0907 08-50-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17877, current rewards: -1306.82871, mean: -0.99758
[32m[0907 08-50-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17874, current rewards: -1356.82871, mean: -0.99767
[32m[0907 08-51-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17872, current rewards: -1406.82871, mean: -0.99775
[32m[0907 08-51-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17888, current rewards: -1456.82871, mean: -0.99783
[32m[0907 08-51-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17908, current rewards: -1506.82871, mean: -0.99790
[32m[0907 08-51-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17924, current rewards: -1556.82871, mean: -0.99797
[32m[0907 08-51-40 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17938, current rewards: -1606.82871, mean: -0.99803
[32m[0907 08-51-49 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17951, current rewards: -1656.82871, mean: -0.99809
[32m[0907 08-51-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17964, current rewards: -1706.82871, mean: -0.99815
[32m[0907 08-52-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17991, current rewards: -1756.82871, mean: -0.99820
[32m[0907 08-52-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18017, current rewards: -1806.82871, mean: -0.99825
[32m[0907 08-52-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18041, current rewards: -1856.82871, mean: -0.99830
[32m[0907 08-52-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18062, current rewards: -1906.82871, mean: -0.99834
[32m[0907 08-52-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18085, current rewards: -1956.82871, mean: -0.99838
[32m[0907 08-52-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18108, current rewards: -2006.82871, mean: -0.99842
[32m[0907 08-53-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18127, current rewards: -2056.82871, mean: -0.99846
[32m[0907 08-53-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18146, current rewards: -2106.82871, mean: -0.99850
[32m[0907 08-53-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18164, current rewards: -2156.82871, mean: -0.99853
[32m[0907 08-53-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18180, current rewards: -2206.82871, mean: -0.99857
[32m[0907 08-53-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18198, current rewards: -2205.13695, mean: -0.97572
[32m[0907 08-53-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18217, current rewards: -2200.05285, mean: -0.95240
[32m[0907 08-54-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18231, current rewards: -2193.87517, mean: -0.92961
[32m[0907 08-54-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18244, current rewards: -2187.69749, mean: -0.90776
[32m[0907 08-54-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18259, current rewards: -2181.51981, mean: -0.88680
[32m[0907 08-54-28 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0907 08-54-28 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-54-28 @MBExp.py:227][0m Rewards obtained: [-2176.577661161114], Lows: [0], Highs: [2208], Total time: 54548.77372000001
[32m[0907 08-58-37 @MBExp.py:144][0m ####################################################################
[32m[0907 08-58-37 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 08-58-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17804, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-58-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18043, current rewards: -110.00000, mean: -1.83333
[32m[0907 08-58-56 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17265, current rewards: -210.00000, mean: -1.90909
[32m[0907 08-59-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.16952, current rewards: -310.00000, mean: -1.93750
[32m[0907 08-59-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.16791, current rewards: -410.00000, mean: -1.95238
[32m[0907 08-59-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.16803, current rewards: -510.00000, mean: -1.96154
[32m[0907 08-59-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.16773, current rewards: -610.00000, mean: -1.96774
[32m[0907 08-59-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.16502, current rewards: -691.89615, mean: -1.92193
[32m[0907 08-59-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.16311, current rewards: -750.24766, mean: -1.82987
[32m[0907 08-59-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.16150, current rewards: -821.97224, mean: -1.78690
[32m[0907 08-59-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.16019, current rewards: -886.09063, mean: -1.73743
[32m[0907 09-00-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.15932, current rewards: -939.51753, mean: -1.67771
[32m[0907 09-00-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.15840, current rewards: -1005.31815, mean: -1.64806
[32m[0907 09-00-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.15777, current rewards: -1049.65322, mean: -1.59038
[32m[0907 09-00-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.15730, current rewards: -1106.27495, mean: -1.55813
[32m[0907 09-00-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.15682, current rewards: -1165.11291, mean: -1.53304
[32m[0907 09-00-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.15628, current rewards: -1265.11291, mean: -1.56187
[32m[0907 09-00-51 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.15582, current rewards: -1365.11291, mean: -1.58734
[32m[0907 09-00-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.15539, current rewards: -1465.11291, mean: -1.61001
[32m[0907 09-01-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.15503, current rewards: -1565.11291, mean: -1.63033
[32m[0907 09-01-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.15470, current rewards: -1665.11291, mean: -1.64863
[32m[0907 09-01-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.15439, current rewards: -1765.11291, mean: -1.66520
[32m[0907 09-01-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.15410, current rewards: -1865.11291, mean: -1.68028
[32m[0907 09-01-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.15384, current rewards: -1965.11291, mean: -1.69406
[32m[0907 09-01-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.15361, current rewards: -2065.11291, mean: -1.70670
[32m[0907 09-01-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.15342, current rewards: -2165.11291, mean: -1.71834
[32m[0907 09-01-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.15322, current rewards: -2265.11291, mean: -1.72909
[32m[0907 09-02-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.15307, current rewards: -2318.60905, mean: -1.70486
[32m[0907 09-02-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.15294, current rewards: -2374.12471, mean: -1.68378
[32m[0907 09-02-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.15279, current rewards: -2422.49685, mean: -1.65924
[32m[0907 09-02-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.15264, current rewards: -2455.30871, mean: -1.62603
[32m[0907 09-02-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.15249, current rewards: -2505.30871, mean: -1.60597
[32m[0907 09-02-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.15235, current rewards: -2555.30871, mean: -1.58715
[32m[0907 09-02-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.15223, current rewards: -2569.35499, mean: -1.54780
[32m[0907 09-02-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.15211, current rewards: -2563.17731, mean: -1.49893
[32m[0907 09-03-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.15200, current rewards: -2556.99963, mean: -1.45284
[32m[0907 09-03-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.15188, current rewards: -2550.82195, mean: -1.40929
[32m[0907 09-03-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.15179, current rewards: -2587.33930, mean: -1.39104
[32m[0907 09-03-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.15169, current rewards: -2637.33930, mean: -1.38081
[32m[0907 09-03-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.15160, current rewards: -2687.33930, mean: -1.37109
[32m[0907 09-03-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.15151, current rewards: -2737.33930, mean: -1.36186
[32m[0907 09-03-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.15143, current rewards: -2787.33930, mean: -1.35308
[32m[0907 09-03-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.15135, current rewards: -2837.33930, mean: -1.34471
[32m[0907 09-04-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.15128, current rewards: -2887.33930, mean: -1.33673
[32m[0907 09-04-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.15121, current rewards: -2937.33930, mean: -1.32911
[32m[0907 09-04-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.15114, current rewards: -2987.33930, mean: -1.32183
[32m[0907 09-04-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.15108, current rewards: -3037.33930, mean: -1.31487
[32m[0907 09-04-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.15101, current rewards: -3087.33930, mean: -1.30819
[32m[0907 09-04-41 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.15095, current rewards: -3137.33930, mean: -1.30180
[32m[0907 09-04-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.15089, current rewards: -3187.33930, mean: -1.29567
[32m[0907 09-04-55 @Agent.py:117][0m Average action selection time: 0.1508
[32m[0907 09-04-55 @Agent.py:118][0m Rollout length: 2510
[32m[0907 09-04-55 @MBExp.py:227][0m Rewards obtained: [-3227.339302329716], Lows: [1031], Highs: [1196], Total time: 54926.72028400001
