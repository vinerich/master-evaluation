[32m[0906 13-39-53 @logger.py:99][0m Log file set to /app/logs/dats-delay-10/zinc-coating-v0_1/Tuesday_06_September_2022_01-39PM.log
[32m[0906 13-39-53 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -61.63159, mean: -1.02719
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -110.43241, mean: -1.00393
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -170.65784, mean: -1.06661
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -218.34615, mean: -1.03974
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -272.02628, mean: -1.04625
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -322.45883, mean: -1.04019
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -377.49875, mean: -1.04861
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -438.51611, mean: -1.06955
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -491.59880, mean: -1.06869
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -551.24674, mean: -1.08088
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -607.88172, mean: -1.08550
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -666.77148, mean: -1.09307
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -724.86590, mean: -1.09828
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -788.60108, mean: -1.11071
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -857.73664, mean: -1.12860
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -924.40942, mean: -1.14125
[32m[0906 13-39-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1002.24504, mean: -1.16540
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1095.59762, mean: -1.20395
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1178.03320, mean: -1.22712
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1229.00505, mean: -1.21684
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1279.83950, mean: -1.20740
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1344.83161, mean: -1.21156
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1393.34563, mean: -1.20116
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1444.14389, mean: -1.19351
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1488.65152, mean: -1.18147
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1535.45187, mean: -1.17210
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1580.65933, mean: -1.16225
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1640.64044, mean: -1.16357
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1687.83078, mean: -1.15605
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1741.50916, mean: -1.15332
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -1785.24690, mean: -1.14439
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -1845.15967, mean: -1.14606
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -1905.97481, mean: -1.14818
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -1959.24235, mean: -1.14576
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2014.35629, mean: -1.14452
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2057.91498, mean: -1.13697
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2110.70338, mean: -1.13479
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2161.68395, mean: -1.13177
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2213.38954, mean: -1.12928
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2288.05873, mean: -1.13834
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2340.71289, mean: -1.13627
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2408.31977, mean: -1.14138
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2464.98980, mean: -1.14120
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2524.31712, mean: -1.14222
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2577.43981, mean: -1.14046
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2635.76182, mean: -1.14102
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2687.15777, mean: -1.13863
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2735.77123, mean: -1.13517
[32m[0906 13-39-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2783.13885, mean: -1.13136
[32m[0906 13-39-54 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-39-54 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-39-56 @MBExp.py:144][0m ####################################################################
[32m[0906 13-39-56 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-39-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.13757, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.12663, current rewards: -45.34577, mean: -0.75576
[32m[0906 13-40-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.12661, current rewards: -36.33335, mean: -0.33030
[32m[0906 13-40-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.13023, current rewards: -21.17380, mean: -0.13234
[32m[0906 13-40-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.13414, current rewards: -5.89220, mean: -0.02806
[32m[0906 13-40-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.13713, current rewards: 9.33228, mean: 0.03589
[32m[0906 13-40-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.14113, current rewards: 24.56392, mean: 0.07924
[32m[0906 13-40-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.14510, current rewards: 39.81147, mean: 0.11059
[32m[0906 13-40-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.14805, current rewards: 55.07048, mean: 0.13432
[32m[0906 13-41-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.15032, current rewards: 70.30498, mean: 0.15284
[32m[0906 13-41-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.15211, current rewards: 82.23173, mean: 0.16124
[32m[0906 13-41-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.15383, current rewards: 101.50762, mean: 0.18126
[32m[0906 13-41-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.15626, current rewards: 78.51034, mean: 0.12871
[32m[0906 13-41-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.15873, current rewards: 40.82928, mean: 0.06186
[32m[0906 13-41-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.16078, current rewards: 13.32490, mean: 0.01877
[32m[0906 13-41-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.16249, current rewards: -22.01245, mean: -0.02896
[32m[0906 13-42-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.16405, current rewards: -60.96102, mean: -0.07526
[32m[0906 13-42-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.16536, current rewards: -85.43063, mean: -0.09934
[32m[0906 13-42-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.16655, current rewards: -135.97793, mean: -0.14943
[32m[0906 13-42-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.16754, current rewards: -170.20301, mean: -0.17729
[32m[0906 13-42-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.16846, current rewards: -212.60208, mean: -0.21050
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.16930, current rewards: -264.07842, mean: -0.24913
[32m[0906 13-43-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17008, current rewards: -309.17024, mean: -0.27853
[32m[0906 13-43-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17083, current rewards: -347.63859, mean: -0.29969
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17148, current rewards: -396.97143, mean: -0.32808
[32m[0906 13-43-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17206, current rewards: -448.58137, mean: -0.35602
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17266, current rewards: -484.63215, mean: -0.36995
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17321, current rewards: -525.77323, mean: -0.38660
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17365, current rewards: -572.34553, mean: -0.40592
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17406, current rewards: -607.48380, mean: -0.41608
[32m[0906 13-44-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17451, current rewards: -638.83019, mean: -0.42307
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17489, current rewards: -685.37727, mean: -0.43934
[32m[0906 13-44-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17530, current rewards: -730.97245, mean: -0.45402
[32m[0906 13-44-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17566, current rewards: -730.30280, mean: -0.43994
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17599, current rewards: -725.30643, mean: -0.42416
[32m[0906 13-45-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17632, current rewards: -770.05022, mean: -0.43753
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17660, current rewards: -820.05022, mean: -0.45307
[32m[0906 13-45-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17684, current rewards: -870.05022, mean: -0.46777
[32m[0906 13-45-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17709, current rewards: -920.05022, mean: -0.48170
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17734, current rewards: -970.05022, mean: -0.49492
[32m[0906 13-45-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17759, current rewards: -1020.05022, mean: -0.50749
[32m[0906 13-46-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17781, current rewards: -1070.05022, mean: -0.51944
[32m[0906 13-46-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17800, current rewards: -1120.05022, mean: -0.53083
[32m[0906 13-46-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17813, current rewards: -1170.05022, mean: -0.54169
[32m[0906 13-46-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17833, current rewards: -1220.05022, mean: -0.55206
[32m[0906 13-46-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17853, current rewards: -1270.05022, mean: -0.56197
[32m[0906 13-46-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17869, current rewards: -1320.05022, mean: -0.57145
[32m[0906 13-46-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17885, current rewards: -1370.05022, mean: -0.58053
[32m[0906 13-47-07 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17900, current rewards: -1420.05022, mean: -0.58923
[32m[0906 13-47-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17913, current rewards: -1470.05022, mean: -0.59758
[32m[0906 13-47-24 @Agent.py:117][0m Average action selection time: 0.1792
[32m[0906 13-47-24 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-47-24 @MBExp.py:227][0m Rewards obtained: [-1510.0502188141818], Lows: [507], Highs: [826], Total time: 448.779402
[32m[0906 13-47-29 @MBExp.py:144][0m ####################################################################
[32m[0906 13-47-29 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-47-31 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18677, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-47-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18568, current rewards: -10.14639, mean: -0.16911
[32m[0906 13-47-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18555, current rewards: -7.32501, mean: -0.06659
[32m[0906 13-47-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18489, current rewards: -4.50338, mean: -0.02815
[32m[0906 13-48-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18484, current rewards: -1.68270, mean: -0.00801
[32m[0906 13-48-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18475, current rewards: 1.13827, mean: 0.00438
[32m[0906 13-48-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18434, current rewards: 3.96030, mean: 0.01278
[32m[0906 13-48-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18443, current rewards: 6.78112, mean: 0.01884
[32m[0906 13-48-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18459, current rewards: 9.60474, mean: 0.02343
[32m[0906 13-48-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18465, current rewards: 12.50116, mean: 0.02718
[32m[0906 13-49-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18459, current rewards: 15.46804, mean: 0.03033
[32m[0906 13-49-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18449, current rewards: 18.43768, mean: 0.03292
[32m[0906 13-49-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18430, current rewards: 21.40872, mean: 0.03510
[32m[0906 13-49-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18430, current rewards: 24.37865, mean: 0.03694
[32m[0906 13-49-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18433, current rewards: 27.35139, mean: 0.03852
[32m[0906 13-49-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18438, current rewards: 30.32035, mean: 0.03990
[32m[0906 13-49-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18443, current rewards: -20.01012, mean: -0.02470
[32m[0906 13-50-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18444, current rewards: -70.01012, mean: -0.08141
[32m[0906 13-50-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18440, current rewards: -120.01012, mean: -0.13188
[32m[0906 13-50-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18438, current rewards: -170.01012, mean: -0.17709
[32m[0906 13-50-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18437, current rewards: -220.01012, mean: -0.21783
[32m[0906 13-50-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18432, current rewards: -270.01012, mean: -0.25473
[32m[0906 13-50-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18428, current rewards: -320.01012, mean: -0.28830
[32m[0906 13-51-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18429, current rewards: -370.01012, mean: -0.31897
[32m[0906 13-51-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18425, current rewards: -415.79989, mean: -0.34364
[32m[0906 13-51-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18427, current rewards: -465.79989, mean: -0.36968
[32m[0906 13-51-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18425, current rewards: -515.79989, mean: -0.39374
[32m[0906 13-51-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18425, current rewards: -565.79989, mean: -0.41603
[32m[0906 13-51-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18423, current rewards: -615.79989, mean: -0.43674
[32m[0906 13-51-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18421, current rewards: -665.79989, mean: -0.45603
[32m[0906 13-52-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18425, current rewards: -715.79989, mean: -0.47404
[32m[0906 13-52-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18421, current rewards: -765.79989, mean: -0.49090
[32m[0906 13-52-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18421, current rewards: -815.79989, mean: -0.50671
[32m[0906 13-52-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18416, current rewards: -854.54745, mean: -0.51479
[32m[0906 13-52-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18415, current rewards: -849.67294, mean: -0.49688
[32m[0906 13-52-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18412, current rewards: -843.75506, mean: -0.47941
[32m[0906 13-53-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18411, current rewards: -837.83719, mean: -0.46289
[32m[0906 13-53-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18409, current rewards: -831.91931, mean: -0.44727
[32m[0906 13-53-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18408, current rewards: -826.00144, mean: -0.43246
[32m[0906 13-53-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18407, current rewards: -820.08356, mean: -0.41841
[32m[0906 13-53-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18408, current rewards: -814.16569, mean: -0.40506
[32m[0906 13-53-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18406, current rewards: -812.72124, mean: -0.39452
[32m[0906 13-53-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18405, current rewards: -862.72124, mean: -0.40887
[32m[0906 13-54-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18398, current rewards: -912.72124, mean: -0.42256
[32m[0906 13-54-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18402, current rewards: -962.72124, mean: -0.43562
[32m[0906 13-54-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18404, current rewards: -1012.72124, mean: -0.44811
[32m[0906 13-54-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18403, current rewards: -1062.72124, mean: -0.46005
[32m[0906 13-54-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18402, current rewards: -1112.72124, mean: -0.47149
[32m[0906 13-54-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18402, current rewards: -1162.72124, mean: -0.48246
[32m[0906 13-55-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18402, current rewards: -1212.72124, mean: -0.49298
[32m[0906 13-55-09 @Agent.py:117][0m Average action selection time: 0.1840
[32m[0906 13-55-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-55-09 @MBExp.py:227][0m Rewards obtained: [-1252.7212437105327], Lows: [21], Highs: [1302], Total time: 909.494045
[32m[0906 13-55-16 @MBExp.py:144][0m ####################################################################
[32m[0906 13-55-16 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-55-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18451, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-55-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18516, current rewards: -55.75421, mean: -0.92924
[32m[0906 13-55-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18495, current rewards: -105.75421, mean: -0.96140
[32m[0906 13-55-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18413, current rewards: -155.75421, mean: -0.97346
[32m[0906 13-55-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18399, current rewards: -205.75421, mean: -0.97978
[32m[0906 13-56-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18404, current rewards: -255.75421, mean: -0.98367
[32m[0906 13-56-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18406, current rewards: -305.75421, mean: -0.98630
[32m[0906 13-56-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18414, current rewards: -355.75421, mean: -0.98821
[32m[0906 13-56-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18424, current rewards: -388.85952, mean: -0.94844
[32m[0906 13-56-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18414, current rewards: -385.95445, mean: -0.83903
[32m[0906 13-56-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18416, current rewards: -383.05239, mean: -0.75108
[32m[0906 13-56-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18413, current rewards: -380.14962, mean: -0.67884
[32m[0906 13-57-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18404, current rewards: -377.24810, mean: -0.61844
[32m[0906 13-57-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18400, current rewards: -374.34723, mean: -0.56719
[32m[0906 13-57-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18411, current rewards: -371.44357, mean: -0.52316
[32m[0906 13-57-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18418, current rewards: -368.54007, mean: -0.48492
[32m[0906 13-57-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18415, current rewards: -365.59776, mean: -0.45136
[32m[0906 13-57-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18420, current rewards: -362.10208, mean: -0.42105
[32m[0906 13-58-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18423, current rewards: -380.54918, mean: -0.41819
[32m[0906 13-58-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18425, current rewards: -377.21117, mean: -0.39293
[32m[0906 13-58-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18429, current rewards: -373.87298, mean: -0.37017
[32m[0906 13-58-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18430, current rewards: -370.53603, mean: -0.34956
[32m[0906 13-58-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18428, current rewards: -367.20058, mean: -0.33081
[32m[0906 13-58-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18428, current rewards: -363.86071, mean: -0.31367
[32m[0906 13-58-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18426, current rewards: -360.52036, mean: -0.29795
[32m[0906 13-59-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18424, current rewards: -357.61182, mean: -0.28382
[32m[0906 13-59-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18421, current rewards: -353.87835, mean: -0.27014
[32m[0906 13-59-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18419, current rewards: -351.35583, mean: -0.25835
[32m[0906 13-59-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18418, current rewards: -348.83344, mean: -0.24740
[32m[0906 13-59-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18418, current rewards: -346.31137, mean: -0.23720
[32m[0906 13-59-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18420, current rewards: -342.74710, mean: -0.22698
[32m[0906 14-00-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18420, current rewards: -339.05457, mean: -0.21734
[32m[0906 14-00-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18418, current rewards: -335.76413, mean: -0.20855
[32m[0906 14-00-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18416, current rewards: -366.66132, mean: -0.22088
[32m[0906 14-00-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18418, current rewards: -416.66132, mean: -0.24366
[32m[0906 14-00-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18417, current rewards: -466.66132, mean: -0.26515
[32m[0906 14-00-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18415, current rewards: -516.66132, mean: -0.28545
[32m[0906 14-00-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18414, current rewards: -566.66132, mean: -0.30466
[32m[0906 14-01-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18415, current rewards: -616.66132, mean: -0.32286
[32m[0906 14-01-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18413, current rewards: -666.66132, mean: -0.34013
[32m[0906 14-01-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18412, current rewards: -716.66132, mean: -0.35655
[32m[0906 14-01-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18411, current rewards: -766.66132, mean: -0.37217
[32m[0906 14-01-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18409, current rewards: -816.66132, mean: -0.38704
[32m[0906 14-01-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18401, current rewards: -866.66132, mean: -0.40123
[32m[0906 14-02-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18401, current rewards: -916.66132, mean: -0.41478
[32m[0906 14-02-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18403, current rewards: -966.66132, mean: -0.42773
[32m[0906 14-02-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18402, current rewards: -1016.66132, mean: -0.44011
[32m[0906 14-02-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18402, current rewards: -1066.66132, mean: -0.45198
[32m[0906 14-02-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18403, current rewards: -1116.66132, mean: -0.46334
[32m[0906 14-02-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18401, current rewards: -1166.66132, mean: -0.47425
[32m[0906 14-02-57 @Agent.py:117][0m Average action selection time: 0.1840
[32m[0906 14-02-57 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-02-57 @MBExp.py:227][0m Rewards obtained: [-1206.661322936451], Lows: [10], Highs: [1263], Total time: 1370.1863560000002
[32m[0906 14-03-05 @MBExp.py:144][0m ####################################################################
[32m[0906 14-03-05 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-03-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18481, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-03-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18488, current rewards: -7.89129, mean: -0.13152
[32m[0906 14-03-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18481, current rewards: -5.04077, mean: -0.04583
[32m[0906 14-03-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18427, current rewards: -2.18951, mean: -0.01368
[32m[0906 14-03-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18377, current rewards: 0.66294, mean: 0.00316
[32m[0906 14-03-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18380, current rewards: 3.51617, mean: 0.01352
[32m[0906 14-04-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18364, current rewards: 6.36813, mean: 0.02054
[32m[0906 14-04-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18334, current rewards: -12.40330, mean: -0.03445
[32m[0906 14-04-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18350, current rewards: -8.20704, mean: -0.02002
[32m[0906 14-04-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18359, current rewards: -3.81465, mean: -0.00829
[32m[0906 14-04-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18376, current rewards: 0.57991, mean: 0.00114
[32m[0906 14-04-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18378, current rewards: 4.97257, mean: 0.00888
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18361, current rewards: 9.36556, mean: 0.01535
[32m[0906 14-05-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18351, current rewards: 13.76106, mean: 0.02085
[32m[0906 14-05-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18362, current rewards: 18.15399, mean: 0.02557
[32m[0906 14-05-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18362, current rewards: 22.74194, mean: 0.02992
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18361, current rewards: 18.66075, mean: 0.02304
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18360, current rewards: 24.04751, mean: 0.02796
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18360, current rewards: 29.44972, mean: 0.03236
[32m[0906 14-06-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18360, current rewards: 34.86113, mean: 0.03631
[32m[0906 14-06-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18358, current rewards: 40.26479, mean: 0.03987
[32m[0906 14-06-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18359, current rewards: 45.66578, mean: 0.04308
[32m[0906 14-06-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18359, current rewards: 31.86604, mean: 0.02871
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18356, current rewards: 41.82846, mean: 0.03606
[32m[0906 14-06-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18362, current rewards: 50.20838, mean: 0.04149
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18362, current rewards: 58.72233, mean: 0.04661
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18361, current rewards: 67.22937, mean: 0.05132
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18361, current rewards: 75.73867, mean: 0.05569
[32m[0906 14-07-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18360, current rewards: 84.24127, mean: 0.05975
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18360, current rewards: 92.75526, mean: 0.06353
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18360, current rewards: 83.90231, mean: 0.05556
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18360, current rewards: 91.72422, mean: 0.05880
[32m[0906 14-08-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18358, current rewards: 99.23748, mean: 0.06164
[32m[0906 14-08-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18360, current rewards: 106.81924, mean: 0.06435
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18360, current rewards: 114.47832, mean: 0.06695
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18360, current rewards: 122.12838, mean: 0.06939
[32m[0906 14-08-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18360, current rewards: 129.78703, mean: 0.07171
[32m[0906 14-08-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18361, current rewards: 137.43897, mean: 0.07389
[32m[0906 14-08-56 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18362, current rewards: 145.10349, mean: 0.07597
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18362, current rewards: 141.07188, mean: 0.07198
[32m[0906 14-09-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18362, current rewards: 144.72754, mean: 0.07200
[32m[0906 14-09-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18361, current rewards: 149.90022, mean: 0.07277
[32m[0906 14-09-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18360, current rewards: 154.36461, mean: 0.07316
[32m[0906 14-09-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18356, current rewards: 158.82444, mean: 0.07353
[32m[0906 14-09-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18347, current rewards: 170.88065, mean: 0.07732
[32m[0906 14-10-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18351, current rewards: 175.55952, mean: 0.07768
[32m[0906 14-10-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18353, current rewards: 180.23756, mean: 0.07802
[32m[0906 14-10-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18353, current rewards: 184.91472, mean: 0.07835
[32m[0906 14-10-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18355, current rewards: 189.58999, mean: 0.07867
[32m[0906 14-10-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18356, current rewards: 193.24453, mean: 0.07855
[32m[0906 14-10-45 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 14-10-45 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-10-45 @MBExp.py:227][0m Rewards obtained: [196.01139746504938], Lows: [30], Highs: [32], Total time: 1829.7544590000002
[32m[0906 14-10-55 @MBExp.py:144][0m ####################################################################
[32m[0906 14-10-55 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18707, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-11-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18597, current rewards: -8.83624, mean: -0.14727
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18535, current rewards: -5.45693, mean: -0.04961
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18446, current rewards: -2.07727, mean: -0.01298
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18337, current rewards: 1.30101, mean: 0.00620
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18365, current rewards: 4.67917, mean: 0.01800
[32m[0906 14-11-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18364, current rewards: 8.05755, mean: 0.02599
[32m[0906 14-12-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18306, current rewards: 11.36837, mean: 0.03158
[32m[0906 14-12-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18334, current rewards: 4.91274, mean: 0.01198
[32m[0906 14-12-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18343, current rewards: 8.13754, mean: 0.01769
[32m[0906 14-12-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18351, current rewards: -6.75675, mean: -0.01325
[32m[0906 14-12-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18360, current rewards: -37.67955, mean: -0.06728
[32m[0906 14-12-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18342, current rewards: -67.54054, mean: -0.11072
[32m[0906 14-12-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18324, current rewards: -99.52353, mean: -0.15079
[32m[0906 14-13-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18344, current rewards: -128.32525, mean: -0.18074
[32m[0906 14-13-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18354, current rewards: -161.36767, mean: -0.21233
[32m[0906 14-13-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18356, current rewards: -167.48136, mean: -0.20677
[32m[0906 14-13-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18360, current rewards: -164.68350, mean: -0.19149
[32m[0906 14-13-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18363, current rewards: -161.90733, mean: -0.17792
[32m[0906 14-13-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18362, current rewards: -178.81687, mean: -0.18627
[32m[0906 14-14-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18365, current rewards: -170.74259, mean: -0.16905
[32m[0906 14-14-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18368, current rewards: -162.66830, mean: -0.15346
[32m[0906 14-14-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18371, current rewards: -154.59401, mean: -0.13927
[32m[0906 14-14-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18369, current rewards: -146.51973, mean: -0.12631
[32m[0906 14-14-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18374, current rewards: -160.51367, mean: -0.13266
[32m[0906 14-14-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18375, current rewards: -210.51367, mean: -0.16707
[32m[0906 14-14-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18376, current rewards: -260.51367, mean: -0.19887
[32m[0906 14-15-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18378, current rewards: -310.51367, mean: -0.22832
[32m[0906 14-15-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18381, current rewards: -360.51367, mean: -0.25568
[32m[0906 14-15-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18378, current rewards: -410.51367, mean: -0.28117
[32m[0906 14-15-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18379, current rewards: -460.51367, mean: -0.30498
[32m[0906 14-15-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18378, current rewards: -510.51367, mean: -0.32725
[32m[0906 14-15-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18377, current rewards: -560.51367, mean: -0.34815
[32m[0906 14-16-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18377, current rewards: -610.51367, mean: -0.36778
[32m[0906 14-16-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18377, current rewards: -660.51367, mean: -0.38627
[32m[0906 14-16-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18377, current rewards: -710.51367, mean: -0.40370
[32m[0906 14-16-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18377, current rewards: -760.51367, mean: -0.42017
[32m[0906 14-16-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18379, current rewards: -810.51367, mean: -0.43576
[32m[0906 14-16-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18380, current rewards: -860.51367, mean: -0.45053
[32m[0906 14-16-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18382, current rewards: -910.51367, mean: -0.46455
[32m[0906 14-17-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18381, current rewards: -960.51367, mean: -0.47787
[32m[0906 14-17-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18383, current rewards: -1010.51367, mean: -0.49054
[32m[0906 14-17-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18384, current rewards: -1060.51367, mean: -0.50261
[32m[0906 14-17-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18385, current rewards: -1110.51367, mean: -0.51413
[32m[0906 14-17-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18376, current rewards: -1160.51367, mean: -0.52512
[32m[0906 14-17-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18374, current rewards: -1210.51367, mean: -0.53563
[32m[0906 14-18-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18378, current rewards: -1260.51367, mean: -0.54568
[32m[0906 14-18-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18379, current rewards: -1310.51367, mean: -0.55530
[32m[0906 14-18-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18379, current rewards: -1360.51367, mean: -0.56453
[32m[0906 14-18-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18381, current rewards: -1410.51367, mean: -0.57338
[32m[0906 14-18-36 @Agent.py:117][0m Average action selection time: 0.1838
[32m[0906 14-18-36 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-18-36 @MBExp.py:227][0m Rewards obtained: [-1450.5136698343927], Lows: [10], Highs: [1516], Total time: 2289.925372
[32m[0906 14-18-48 @MBExp.py:144][0m ####################################################################
[32m[0906 14-18-48 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-18-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18388, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-19-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18462, current rewards: -9.71105, mean: -0.16185
[32m[0906 14-19-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18457, current rewards: -6.35231, mean: -0.05775
[32m[0906 14-19-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18419, current rewards: -2.99472, mean: -0.01872
[32m[0906 14-19-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18325, current rewards: 0.36313, mean: 0.00173
[32m[0906 14-19-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18338, current rewards: 3.72157, mean: 0.01431
[32m[0906 14-19-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18346, current rewards: 7.08015, mean: 0.02284
[32m[0906 14-19-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18284, current rewards: 10.58161, mean: 0.02939
[32m[0906 14-20-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18290, current rewards: 13.98394, mean: 0.03411
[32m[0906 14-20-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18311, current rewards: 17.36992, mean: 0.03776
[32m[0906 14-20-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18324, current rewards: 20.75480, mean: 0.04070
[32m[0906 14-20-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18336, current rewards: 24.13997, mean: 0.04311
[32m[0906 14-20-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18329, current rewards: 27.52592, mean: 0.04512
[32m[0906 14-20-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18303, current rewards: 30.91178, mean: 0.04684
[32m[0906 14-20-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18318, current rewards: 34.29700, mean: 0.04831
[32m[0906 14-21-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18325, current rewards: 17.55014, mean: 0.02309
[32m[0906 14-21-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18330, current rewards: 21.51128, mean: 0.02656
[32m[0906 14-21-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18342, current rewards: 25.11612, mean: 0.02920
[32m[0906 14-21-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18348, current rewards: 26.57828, mean: 0.02921
[32m[0906 14-21-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18351, current rewards: 22.15577, mean: 0.02308
[32m[0906 14-21-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18353, current rewards: 26.03087, mean: 0.02577
[32m[0906 14-22-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18357, current rewards: 29.90331, mean: 0.02821
[32m[0906 14-22-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18359, current rewards: 33.77618, mean: 0.03043
[32m[0906 14-22-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18360, current rewards: 37.64872, mean: 0.03246
[32m[0906 14-22-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18363, current rewards: 41.05727, mean: 0.03393
[32m[0906 14-22-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18366, current rewards: 45.03272, mean: 0.03574
[32m[0906 14-22-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18367, current rewards: 49.94562, mean: 0.03813
[32m[0906 14-22-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18370, current rewards: 53.22621, mean: 0.03914
[32m[0906 14-23-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18373, current rewards: 56.55093, mean: 0.04011
[32m[0906 14-23-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18374, current rewards: 59.87610, mean: 0.04101
[32m[0906 14-23-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18375, current rewards: 63.20001, mean: 0.04185
[32m[0906 14-23-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18379, current rewards: 66.52421, mean: 0.04264
[32m[0906 14-23-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18378, current rewards: 69.98544, mean: 0.04347
[32m[0906 14-23-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18376, current rewards: 73.39670, mean: 0.04421
[32m[0906 14-24-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18377, current rewards: 76.80191, mean: 0.04491
[32m[0906 14-24-12 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18377, current rewards: 80.20706, mean: 0.04557
[32m[0906 14-24-21 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18377, current rewards: 83.61351, mean: 0.04620
[32m[0906 14-24-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18376, current rewards: 87.01903, mean: 0.04678
[32m[0906 14-24-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18376, current rewards: 90.42413, mean: 0.04734
[32m[0906 14-24-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18374, current rewards: 75.21707, mean: 0.03838
[32m[0906 14-24-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18375, current rewards: 77.07216, mean: 0.03834
[32m[0906 14-25-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18375, current rewards: 81.32253, mean: 0.03948
[32m[0906 14-25-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18377, current rewards: 85.57108, mean: 0.04056
[32m[0906 14-25-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18377, current rewards: 89.82016, mean: 0.04158
[32m[0906 14-25-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18372, current rewards: 94.06756, mean: 0.04256
[32m[0906 14-25-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18367, current rewards: 98.31312, mean: 0.04350
[32m[0906 14-25-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18369, current rewards: 102.56022, mean: 0.04440
[32m[0906 14-26-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18372, current rewards: 106.80623, mean: 0.04526
[32m[0906 14-26-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18372, current rewards: 111.10543, mean: 0.04610
[32m[0906 14-26-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18373, current rewards: 95.60935, mean: 0.03887
[32m[0906 14-26-28 @Agent.py:117][0m Average action selection time: 0.1837
[32m[0906 14-26-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-26-28 @MBExp.py:227][0m Rewards obtained: [98.76391607327152], Lows: [30], Highs: [24], Total time: 2749.902305
[32m[0906 14-26-43 @MBExp.py:144][0m ####################################################################
[32m[0906 14-26-43 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-26-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18322, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-26-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18439, current rewards: -6.23574, mean: -0.10393
[32m[0906 14-27-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18468, current rewards: 1.30837, mean: 0.01189
[32m[0906 14-27-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18433, current rewards: 8.85224, mean: 0.05533
[32m[0906 14-27-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18318, current rewards: 16.39532, mean: 0.07807
[32m[0906 14-27-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18299, current rewards: 23.93396, mean: 0.09205
[32m[0906 14-27-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18335, current rewards: 31.47382, mean: 0.10153
[32m[0906 14-27-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18304, current rewards: 17.98448, mean: 0.04996
[32m[0906 14-27-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18282, current rewards: 24.19800, mean: 0.05902
[32m[0906 14-28-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18317, current rewards: 30.32966, mean: 0.06593
[32m[0906 14-28-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18332, current rewards: 36.46134, mean: 0.07149
[32m[0906 14-28-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18337, current rewards: 42.59412, mean: 0.07606
[32m[0906 14-28-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18325, current rewards: 48.72489, mean: 0.07988
[32m[0906 14-28-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18298, current rewards: 54.85642, mean: 0.08312
[32m[0906 14-28-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18303, current rewards: 50.88373, mean: 0.07167
[32m[0906 14-29-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18313, current rewards: 52.89109, mean: 0.06959
[32m[0906 14-29-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18320, current rewards: 57.25468, mean: 0.07068
[32m[0906 14-29-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18329, current rewards: 61.61407, mean: 0.07164
[32m[0906 14-29-30 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18335, current rewards: 65.97602, mean: 0.07250
[32m[0906 14-29-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18339, current rewards: 70.33555, mean: 0.07327
[32m[0906 14-29-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18346, current rewards: 74.69678, mean: 0.07396
[32m[0906 14-29-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18349, current rewards: 79.05864, mean: 0.07458
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18353, current rewards: 83.41870, mean: 0.07515
[32m[0906 14-30-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18355, current rewards: 72.46291, mean: 0.06247
[32m[0906 14-30-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18357, current rewards: 75.98693, mean: 0.06280
[32m[0906 14-30-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18355, current rewards: 79.64851, mean: 0.06321
[32m[0906 14-30-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18354, current rewards: 83.31085, mean: 0.06360
[32m[0906 14-30-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18355, current rewards: 86.97249, mean: 0.06395
[32m[0906 14-31-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18356, current rewards: 90.63508, mean: 0.06428
[32m[0906 14-31-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18359, current rewards: 94.29438, mean: 0.06459
[32m[0906 14-31-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18360, current rewards: 97.95841, mean: 0.06487
[32m[0906 14-31-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18360, current rewards: 80.08934, mean: 0.05134
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18359, current rewards: 85.13088, mean: 0.05288
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18358, current rewards: 90.08038, mean: 0.05427
[32m[0906 14-31-58 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18363, current rewards: 95.03399, mean: 0.05558
[32m[0906 14-32-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18364, current rewards: 99.98787, mean: 0.05681
[32m[0906 14-32-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18363, current rewards: 104.93935, mean: 0.05798
[32m[0906 14-32-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18361, current rewards: 109.89336, mean: 0.05908
[32m[0906 14-32-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18361, current rewards: 114.84570, mean: 0.06013
[32m[0906 14-32-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18361, current rewards: 119.82600, mean: 0.06114
[32m[0906 14-32-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18360, current rewards: 126.40912, mean: 0.06289
[32m[0906 14-33-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18362, current rewards: 131.80460, mean: 0.06398
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18363, current rewards: 117.79842, mean: 0.05583
[32m[0906 14-33-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18363, current rewards: 123.85642, mean: 0.05734
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18358, current rewards: 129.90996, mean: 0.05878
[32m[0906 14-33-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18350, current rewards: 135.96772, mean: 0.06016
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18348, current rewards: 142.02433, mean: 0.06148
[32m[0906 14-33-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18353, current rewards: 148.08131, mean: 0.06275
[32m[0906 14-34-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18355, current rewards: 153.31578, mean: 0.06362
[32m[0906 14-34-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18355, current rewards: 158.99852, mean: 0.06463
[32m[0906 14-34-23 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 14-34-23 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-34-23 @MBExp.py:227][0m Rewards obtained: [163.53823630512844], Lows: [30], Highs: [39], Total time: 3209.4167820000002
[32m[0906 14-34-40 @MBExp.py:144][0m ####################################################################
[32m[0906 14-34-40 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-34-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18495, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-34-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18477, current rewards: -9.94642, mean: -0.16577
[32m[0906 14-35-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18470, current rewards: -5.35319, mean: -0.04867
[32m[0906 14-35-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18455, current rewards: -0.75551, mean: -0.00472
[32m[0906 14-35-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18337, current rewards: 3.83404, mean: 0.01826
[32m[0906 14-35-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18285, current rewards: 8.42729, mean: 0.03241
[32m[0906 14-35-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18330, current rewards: 13.06452, mean: 0.04214
[32m[0906 14-35-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18282, current rewards: 18.49452, mean: 0.05137
[32m[0906 14-35-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18255, current rewards: 26.09884, mean: 0.06366
[32m[0906 14-36-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18313, current rewards: 33.73593, mean: 0.07334
[32m[0906 14-36-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18384, current rewards: 41.35550, mean: 0.08109
[32m[0906 14-36-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18409, current rewards: 48.99721, mean: 0.08750
[32m[0906 14-36-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18396, current rewards: 56.63607, mean: 0.09285
[32m[0906 14-36-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18369, current rewards: 64.28120, mean: 0.09740
[32m[0906 14-36-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18361, current rewards: 71.21960, mean: 0.10031
[32m[0906 14-37-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18368, current rewards: 78.29485, mean: 0.10302
[32m[0906 14-37-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18373, current rewards: 85.88659, mean: 0.10603
[32m[0906 14-37-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18372, current rewards: 69.99706, mean: 0.08139
[32m[0906 14-37-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18379, current rewards: 75.49014, mean: 0.08296
[32m[0906 14-37-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18383, current rewards: 81.00368, mean: 0.08438
[32m[0906 14-37-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18384, current rewards: 86.52132, mean: 0.08566
[32m[0906 14-37-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18384, current rewards: 92.03928, mean: 0.08683
[32m[0906 14-38-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18386, current rewards: 97.55302, mean: 0.08789
[32m[0906 14-38-13 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18392, current rewards: 103.60131, mean: 0.08931
[32m[0906 14-38-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18392, current rewards: 109.34450, mean: 0.09037
[32m[0906 14-38-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18394, current rewards: 115.08757, mean: 0.09134
[32m[0906 14-38-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18394, current rewards: 120.82527, mean: 0.09223
[32m[0906 14-38-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18399, current rewards: 126.57092, mean: 0.09307
[32m[0906 14-39-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18400, current rewards: 132.30749, mean: 0.09384
[32m[0906 14-39-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18398, current rewards: 126.66644, mean: 0.08676
[32m[0906 14-39-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18399, current rewards: 131.48694, mean: 0.08708
[32m[0906 14-39-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18400, current rewards: 136.30293, mean: 0.08737
[32m[0906 14-39-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18401, current rewards: 141.11876, mean: 0.08765
[32m[0906 14-39-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18403, current rewards: 145.93254, mean: 0.08791
[32m[0906 14-39-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18402, current rewards: 150.74877, mean: 0.08816
[32m[0906 14-40-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18404, current rewards: 155.56119, mean: 0.08839
[32m[0906 14-40-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18407, current rewards: 160.38174, mean: 0.08861
[32m[0906 14-40-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18409, current rewards: 165.19844, mean: 0.08882
[32m[0906 14-40-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18408, current rewards: 170.01672, mean: 0.08901
[32m[0906 14-40-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18406, current rewards: 174.25452, mean: 0.08891
[32m[0906 14-40-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18403, current rewards: 179.03749, mean: 0.08907
[32m[0906 14-40-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18401, current rewards: 183.82257, mean: 0.08923
[32m[0906 14-41-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18400, current rewards: 188.60802, mean: 0.08939
[32m[0906 14-41-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18400, current rewards: 170.41960, mean: 0.07890
[32m[0906 14-41-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18397, current rewards: 175.94600, mean: 0.07961
[32m[0906 14-41-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18386, current rewards: 181.48455, mean: 0.08030
[32m[0906 14-41-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18377, current rewards: 187.01901, mean: 0.08096
[32m[0906 14-41-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18380, current rewards: 200.39899, mean: 0.08491
[32m[0906 14-42-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18383, current rewards: 189.55355, mean: 0.07865
[32m[0906 14-42-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18383, current rewards: 139.55355, mean: 0.05673
[32m[0906 14-42-20 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 14-42-20 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-42-20 @MBExp.py:227][0m Rewards obtained: [99.55354701757386], Lows: [22], Highs: [131], Total time: 3669.726834
[32m[0906 14-42-39 @MBExp.py:144][0m ####################################################################
[32m[0906 14-42-39 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-42-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18339, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-42-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18485, current rewards: -35.11109, mean: -0.58518
[32m[0906 14-43-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18436, current rewards: -29.63207, mean: -0.26938
[32m[0906 14-43-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18416, current rewards: -24.13322, mean: -0.15083
[32m[0906 14-43-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18303, current rewards: -18.64174, mean: -0.08877
[32m[0906 14-43-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18230, current rewards: -13.14596, mean: -0.05056
[32m[0906 14-43-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18264, current rewards: -28.48549, mean: -0.09189
[32m[0906 14-43-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18234, current rewards: -23.19315, mean: -0.06443
[32m[0906 14-43-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18206, current rewards: -18.03813, mean: -0.04400
[32m[0906 14-44-03 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18232, current rewards: -12.88484, mean: -0.02801
[32m[0906 14-44-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18258, current rewards: -7.73268, mean: -0.01516
[32m[0906 14-44-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18272, current rewards: -2.58153, mean: -0.00461
[32m[0906 14-44-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18279, current rewards: 2.57264, mean: 0.00422
[32m[0906 14-44-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18260, current rewards: 7.72601, mean: 0.01171
[32m[0906 14-44-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18248, current rewards: 12.16930, mean: 0.01714
[32m[0906 14-44-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18261, current rewards: 16.80899, mean: 0.02212
[32m[0906 14-45-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18274, current rewards: 21.45947, mean: 0.02649
[32m[0906 14-45-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18282, current rewards: 26.11075, mean: 0.03036
[32m[0906 14-45-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18289, current rewards: 19.90062, mean: 0.02187
[32m[0906 14-45-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18295, current rewards: 24.34133, mean: 0.02536
[32m[0906 14-45-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18300, current rewards: 28.80519, mean: 0.02852
[32m[0906 14-45-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18308, current rewards: 33.26907, mean: 0.03139
[32m[0906 14-46-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18313, current rewards: 37.99814, mean: 0.03423
[32m[0906 14-46-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18317, current rewards: 42.57796, mean: 0.03671
[32m[0906 14-46-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18320, current rewards: 47.17794, mean: 0.03899
[32m[0906 14-46-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18323, current rewards: 51.77913, mean: 0.04109
[32m[0906 14-46-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18332, current rewards: 56.37518, mean: 0.04303
[32m[0906 14-46-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18335, current rewards: 60.97145, mean: 0.04483
[32m[0906 14-46-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18338, current rewards: 65.57520, mean: 0.04651
[32m[0906 14-47-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18339, current rewards: 70.17303, mean: 0.04806
[32m[0906 14-47-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18339, current rewards: 75.23031, mean: 0.04982
[32m[0906 14-47-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18340, current rewards: 70.13137, mean: 0.04496
[32m[0906 14-47-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18344, current rewards: 76.03506, mean: 0.04723
[32m[0906 14-47-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18346, current rewards: 81.94494, mean: 0.04936
[32m[0906 14-47-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18347, current rewards: 87.85632, mean: 0.05138
[32m[0906 14-48-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18348, current rewards: 93.75961, mean: 0.05327
[32m[0906 14-48-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18348, current rewards: 99.67107, mean: 0.05507
[32m[0906 14-48-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18348, current rewards: 105.58130, mean: 0.05676
[32m[0906 14-48-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18348, current rewards: 111.49272, mean: 0.05837
[32m[0906 14-48-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18352, current rewards: 95.46236, mean: 0.04871
[32m[0906 14-48-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18355, current rewards: 100.47260, mean: 0.04999
[32m[0906 14-48-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18356, current rewards: 105.47231, mean: 0.05120
[32m[0906 14-49-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18357, current rewards: 110.47333, mean: 0.05236
[32m[0906 14-49-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18358, current rewards: 115.47342, mean: 0.05346
[32m[0906 14-49-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18359, current rewards: 120.47278, mean: 0.05451
[32m[0906 14-49-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18350, current rewards: 125.46993, mean: 0.05552
[32m[0906 14-49-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18342, current rewards: 130.46823, mean: 0.05648
[32m[0906 14-49-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18341, current rewards: 135.46980, mean: 0.05740
[32m[0906 14-50-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18344, current rewards: 140.47036, mean: 0.05829
[32m[0906 14-50-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18346, current rewards: 145.46780, mean: 0.05913
[32m[0906 14-50-19 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 14-50-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-50-19 @MBExp.py:227][0m Rewards obtained: [149.47074804497038], Lows: [36], Highs: [31], Total time: 4129.04611
[32m[0906 14-50-40 @MBExp.py:144][0m ####################################################################
[32m[0906 14-50-40 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-50-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18685, current rewards: 0.68979, mean: 0.06898
[32m[0906 14-50-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18629, current rewards: 6.09486, mean: 0.10158
[32m[0906 14-51-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18486, current rewards: 11.54811, mean: 0.10498
[32m[0906 14-51-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18485, current rewards: 17.00136, mean: 0.10626
[32m[0906 14-51-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18363, current rewards: 22.45460, mean: 0.10693
[32m[0906 14-51-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18269, current rewards: 27.90785, mean: 0.10734
[32m[0906 14-51-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18262, current rewards: 33.65520, mean: 0.10857
[32m[0906 14-51-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18231, current rewards: 39.45043, mean: 0.10958
[32m[0906 14-51-54 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18198, current rewards: 45.24566, mean: 0.11036
[32m[0906 14-52-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18201, current rewards: 9.75242, mean: 0.02120
[32m[0906 14-52-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18228, current rewards: -40.24758, mean: -0.07892
[32m[0906 14-52-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18251, current rewards: -90.24758, mean: -0.16116
[32m[0906 14-52-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18251, current rewards: -140.24758, mean: -0.22991
[32m[0906 14-52-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18233, current rewards: -190.24758, mean: -0.28825
[32m[0906 14-52-49 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18217, current rewards: -240.24758, mean: -0.33838
[32m[0906 14-52-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18240, current rewards: -290.24758, mean: -0.38190
[32m[0906 14-53-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18259, current rewards: -340.24758, mean: -0.42006
[32m[0906 14-53-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18268, current rewards: -390.24758, mean: -0.45378
[32m[0906 14-53-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18279, current rewards: -440.24758, mean: -0.48379
[32m[0906 14-53-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18285, current rewards: -490.24758, mean: -0.51067
[32m[0906 14-53-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18292, current rewards: -540.24758, mean: -0.53490
[32m[0906 14-53-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18296, current rewards: -590.24758, mean: -0.55684
[32m[0906 14-54-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18301, current rewards: -640.24758, mean: -0.57680
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18306, current rewards: -690.24758, mean: -0.59504
[32m[0906 14-54-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18310, current rewards: -740.24758, mean: -0.61177
[32m[0906 14-54-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18315, current rewards: -790.24758, mean: -0.62718
[32m[0906 14-54-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18316, current rewards: -840.24758, mean: -0.64141
[32m[0906 14-54-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18319, current rewards: -890.24758, mean: -0.65459
[32m[0906 14-54-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18326, current rewards: -940.24758, mean: -0.66684
[32m[0906 14-55-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18329, current rewards: -990.24758, mean: -0.67825
[32m[0906 14-55-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18331, current rewards: -1040.24758, mean: -0.68891
[32m[0906 14-55-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18331, current rewards: -1090.24758, mean: -0.69888
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18333, current rewards: -1140.24758, mean: -0.70823
[32m[0906 14-55-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18336, current rewards: -1190.24758, mean: -0.71702
[32m[0906 14-55-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18338, current rewards: -1240.24758, mean: -0.72529
[32m[0906 14-56-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18339, current rewards: -1290.24758, mean: -0.73310
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18342, current rewards: -1340.24758, mean: -0.74047
[32m[0906 14-56-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18342, current rewards: -1390.24758, mean: -0.74744
[32m[0906 14-56-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18345, current rewards: -1440.24758, mean: -0.75406
[32m[0906 14-56-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18348, current rewards: -1490.24758, mean: -0.76033
[32m[0906 14-56-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18349, current rewards: -1540.24758, mean: -0.76629
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18351, current rewards: -1590.24758, mean: -0.77196
[32m[0906 14-57-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18355, current rewards: -1640.24758, mean: -0.77737
[32m[0906 14-57-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18355, current rewards: -1690.24758, mean: -0.78252
[32m[0906 14-57-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18355, current rewards: -1740.24758, mean: -0.78744
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18348, current rewards: -1790.24758, mean: -0.79214
[32m[0906 14-57-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18339, current rewards: -1840.24758, mean: -0.79664
[32m[0906 14-57-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18332, current rewards: -1890.24758, mean: -0.80095
[32m[0906 14-58-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18336, current rewards: -1940.24758, mean: -0.80508
[32m[0906 14-58-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18340, current rewards: -1990.24758, mean: -0.80904
[32m[0906 14-58-19 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0906 14-58-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-58-19 @MBExp.py:227][0m Rewards obtained: [-2030.2475797877569], Lows: [0], Highs: [2077], Total time: 4588.244226000001
[32m[0906 14-58-42 @MBExp.py:144][0m ####################################################################
[32m[0906 14-58-42 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 14-58-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18483, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-58-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18493, current rewards: -7.30722, mean: -0.12179
[32m[0906 14-59-03 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18488, current rewards: -3.55411, mean: -0.03231
[32m[0906 14-59-12 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18503, current rewards: 0.19835, mean: 0.00124
[32m[0906 14-59-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18404, current rewards: 3.94909, mean: 0.01881
[32m[0906 14-59-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18316, current rewards: 7.80301, mean: 0.03001
[32m[0906 14-59-39 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18272, current rewards: 0.58085, mean: 0.00187
[32m[0906 14-59-48 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18245, current rewards: 3.89618, mean: 0.01082
[32m[0906 14-59-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18221, current rewards: 7.21213, mean: 0.01759
[32m[0906 15-00-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18193, current rewards: 10.52871, mean: 0.02289
[32m[0906 15-00-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18224, current rewards: 13.84493, mean: 0.02715
[32m[0906 15-00-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18242, current rewards: 17.16158, mean: 0.03065
[32m[0906 15-00-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18241, current rewards: 20.47812, mean: 0.03357
[32m[0906 15-00-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18224, current rewards: 22.52438, mean: 0.03413
[32m[0906 15-00-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18207, current rewards: 26.05562, mean: 0.03670
[32m[0906 15-01-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18223, current rewards: 14.92599, mean: 0.01964
[32m[0906 15-01-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18243, current rewards: 18.23547, mean: 0.02251
[32m[0906 15-01-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18263, current rewards: 21.54475, mean: 0.02505
[32m[0906 15-01-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18278, current rewards: 24.85671, mean: 0.02732
[32m[0906 15-01-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18286, current rewards: 28.16808, mean: 0.02934
[32m[0906 15-01-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18291, current rewards: 31.47774, mean: 0.03117
[32m[0906 15-01-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18297, current rewards: 14.47571, mean: 0.01366
[32m[0906 15-02-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18305, current rewards: 18.12925, mean: 0.01633
[32m[0906 15-02-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18308, current rewards: 21.75711, mean: 0.01876
[32m[0906 15-02-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18310, current rewards: 25.38630, mean: 0.02098
[32m[0906 15-02-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18315, current rewards: 29.01401, mean: 0.02303
[32m[0906 15-02-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18321, current rewards: 19.93168, mean: 0.01522
[32m[0906 15-02-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18328, current rewards: 24.02468, mean: 0.01767
[32m[0906 15-03-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18329, current rewards: 28.03146, mean: 0.01988
[32m[0906 15-03-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18334, current rewards: 32.07425, mean: 0.02197
[32m[0906 15-03-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18340, current rewards: 36.08829, mean: 0.02390
[32m[0906 15-03-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18345, current rewards: 40.10603, mean: 0.02571
[32m[0906 15-03-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18348, current rewards: 44.12508, mean: 0.02741
[32m[0906 15-03-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18346, current rewards: 48.14289, mean: 0.02900
[32m[0906 15-03-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18347, current rewards: 52.16066, mean: 0.03050
[32m[0906 15-04-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18350, current rewards: 56.17662, mean: 0.03192
[32m[0906 15-04-15 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18352, current rewards: 60.19387, mean: 0.03326
[32m[0906 15-04-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18351, current rewards: 64.40023, mean: 0.03462
[32m[0906 15-04-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18351, current rewards: 68.96298, mean: 0.03611
[32m[0906 15-04-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18353, current rewards: 52.90748, mean: 0.02699
[32m[0906 15-04-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18355, current rewards: 57.68809, mean: 0.02870
[32m[0906 15-05-01 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18356, current rewards: 62.46870, mean: 0.03032
[32m[0906 15-05-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18358, current rewards: 67.24931, mean: 0.03187
[32m[0906 15-05-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18360, current rewards: 72.02993, mean: 0.03335
[32m[0906 15-05-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18364, current rewards: 76.81054, mean: 0.03476
[32m[0906 15-05-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18360, current rewards: 79.39992, mean: 0.03513
[32m[0906 15-05-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18353, current rewards: 29.39992, mean: 0.01273
[32m[0906 15-05-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18345, current rewards: -20.60008, mean: -0.00873
[32m[0906 15-06-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18344, current rewards: -70.60008, mean: -0.02929
[32m[0906 15-06-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18348, current rewards: -120.60008, mean: -0.04902
[32m[0906 15-06-22 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 15-06-22 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-06-22 @MBExp.py:227][0m Rewards obtained: [-160.6000761248494], Lows: [23], Highs: [284], Total time: 5047.576558000001
[32m[0906 15-06-47 @MBExp.py:144][0m ####################################################################
[32m[0906 15-06-47 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 15-06-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18513, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-06-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18513, current rewards: -48.12381, mean: -0.80206
[32m[0906 15-07-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18496, current rewards: -40.30113, mean: -0.36637
[32m[0906 15-07-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18423, current rewards: -32.45392, mean: -0.20284
[32m[0906 15-07-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18361, current rewards: -80.83506, mean: -0.38493
[32m[0906 15-07-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18301, current rewards: -77.13026, mean: -0.29665
[32m[0906 15-07-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18246, current rewards: -74.21028, mean: -0.23939
[32m[0906 15-07-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18224, current rewards: -71.29127, mean: -0.19803
[32m[0906 15-08-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18195, current rewards: -68.37609, mean: -0.16677
[32m[0906 15-08-11 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18173, current rewards: -65.45655, mean: -0.14230
[32m[0906 15-08-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18196, current rewards: -62.54072, mean: -0.12263
[32m[0906 15-08-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18225, current rewards: -59.62111, mean: -0.10647
[32m[0906 15-08-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18233, current rewards: -56.66891, mean: -0.09290
[32m[0906 15-08-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18215, current rewards: -72.54025, mean: -0.10991
[32m[0906 15-08-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18202, current rewards: -65.15340, mean: -0.09177
[32m[0906 15-09-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18207, current rewards: -57.76290, mean: -0.07600
[32m[0906 15-09-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18225, current rewards: -50.37069, mean: -0.06219
[32m[0906 15-09-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18232, current rewards: -42.98772, mean: -0.04999
[32m[0906 15-09-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18243, current rewards: -35.60224, mean: -0.03912
[32m[0906 15-09-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18258, current rewards: -28.22038, mean: -0.02940
[32m[0906 15-09-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18268, current rewards: -20.84261, mean: -0.02064
[32m[0906 15-10-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18277, current rewards: -15.56071, mean: -0.01468
[32m[0906 15-10-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18283, current rewards: -9.05585, mean: -0.00816
[32m[0906 15-10-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18288, current rewards: -2.55406, mean: -0.00220
[32m[0906 15-10-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18295, current rewards: 2.97591, mean: 0.00246
[32m[0906 15-10-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18299, current rewards: 9.00075, mean: 0.00714
[32m[0906 15-10-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18303, current rewards: 15.02219, mean: 0.01147
[32m[0906 15-10-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18311, current rewards: 21.04274, mean: 0.01547
[32m[0906 15-11-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18315, current rewards: 27.06243, mean: 0.01919
[32m[0906 15-11-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18323, current rewards: 37.77914, mean: 0.02588
[32m[0906 15-11-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18324, current rewards: 48.35165, mean: 0.03202
[32m[0906 15-11-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18327, current rewards: -45.11920, mean: -0.02892
[32m[0906 15-11-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18330, current rewards: -145.11920, mean: -0.09014
[32m[0906 15-11-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18333, current rewards: -245.11920, mean: -0.14766
[32m[0906 15-12-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18336, current rewards: -298.57516, mean: -0.17461
[32m[0906 15-12-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18340, current rewards: -293.99329, mean: -0.16704
[32m[0906 15-12-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18341, current rewards: -289.32877, mean: -0.15985
[32m[0906 15-12-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18343, current rewards: -284.66394, mean: -0.15305
[32m[0906 15-12-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18344, current rewards: -279.99709, mean: -0.14660
[32m[0906 15-12-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18347, current rewards: -275.33367, mean: -0.14048
[32m[0906 15-12-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18350, current rewards: -270.67041, mean: -0.13466
[32m[0906 15-13-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18352, current rewards: -266.00536, mean: -0.12913
[32m[0906 15-13-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18352, current rewards: -270.84127, mean: -0.12836
[32m[0906 15-13-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18353, current rewards: -262.78416, mean: -0.12166
[32m[0906 15-13-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18355, current rewards: -254.73353, mean: -0.11526
[32m[0906 15-13-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18354, current rewards: -246.68455, mean: -0.10915
[32m[0906 15-13-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18348, current rewards: -240.92360, mean: -0.10430
[32m[0906 15-14-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18340, current rewards: -234.17778, mean: -0.09923
[32m[0906 15-14-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18333, current rewards: -227.41472, mean: -0.09436
[32m[0906 15-14-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18335, current rewards: -241.82668, mean: -0.09830
[32m[0906 15-14-26 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0906 15-14-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-14-26 @MBExp.py:227][0m Rewards obtained: [-238.8904098408309], Lows: [239], Highs: [31], Total time: 5506.648882
[32m[0906 15-14-53 @MBExp.py:144][0m ####################################################################
[32m[0906 15-14-53 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 15-14-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18463, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-15-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18459, current rewards: -5.26777, mean: -0.08780
[32m[0906 15-15-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18474, current rewards: 0.79732, mean: 0.00725
[32m[0906 15-15-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18440, current rewards: 6.86722, mean: 0.04292
[32m[0906 15-15-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18371, current rewards: 12.68788, mean: 0.06042
[32m[0906 15-15-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18286, current rewards: 18.88825, mean: 0.07265
[32m[0906 15-15-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18231, current rewards: 25.08188, mean: 0.08091
[32m[0906 15-15-59 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18212, current rewards: 17.17077, mean: 0.04770
[32m[0906 15-16-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18183, current rewards: 14.87910, mean: 0.03629
[32m[0906 15-16-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18159, current rewards: 10.62809, mean: 0.02310
[32m[0906 15-16-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18166, current rewards: 8.46932, mean: 0.01661
[32m[0906 15-16-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18198, current rewards: 4.20254, mean: 0.00750
[32m[0906 15-16-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18208, current rewards: 1.75454, mean: 0.00288
[32m[0906 15-16-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18189, current rewards: -3.81748, mean: -0.00578
[32m[0906 15-17-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18176, current rewards: -7.00151, mean: -0.00986
[32m[0906 15-17-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18168, current rewards: -12.32323, mean: -0.01621
[32m[0906 15-17-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18190, current rewards: -17.61322, mean: -0.02174
[32m[0906 15-17-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18207, current rewards: -20.83162, mean: -0.02422
[32m[0906 15-17-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18225, current rewards: -26.12455, mean: -0.02871
[32m[0906 15-17-49 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18237, current rewards: -29.33292, mean: -0.03056
[32m[0906 15-17-58 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18251, current rewards: -34.63098, mean: -0.03429
[32m[0906 15-18-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18265, current rewards: -35.52348, mean: -0.03351
[32m[0906 15-18-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18269, current rewards: -98.18121, mean: -0.08845
[32m[0906 15-18-26 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18274, current rewards: -136.28745, mean: -0.11749
[32m[0906 15-18-35 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18280, current rewards: -178.48583, mean: -0.14751
[32m[0906 15-18-44 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18287, current rewards: -229.78075, mean: -0.18237
[32m[0906 15-18-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18291, current rewards: -274.55358, mean: -0.20958
[32m[0906 15-19-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18296, current rewards: -290.23363, mean: -0.21341
[32m[0906 15-19-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18299, current rewards: -283.80017, mean: -0.20128
[32m[0906 15-19-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18303, current rewards: -276.32084, mean: -0.18926
[32m[0906 15-19-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18309, current rewards: -269.09686, mean: -0.17821
[32m[0906 15-19-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18315, current rewards: -273.94958, mean: -0.17561
[32m[0906 15-19-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18319, current rewards: -267.21833, mean: -0.16597
[32m[0906 15-19-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18322, current rewards: -260.47598, mean: -0.15691
[32m[0906 15-20-07 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18328, current rewards: -253.73062, mean: -0.14838
[32m[0906 15-20-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18331, current rewards: -246.97992, mean: -0.14033
[32m[0906 15-20-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18333, current rewards: -261.87447, mean: -0.14468
[32m[0906 15-20-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18335, current rewards: -282.24796, mean: -0.15175
[32m[0906 15-20-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18337, current rewards: -276.08310, mean: -0.14455
[32m[0906 15-20-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18337, current rewards: -269.86989, mean: -0.13769
[32m[0906 15-21-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18341, current rewards: -263.65072, mean: -0.13117
[32m[0906 15-21-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18340, current rewards: -257.43550, mean: -0.12497
[32m[0906 15-21-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18340, current rewards: -251.21740, mean: -0.11906
[32m[0906 15-21-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18340, current rewards: -245.00108, mean: -0.11343
[32m[0906 15-21-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18340, current rewards: -238.78084, mean: -0.10805
[32m[0906 15-21-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18341, current rewards: -232.56469, mean: -0.10290
[32m[0906 15-21-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18335, current rewards: -234.25350, mean: -0.10141
[32m[0906 15-22-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18328, current rewards: -245.09857, mean: -0.10386
[32m[0906 15-22-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18322, current rewards: -237.78748, mean: -0.09867
[32m[0906 15-22-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18321, current rewards: -230.47342, mean: -0.09369
[32m[0906 15-22-32 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 15-22-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-22-32 @MBExp.py:227][0m Rewards obtained: [-233.79253159102913], Lows: [248], Highs: [39], Total time: 5965.434555000001
[32m[0906 15-23-02 @MBExp.py:144][0m ####################################################################
[32m[0906 15-23-02 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 15-23-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18611, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-23-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18529, current rewards: -31.23338, mean: -0.52056
[32m[0906 15-23-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18470, current rewards: -39.05053, mean: -0.35500
[32m[0906 15-23-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18427, current rewards: -59.14145, mean: -0.36963
[32m[0906 15-23-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18370, current rewards: -79.84434, mean: -0.38021
[32m[0906 15-23-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18304, current rewards: -96.91966, mean: -0.37277
[32m[0906 15-23-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18246, current rewards: -117.67385, mean: -0.37959
[32m[0906 15-24-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18189, current rewards: -143.85687, mean: -0.39960
[32m[0906 15-24-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18173, current rewards: -152.84651, mean: -0.37280
[32m[0906 15-24-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18159, current rewards: -148.99421, mean: -0.32390
[32m[0906 15-24-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18154, current rewards: -145.14222, mean: -0.28459
[32m[0906 15-24-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18189, current rewards: -141.29105, mean: -0.25231
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18191, current rewards: -137.43602, mean: -0.22530
[32m[0906 15-25-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18178, current rewards: -133.86808, mean: -0.20283
[32m[0906 15-25-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18167, current rewards: -130.21576, mean: -0.18340
[32m[0906 15-25-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18154, current rewards: -126.40567, mean: -0.16632
[32m[0906 15-25-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18178, current rewards: -122.59417, mean: -0.15135
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18191, current rewards: -118.78291, mean: -0.13812
[32m[0906 15-25-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18203, current rewards: -114.97212, mean: -0.12634
[32m[0906 15-25-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18219, current rewards: -111.16086, mean: -0.11579
[32m[0906 15-26-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18231, current rewards: -146.15508, mean: -0.14471
[32m[0906 15-26-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18237, current rewards: -173.56264, mean: -0.16374
[32m[0906 15-26-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18250, current rewards: -172.58206, mean: -0.15548
[32m[0906 15-26-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18257, current rewards: -168.88134, mean: -0.14559
[32m[0906 15-26-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18264, current rewards: -165.17963, mean: -0.13651
[32m[0906 15-26-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18266, current rewards: -161.47885, mean: -0.12816
[32m[0906 15-27-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18270, current rewards: -157.77855, mean: -0.12044
[32m[0906 15-27-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18275, current rewards: -154.07760, mean: -0.11329
[32m[0906 15-27-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18280, current rewards: -150.37615, mean: -0.10665
[32m[0906 15-27-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18284, current rewards: -146.67615, mean: -0.10046
[32m[0906 15-27-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18287, current rewards: -164.52953, mean: -0.10896
[32m[0906 15-27-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18290, current rewards: -210.12659, mean: -0.13470
[32m[0906 15-27-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18293, current rewards: -254.61578, mean: -0.15815
[32m[0906 15-28-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18298, current rewards: -300.20871, mean: -0.18085
[32m[0906 15-28-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18301, current rewards: -344.69514, mean: -0.20158
[32m[0906 15-28-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18306, current rewards: -390.28419, mean: -0.22175
[32m[0906 15-28-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18311, current rewards: -434.76990, mean: -0.24020
[32m[0906 15-28-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18313, current rewards: -480.36064, mean: -0.25826
[32m[0906 15-28-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18316, current rewards: -524.84950, mean: -0.27479
[32m[0906 15-29-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18318, current rewards: -519.96327, mean: -0.26529
[32m[0906 15-29-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18319, current rewards: -514.92177, mean: -0.25618
[32m[0906 15-29-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18321, current rewards: -509.90127, mean: -0.24752
[32m[0906 15-29-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18320, current rewards: -504.87920, mean: -0.23928
[32m[0906 15-29-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18321, current rewards: -496.86913, mean: -0.23003
[32m[0906 15-29-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18322, current rewards: -493.51277, mean: -0.22331
[32m[0906 15-29-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18323, current rewards: -490.15718, mean: -0.21688
[32m[0906 15-30-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18318, current rewards: -486.80087, mean: -0.21074
[32m[0906 15-30-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18310, current rewards: -483.13362, mean: -0.20472
[32m[0906 15-30-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18301, current rewards: -479.82670, mean: -0.19910
[32m[0906 15-30-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18297, current rewards: -476.52078, mean: -0.19371
[32m[0906 15-30-40 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 15-30-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-30-40 @MBExp.py:227][0m Rewards obtained: [-473.877045817247], Lows: [95], Highs: [468], Total time: 6423.624914000001
[32m[0906 15-31-12 @MBExp.py:144][0m ####################################################################
[32m[0906 15-31-12 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 15-31-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18600, current rewards: -6.85170, mean: -0.68517
[32m[0906 15-31-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18419, current rewards: -1.32224, mean: -0.02204
[32m[0906 15-31-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18394, current rewards: 4.05471, mean: 0.03686
[32m[0906 15-31-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18386, current rewards: 9.43133, mean: 0.05895
[32m[0906 15-31-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18336, current rewards: 14.80546, mean: 0.07050
[32m[0906 15-31-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18261, current rewards: 21.89180, mean: 0.08420
[32m[0906 15-32-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18216, current rewards: 26.86140, mean: 0.08665
[32m[0906 15-32-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18147, current rewards: 31.76099, mean: 0.08822
[32m[0906 15-32-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18128, current rewards: 36.66000, mean: 0.08941
[32m[0906 15-32-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18111, current rewards: 41.56134, mean: 0.09035
[32m[0906 15-32-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18104, current rewards: 9.75679, mean: 0.01913
[32m[0906 15-32-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18137, current rewards: -90.24321, mean: -0.16115
[32m[0906 15-33-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18155, current rewards: -190.24321, mean: -0.31187
[32m[0906 15-33-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18143, current rewards: -290.24321, mean: -0.43976
[32m[0906 15-33-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18132, current rewards: -390.24321, mean: -0.54964
[32m[0906 15-33-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18119, current rewards: -490.24321, mean: -0.64506
[32m[0906 15-33-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18136, current rewards: -590.24321, mean: -0.72870
[32m[0906 15-33-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18159, current rewards: -690.24321, mean: -0.80261
[32m[0906 15-33-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18171, current rewards: -790.24321, mean: -0.86840
[32m[0906 15-34-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18185, current rewards: -890.24321, mean: -0.92734
[32m[0906 15-34-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18199, current rewards: -990.24321, mean: -0.98044
[32m[0906 15-34-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18211, current rewards: -1075.63785, mean: -1.01475
[32m[0906 15-34-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18217, current rewards: -1071.58709, mean: -0.96539
[32m[0906 15-34-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18227, current rewards: -1065.69773, mean: -0.91870
[32m[0906 15-34-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18237, current rewards: -1059.78574, mean: -0.87586
[32m[0906 15-35-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18243, current rewards: -1053.87103, mean: -0.83641
[32m[0906 15-35-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18252, current rewards: -1047.96551, mean: -0.79997
[32m[0906 15-35-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18258, current rewards: -1042.06038, mean: -0.76622
[32m[0906 15-35-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18262, current rewards: -1036.15181, mean: -0.73486
[32m[0906 15-35-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18267, current rewards: -1030.24466, mean: -0.70565
[32m[0906 15-35-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18270, current rewards: -1024.89267, mean: -0.67874
[32m[0906 15-35-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18274, current rewards: -1019.35801, mean: -0.65343
[32m[0906 15-36-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18277, current rewards: -1013.98665, mean: -0.62981
[32m[0906 15-36-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18282, current rewards: -1008.61837, mean: -0.60760
[32m[0906 15-36-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18287, current rewards: -1003.25080, mean: -0.58670
[32m[0906 15-36-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18288, current rewards: -997.87994, mean: -0.56698
[32m[0906 15-36-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18287, current rewards: -992.50553, mean: -0.54835
[32m[0906 15-36-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18289, current rewards: -987.13706, mean: -0.53072
[32m[0906 15-37-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18294, current rewards: -981.76696, mean: -0.51401
[32m[0906 15-37-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18295, current rewards: -976.75767, mean: -0.49835
[32m[0906 15-37-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18297, current rewards: -971.32385, mean: -0.48325
[32m[0906 15-37-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18298, current rewards: -965.89057, mean: -0.46888
[32m[0906 15-37-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18300, current rewards: -960.80492, mean: -0.45536
[32m[0906 15-37-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18299, current rewards: -955.93575, mean: -0.44256
[32m[0906 15-37-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18302, current rewards: -951.04179, mean: -0.43034
[32m[0906 15-38-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18303, current rewards: -946.14959, mean: -0.41865
[32m[0906 15-38-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18300, current rewards: -941.25858, mean: -0.40747
[32m[0906 15-38-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18291, current rewards: -936.31934, mean: -0.39675
[32m[0906 15-38-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18283, current rewards: -931.42023, mean: -0.38648
[32m[0906 15-38-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18277, current rewards: -926.52594, mean: -0.37664
[32m[0906 15-38-49 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 15-38-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-38-49 @MBExp.py:227][0m Rewards obtained: [-922.607372464767], Lows: [555], Highs: [19], Total time: 6881.181864000001
[32m[0906 15-39-23 @MBExp.py:144][0m ####################################################################
[32m[0906 15-39-23 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 15-39-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18500, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-39-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18549, current rewards: -3.86692, mean: -0.06445
[32m[0906 15-39-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18495, current rewards: 4.49895, mean: 0.04090
[32m[0906 15-39-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18461, current rewards: 12.85915, mean: 0.08037
[32m[0906 15-40-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18398, current rewards: 21.22825, mean: 0.10109
[32m[0906 15-40-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18308, current rewards: 29.59294, mean: 0.11382
[32m[0906 15-40-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18246, current rewards: 37.94828, mean: 0.12241
[32m[0906 15-40-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18176, current rewards: 46.30067, mean: 0.12861
[32m[0906 15-40-38 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18126, current rewards: 54.66221, mean: 0.13332
[32m[0906 15-40-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18107, current rewards: 63.02181, mean: 0.13700
[32m[0906 15-40-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18091, current rewards: 71.39123, mean: 0.13998
[32m[0906 15-41-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18119, current rewards: 79.74533, mean: 0.14240
[32m[0906 15-41-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18140, current rewards: 88.10495, mean: 0.14443
[32m[0906 15-41-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18129, current rewards: 39.28164, mean: 0.05952
[32m[0906 15-41-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18118, current rewards: -60.71836, mean: -0.08552
[32m[0906 15-41-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18109, current rewards: -160.71836, mean: -0.21147
[32m[0906 15-41-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18121, current rewards: -260.71836, mean: -0.32187
[32m[0906 15-42-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18144, current rewards: -360.71836, mean: -0.41944
[32m[0906 15-42-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18162, current rewards: -460.71836, mean: -0.50628
[32m[0906 15-42-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18177, current rewards: -560.71836, mean: -0.58408
[32m[0906 15-42-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18187, current rewards: -660.71836, mean: -0.65418
[32m[0906 15-42-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18196, current rewards: -737.73531, mean: -0.69598
[32m[0906 15-42-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18207, current rewards: -728.59177, mean: -0.65639
[32m[0906 15-42-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18218, current rewards: -720.45747, mean: -0.62108
[32m[0906 15-43-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18226, current rewards: -712.34183, mean: -0.58871
[32m[0906 15-43-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18239, current rewards: -704.23140, mean: -0.55891
[32m[0906 15-43-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18245, current rewards: -696.12195, mean: -0.53139
[32m[0906 15-43-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18251, current rewards: -688.01494, mean: -0.50589
[32m[0906 15-43-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18257, current rewards: -679.89111, mean: -0.48219
[32m[0906 15-43-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18263, current rewards: -671.78011, mean: -0.46012
[32m[0906 15-43-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18267, current rewards: -663.53029, mean: -0.43942
[32m[0906 15-44-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18273, current rewards: -674.48443, mean: -0.43236
[32m[0906 15-44-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18276, current rewards: -667.93275, mean: -0.41487
[32m[0906 15-44-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18278, current rewards: -661.37972, mean: -0.39842
[32m[0906 15-44-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18282, current rewards: -654.82619, mean: -0.38294
[32m[0906 15-44-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18286, current rewards: -648.27566, mean: -0.36834
[32m[0906 15-44-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18287, current rewards: -641.72503, mean: -0.35454
[32m[0906 15-45-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18289, current rewards: -635.17415, mean: -0.34149
[32m[0906 15-45-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18292, current rewards: -626.96726, mean: -0.32826
[32m[0906 15-45-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18295, current rewards: -619.27324, mean: -0.31596
[32m[0906 15-45-32 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18298, current rewards: -612.27906, mean: -0.30462
[32m[0906 15-45-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18297, current rewards: -615.40448, mean: -0.29874
[32m[0906 15-45-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18299, current rewards: -608.87396, mean: -0.28857
[32m[0906 15-45-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18299, current rewards: -602.34485, mean: -0.27886
[32m[0906 15-46-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18302, current rewards: -595.81223, mean: -0.26960
[32m[0906 15-46-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18303, current rewards: -589.27595, mean: -0.26074
[32m[0906 15-46-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: -582.74568, mean: -0.25227
[32m[0906 15-46-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18295, current rewards: -576.75182, mean: -0.24439
[32m[0906 15-46-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18287, current rewards: -580.60577, mean: -0.24092
[32m[0906 15-46-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18281, current rewards: -634.92570, mean: -0.25810
[32m[0906 15-47-01 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 15-47-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-47-01 @MBExp.py:227][0m Rewards obtained: [-672.5505255321349], Lows: [470], Highs: [41], Total time: 7338.722601000001
[32m[0906 15-47-37 @MBExp.py:144][0m ####################################################################
[32m[0906 15-47-37 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 15-47-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18461, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-47-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18486, current rewards: -5.24381, mean: -0.08740
[32m[0906 15-47-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18438, current rewards: -0.54322, mean: -0.00494
[32m[0906 15-48-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18403, current rewards: 4.16728, mean: 0.02605
[32m[0906 15-48-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18343, current rewards: 8.87175, mean: 0.04225
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18262, current rewards: 13.46558, mean: 0.05179
[32m[0906 15-48-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18210, current rewards: 18.14123, mean: 0.05852
[32m[0906 15-48-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18145, current rewards: 22.82286, mean: 0.06340
[32m[0906 15-48-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18079, current rewards: 27.49946, mean: 0.06707
[32m[0906 15-49-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18062, current rewards: 32.18161, mean: 0.06996
[32m[0906 15-49-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18049, current rewards: 36.86002, mean: 0.07227
[32m[0906 15-49-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18053, current rewards: 41.53923, mean: 0.07418
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18085, current rewards: 46.21918, mean: 0.07577
[32m[0906 15-49-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18079, current rewards: 51.10023, mean: 0.07742
[32m[0906 15-49-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18070, current rewards: 57.21542, mean: 0.08059
[32m[0906 15-49-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18062, current rewards: 63.32130, mean: 0.08332
[32m[0906 15-50-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18069, current rewards: 69.43758, mean: 0.08573
[32m[0906 15-50-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18088, current rewards: 75.55009, mean: 0.08785
[32m[0906 15-50-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18110, current rewards: 81.65794, mean: 0.08973
[32m[0906 15-50-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18126, current rewards: 87.76929, mean: 0.09143
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18143, current rewards: 93.88565, mean: 0.09296
[32m[0906 15-50-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18157, current rewards: 102.08470, mean: 0.09631
[32m[0906 15-50-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18172, current rewards: 108.57420, mean: 0.09781
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18187, current rewards: 95.38070, mean: 0.08222
[32m[0906 15-51-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18194, current rewards: 101.56067, mean: 0.08393
[32m[0906 15-51-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18203, current rewards: 107.74534, mean: 0.08551
[32m[0906 15-51-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18212, current rewards: 113.92770, mean: 0.08697
[32m[0906 15-51-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18221, current rewards: 120.10692, mean: 0.08831
[32m[0906 15-51-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18228, current rewards: 126.28509, mean: 0.08956
[32m[0906 15-52-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18233, current rewards: 111.39992, mean: 0.07630
[32m[0906 15-52-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18241, current rewards: 117.73649, mean: 0.07797
[32m[0906 15-52-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18245, current rewards: 124.07552, mean: 0.07954
[32m[0906 15-52-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18250, current rewards: 130.41393, mean: 0.08100
[32m[0906 15-52-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18255, current rewards: 136.75239, mean: 0.08238
[32m[0906 15-52-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18260, current rewards: 143.09297, mean: 0.08368
[32m[0906 15-52-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18263, current rewards: 149.43358, mean: 0.08491
[32m[0906 15-53-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18267, current rewards: 155.77468, mean: 0.08606
[32m[0906 15-53-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18270, current rewards: 161.63904, mean: 0.08690
[32m[0906 15-53-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18273, current rewards: 157.02606, mean: 0.08221
[32m[0906 15-53-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18277, current rewards: 152.97096, mean: 0.07805
[32m[0906 15-53-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18284, current rewards: 158.91304, mean: 0.07906
[32m[0906 15-53-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18286, current rewards: 164.85630, mean: 0.08003
[32m[0906 15-54-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18288, current rewards: 170.79850, mean: 0.08095
[32m[0906 15-54-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18290, current rewards: 176.74398, mean: 0.08183
[32m[0906 15-54-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18291, current rewards: 182.68919, mean: 0.08266
[32m[0906 15-54-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18293, current rewards: 178.56060, mean: 0.07901
[32m[0906 15-54-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18295, current rewards: 184.62856, mean: 0.07993
[32m[0906 15-54-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18290, current rewards: 191.10830, mean: 0.08098
[32m[0906 15-54-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18282, current rewards: 197.58480, mean: 0.08199
[32m[0906 15-55-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18276, current rewards: 204.06335, mean: 0.08295
[32m[0906 15-55-14 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 15-55-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-55-14 @MBExp.py:227][0m Rewards obtained: [209.23997181866025], Lows: [30], Highs: [22], Total time: 7796.132745000002
[32m[0906 15-55-52 @MBExp.py:144][0m ####################################################################
[32m[0906 15-55-52 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-55-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18347, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-56-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18501, current rewards: -6.22966, mean: -0.10383
[32m[0906 15-56-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18490, current rewards: -0.61412, mean: -0.00558
[32m[0906 15-56-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18446, current rewards: 5.01129, mean: 0.03132
[32m[0906 15-56-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18387, current rewards: 10.74912, mean: 0.05119
[32m[0906 15-56-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18291, current rewards: 17.95701, mean: 0.06907
[32m[0906 15-56-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18249, current rewards: 3.01674, mean: 0.00973
[32m[0906 15-56-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18190, current rewards: 8.21197, mean: 0.02281
[32m[0906 15-57-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18100, current rewards: 13.44527, mean: 0.03279
[32m[0906 15-57-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18085, current rewards: 18.67112, mean: 0.04059
[32m[0906 15-57-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18076, current rewards: 23.89262, mean: 0.04685
[32m[0906 15-57-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18062, current rewards: 29.11186, mean: 0.05199
[32m[0906 15-57-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18079, current rewards: 34.33336, mean: 0.05628
[32m[0906 15-57-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18084, current rewards: 39.38146, mean: 0.05967
[32m[0906 15-58-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18079, current rewards: 44.57742, mean: 0.06279
[32m[0906 15-58-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18070, current rewards: 49.77483, mean: 0.06549
[32m[0906 15-58-19 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18071, current rewards: 44.45024, mean: 0.05488
[32m[0906 15-58-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18091, current rewards: 38.90849, mean: 0.04524
[32m[0906 15-58-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18111, current rewards: 42.54182, mean: 0.04675
[32m[0906 15-58-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18124, current rewards: 46.17515, mean: 0.04810
[32m[0906 15-58-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18138, current rewards: 49.80848, mean: 0.04932
[32m[0906 15-59-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18152, current rewards: 30.75080, mean: 0.02901
[32m[0906 15-59-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18165, current rewards: -19.24920, mean: -0.01734
[32m[0906 15-59-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18180, current rewards: -69.24920, mean: -0.05970
[32m[0906 15-59-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18192, current rewards: -119.24920, mean: -0.09855
[32m[0906 15-59-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18200, current rewards: -169.24920, mean: -0.13432
[32m[0906 15-59-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18210, current rewards: -219.24920, mean: -0.16737
[32m[0906 16-00-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18223, current rewards: -269.24920, mean: -0.19798
[32m[0906 16-00-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18230, current rewards: -319.24920, mean: -0.22642
[32m[0906 16-00-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18235, current rewards: -369.24920, mean: -0.25291
[32m[0906 16-00-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18244, current rewards: -419.24920, mean: -0.27765
[32m[0906 16-00-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18249, current rewards: -469.24920, mean: -0.30080
[32m[0906 16-00-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18255, current rewards: -519.24920, mean: -0.32252
[32m[0906 16-00-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18260, current rewards: -569.24920, mean: -0.34292
[32m[0906 16-01-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18264, current rewards: -619.24920, mean: -0.36213
[32m[0906 16-01-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18267, current rewards: -669.24920, mean: -0.38026
[32m[0906 16-01-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18270, current rewards: -719.24920, mean: -0.39738
[32m[0906 16-01-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18276, current rewards: -769.24920, mean: -0.41357
[32m[0906 16-01-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18279, current rewards: -819.24920, mean: -0.42893
[32m[0906 16-01-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18282, current rewards: -869.24920, mean: -0.44349
[32m[0906 16-02-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18285, current rewards: -919.24920, mean: -0.45734
[32m[0906 16-02-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18290, current rewards: -969.24920, mean: -0.47051
[32m[0906 16-02-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18294, current rewards: -1019.24920, mean: -0.48306
[32m[0906 16-02-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18298, current rewards: -1069.24920, mean: -0.49502
[32m[0906 16-02-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18300, current rewards: -1119.24920, mean: -0.50645
[32m[0906 16-02-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18301, current rewards: -1169.24920, mean: -0.51737
[32m[0906 16-02-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: -1219.24920, mean: -0.52781
[32m[0906 16-03-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18296, current rewards: -1269.24920, mean: -0.53782
[32m[0906 16-03-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18288, current rewards: -1319.24920, mean: -0.54741
[32m[0906 16-03-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18281, current rewards: -1369.24920, mean: -0.55661
[32m[0906 16-03-30 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 16-03-30 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-03-30 @MBExp.py:227][0m Rewards obtained: [-1409.249201493117], Lows: [20], Highs: [1472], Total time: 8253.668976
[32m[0906 16-04-09 @MBExp.py:144][0m ####################################################################
[32m[0906 16-04-09 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 16-04-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18613, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-04-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18449, current rewards: -4.97816, mean: -0.08297
[32m[0906 16-04-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18384, current rewards: 1.26942, mean: 0.01154
[32m[0906 16-04-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18389, current rewards: 7.51089, mean: 0.04694
[32m[0906 16-04-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18343, current rewards: 13.75650, mean: 0.06551
[32m[0906 16-04-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18258, current rewards: 20.44479, mean: 0.07863
[32m[0906 16-05-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18213, current rewards: 26.59081, mean: 0.08578
[32m[0906 16-05-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18166, current rewards: 32.74101, mean: 0.09095
[32m[0906 16-05-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18066, current rewards: 38.89413, mean: 0.09486
[32m[0906 16-05-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18036, current rewards: 45.04193, mean: 0.09792
[32m[0906 16-05-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18027, current rewards: 51.18711, mean: 0.10037
[32m[0906 16-05-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18023, current rewards: 57.33932, mean: 0.10239
[32m[0906 16-06-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18023, current rewards: 63.48226, mean: 0.10407
[32m[0906 16-06-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18019, current rewards: 69.27696, mean: 0.10497
[32m[0906 16-06-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18027, current rewards: 75.57308, mean: 0.10644
[32m[0906 16-06-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18022, current rewards: 59.61275, mean: 0.07844
[32m[0906 16-06-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18015, current rewards: 70.38477, mean: 0.08689
[32m[0906 16-06-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18040, current rewards: 81.13834, mean: 0.09435
[32m[0906 16-06-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18058, current rewards: 91.91476, mean: 0.10101
[32m[0906 16-07-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18078, current rewards: 102.68911, mean: 0.10697
[32m[0906 16-07-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18094, current rewards: 113.47723, mean: 0.11235
[32m[0906 16-07-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18110, current rewards: 111.21050, mean: 0.10492
[32m[0906 16-07-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18121, current rewards: 116.07035, mean: 0.10457
[32m[0906 16-07-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18136, current rewards: 120.93371, mean: 0.10425
[32m[0906 16-07-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18148, current rewards: 125.79292, mean: 0.10396
[32m[0906 16-07-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18162, current rewards: 130.65578, mean: 0.10370
[32m[0906 16-08-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18173, current rewards: 135.51854, mean: 0.10345
[32m[0906 16-08-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18183, current rewards: 140.37902, mean: 0.10322
[32m[0906 16-08-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18194, current rewards: 145.23912, mean: 0.10301
[32m[0906 16-08-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18203, current rewards: 150.27675, mean: 0.10293
[32m[0906 16-08-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18210, current rewards: 155.12372, mean: 0.10273
[32m[0906 16-08-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18218, current rewards: 159.98003, mean: 0.10255
[32m[0906 16-09-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18225, current rewards: 164.83824, mean: 0.10238
[32m[0906 16-09-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18231, current rewards: 160.35345, mean: 0.09660
[32m[0906 16-09-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18236, current rewards: 168.33140, mean: 0.09844
[32m[0906 16-09-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18241, current rewards: 176.32319, mean: 0.10018
[32m[0906 16-09-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18245, current rewards: 184.28934, mean: 0.10182
[32m[0906 16-09-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18247, current rewards: 192.64691, mean: 0.10357
[32m[0906 16-09-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18250, current rewards: 200.59045, mean: 0.10502
[32m[0906 16-10-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18253, current rewards: 208.48128, mean: 0.10637
[32m[0906 16-10-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18257, current rewards: 199.10656, mean: 0.09906
[32m[0906 16-10-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18265, current rewards: 172.48528, mean: 0.08373
[32m[0906 16-10-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18270, current rewards: 149.66975, mean: 0.07093
[32m[0906 16-10-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18273, current rewards: 129.20093, mean: 0.05982
[32m[0906 16-10-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18273, current rewards: 105.92097, mean: 0.04793
[32m[0906 16-11-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18275, current rewards: 111.90357, mean: 0.04951
[32m[0906 16-11-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18276, current rewards: 117.93187, mean: 0.05105
[32m[0906 16-11-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18272, current rewards: 123.93102, mean: 0.05251
[32m[0906 16-11-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18266, current rewards: 129.93342, mean: 0.05391
[32m[0906 16-11-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18259, current rewards: 135.93246, mean: 0.05526
[32m[0906 16-11-46 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 16-11-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-11-46 @MBExp.py:227][0m Rewards obtained: [140.73206760490905], Lows: [82], Highs: [31], Total time: 8710.65557
[32m[0906 16-12-28 @MBExp.py:144][0m ####################################################################
[32m[0906 16-12-28 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 16-12-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18516, current rewards: 0.72883, mean: 0.07288
[32m[0906 16-12-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18559, current rewards: -37.58312, mean: -0.62639
[32m[0906 16-12-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18517, current rewards: -75.47523, mean: -0.68614
[32m[0906 16-12-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18480, current rewards: -114.12241, mean: -0.71327
[32m[0906 16-13-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18461, current rewards: -149.95206, mean: -0.71406
[32m[0906 16-13-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18366, current rewards: -183.23581, mean: -0.70475
[32m[0906 16-13-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18304, current rewards: -216.34900, mean: -0.69790
[32m[0906 16-13-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18261, current rewards: -244.58978, mean: -0.67942
[32m[0906 16-13-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18155, current rewards: -284.36836, mean: -0.69358
[32m[0906 16-13-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18096, current rewards: -325.91531, mean: -0.70851
[32m[0906 16-14-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18082, current rewards: -378.46020, mean: -0.74208
[32m[0906 16-14-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18075, current rewards: -428.75702, mean: -0.76564
[32m[0906 16-14-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18056, current rewards: -482.49940, mean: -0.79098
[32m[0906 16-14-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18049, current rewards: -521.50505, mean: -0.79016
[32m[0906 16-14-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18051, current rewards: -565.44952, mean: -0.79641
[32m[0906 16-14-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18049, current rewards: -617.61706, mean: -0.81265
[32m[0906 16-14-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18043, current rewards: -655.97538, mean: -0.80985
[32m[0906 16-15-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18062, current rewards: -695.63184, mean: -0.80887
[32m[0906 16-15-13 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18086, current rewards: -737.80466, mean: -0.81077
[32m[0906 16-15-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18102, current rewards: -790.74634, mean: -0.82369
[32m[0906 16-15-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18119, current rewards: -839.35489, mean: -0.83104
[32m[0906 16-15-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18136, current rewards: -878.91488, mean: -0.82916
[32m[0906 16-15-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18147, current rewards: -969.46710, mean: -0.87339
[32m[0906 16-15-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18155, current rewards: -1066.63334, mean: -0.91951
[32m[0906 16-16-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18164, current rewards: -1166.63334, mean: -0.96416
[32m[0906 16-16-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18173, current rewards: -1266.63334, mean: -1.00526
[32m[0906 16-16-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18182, current rewards: -1366.63334, mean: -1.04323
[32m[0906 16-16-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18187, current rewards: -1466.63334, mean: -1.07841
[32m[0906 16-16-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18202, current rewards: -1566.63334, mean: -1.11109
[32m[0906 16-16-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18206, current rewards: -1659.63334, mean: -1.13674
[32m[0906 16-17-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18215, current rewards: -1703.19441, mean: -1.12794
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18219, current rewards: -1742.79621, mean: -1.11718
[32m[0906 16-17-22 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18225, current rewards: -1793.25028, mean: -1.11382
[32m[0906 16-17-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18230, current rewards: -1845.85065, mean: -1.11196
[32m[0906 16-17-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18234, current rewards: -1885.63301, mean: -1.10271
[32m[0906 16-17-50 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18236, current rewards: -1927.38373, mean: -1.09510
[32m[0906 16-17-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18240, current rewards: -1980.56485, mean: -1.09423
[32m[0906 16-18-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18245, current rewards: -2046.51660, mean: -1.10028
[32m[0906 16-18-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18248, current rewards: -2138.77928, mean: -1.11978
[32m[0906 16-18-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18252, current rewards: -2230.43241, mean: -1.13798
[32m[0906 16-18-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18254, current rewards: -2330.43241, mean: -1.15942
[32m[0906 16-18-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18258, current rewards: -2430.43241, mean: -1.17982
[32m[0906 16-18-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18264, current rewards: -2530.43241, mean: -1.19926
[32m[0906 16-19-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18266, current rewards: -2630.43241, mean: -1.21779
[32m[0906 16-19-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18267, current rewards: -2723.28531, mean: -1.23226
[32m[0906 16-19-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18269, current rewards: -2817.86477, mean: -1.24684
[32m[0906 16-19-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18270, current rewards: -2917.86477, mean: -1.26314
[32m[0906 16-19-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18271, current rewards: -3017.86477, mean: -1.27876
[32m[0906 16-19-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18264, current rewards: -3117.86477, mean: -1.29372
[32m[0906 16-19-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18257, current rewards: -3165.31725, mean: -1.28671
[32m[0906 16-20-05 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 16-20-05 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-20-05 @MBExp.py:227][0m Rewards obtained: [-3202.963766607853], Lows: [1664], Highs: [33], Total time: 9167.628627
[32m[0906 16-20-49 @MBExp.py:144][0m ####################################################################
[32m[0906 16-20-49 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 16-20-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18710, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-21-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18590, current rewards: -20.08721, mean: -0.33479
[32m[0906 16-21-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18523, current rewards: -0.35279, mean: -0.00321
[32m[0906 16-21-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18487, current rewards: -36.54389, mean: -0.22840
[32m[0906 16-21-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18441, current rewards: -93.26499, mean: -0.44412
[32m[0906 16-21-37 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18346, current rewards: -155.88538, mean: -0.59956
[32m[0906 16-21-46 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18284, current rewards: -212.25127, mean: -0.68468
[32m[0906 16-21-55 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18230, current rewards: -260.15286, mean: -0.72265
[32m[0906 16-22-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18139, current rewards: -323.87744, mean: -0.78994
[32m[0906 16-22-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18073, current rewards: -388.29266, mean: -0.84411
[32m[0906 16-22-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18059, current rewards: -455.83060, mean: -0.89379
[32m[0906 16-22-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18048, current rewards: -521.96949, mean: -0.93209
[32m[0906 16-22-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18020, current rewards: -612.70314, mean: -1.00443
[32m[0906 16-22-48 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18013, current rewards: -703.57330, mean: -1.06602
[32m[0906 16-22-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18016, current rewards: -792.18548, mean: -1.11575
[32m[0906 16-23-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18019, current rewards: -880.80416, mean: -1.15895
[32m[0906 16-23-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18015, current rewards: -971.68413, mean: -1.19961
[32m[0906 16-23-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18026, current rewards: -1060.30225, mean: -1.23291
[32m[0906 16-23-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18054, current rewards: -1135.38469, mean: -1.24768
[32m[0906 16-23-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18073, current rewards: -1235.38469, mean: -1.28686
[32m[0906 16-23-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18091, current rewards: -1335.38469, mean: -1.32216
[32m[0906 16-24-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18104, current rewards: -1435.38469, mean: -1.35414
[32m[0906 16-24-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18118, current rewards: -1535.38469, mean: -1.38323
[32m[0906 16-24-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18134, current rewards: -1635.38469, mean: -1.40981
[32m[0906 16-24-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18148, current rewards: -1735.38469, mean: -1.43420
[32m[0906 16-24-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18159, current rewards: -1835.38469, mean: -1.45665
[32m[0906 16-24-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18169, current rewards: -1935.38469, mean: -1.47739
[32m[0906 16-24-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18176, current rewards: -2035.38469, mean: -1.49661
[32m[0906 16-25-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18189, current rewards: -2037.46634, mean: -1.44501
[32m[0906 16-25-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18202, current rewards: -2030.12378, mean: -1.39050
[32m[0906 16-25-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18210, current rewards: -2022.77875, mean: -1.33959
[32m[0906 16-25-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18215, current rewards: -2015.43829, mean: -1.29195
[32m[0906 16-25-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18221, current rewards: -2008.09649, mean: -1.24726
[32m[0906 16-25-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18225, current rewards: -2000.75436, mean: -1.20527
[32m[0906 16-26-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18229, current rewards: -1993.41593, mean: -1.16574
[32m[0906 16-26-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18232, current rewards: -2006.66658, mean: -1.14015
[32m[0906 16-26-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18235, current rewards: -1996.92668, mean: -1.10327
[32m[0906 16-26-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18239, current rewards: -1988.62656, mean: -1.06915
[32m[0906 16-26-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18241, current rewards: -1980.32644, mean: -1.03682
[32m[0906 16-26-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18244, current rewards: -1972.02632, mean: -1.00614
[32m[0906 16-26-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18246, current rewards: -1963.72620, mean: -0.97698
[32m[0906 16-27-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18249, current rewards: -1955.42608, mean: -0.94924
[32m[0906 16-27-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18255, current rewards: -1984.43804, mean: -0.94049
[32m[0906 16-27-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18259, current rewards: -2034.43804, mean: -0.94187
[32m[0906 16-27-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18264, current rewards: -2084.43804, mean: -0.94318
[32m[0906 16-27-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18266, current rewards: -2134.43804, mean: -0.94444
[32m[0906 16-27-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18270, current rewards: -2184.43804, mean: -0.94564
[32m[0906 16-28-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18272, current rewards: -2234.43804, mean: -0.94680
[32m[0906 16-28-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18265, current rewards: -2284.43804, mean: -0.94790
[32m[0906 16-28-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18258, current rewards: -2334.43804, mean: -0.94896
[32m[0906 16-28-26 @Agent.py:117][0m Average action selection time: 0.1825
[32m[0906 16-28-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-28-26 @MBExp.py:227][0m Rewards obtained: [-2374.4380416373333], Lows: [1075], Highs: [434], Total time: 9624.626141
[32m[0906 16-29-12 @MBExp.py:144][0m ####################################################################
[32m[0906 16-29-12 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 16-29-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18824, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-29-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18574, current rewards: -4.23182, mean: -0.07053
[32m[0906 16-29-32 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18550, current rewards: 1.59609, mean: 0.01451
[32m[0906 16-29-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18528, current rewards: 7.48078, mean: 0.04675
[32m[0906 16-29-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18501, current rewards: 13.36822, mean: 0.06366
[32m[0906 16-30-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18382, current rewards: 19.25941, mean: 0.07407
[32m[0906 16-30-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18315, current rewards: 25.14904, mean: 0.08113
[32m[0906 16-30-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18266, current rewards: 31.03526, mean: 0.08621
[32m[0906 16-30-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18173, current rewards: 36.92448, mean: 0.09006
[32m[0906 16-30-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18087, current rewards: 42.82055, mean: 0.09309
[32m[0906 16-30-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18068, current rewards: 48.85387, mean: 0.09579
[32m[0906 16-30-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18061, current rewards: 54.75850, mean: 0.09778
[32m[0906 16-31-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18031, current rewards: 56.18260, mean: 0.09210
[32m[0906 16-31-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18014, current rewards: 12.94283, mean: 0.01961
[32m[0906 16-31-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18013, current rewards: -44.89772, mean: -0.06324
[32m[0906 16-31-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18015, current rewards: -102.72025, mean: -0.13516
[32m[0906 16-31-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18013, current rewards: -158.49819, mean: -0.19568
[32m[0906 16-31-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18018, current rewards: -218.71450, mean: -0.25432
[32m[0906 16-31-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18043, current rewards: -272.07098, mean: -0.29898
[32m[0906 16-32-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18063, current rewards: -334.78868, mean: -0.34874
[32m[0906 16-32-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18081, current rewards: -388.12847, mean: -0.38429
[32m[0906 16-32-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18098, current rewards: -433.52047, mean: -0.40898
[32m[0906 16-32-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18107, current rewards: -426.95013, mean: -0.38464
[32m[0906 16-32-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18119, current rewards: -420.33588, mean: -0.36236
[32m[0906 16-32-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18135, current rewards: -413.73046, mean: -0.34193
[32m[0906 16-33-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18142, current rewards: -407.13556, mean: -0.32312
[32m[0906 16-33-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18153, current rewards: -421.82150, mean: -0.32200
[32m[0906 16-33-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18159, current rewards: -414.95853, mean: -0.30512
[32m[0906 16-33-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18168, current rewards: -408.22185, mean: -0.28952
[32m[0906 16-33-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18181, current rewards: -401.49194, mean: -0.27499
[32m[0906 16-33-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18186, current rewards: -394.76698, mean: -0.26144
[32m[0906 16-33-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18193, current rewards: -388.03714, mean: -0.24874
[32m[0906 16-34-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18197, current rewards: -381.30353, mean: -0.23683
[32m[0906 16-34-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18202, current rewards: -374.58431, mean: -0.22565
[32m[0906 16-34-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18208, current rewards: -365.30700, mean: -0.21363
[32m[0906 16-34-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18213, current rewards: -358.73084, mean: -0.20382
[32m[0906 16-34-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18219, current rewards: -352.17965, mean: -0.19457
[32m[0906 16-34-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18224, current rewards: -345.95221, mean: -0.18600
[32m[0906 16-35-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18227, current rewards: -340.14222, mean: -0.17808
[32m[0906 16-35-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18231, current rewards: -334.15876, mean: -0.17049
[32m[0906 16-35-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18234, current rewards: -328.18145, mean: -0.16327
[32m[0906 16-35-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18239, current rewards: -322.20213, mean: -0.15641
[32m[0906 16-35-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18245, current rewards: -316.46366, mean: -0.14998
[32m[0906 16-35-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18248, current rewards: -311.38440, mean: -0.14416
[32m[0906 16-35-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18251, current rewards: -305.62464, mean: -0.13829
[32m[0906 16-36-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18253, current rewards: -299.87439, mean: -0.13269
[32m[0906 16-36-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18255, current rewards: -294.12421, mean: -0.12733
[32m[0906 16-36-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18256, current rewards: -311.27740, mean: -0.13190
[32m[0906 16-36-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18254, current rewards: -310.90326, mean: -0.12901
[32m[0906 16-36-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18248, current rewards: -314.25682, mean: -0.12775
[32m[0906 16-36-48 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 16-36-48 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-36-48 @MBExp.py:227][0m Rewards obtained: [-316.9157374018161], Lows: [305], Highs: [20], Total time: 10081.361849
[32m[0906 16-37-36 @MBExp.py:144][0m ####################################################################
[32m[0906 16-37-36 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 16-37-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18581, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-37-47 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18639, current rewards: -3.87272, mean: -0.06455
[32m[0906 16-37-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18611, current rewards: 2.04595, mean: 0.01860
[32m[0906 16-38-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18580, current rewards: 7.96716, mean: 0.04979
[32m[0906 16-38-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18562, current rewards: 13.87859, mean: 0.06609
[32m[0906 16-38-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18448, current rewards: 19.79915, mean: 0.07615
[32m[0906 16-38-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18375, current rewards: 25.71845, mean: 0.08296
[32m[0906 16-38-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18316, current rewards: 31.63570, mean: 0.08788
[32m[0906 16-38-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18217, current rewards: 37.55434, mean: 0.09160
[32m[0906 16-39-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18128, current rewards: 19.51940, mean: 0.04243
[32m[0906 16-39-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18084, current rewards: 12.06426, mean: 0.02366
[32m[0906 16-39-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18073, current rewards: 0.23030, mean: 0.00041
[32m[0906 16-39-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18040, current rewards: -9.19860, mean: -0.01508
[32m[0906 16-39-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18006, current rewards: -18.84459, mean: -0.02855
[32m[0906 16-39-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18008, current rewards: -30.48186, mean: -0.04293
[32m[0906 16-39-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18010, current rewards: -37.91984, mean: -0.04989
[32m[0906 16-40-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18008, current rewards: -49.61269, mean: -0.06125
[32m[0906 16-40-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18008, current rewards: -55.73057, mean: -0.06480
[32m[0906 16-40-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18035, current rewards: -77.49051, mean: -0.08515
[32m[0906 16-40-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18049, current rewards: -75.06447, mean: -0.07819
[32m[0906 16-40-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18070, current rewards: -69.48240, mean: -0.06879
[32m[0906 16-40-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18086, current rewards: -63.90432, mean: -0.06029
[32m[0906 16-40-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18104, current rewards: -58.32672, mean: -0.05255
[32m[0906 16-41-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18126, current rewards: -62.65669, mean: -0.05401
[32m[0906 16-41-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18139, current rewards: -56.59133, mean: -0.04677
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18151, current rewards: -50.66246, mean: -0.04021
[32m[0906 16-41-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18162, current rewards: -46.08951, mean: -0.03518
[32m[0906 16-41-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18174, current rewards: -39.72158, mean: -0.02921
[32m[0906 16-41-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18188, current rewards: -33.34951, mean: -0.02365
[32m[0906 16-42-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18198, current rewards: -26.97879, mean: -0.01848
[32m[0906 16-42-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18205, current rewards: -20.61087, mean: -0.01365
[32m[0906 16-42-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18214, current rewards: -35.64579, mean: -0.02285
[32m[0906 16-42-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18217, current rewards: -28.86815, mean: -0.01793
[32m[0906 16-42-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18220, current rewards: -22.08512, mean: -0.01330
[32m[0906 16-42-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18228, current rewards: -9.88894, mean: -0.00578
[32m[0906 16-42-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18234, current rewards: 0.10298, mean: 0.00006
[32m[0906 16-43-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18237, current rewards: 6.70229, mean: 0.00370
[32m[0906 16-43-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18239, current rewards: 13.30011, mean: 0.00715
[32m[0906 16-43-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18241, current rewards: 19.89999, mean: 0.01042
[32m[0906 16-43-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18244, current rewards: 26.49716, mean: 0.01352
[32m[0906 16-43-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18248, current rewards: 33.09463, mean: 0.01646
[32m[0906 16-43-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18252, current rewards: 36.29515, mean: 0.01762
[32m[0906 16-44-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18258, current rewards: 33.45630, mean: 0.01586
[32m[0906 16-44-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18261, current rewards: 39.35976, mean: 0.01822
[32m[0906 16-44-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18263, current rewards: 45.45727, mean: 0.02057
[32m[0906 16-44-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18265, current rewards: 51.54698, mean: 0.02281
[32m[0906 16-44-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18268, current rewards: 57.64256, mean: 0.02495
[32m[0906 16-44-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18272, current rewards: 63.74420, mean: 0.02701
[32m[0906 16-44-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18270, current rewards: 69.84173, mean: 0.02898
[32m[0906 16-45-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18265, current rewards: 75.94255, mean: 0.03087
[32m[0906 16-45-13 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 16-45-13 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-45-13 @MBExp.py:227][0m Rewards obtained: [80.81432325227851], Lows: [107], Highs: [41], Total time: 10538.524048000001
[32m[0906 16-46-03 @MBExp.py:144][0m ####################################################################
[32m[0906 16-46-03 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 16-46-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18523, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-46-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18548, current rewards: -5.90647, mean: -0.09844
[32m[0906 16-46-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18472, current rewards: -1.88881, mean: -0.01717
[32m[0906 16-46-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18453, current rewards: 2.12513, mean: 0.01328
[32m[0906 16-46-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18448, current rewards: 6.13817, mean: 0.02923
[32m[0906 16-46-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18355, current rewards: 10.15271, mean: 0.03905
[32m[0906 16-47-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18286, current rewards: 14.16587, mean: 0.04570
[32m[0906 16-47-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18248, current rewards: 18.18167, mean: 0.05050
[32m[0906 16-47-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18165, current rewards: 22.19753, mean: 0.05414
[32m[0906 16-47-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18079, current rewards: 26.32445, mean: 0.05723
[32m[0906 16-47-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18025, current rewards: 30.36921, mean: 0.05955
[32m[0906 16-47-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18026, current rewards: 13.78440, mean: 0.02462
[32m[0906 16-47-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17999, current rewards: 22.76042, mean: 0.03731
[32m[0906 16-48-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17958, current rewards: 28.75941, mean: 0.04357
[32m[0906 16-48-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17963, current rewards: 34.72808, mean: 0.04891
[32m[0906 16-48-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17968, current rewards: 40.69701, mean: 0.05355
[32m[0906 16-48-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17965, current rewards: 46.66600, mean: 0.05761
[32m[0906 16-48-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17963, current rewards: 52.25006, mean: 0.06076
[32m[0906 16-48-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17990, current rewards: 47.62907, mean: 0.05234
[32m[0906 16-48-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18019, current rewards: 53.23012, mean: 0.05545
[32m[0906 16-49-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18042, current rewards: 58.82421, mean: 0.05824
[32m[0906 16-49-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18061, current rewards: 64.42409, mean: 0.06078
[32m[0906 16-49-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18075, current rewards: 70.02884, mean: 0.06309
[32m[0906 16-49-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18097, current rewards: 75.63182, mean: 0.06520
[32m[0906 16-49-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18108, current rewards: 81.23379, mean: 0.06714
[32m[0906 16-49-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18118, current rewards: 86.57235, mean: 0.06871
[32m[0906 16-50-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18129, current rewards: 81.45124, mean: 0.06218
[32m[0906 16-50-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18139, current rewards: 86.96763, mean: 0.06395
[32m[0906 16-50-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18153, current rewards: 92.13333, mean: 0.06534
[32m[0906 16-50-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18163, current rewards: 97.30109, mean: 0.06664
[32m[0906 16-50-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18170, current rewards: 102.46712, mean: 0.06786
[32m[0906 16-50-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18181, current rewards: 107.63179, mean: 0.06899
[32m[0906 16-50-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18188, current rewards: 112.80074, mean: 0.07006
[32m[0906 16-51-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18194, current rewards: 117.83408, mean: 0.07098
[32m[0906 16-51-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18201, current rewards: 122.98962, mean: 0.07192
[32m[0906 16-51-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18205, current rewards: 128.14621, mean: 0.07281
[32m[0906 16-51-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18211, current rewards: 133.30505, mean: 0.07365
[32m[0906 16-51-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18216, current rewards: 117.40906, mean: 0.06312
[32m[0906 16-51-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18220, current rewards: 122.42046, mean: 0.06409
[32m[0906 16-52-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18223, current rewards: 127.42210, mean: 0.06501
[32m[0906 16-52-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18226, current rewards: 132.42304, mean: 0.06588
[32m[0906 16-52-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18229, current rewards: 136.88466, mean: 0.06645
[32m[0906 16-52-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18234, current rewards: 120.73649, mean: 0.05722
[32m[0906 16-52-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18238, current rewards: 126.40658, mean: 0.05852
[32m[0906 16-52-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18242, current rewards: 132.04273, mean: 0.05975
[32m[0906 16-52-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18245, current rewards: 137.68332, mean: 0.06092
[32m[0906 16-53-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18249, current rewards: 143.32063, mean: 0.06204
[32m[0906 16-53-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18251, current rewards: 148.95634, mean: 0.06312
[32m[0906 16-53-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18250, current rewards: 154.59879, mean: 0.06415
[32m[0906 16-53-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18244, current rewards: 160.32687, mean: 0.06517
[32m[0906 16-53-40 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 16-53-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-53-40 @MBExp.py:227][0m Rewards obtained: [165.57750863558573], Lows: [30], Highs: [30], Total time: 10995.159145000001
[32m[0906 16-54-32 @MBExp.py:144][0m ####################################################################
[32m[0906 16-54-32 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 16-54-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18437, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-54-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18441, current rewards: -5.58992, mean: -0.09317
[32m[0906 16-54-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18431, current rewards: 0.36993, mean: 0.00336
[32m[0906 16-55-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18438, current rewards: 6.31923, mean: 0.03950
[32m[0906 16-55-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18422, current rewards: 12.27508, mean: 0.05845
[32m[0906 16-55-19 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18353, current rewards: 18.21934, mean: 0.07007
[32m[0906 16-55-28 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18281, current rewards: 24.17879, mean: 0.07800
[32m[0906 16-55-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18234, current rewards: 30.12315, mean: 0.08368
[32m[0906 16-55-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18156, current rewards: 35.82022, mean: 0.08737
[32m[0906 16-55-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18070, current rewards: 41.82404, mean: 0.09092
[32m[0906 16-56-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18008, current rewards: 47.83413, mean: 0.09379
[32m[0906 16-56-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18001, current rewards: 53.84725, mean: 0.09616
[32m[0906 16-56-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17971, current rewards: 59.85357, mean: 0.09812
[32m[0906 16-56-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17931, current rewards: 65.86709, mean: 0.09980
[32m[0906 16-56-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17933, current rewards: 50.64725, mean: 0.07133
[32m[0906 16-56-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17940, current rewards: 56.85327, mean: 0.07481
[32m[0906 16-56-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17943, current rewards: 63.81822, mean: 0.07879
[32m[0906 16-57-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17944, current rewards: 70.01135, mean: 0.08141
[32m[0906 16-57-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17969, current rewards: 76.19870, mean: 0.08373
[32m[0906 16-57-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17994, current rewards: 82.38646, mean: 0.08582
[32m[0906 16-57-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18016, current rewards: 88.58194, mean: 0.08770
[32m[0906 16-57-43 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18034, current rewards: 94.76996, mean: 0.08941
[32m[0906 16-57-52 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18051, current rewards: 100.95751, mean: 0.09095
[32m[0906 16-58-01 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18064, current rewards: 107.14927, mean: 0.09237
[32m[0906 16-58-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18078, current rewards: 112.81198, mean: 0.09323
[32m[0906 16-58-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18090, current rewards: 119.04977, mean: 0.09448
[32m[0906 16-58-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18103, current rewards: 125.22530, mean: 0.09559
[32m[0906 16-58-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18117, current rewards: 119.99175, mean: 0.08823
[32m[0906 16-58-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18124, current rewards: 126.16746, mean: 0.08948
[32m[0906 16-58-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18133, current rewards: 132.35909, mean: 0.09066
[32m[0906 16-59-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18140, current rewards: 138.55537, mean: 0.09176
[32m[0906 16-59-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18148, current rewards: 144.74350, mean: 0.09278
[32m[0906 16-59-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18154, current rewards: 151.88145, mean: 0.09434
[32m[0906 16-59-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18158, current rewards: 160.18905, mean: 0.09650
[32m[0906 16-59-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18161, current rewards: 166.29549, mean: 0.09725
[32m[0906 16-59-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18168, current rewards: 172.40366, mean: 0.09796
[32m[0906 17-00-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18173, current rewards: 178.51267, mean: 0.09863
[32m[0906 17-00-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18179, current rewards: 184.62841, mean: 0.09926
[32m[0906 17-00-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18186, current rewards: 190.73843, mean: 0.09986
[32m[0906 17-00-29 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18191, current rewards: 175.88926, mean: 0.08974
[32m[0906 17-00-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18196, current rewards: 181.72979, mean: 0.09041
[32m[0906 17-00-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18202, current rewards: 188.03200, mean: 0.09128
[32m[0906 17-00-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18207, current rewards: 193.84174, mean: 0.09187
[32m[0906 17-01-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18212, current rewards: 199.64641, mean: 0.09243
[32m[0906 17-01-15 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18216, current rewards: 205.45946, mean: 0.09297
[32m[0906 17-01-24 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18219, current rewards: 211.27057, mean: 0.09348
[32m[0906 17-01-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18220, current rewards: 217.07567, mean: 0.09397
[32m[0906 17-01-42 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18222, current rewards: 222.88880, mean: 0.09444
[32m[0906 17-01-51 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18226, current rewards: 228.69605, mean: 0.09489
[32m[0906 17-02-00 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18221, current rewards: 223.88356, mean: 0.09101
[32m[0906 17-02-08 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 17-02-08 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-02-08 @MBExp.py:227][0m Rewards obtained: [229.38679876065416], Lows: [20], Highs: [31], Total time: 11451.252691000002
[32m[0906 17-03-01 @MBExp.py:144][0m ####################################################################
[32m[0906 17-03-01 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 17-03-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18674, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-03-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18494, current rewards: -4.95066, mean: -0.08251
[32m[0906 17-03-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18450, current rewards: 0.78060, mean: 0.00710
[32m[0906 17-03-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18422, current rewards: 6.50894, mean: 0.04068
[32m[0906 17-03-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18430, current rewards: 12.23568, mean: 0.05827
[32m[0906 17-03-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18357, current rewards: 17.96561, mean: 0.06910
[32m[0906 17-03-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18285, current rewards: 23.69228, mean: 0.07643
[32m[0906 17-04-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18241, current rewards: 29.42418, mean: 0.08173
[32m[0906 17-04-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18161, current rewards: 35.15170, mean: 0.08574
[32m[0906 17-04-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18078, current rewards: 40.88169, mean: 0.08887
[32m[0906 17-04-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18016, current rewards: 26.17701, mean: 0.05133
[32m[0906 17-04-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17987, current rewards: 32.85577, mean: 0.05867
[32m[0906 17-04-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17964, current rewards: 39.28776, mean: 0.06441
[32m[0906 17-05-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17922, current rewards: 45.72859, mean: 0.06929
[32m[0906 17-05-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17909, current rewards: 52.16683, mean: 0.07347
[32m[0906 17-05-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17914, current rewards: 55.19701, mean: 0.07263
[32m[0906 17-05-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17918, current rewards: 53.73862, mean: 0.06634
[32m[0906 17-05-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17921, current rewards: 58.74628, mean: 0.06831
[32m[0906 17-05-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17935, current rewards: 63.76222, mean: 0.07007
[32m[0906 17-05-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17967, current rewards: 46.35472, mean: 0.04829
[32m[0906 17-06-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17995, current rewards: 52.85265, mean: 0.05233
[32m[0906 17-06-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18015, current rewards: 59.35635, mean: 0.05600
[32m[0906 17-06-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18036, current rewards: 65.85862, mean: 0.05933
[32m[0906 17-06-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18054, current rewards: 71.85974, mean: 0.06195
[32m[0906 17-06-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18070, current rewards: 77.00284, mean: 0.06364
[32m[0906 17-06-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18082, current rewards: 83.89803, mean: 0.06659
[32m[0906 17-06-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18093, current rewards: 90.79657, mean: 0.06931
[32m[0906 17-07-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18111, current rewards: 97.68846, mean: 0.07183
[32m[0906 17-07-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18121, current rewards: 104.57531, mean: 0.07417
[32m[0906 17-07-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18132, current rewards: 98.68530, mean: 0.06759
[32m[0906 17-07-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18143, current rewards: 103.83459, mean: 0.06876
[32m[0906 17-07-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18152, current rewards: 108.98356, mean: 0.06986
[32m[0906 17-07-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18161, current rewards: 117.02426, mean: 0.07269
[32m[0906 17-08-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18167, current rewards: 123.98258, mean: 0.07469
[32m[0906 17-08-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18175, current rewards: 130.89523, mean: 0.07655
[32m[0906 17-08-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18183, current rewards: 137.80805, mean: 0.07830
[32m[0906 17-08-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18190, current rewards: 144.71741, mean: 0.07995
[32m[0906 17-08-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18198, current rewards: 151.63170, mean: 0.08152
[32m[0906 17-08-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18202, current rewards: 158.54727, mean: 0.08301
[32m[0906 17-08-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18206, current rewards: 142.29747, mean: 0.07260
[32m[0906 17-09-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18215, current rewards: 149.28708, mean: 0.07427
[32m[0906 17-09-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18220, current rewards: 156.80328, mean: 0.07612
[32m[0906 17-09-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18223, current rewards: 163.56732, mean: 0.07752
[32m[0906 17-09-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18227, current rewards: 170.33136, mean: 0.07886
[32m[0906 17-09-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18233, current rewards: 177.09540, mean: 0.08013
[32m[0906 17-09-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18237, current rewards: 183.85944, mean: 0.08135
[32m[0906 17-10-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18240, current rewards: 190.62348, mean: 0.08252
[32m[0906 17-10-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18243, current rewards: 197.38752, mean: 0.08364
[32m[0906 17-10-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18248, current rewards: 167.62094, mean: 0.06955
[32m[0906 17-10-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18243, current rewards: 172.35410, mean: 0.07006
[32m[0906 17-10-38 @Agent.py:117][0m Average action selection time: 0.1824
[32m[0906 17-10-38 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-10-38 @MBExp.py:227][0m Rewards obtained: [176.56181883619058], Lows: [32], Highs: [63], Total time: 11907.895323
[32m[0906 17-11-34 @MBExp.py:144][0m ####################################################################
[32m[0906 17-11-34 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 17-11-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18441, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-11-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18489, current rewards: -4.64678, mean: -0.07745
[32m[0906 17-11-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18499, current rewards: 1.75796, mean: 0.01598
[32m[0906 17-12-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18476, current rewards: 8.16603, mean: 0.05104
[32m[0906 17-12-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18451, current rewards: 14.57753, mean: 0.06942
[32m[0906 17-12-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18385, current rewards: 20.98598, mean: 0.08072
[32m[0906 17-12-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18308, current rewards: 27.38617, mean: 0.08834
[32m[0906 17-12-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18258, current rewards: 33.48604, mean: 0.09302
[32m[0906 17-12-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18181, current rewards: 39.46132, mean: 0.09625
[32m[0906 17-12-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18095, current rewards: 41.72039, mean: 0.09070
[32m[0906 17-13-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18025, current rewards: 58.59742, mean: 0.11490
[32m[0906 17-13-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17988, current rewards: 75.52658, mean: 0.13487
[32m[0906 17-13-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17962, current rewards: 92.42310, mean: 0.15151
[32m[0906 17-13-32 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17923, current rewards: 109.36443, mean: 0.16570
[32m[0906 17-13-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17896, current rewards: 126.27676, mean: 0.17785
[32m[0906 17-13-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17903, current rewards: 143.30302, mean: 0.18856
[32m[0906 17-13-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17907, current rewards: 158.08038, mean: 0.19516
[32m[0906 17-14-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17911, current rewards: 169.37839, mean: 0.19695
[32m[0906 17-14-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17923, current rewards: 158.94345, mean: 0.17466
[32m[0906 17-14-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17951, current rewards: 165.35710, mean: 0.17225
[32m[0906 17-14-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17981, current rewards: 171.78301, mean: 0.17008
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18002, current rewards: 178.20224, mean: 0.16812
[32m[0906 17-14-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18020, current rewards: 184.63115, mean: 0.16633
[32m[0906 17-15-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18037, current rewards: 191.05585, mean: 0.16470
[32m[0906 17-15-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18053, current rewards: 196.47633, mean: 0.16238
[32m[0906 17-15-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18067, current rewards: 202.49731, mean: 0.16071
[32m[0906 17-15-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18080, current rewards: 187.44337, mean: 0.14309
[32m[0906 17-15-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18089, current rewards: 193.35826, mean: 0.14218
[32m[0906 17-15-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18101, current rewards: 199.27602, mean: 0.14133
[32m[0906 17-15-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18109, current rewards: 205.19193, mean: 0.14054
[32m[0906 17-16-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18119, current rewards: 211.10645, mean: 0.13981
[32m[0906 17-16-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18126, current rewards: 217.01149, mean: 0.13911
[32m[0906 17-16-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18137, current rewards: 230.63480, mean: 0.14325
[32m[0906 17-16-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18145, current rewards: 238.39215, mean: 0.14361
[32m[0906 17-16-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18153, current rewards: 244.62038, mean: 0.14305
[32m[0906 17-16-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18159, current rewards: 228.07058, mean: 0.12959
[32m[0906 17-17-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18166, current rewards: 236.37442, mean: 0.13059
[32m[0906 17-17-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18172, current rewards: 244.67454, mean: 0.13155
[32m[0906 17-17-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18177, current rewards: 252.97466, mean: 0.13245
[32m[0906 17-17-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18185, current rewards: 261.27478, mean: 0.13330
[32m[0906 17-17-40 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18190, current rewards: 269.57490, mean: 0.13412
[32m[0906 17-17-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18193, current rewards: 272.91355, mean: 0.13248
[32m[0906 17-17-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18198, current rewards: 275.38363, mean: 0.13051
[32m[0906 17-18-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18201, current rewards: 277.85370, mean: 0.12864
[32m[0906 17-18-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18204, current rewards: 233.10071, mean: 0.10548
[32m[0906 17-18-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18210, current rewards: 183.10071, mean: 0.08102
[32m[0906 17-18-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18211, current rewards: 133.10071, mean: 0.05762
[32m[0906 17-18-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18215, current rewards: 83.10071, mean: 0.03521
[32m[0906 17-18-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18218, current rewards: 33.10071, mean: 0.01373
[32m[0906 17-19-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18216, current rewards: -16.89929, mean: -0.00687
[32m[0906 17-19-10 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 17-19-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-19-10 @MBExp.py:227][0m Rewards obtained: [-56.89928853214121], Lows: [31], Highs: [356], Total time: 12363.864938
[32m[0906 17-20-08 @MBExp.py:144][0m ####################################################################
[32m[0906 17-20-08 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 17-20-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18510, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-20-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18488, current rewards: -5.06211, mean: -0.08437
[32m[0906 17-20-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18516, current rewards: -0.50200, mean: -0.00456
[32m[0906 17-20-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18460, current rewards: 4.06498, mean: 0.02541
[32m[0906 17-20-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18423, current rewards: 8.63161, mean: 0.04110
[32m[0906 17-20-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18351, current rewards: -7.34080, mean: -0.02823
[32m[0906 17-21-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18289, current rewards: -2.70410, mean: -0.00872
[32m[0906 17-21-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18249, current rewards: 1.14166, mean: 0.00317
[32m[0906 17-21-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18171, current rewards: 5.75001, mean: 0.01402
[32m[0906 17-21-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18091, current rewards: 10.45538, mean: 0.02273
[32m[0906 17-21-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18030, current rewards: 15.15784, mean: 0.02972
[32m[0906 17-21-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17987, current rewards: 19.85561, mean: 0.03546
[32m[0906 17-21-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17957, current rewards: 24.55458, mean: 0.04025
[32m[0906 17-22-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17917, current rewards: 29.25926, mean: 0.04433
[32m[0906 17-22-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17884, current rewards: 33.96286, mean: 0.04784
[32m[0906 17-22-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17884, current rewards: 16.47105, mean: 0.02167
[32m[0906 17-22-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17887, current rewards: 21.64519, mean: 0.02672
[32m[0906 17-22-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17893, current rewards: 26.27541, mean: 0.03055
[32m[0906 17-22-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17900, current rewards: 30.90668, mean: 0.03396
[32m[0906 17-23-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17930, current rewards: 35.53638, mean: 0.03702
[32m[0906 17-23-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17954, current rewards: 40.16580, mean: 0.03977
[32m[0906 17-23-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17977, current rewards: 44.79949, mean: 0.04226
[32m[0906 17-23-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17998, current rewards: 49.42996, mean: 0.04453
[32m[0906 17-23-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18019, current rewards: 54.06170, mean: 0.04660
[32m[0906 17-23-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18039, current rewards: 58.38737, mean: 0.04825
[32m[0906 17-23-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18055, current rewards: 63.18510, mean: 0.05015
[32m[0906 17-24-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18070, current rewards: 67.98252, mean: 0.05190
[32m[0906 17-24-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18084, current rewards: 72.77706, mean: 0.05351
[32m[0906 17-24-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18095, current rewards: 77.57745, mean: 0.05502
[32m[0906 17-24-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18105, current rewards: 79.08588, mean: 0.05417
[32m[0906 17-24-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18116, current rewards: 78.18033, mean: 0.05178
[32m[0906 17-24-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18126, current rewards: 83.18981, mean: 0.05333
[32m[0906 17-25-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18136, current rewards: 89.68077, mean: 0.05570
[32m[0906 17-25-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18145, current rewards: 94.32274, mean: 0.05682
[32m[0906 17-25-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18152, current rewards: 98.96396, mean: 0.05787
[32m[0906 17-25-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18160, current rewards: 103.60622, mean: 0.05887
[32m[0906 17-25-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18166, current rewards: 108.24483, mean: 0.05980
[32m[0906 17-25-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18172, current rewards: 112.88967, mean: 0.06069
[32m[0906 17-25-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18180, current rewards: 117.53496, mean: 0.06154
[32m[0906 17-26-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18185, current rewards: 122.17329, mean: 0.06233
[32m[0906 17-26-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18189, current rewards: 126.74964, mean: 0.06306
[32m[0906 17-26-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18194, current rewards: 131.24181, mean: 0.06371
[32m[0906 17-26-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18199, current rewards: 135.66035, mean: 0.06429
[32m[0906 17-26-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18203, current rewards: 140.08901, mean: 0.06486
[32m[0906 17-26-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18207, current rewards: 144.51341, mean: 0.06539
[32m[0906 17-27-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18209, current rewards: 148.93845, mean: 0.06590
[32m[0906 17-27-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18214, current rewards: 153.36349, mean: 0.06639
[32m[0906 17-27-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18217, current rewards: 157.78508, mean: 0.06686
[32m[0906 17-27-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18219, current rewards: 141.32562, mean: 0.05864
[32m[0906 17-27-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18219, current rewards: 145.81185, mean: 0.05927
[32m[0906 17-27-44 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 17-27-44 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-27-44 @MBExp.py:227][0m Rewards obtained: [149.45399960482123], Lows: [31], Highs: [20], Total time: 12819.879359
[32m[0906 17-28-43 @MBExp.py:144][0m ####################################################################
[32m[0906 17-28-43 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 17-28-45 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18451, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-28-54 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18480, current rewards: -6.53515, mean: -0.10892
[32m[0906 17-29-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18428, current rewards: -1.30634, mean: -0.01188
[32m[0906 17-29-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18409, current rewards: 3.92700, mean: 0.02454
[32m[0906 17-29-22 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18396, current rewards: 9.15251, mean: 0.04358
[32m[0906 17-29-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18347, current rewards: 14.38070, mean: 0.05531
[32m[0906 17-29-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18289, current rewards: 19.61363, mean: 0.06327
[32m[0906 17-29-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18243, current rewards: 24.84509, mean: 0.06901
[32m[0906 17-29-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18177, current rewards: 9.24284, mean: 0.02254
[32m[0906 17-30-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18098, current rewards: 15.09695, mean: 0.03282
[32m[0906 17-30-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18028, current rewards: 20.95753, mean: 0.04109
[32m[0906 17-30-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17968, current rewards: 26.80987, mean: 0.04787
[32m[0906 17-30-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17931, current rewards: 32.67669, mean: 0.05357
[32m[0906 17-30-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17890, current rewards: 38.53845, mean: 0.05839
[32m[0906 17-30-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17856, current rewards: 44.39290, mean: 0.06253
[32m[0906 17-30-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17846, current rewards: 50.46112, mean: 0.06640
[32m[0906 17-31-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17854, current rewards: 56.37133, mean: 0.06959
[32m[0906 17-31-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17858, current rewards: 62.27791, mean: 0.07242
[32m[0906 17-31-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17863, current rewards: 68.18835, mean: 0.07493
[32m[0906 17-31-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17892, current rewards: 74.10403, mean: 0.07719
[32m[0906 17-31-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17924, current rewards: 80.01457, mean: 0.07922
[32m[0906 17-31-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17947, current rewards: 85.92684, mean: 0.08106
[32m[0906 17-32-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17969, current rewards: 91.83552, mean: 0.08273
[32m[0906 17-32-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17994, current rewards: 86.45684, mean: 0.07453
[32m[0906 17-32-22 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18012, current rewards: 91.89155, mean: 0.07594
[32m[0906 17-32-31 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18029, current rewards: 97.32470, mean: 0.07724
[32m[0906 17-32-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18043, current rewards: 102.75834, mean: 0.07844
[32m[0906 17-32-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18056, current rewards: 108.18942, mean: 0.07955
[32m[0906 17-32-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18067, current rewards: 113.62107, mean: 0.08058
[32m[0906 17-33-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18079, current rewards: 119.05635, mean: 0.08155
[32m[0906 17-33-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18090, current rewards: 124.48901, mean: 0.08244
[32m[0906 17-33-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18099, current rewards: 130.24187, mean: 0.08349
[32m[0906 17-33-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18108, current rewards: 135.67227, mean: 0.08427
[32m[0906 17-33-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18116, current rewards: 141.10656, mean: 0.08500
[32m[0906 17-33-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18127, current rewards: 146.54166, mean: 0.08570
[32m[0906 17-34-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18135, current rewards: 141.08628, mean: 0.08016
[32m[0906 17-34-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18145, current rewards: 146.53321, mean: 0.08096
[32m[0906 17-34-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18156, current rewards: 151.97874, mean: 0.08171
[32m[0906 17-34-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18163, current rewards: 157.42840, mean: 0.08242
[32m[0906 17-34-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18168, current rewards: 163.85657, mean: 0.08360
[32m[0906 17-34-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18174, current rewards: 148.74742, mean: 0.07400
[32m[0906 17-34-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18177, current rewards: 148.23741, mean: 0.07196
[32m[0906 17-35-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18182, current rewards: 153.52458, mean: 0.07276
[32m[0906 17-35-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18186, current rewards: 158.81073, mean: 0.07352
[32m[0906 17-35-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18188, current rewards: 164.09697, mean: 0.07425
[32m[0906 17-35-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18193, current rewards: 169.38331, mean: 0.07495
[32m[0906 17-35-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18197, current rewards: 174.66980, mean: 0.07561
[32m[0906 17-35-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18201, current rewards: 179.96246, mean: 0.07626
[32m[0906 17-36-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18205, current rewards: 186.58949, mean: 0.07742
[32m[0906 17-36-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18209, current rewards: 193.19772, mean: 0.07854
[32m[0906 17-36-19 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0906 17-36-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-36-19 @MBExp.py:227][0m Rewards obtained: [182.63400004709703], Lows: [24], Highs: [45], Total time: 13275.663352
[32m[0906 17-37-21 @MBExp.py:144][0m ####################################################################
[32m[0906 17-37-21 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 17-37-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18541, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-37-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18491, current rewards: -23.30890, mean: -0.38848
[32m[0906 17-37-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18415, current rewards: -56.09938, mean: -0.50999
[32m[0906 17-37-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18392, current rewards: -81.47392, mean: -0.50921
[32m[0906 17-37-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18400, current rewards: -108.29422, mean: -0.51569
[32m[0906 17-38-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18345, current rewards: -145.03872, mean: -0.55784
[32m[0906 17-38-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18288, current rewards: -176.55254, mean: -0.56952
[32m[0906 17-38-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18249, current rewards: -207.42933, mean: -0.57619
[32m[0906 17-38-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18195, current rewards: -200.20120, mean: -0.48830
[32m[0906 17-38-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18110, current rewards: -193.95440, mean: -0.42164
[32m[0906 17-38-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18043, current rewards: -188.01076, mean: -0.36865
[32m[0906 17-39-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17988, current rewards: -182.06608, mean: -0.32512
[32m[0906 17-39-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17933, current rewards: -197.49961, mean: -0.32377
[32m[0906 17-39-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17895, current rewards: -191.46014, mean: -0.29009
[32m[0906 17-39-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17862, current rewards: -185.46033, mean: -0.26121
[32m[0906 17-39-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17845, current rewards: -179.46491, mean: -0.23614
[32m[0906 17-39-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17852, current rewards: -173.46876, mean: -0.21416
[32m[0906 17-39-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17859, current rewards: -178.58782, mean: -0.20766
[32m[0906 17-40-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17868, current rewards: -182.70873, mean: -0.20078
[32m[0906 17-40-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17896, current rewards: -196.32538, mean: -0.20451
[32m[0906 17-40-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17922, current rewards: -213.61832, mean: -0.21150
[32m[0906 17-40-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17949, current rewards: -226.22120, mean: -0.21342
[32m[0906 17-40-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17974, current rewards: -230.46399, mean: -0.20763
[32m[0906 17-40-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17994, current rewards: -258.35066, mean: -0.22272
[32m[0906 17-40-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18014, current rewards: -293.53025, mean: -0.24259
[32m[0906 17-41-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18028, current rewards: -342.30316, mean: -0.27167
[32m[0906 17-41-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18041, current rewards: -386.87784, mean: -0.29533
[32m[0906 17-41-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18050, current rewards: -423.75353, mean: -0.31158
[32m[0906 17-41-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18063, current rewards: -450.88776, mean: -0.31978
[32m[0906 17-41-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18074, current rewards: -445.31105, mean: -0.30501
[32m[0906 17-41-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18083, current rewards: -439.72417, mean: -0.29121
[32m[0906 17-42-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18092, current rewards: -433.68070, mean: -0.27800
[32m[0906 17-42-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18101, current rewards: -428.17873, mean: -0.26595
[32m[0906 17-42-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18108, current rewards: -422.67548, mean: -0.25462
[32m[0906 17-42-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18116, current rewards: -417.17354, mean: -0.24396
[32m[0906 17-42-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18127, current rewards: -411.66589, mean: -0.23390
[32m[0906 17-42-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18132, current rewards: -406.15999, mean: -0.22440
[32m[0906 17-42-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18138, current rewards: -400.65856, mean: -0.21541
[32m[0906 17-43-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18144, current rewards: -395.15760, mean: -0.20689
[32m[0906 17-43-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18149, current rewards: -389.96590, mean: -0.19896
[32m[0906 17-43-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18155, current rewards: -384.37078, mean: -0.19123
[32m[0906 17-43-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18159, current rewards: -378.77507, mean: -0.18387
[32m[0906 17-43-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18163, current rewards: -373.17783, mean: -0.17686
[32m[0906 17-43-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18166, current rewards: -367.58412, mean: -0.17018
[32m[0906 17-44-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18169, current rewards: -374.65489, mean: -0.16953
[32m[0906 17-44-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18173, current rewards: -378.59152, mean: -0.16752
[32m[0906 17-44-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18176, current rewards: -374.00324, mean: -0.16191
[32m[0906 17-44-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18180, current rewards: -366.07497, mean: -0.15512
[32m[0906 17-44-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18183, current rewards: -360.02971, mean: -0.14939
[32m[0906 17-44-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18189, current rewards: -353.98444, mean: -0.14390
[32m[0906 17-44-56 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 17-44-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-44-56 @MBExp.py:227][0m Rewards obtained: [-349.1482282239759], Lows: [328], Highs: [21], Total time: 13730.984072
[32m[0906 17-45-59 @MBExp.py:144][0m ####################################################################
[32m[0906 17-45-59 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 17-46-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18476, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-46-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18443, current rewards: -4.66211, mean: -0.07770
[32m[0906 17-46-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18418, current rewards: 0.69225, mean: 0.00629
[32m[0906 17-46-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18409, current rewards: 6.04787, mean: 0.03780
[32m[0906 17-46-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18406, current rewards: 11.39997, mean: 0.05429
[32m[0906 17-46-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18355, current rewards: 17.14248, mean: 0.06593
[32m[0906 17-46-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18306, current rewards: 24.39186, mean: 0.07868
[32m[0906 17-47-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18255, current rewards: 29.49853, mean: 0.08194
[32m[0906 17-47-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18197, current rewards: 34.60784, mean: 0.08441
[32m[0906 17-47-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18108, current rewards: 39.71708, mean: 0.08634
[32m[0906 17-47-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18042, current rewards: 44.82351, mean: 0.08789
[32m[0906 17-47-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17984, current rewards: 27.75574, mean: 0.04956
[32m[0906 17-47-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17915, current rewards: 36.80917, mean: 0.06034
[32m[0906 17-47-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17874, current rewards: 45.86260, mean: 0.06949
[32m[0906 17-48-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17837, current rewards: 52.93419, mean: 0.07456
[32m[0906 17-48-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17808, current rewards: 58.38744, mean: 0.07683
[32m[0906 17-48-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17815, current rewards: 63.84069, mean: 0.07882
[32m[0906 17-48-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17824, current rewards: 69.29394, mean: 0.08057
[32m[0906 17-48-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17830, current rewards: 74.74719, mean: 0.08214
[32m[0906 17-48-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17850, current rewards: 80.20044, mean: 0.08354
[32m[0906 17-49-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17885, current rewards: 85.65369, mean: 0.08481
[32m[0906 17-49-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17909, current rewards: 62.27125, mean: 0.05875
[32m[0906 17-49-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17930, current rewards: 12.27125, mean: 0.01106
[32m[0906 17-49-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17944, current rewards: -37.72875, mean: -0.03252
[32m[0906 17-49-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17960, current rewards: -87.72875, mean: -0.07250
[32m[0906 17-49-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17974, current rewards: -137.72875, mean: -0.10931
[32m[0906 17-49-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17990, current rewards: -187.72875, mean: -0.14330
[32m[0906 17-50-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18005, current rewards: -237.72875, mean: -0.17480
[32m[0906 17-50-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18018, current rewards: -287.72875, mean: -0.20406
[32m[0906 17-50-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18031, current rewards: -337.72875, mean: -0.23132
[32m[0906 17-50-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18042, current rewards: -387.72875, mean: -0.25677
[32m[0906 17-50-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18054, current rewards: -437.72875, mean: -0.28060
[32m[0906 17-50-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18066, current rewards: -487.72875, mean: -0.30294
[32m[0906 17-51-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18076, current rewards: -537.72875, mean: -0.32393
[32m[0906 17-51-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18088, current rewards: -587.72875, mean: -0.34370
[32m[0906 17-51-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18098, current rewards: -637.72875, mean: -0.36235
[32m[0906 17-51-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18104, current rewards: -687.72875, mean: -0.37996
[32m[0906 17-51-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18110, current rewards: -737.72875, mean: -0.39663
[32m[0906 17-51-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18117, current rewards: -787.72875, mean: -0.41242
[32m[0906 17-51-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18123, current rewards: -837.72875, mean: -0.42741
[32m[0906 17-52-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18130, current rewards: -887.72875, mean: -0.44166
[32m[0906 17-52-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18136, current rewards: -937.72875, mean: -0.45521
[32m[0906 17-52-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18141, current rewards: -987.72875, mean: -0.46812
[32m[0906 17-52-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18146, current rewards: -1037.72875, mean: -0.48043
[32m[0906 17-52-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18151, current rewards: -1087.72875, mean: -0.49218
[32m[0906 17-52-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18155, current rewards: -1137.72875, mean: -0.50342
[32m[0906 17-53-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18160, current rewards: -1187.72875, mean: -0.51417
[32m[0906 17-53-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18166, current rewards: -1237.72875, mean: -0.52446
[32m[0906 17-53-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18172, current rewards: -1287.72875, mean: -0.53433
[32m[0906 17-53-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18177, current rewards: -1337.72875, mean: -0.54379
[32m[0906 17-53-34 @Agent.py:117][0m Average action selection time: 0.1818
[32m[0906 17-53-34 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-53-35 @MBExp.py:227][0m Rewards obtained: [-1377.728754372547], Lows: [11], Highs: [1476], Total time: 14186.062462
[32m[0906 17-54-40 @MBExp.py:144][0m ####################################################################
[32m[0906 17-54-40 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 17-54-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18572, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-54-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18542, current rewards: -7.16409, mean: -0.11940
[32m[0906 17-55-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18437, current rewards: -2.16039, mean: -0.01964
[32m[0906 17-55-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18438, current rewards: 2.84538, mean: 0.01778
[32m[0906 17-55-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18465, current rewards: 7.84693, mean: 0.03737
[32m[0906 17-55-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18414, current rewards: 12.33251, mean: 0.04743
[32m[0906 17-55-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18340, current rewards: 16.97232, mean: 0.05475
[32m[0906 17-55-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18285, current rewards: 21.60966, mean: 0.06003
[32m[0906 17-55-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18227, current rewards: 26.24897, mean: 0.06402
[32m[0906 17-56-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18140, current rewards: 30.88982, mean: 0.06715
[32m[0906 17-56-12 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18064, current rewards: 35.52446, mean: 0.06966
[32m[0906 17-56-21 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18007, current rewards: 40.16492, mean: 0.07172
[32m[0906 17-56-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17924, current rewards: 40.43447, mean: 0.06629
[32m[0906 17-56-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17884, current rewards: 40.45616, mean: 0.06130
[32m[0906 17-56-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17850, current rewards: 45.54542, mean: 0.06415
[32m[0906 17-56-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17822, current rewards: 50.39380, mean: 0.06631
[32m[0906 17-57-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17821, current rewards: 55.24426, mean: 0.06820
[32m[0906 17-57-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17831, current rewards: 40.15813, mean: 0.04670
[32m[0906 17-57-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17843, current rewards: 48.69605, mean: 0.05351
[32m[0906 17-57-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17857, current rewards: 57.23397, mean: 0.05962
[32m[0906 17-57-41 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17889, current rewards: 18.94155, mean: 0.01875
[32m[0906 17-57-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17923, current rewards: -31.05845, mean: -0.02930
[32m[0906 17-58-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17948, current rewards: -81.05845, mean: -0.07303
[32m[0906 17-58-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17970, current rewards: -131.05845, mean: -0.11298
[32m[0906 17-58-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17989, current rewards: -181.05845, mean: -0.14964
[32m[0906 17-58-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18005, current rewards: -231.05845, mean: -0.18338
[32m[0906 17-58-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18022, current rewards: -281.05845, mean: -0.21455
[32m[0906 17-58-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18033, current rewards: -331.05845, mean: -0.24343
[32m[0906 17-58-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18048, current rewards: -381.05845, mean: -0.27025
[32m[0906 17-59-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18060, current rewards: -431.05845, mean: -0.29525
[32m[0906 17-59-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18072, current rewards: -481.05845, mean: -0.31858
[32m[0906 17-59-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18085, current rewards: -531.05845, mean: -0.34042
[32m[0906 17-59-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18098, current rewards: -581.05845, mean: -0.36091
[32m[0906 17-59-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18109, current rewards: -631.05845, mean: -0.38016
[32m[0906 17-59-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18119, current rewards: -681.05845, mean: -0.39828
[32m[0906 18-00-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18128, current rewards: -731.05845, mean: -0.41537
[32m[0906 18-00-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18139, current rewards: -781.05845, mean: -0.43152
[32m[0906 18-00-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18147, current rewards: -831.05845, mean: -0.44681
[32m[0906 18-00-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18157, current rewards: -881.05845, mean: -0.46129
[32m[0906 18-00-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18164, current rewards: -931.05845, mean: -0.47503
[32m[0906 18-00-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18169, current rewards: -981.05845, mean: -0.48809
[32m[0906 18-00-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18176, current rewards: -1031.05845, mean: -0.50051
[32m[0906 18-01-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18183, current rewards: -1081.05845, mean: -0.51235
[32m[0906 18-01-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18188, current rewards: -1131.05845, mean: -0.52364
[32m[0906 18-01-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18194, current rewards: -1181.05845, mean: -0.53442
[32m[0906 18-01-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18199, current rewards: -1231.05845, mean: -0.54472
[32m[0906 18-01-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18205, current rewards: -1281.05845, mean: -0.55457
[32m[0906 18-01-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18208, current rewards: -1331.05845, mean: -0.56401
[32m[0906 18-02-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18214, current rewards: -1381.05845, mean: -0.57305
[32m[0906 18-02-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18219, current rewards: -1431.05845, mean: -0.58173
[32m[0906 18-02-16 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 18-02-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-02-16 @MBExp.py:227][0m Rewards obtained: [-1471.0584499763395], Lows: [12], Highs: [1550], Total time: 14642.244764
[32m[0906 18-03-24 @MBExp.py:144][0m ####################################################################
[32m[0906 18-03-24 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 18-03-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18426, current rewards: 0.95026, mean: 0.09503
[32m[0906 18-03-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18527, current rewards: 8.05846, mean: 0.13431
[32m[0906 18-03-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18439, current rewards: 15.51865, mean: 0.14108
[32m[0906 18-03-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18412, current rewards: 22.97884, mean: 0.14362
[32m[0906 18-04-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18398, current rewards: 30.43903, mean: 0.14495
[32m[0906 18-04-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18341, current rewards: 36.06253, mean: 0.13870
[32m[0906 18-04-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18283, current rewards: 38.77608, mean: 0.12508
[32m[0906 18-04-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18231, current rewards: -7.00684, mean: -0.01946
[32m[0906 18-04-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18180, current rewards: -57.00684, mean: -0.13904
[32m[0906 18-04-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18088, current rewards: -107.00684, mean: -0.23262
[32m[0906 18-04-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18014, current rewards: -157.00684, mean: -0.30786
[32m[0906 18-05-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17960, current rewards: -207.00684, mean: -0.36966
[32m[0906 18-05-13 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17885, current rewards: -257.00684, mean: -0.42132
[32m[0906 18-05-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17837, current rewards: -307.00684, mean: -0.46516
[32m[0906 18-05-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17808, current rewards: -357.00684, mean: -0.50283
[32m[0906 18-05-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17786, current rewards: -407.00684, mean: -0.53554
[32m[0906 18-05-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17782, current rewards: -457.00684, mean: -0.56421
[32m[0906 18-05-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17795, current rewards: -507.00684, mean: -0.58954
[32m[0906 18-06-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17804, current rewards: -557.00684, mean: -0.61210
[32m[0906 18-06-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17812, current rewards: -607.00684, mean: -0.63230
[32m[0906 18-06-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17846, current rewards: -657.00684, mean: -0.65050
[32m[0906 18-06-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17876, current rewards: -707.00684, mean: -0.66699
[32m[0906 18-06-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17898, current rewards: -757.00684, mean: -0.68199
[32m[0906 18-06-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17920, current rewards: -807.00684, mean: -0.69570
[32m[0906 18-07-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17935, current rewards: -857.00684, mean: -0.70827
[32m[0906 18-07-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17955, current rewards: -907.00684, mean: -0.71985
[32m[0906 18-07-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17972, current rewards: -957.00684, mean: -0.73054
[32m[0906 18-07-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17986, current rewards: -1007.00684, mean: -0.74045
[32m[0906 18-07-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18000, current rewards: -1057.00684, mean: -0.74965
[32m[0906 18-07-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18014, current rewards: -1107.00684, mean: -0.75822
[32m[0906 18-07-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18030, current rewards: -1157.00684, mean: -0.76623
[32m[0906 18-08-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18043, current rewards: -1207.00684, mean: -0.77372
[32m[0906 18-08-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18052, current rewards: -1257.00684, mean: -0.78075
[32m[0906 18-08-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18062, current rewards: -1307.00684, mean: -0.78735
[32m[0906 18-08-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18070, current rewards: -1357.00684, mean: -0.79357
[32m[0906 18-08-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18078, current rewards: -1407.00684, mean: -0.79944
[32m[0906 18-08-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18088, current rewards: -1457.00684, mean: -0.80498
[32m[0906 18-09-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18093, current rewards: -1507.00684, mean: -0.81022
[32m[0906 18-09-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18102, current rewards: -1557.00684, mean: -0.81519
[32m[0906 18-09-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18109, current rewards: -1607.00684, mean: -0.81990
[32m[0906 18-09-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18116, current rewards: -1657.00684, mean: -0.82438
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18122, current rewards: -1707.00684, mean: -0.82864
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18126, current rewards: -1757.00684, mean: -0.83270
[32m[0906 18-09-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18133, current rewards: -1807.00684, mean: -0.83658
[32m[0906 18-10-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18141, current rewards: -1857.00684, mean: -0.84027
[32m[0906 18-10-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18145, current rewards: -1907.00684, mean: -0.84381
[32m[0906 18-10-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18150, current rewards: -1957.00684, mean: -0.84719
[32m[0906 18-10-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18154, current rewards: -2007.00684, mean: -0.85043
[32m[0906 18-10-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18158, current rewards: -2057.00684, mean: -0.85353
[32m[0906 18-10-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18162, current rewards: -2107.00684, mean: -0.85651
[32m[0906 18-10-59 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0906 18-10-59 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-10-59 @MBExp.py:227][0m Rewards obtained: [-2147.0068362432166], Lows: [1], Highs: [2186], Total time: 15097.048936
[32m[0906 18-12-09 @MBExp.py:144][0m ####################################################################
[32m[0906 18-12-09 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 18-12-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18600, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-12-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18513, current rewards: -4.33043, mean: -0.07217
[32m[0906 18-12-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18440, current rewards: 1.17406, mean: 0.01067
[32m[0906 18-12-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18419, current rewards: 6.67771, mean: 0.04174
[32m[0906 18-12-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18430, current rewards: 12.37144, mean: 0.05891
[32m[0906 18-12-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18391, current rewards: 19.81007, mean: 0.07619
[32m[0906 18-13-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18322, current rewards: 25.49895, mean: 0.08225
[32m[0906 18-13-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18272, current rewards: 19.78517, mean: 0.05496
[32m[0906 18-13-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18220, current rewards: 25.44820, mean: 0.06207
[32m[0906 18-13-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18128, current rewards: 31.16674, mean: 0.06775
[32m[0906 18-13-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18056, current rewards: 36.88101, mean: 0.07232
[32m[0906 18-13-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18001, current rewards: 42.60179, mean: 0.07607
[32m[0906 18-13-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17917, current rewards: 48.31644, mean: 0.07921
[32m[0906 18-14-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17860, current rewards: 52.65651, mean: 0.07978
[32m[0906 18-14-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17831, current rewards: 58.32984, mean: 0.08215
[32m[0906 18-14-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17804, current rewards: 63.94614, mean: 0.08414
[32m[0906 18-14-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17785, current rewards: 69.56455, mean: 0.08588
[32m[0906 18-14-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17795, current rewards: 75.17940, mean: 0.08742
[32m[0906 18-14-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17804, current rewards: 80.79013, mean: 0.08878
[32m[0906 18-15-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17813, current rewards: 86.41106, mean: 0.09001
[32m[0906 18-15-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17839, current rewards: 81.30856, mean: 0.08050
[32m[0906 18-15-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17869, current rewards: 92.01103, mean: 0.08680
[32m[0906 18-15-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17895, current rewards: 94.66603, mean: 0.08528
[32m[0906 18-15-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17917, current rewards: 103.89311, mean: 0.08956
[32m[0906 18-15-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17939, current rewards: 113.14347, mean: 0.09351
[32m[0906 18-15-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17959, current rewards: 122.36129, mean: 0.09711
[32m[0906 18-16-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17976, current rewards: 131.57939, mean: 0.10044
[32m[0906 18-16-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17996, current rewards: 140.82105, mean: 0.10354
[32m[0906 18-16-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18010, current rewards: 150.05391, mean: 0.10642
[32m[0906 18-16-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18024, current rewards: 159.28926, mean: 0.10910
[32m[0906 18-16-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18037, current rewards: 144.97633, mean: 0.09601
[32m[0906 18-16-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18047, current rewards: 150.82221, mean: 0.09668
[32m[0906 18-17-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18057, current rewards: 156.66754, mean: 0.09731
[32m[0906 18-17-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18068, current rewards: 162.51629, mean: 0.09790
[32m[0906 18-17-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18080, current rewards: 168.36042, mean: 0.09846
[32m[0906 18-17-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18088, current rewards: 174.20555, mean: 0.09898
[32m[0906 18-17-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18098, current rewards: 180.04857, mean: 0.09947
[32m[0906 18-17-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18108, current rewards: 185.89709, mean: 0.09994
[32m[0906 18-17-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18117, current rewards: 191.38084, mean: 0.10020
[32m[0906 18-18-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18125, current rewards: 176.68570, mean: 0.09015
[32m[0906 18-18-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18133, current rewards: 182.60363, mean: 0.09085
[32m[0906 18-18-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18139, current rewards: 188.53006, mean: 0.09152
[32m[0906 18-18-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18144, current rewards: 194.45415, mean: 0.09216
[32m[0906 18-18-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18150, current rewards: 200.38053, mean: 0.09277
[32m[0906 18-18-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18154, current rewards: 206.30443, mean: 0.09335
[32m[0906 18-19-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18159, current rewards: 212.23026, mean: 0.09391
[32m[0906 18-19-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18164, current rewards: 220.57104, mean: 0.09549
[32m[0906 18-19-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18169, current rewards: 229.10896, mean: 0.09708
[32m[0906 18-19-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18172, current rewards: 237.64688, mean: 0.09861
[32m[0906 18-19-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18177, current rewards: 230.96494, mean: 0.09389
[32m[0906 18-19-44 @Agent.py:117][0m Average action selection time: 0.1818
[32m[0906 18-19-44 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-19-44 @MBExp.py:227][0m Rewards obtained: [190.9649376274111], Lows: [25], Highs: [83], Total time: 15552.201516
[32m[0906 18-20-56 @MBExp.py:144][0m ####################################################################
[32m[0906 18-20-56 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 18-20-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17884, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-21-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18382, current rewards: -3.63240, mean: -0.06054
[32m[0906 18-21-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18410, current rewards: 2.37731, mean: 0.02161
[32m[0906 18-21-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18419, current rewards: 8.39067, mean: 0.05244
[32m[0906 18-21-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18407, current rewards: 14.28524, mean: 0.06802
[32m[0906 18-21-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18379, current rewards: 20.03676, mean: 0.07706
[32m[0906 18-21-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18313, current rewards: 25.91092, mean: 0.08358
[32m[0906 18-22-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18267, current rewards: 31.78638, mean: 0.08830
[32m[0906 18-22-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18227, current rewards: 37.65589, mean: 0.09184
[32m[0906 18-22-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18129, current rewards: 43.52767, mean: 0.09463
[32m[0906 18-22-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18063, current rewards: 49.40048, mean: 0.09686
[32m[0906 18-22-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18001, current rewards: 55.27272, mean: 0.09870
[32m[0906 18-22-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17913, current rewards: 49.75897, mean: 0.08157
[32m[0906 18-22-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17836, current rewards: 54.97866, mean: 0.08330
[32m[0906 18-23-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17805, current rewards: 60.41893, mean: 0.08510
[32m[0906 18-23-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17777, current rewards: 65.85788, mean: 0.08666
[32m[0906 18-23-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17752, current rewards: 71.29586, mean: 0.08802
[32m[0906 18-23-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17756, current rewards: 76.73172, mean: 0.08922
[32m[0906 18-23-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17766, current rewards: 73.74314, mean: 0.08104
[32m[0906 18-23-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17776, current rewards: 66.76130, mean: 0.06954
[32m[0906 18-23-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17797, current rewards: 72.45178, mean: 0.07173
[32m[0906 18-24-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17829, current rewards: 77.69525, mean: 0.07330
[32m[0906 18-24-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17859, current rewards: 83.38851, mean: 0.07512
[32m[0906 18-24-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17882, current rewards: 89.08394, mean: 0.07680
[32m[0906 18-24-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17904, current rewards: 94.78165, mean: 0.07833
[32m[0906 18-24-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17924, current rewards: 100.47151, mean: 0.07974
[32m[0906 18-24-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17941, current rewards: 106.16124, mean: 0.08104
[32m[0906 18-25-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17958, current rewards: 111.85109, mean: 0.08224
[32m[0906 18-25-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17973, current rewards: 117.54048, mean: 0.08336
[32m[0906 18-25-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17988, current rewards: 123.56135, mean: 0.08463
[32m[0906 18-25-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17999, current rewards: 129.24196, mean: 0.08559
[32m[0906 18-25-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18012, current rewards: 134.92395, mean: 0.08649
[32m[0906 18-25-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18026, current rewards: 140.59893, mean: 0.08733
[32m[0906 18-25-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18037, current rewards: 146.28047, mean: 0.08812
[32m[0906 18-26-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18046, current rewards: 151.96139, mean: 0.08887
[32m[0906 18-26-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18057, current rewards: 147.04612, mean: 0.08355
[32m[0906 18-26-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18065, current rewards: 152.18623, mean: 0.08408
[32m[0906 18-26-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18073, current rewards: 159.04439, mean: 0.08551
[32m[0906 18-26-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18082, current rewards: 164.29654, mean: 0.08602
[32m[0906 18-26-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18091, current rewards: 169.54663, mean: 0.08650
[32m[0906 18-27-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18099, current rewards: 174.80152, mean: 0.08697
[32m[0906 18-27-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18109, current rewards: 180.05402, mean: 0.08740
[32m[0906 18-27-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18116, current rewards: 185.30690, mean: 0.08782
[32m[0906 18-27-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18122, current rewards: 190.55914, mean: 0.08822
[32m[0906 18-27-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18126, current rewards: 195.81044, mean: 0.08860
[32m[0906 18-27-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18131, current rewards: 201.26853, mean: 0.08906
[32m[0906 18-27-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18136, current rewards: 196.03839, mean: 0.08487
[32m[0906 18-28-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18141, current rewards: 194.70142, mean: 0.08250
[32m[0906 18-28-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18145, current rewards: 200.74668, mean: 0.08330
[32m[0906 18-28-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18150, current rewards: 206.79195, mean: 0.08406
[32m[0906 18-28-30 @Agent.py:117][0m Average action selection time: 0.1815
[32m[0906 18-28-30 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-28-30 @MBExp.py:227][0m Rewards obtained: [211.628160638301], Lows: [21], Highs: [30], Total time: 16006.73142
[32m[0906 18-29-44 @MBExp.py:144][0m ####################################################################
[32m[0906 18-29-44 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 18-29-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17956, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-29-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18239, current rewards: -4.18241, mean: -0.06971
[32m[0906 18-30-04 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18340, current rewards: 1.01559, mean: 0.00923
[32m[0906 18-30-13 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18350, current rewards: 6.21283, mean: 0.03883
[32m[0906 18-30-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18355, current rewards: 11.40985, mean: 0.05433
[32m[0906 18-30-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18332, current rewards: 16.60287, mean: 0.06386
[32m[0906 18-30-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18267, current rewards: 2.19091, mean: 0.00707
[32m[0906 18-30-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18235, current rewards: 13.60269, mean: 0.03779
[32m[0906 18-30-59 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18210, current rewards: 25.17038, mean: 0.06139
[32m[0906 18-31-07 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18132, current rewards: 36.75627, mean: 0.07990
[32m[0906 18-31-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18060, current rewards: 48.33718, mean: 0.09478
[32m[0906 18-31-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18003, current rewards: 59.91683, mean: 0.10699
[32m[0906 18-31-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17916, current rewards: 67.25649, mean: 0.11026
[32m[0906 18-31-42 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17835, current rewards: 76.17055, mean: 0.11541
[32m[0906 18-31-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17793, current rewards: 85.09992, mean: 0.11986
[32m[0906 18-31-59 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17766, current rewards: 94.01076, mean: 0.12370
[32m[0906 18-32-08 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17744, current rewards: 102.93180, mean: 0.12708
[32m[0906 18-32-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17737, current rewards: 111.84288, mean: 0.13005
[32m[0906 18-32-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17750, current rewards: 120.77725, mean: 0.13272
[32m[0906 18-32-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17765, current rewards: 129.69681, mean: 0.13510
[32m[0906 18-32-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17780, current rewards: 119.64350, mean: 0.11846
[32m[0906 18-32-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17816, current rewards: 125.81692, mean: 0.11870
[32m[0906 18-33-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17852, current rewards: 130.81977, mean: 0.11786
[32m[0906 18-33-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17879, current rewards: 135.83111, mean: 0.11710
[32m[0906 18-33-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17902, current rewards: 140.84318, mean: 0.11640
[32m[0906 18-33-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17925, current rewards: 145.85094, mean: 0.11575
[32m[0906 18-33-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17943, current rewards: 150.85773, mean: 0.11516
[32m[0906 18-33-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17961, current rewards: 155.87335, mean: 0.11461
[32m[0906 18-33-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17976, current rewards: 160.76711, mean: 0.11402
[32m[0906 18-34-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17992, current rewards: 165.78085, mean: 0.11355
[32m[0906 18-34-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18005, current rewards: 171.12341, mean: 0.11333
[32m[0906 18-34-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18016, current rewards: 176.46588, mean: 0.11312
[32m[0906 18-34-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18030, current rewards: 170.31578, mean: 0.10579
[32m[0906 18-34-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18042, current rewards: 175.28421, mean: 0.10559
[32m[0906 18-34-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18051, current rewards: 180.25646, mean: 0.10541
[32m[0906 18-35-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18061, current rewards: 185.22715, mean: 0.10524
[32m[0906 18-35-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18070, current rewards: 190.18749, mean: 0.10508
[32m[0906 18-35-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18078, current rewards: 183.70073, mean: 0.09876
[32m[0906 18-35-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18085, current rewards: 189.25918, mean: 0.09909
[32m[0906 18-35-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18093, current rewards: 194.85118, mean: 0.09941
[32m[0906 18-35-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18100, current rewards: 200.43578, mean: 0.09972
[32m[0906 18-35-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18108, current rewards: 206.03090, mean: 0.10001
[32m[0906 18-36-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18115, current rewards: 211.61894, mean: 0.10029
[32m[0906 18-36-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18120, current rewards: 217.20697, mean: 0.10056
[32m[0906 18-36-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18125, current rewards: 222.79888, mean: 0.10081
[32m[0906 18-36-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18132, current rewards: 228.33078, mean: 0.10103
[32m[0906 18-36-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18139, current rewards: 221.57938, mean: 0.09592
[32m[0906 18-36-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18145, current rewards: 226.03251, mean: 0.09578
[32m[0906 18-37-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18149, current rewards: 230.31907, mean: 0.09557
[32m[0906 18-37-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18155, current rewards: 234.58354, mean: 0.09536
[32m[0906 18-37-19 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 18-37-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-37-19 @MBExp.py:227][0m Rewards obtained: [237.9978170811282], Lows: [20], Highs: [41], Total time: 16461.396978
[32m[0906 18-38-35 @MBExp.py:144][0m ####################################################################
[32m[0906 18-38-35 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 18-38-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17850, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-38-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18151, current rewards: -24.01231, mean: -0.40021
[32m[0906 18-38-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18310, current rewards: -18.18093, mean: -0.16528
[32m[0906 18-39-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18332, current rewards: -10.18808, mean: -0.06368
[32m[0906 18-39-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18340, current rewards: -6.24429, mean: -0.02973
[32m[0906 18-39-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18365, current rewards: -2.36770, mean: -0.00911
[32m[0906 18-39-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18302, current rewards: 1.50255, mean: 0.00485
[32m[0906 18-39-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18252, current rewards: 5.38196, mean: 0.01495
[32m[0906 18-39-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18216, current rewards: 9.25521, mean: 0.02257
[32m[0906 18-39-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18140, current rewards: 13.13214, mean: 0.02855
[32m[0906 18-40-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18070, current rewards: -3.27299, mean: -0.00642
[32m[0906 18-40-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18009, current rewards: 1.99335, mean: 0.00356
[32m[0906 18-40-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17929, current rewards: 7.30232, mean: 0.01197
[32m[0906 18-40-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17850, current rewards: 12.61816, mean: 0.01912
[32m[0906 18-40-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17794, current rewards: -2.87978, mean: -0.00406
[32m[0906 18-40-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17769, current rewards: 2.63798, mean: 0.00347
[32m[0906 18-40-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17746, current rewards: 8.15818, mean: 0.01007
[32m[0906 18-41-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17731, current rewards: 13.68202, mean: 0.01591
[32m[0906 18-41-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17744, current rewards: 19.19899, mean: 0.02110
[32m[0906 18-41-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17763, current rewards: 25.72162, mean: 0.02679
[32m[0906 18-41-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17774, current rewards: 31.39811, mean: 0.03109
[32m[0906 18-41-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17808, current rewards: 25.81022, mean: 0.02435
[32m[0906 18-41-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17837, current rewards: 31.07521, mean: 0.02800
[32m[0906 18-42-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17862, current rewards: 36.33648, mean: 0.03132
[32m[0906 18-42-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17886, current rewards: 41.59894, mean: 0.03438
[32m[0906 18-42-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17907, current rewards: 46.86496, mean: 0.03719
[32m[0906 18-42-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17928, current rewards: 52.13272, mean: 0.03980
[32m[0906 18-42-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17943, current rewards: 57.33077, mean: 0.04215
[32m[0906 18-42-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17961, current rewards: 51.30823, mean: 0.03639
[32m[0906 18-42-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17979, current rewards: 56.87578, mean: 0.03896
[32m[0906 18-43-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17995, current rewards: 62.43382, mean: 0.04135
[32m[0906 18-43-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18008, current rewards: 68.00463, mean: 0.04359
[32m[0906 18-43-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18021, current rewards: 73.57200, mean: 0.04570
[32m[0906 18-43-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18035, current rewards: 79.13618, mean: 0.04767
[32m[0906 18-43-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18047, current rewards: 84.70655, mean: 0.04954
[32m[0906 18-43-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18057, current rewards: 90.26813, mean: 0.05129
[32m[0906 18-44-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18068, current rewards: 95.83316, mean: 0.05295
[32m[0906 18-44-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18078, current rewards: 101.39899, mean: 0.05452
[32m[0906 18-44-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18086, current rewards: 85.87252, mean: 0.04496
[32m[0906 18-44-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18093, current rewards: 91.35577, mean: 0.04661
[32m[0906 18-44-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18101, current rewards: 96.90616, mean: 0.04821
[32m[0906 18-44-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18107, current rewards: 102.45287, mean: 0.04973
[32m[0906 18-44-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18115, current rewards: 108.00367, mean: 0.05119
[32m[0906 18-45-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18121, current rewards: 113.55387, mean: 0.05257
[32m[0906 18-45-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18126, current rewards: 119.10211, mean: 0.05389
[32m[0906 18-45-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18132, current rewards: 124.64995, mean: 0.05515
[32m[0906 18-45-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18138, current rewards: 130.19612, mean: 0.05636
[32m[0906 18-45-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18143, current rewards: 135.74208, mean: 0.05752
[32m[0906 18-45-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18147, current rewards: 141.28939, mean: 0.05863
[32m[0906 18-46-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18152, current rewards: 146.83737, mean: 0.05969
[32m[0906 18-46-09 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 18-46-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-46-09 @MBExp.py:227][0m Rewards obtained: [151.27247610266494], Lows: [39], Highs: [31], Total time: 16915.988132000002
[32m[0906 18-47-27 @MBExp.py:144][0m ####################################################################
[32m[0906 18-47-27 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 18-47-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17844, current rewards: 0.91120, mean: 0.09112
[32m[0906 18-47-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18074, current rewards: 6.92790, mean: 0.11546
[32m[0906 18-47-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18302, current rewards: 13.14312, mean: 0.11948
[32m[0906 18-47-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18361, current rewards: 19.41682, mean: 0.12136
[32m[0906 18-48-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18391, current rewards: 21.18999, mean: 0.10090
[32m[0906 18-48-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18385, current rewards: 19.88712, mean: 0.07649
[32m[0906 18-48-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18309, current rewards: 25.63840, mean: 0.08270
[32m[0906 18-48-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18262, current rewards: 31.38534, mean: 0.08718
[32m[0906 18-48-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18230, current rewards: 37.14193, mean: 0.09059
[32m[0906 18-48-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18151, current rewards: 42.89082, mean: 0.09324
[32m[0906 18-49-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18074, current rewards: 49.20463, mean: 0.09648
[32m[0906 18-49-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18013, current rewards: 54.95879, mean: 0.09814
[32m[0906 18-49-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17928, current rewards: 60.35382, mean: 0.09894
[32m[0906 18-49-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17851, current rewards: 65.84681, mean: 0.09977
[32m[0906 18-49-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17787, current rewards: 71.89384, mean: 0.10126
[32m[0906 18-49-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17764, current rewards: 77.94247, mean: 0.10256
[32m[0906 18-49-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17745, current rewards: 83.99537, mean: 0.10370
[32m[0906 18-50-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17724, current rewards: 90.04696, mean: 0.10471
[32m[0906 18-50-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17732, current rewards: 96.48769, mean: 0.10603
[32m[0906 18-50-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17744, current rewards: 102.61729, mean: 0.10689
[32m[0906 18-50-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17758, current rewards: 108.69723, mean: 0.10762
[32m[0906 18-50-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17792, current rewards: 91.72505, mean: 0.08653
[32m[0906 18-50-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17825, current rewards: 98.50759, mean: 0.08875
[32m[0906 18-50-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17852, current rewards: 105.29279, mean: 0.09077
[32m[0906 18-51-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17877, current rewards: 112.07584, mean: 0.09262
[32m[0906 18-51-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17898, current rewards: 118.86128, mean: 0.09433
[32m[0906 18-51-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17921, current rewards: 125.49577, mean: 0.09580
[32m[0906 18-51-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17937, current rewards: 130.07124, mean: 0.09564
[32m[0906 18-51-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17955, current rewards: 125.54553, mean: 0.08904
[32m[0906 18-51-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17974, current rewards: 130.87909, mean: 0.08964
[32m[0906 18-51-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17988, current rewards: 136.21874, mean: 0.09021
[32m[0906 18-52-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18000, current rewards: 141.56336, mean: 0.09075
[32m[0906 18-52-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18013, current rewards: 146.90063, mean: 0.09124
[32m[0906 18-52-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18025, current rewards: 152.23396, mean: 0.09171
[32m[0906 18-52-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18037, current rewards: 157.56947, mean: 0.09215
[32m[0906 18-52-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18048, current rewards: 162.90980, mean: 0.09256
[32m[0906 18-52-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18058, current rewards: 168.24963, mean: 0.09296
[32m[0906 18-53-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18067, current rewards: 173.59075, mean: 0.09333
[32m[0906 18-53-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18075, current rewards: 178.41957, mean: 0.09341
[32m[0906 18-53-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18083, current rewards: 182.66508, mean: 0.09320
[32m[0906 18-53-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18091, current rewards: 186.84702, mean: 0.09296
[32m[0906 18-53-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18099, current rewards: 191.01839, mean: 0.09273
[32m[0906 18-53-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18106, current rewards: 195.19117, mean: 0.09251
[32m[0906 18-53-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18116, current rewards: 199.93998, mean: 0.09256
[32m[0906 18-54-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18123, current rewards: 203.97787, mean: 0.09230
[32m[0906 18-54-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18129, current rewards: 208.02375, mean: 0.09205
[32m[0906 18-54-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18135, current rewards: 189.23599, mean: 0.08192
[32m[0906 18-54-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18141, current rewards: 195.26651, mean: 0.08274
[32m[0906 18-54-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18145, current rewards: 201.43621, mean: 0.08358
[32m[0906 18-54-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18151, current rewards: 207.60712, mean: 0.08439
[32m[0906 18-55-02 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 18-55-02 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-55-02 @MBExp.py:227][0m Rewards obtained: [212.54199454215805], Lows: [22], Highs: [20], Total time: 17370.572360000002
[32m[0906 18-56-22 @MBExp.py:144][0m ####################################################################
[32m[0906 18-56-22 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 18-56-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17952, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-56-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17995, current rewards: -6.50863, mean: -0.10848
[32m[0906 18-56-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18237, current rewards: -0.92027, mean: -0.00837
[32m[0906 18-56-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18289, current rewards: 4.90696, mean: 0.03067
[32m[0906 18-57-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18304, current rewards: 10.73617, mean: 0.05112
[32m[0906 18-57-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18323, current rewards: 16.57017, mean: 0.06373
[32m[0906 18-57-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18259, current rewards: 22.39555, mean: 0.07224
[32m[0906 18-57-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18215, current rewards: 28.22495, mean: 0.07840
[32m[0906 18-57-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18182, current rewards: 34.05863, mean: 0.08307
[32m[0906 18-57-45 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18120, current rewards: 39.88699, mean: 0.08671
[32m[0906 18-57-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18050, current rewards: 46.22673, mean: 0.09064
[32m[0906 18-58-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18001, current rewards: 52.08733, mean: 0.09301
[32m[0906 18-58-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17926, current rewards: 57.94016, mean: 0.09498
[32m[0906 18-58-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17847, current rewards: 63.78492, mean: 0.09664
[32m[0906 18-58-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17773, current rewards: 48.34642, mean: 0.06809
[32m[0906 18-58-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17740, current rewards: 53.98397, mean: 0.07103
[32m[0906 18-58-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17719, current rewards: 59.75805, mean: 0.07378
[32m[0906 18-58-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17701, current rewards: 65.53974, mean: 0.07621
[32m[0906 18-59-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17698, current rewards: 74.94371, mean: 0.08236
[32m[0906 18-59-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17713, current rewards: 80.92485, mean: 0.08430
[32m[0906 18-59-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17724, current rewards: 86.90168, mean: 0.08604
[32m[0906 18-59-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17751, current rewards: 92.87949, mean: 0.08762
[32m[0906 18-59-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17786, current rewards: 78.05825, mean: 0.07032
[32m[0906 18-59-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17816, current rewards: 84.26809, mean: 0.07264
[32m[0906 18-59-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17842, current rewards: 90.47758, mean: 0.07477
[32m[0906 19-00-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17865, current rewards: 83.19669, mean: 0.06603
[32m[0906 19-00-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17892, current rewards: 86.73837, mean: 0.06621
[32m[0906 19-00-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17911, current rewards: 91.73573, mean: 0.06745
[32m[0906 19-00-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17927, current rewards: 97.27954, mean: 0.06899
[32m[0906 19-00-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17943, current rewards: 102.82505, mean: 0.07043
[32m[0906 19-00-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17959, current rewards: 108.36948, mean: 0.07177
[32m[0906 19-01-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17973, current rewards: 113.91159, mean: 0.07302
[32m[0906 19-01-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17987, current rewards: 119.45235, mean: 0.07419
[32m[0906 19-01-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17997, current rewards: 124.99447, mean: 0.07530
[32m[0906 19-01-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18008, current rewards: 130.54040, mean: 0.07634
[32m[0906 19-01-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18019, current rewards: 139.41489, mean: 0.07921
[32m[0906 19-01-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18029, current rewards: 144.89911, mean: 0.08005
[32m[0906 19-01-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18036, current rewards: 139.17448, mean: 0.07482
[32m[0906 19-02-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18043, current rewards: 144.73025, mean: 0.07578
[32m[0906 19-02-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18053, current rewards: 150.48488, mean: 0.07678
[32m[0906 19-02-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18063, current rewards: 156.23862, mean: 0.07773
[32m[0906 19-02-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18070, current rewards: 161.98809, mean: 0.07863
[32m[0906 19-02-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18078, current rewards: 167.74238, mean: 0.07950
[32m[0906 19-02-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18084, current rewards: 173.22193, mean: 0.08020
[32m[0906 19-03-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18090, current rewards: 178.37284, mean: 0.08071
[32m[0906 19-03-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18095, current rewards: 183.84872, mean: 0.08135
[32m[0906 19-03-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18101, current rewards: 189.31526, mean: 0.08195
[32m[0906 19-03-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18106, current rewards: 194.78629, mean: 0.08254
[32m[0906 19-03-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18112, current rewards: 200.25515, mean: 0.08309
[32m[0906 19-03-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18115, current rewards: 205.72819, mean: 0.08363
[32m[0906 19-03-56 @Agent.py:117][0m Average action selection time: 0.1812
[32m[0906 19-03-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-03-56 @MBExp.py:227][0m Rewards obtained: [210.10172117401413], Lows: [20], Highs: [35], Total time: 17824.270861
[32m[0906 19-05-18 @MBExp.py:144][0m ####################################################################
[32m[0906 19-05-18 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 19-05-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17965, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-05-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17975, current rewards: -5.84435, mean: -0.09741
[32m[0906 19-05-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18111, current rewards: 0.45946, mean: 0.00418
[32m[0906 19-05-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18213, current rewards: 5.87575, mean: 0.03672
[32m[0906 19-05-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18268, current rewards: 11.27846, mean: 0.05371
[32m[0906 19-06-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18308, current rewards: 16.68663, mean: 0.06418
[32m[0906 19-06-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18260, current rewards: 22.09267, mean: 0.07127
[32m[0906 19-06-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18216, current rewards: 27.50004, mean: 0.07639
[32m[0906 19-06-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18196, current rewards: 32.91342, mean: 0.08028
[32m[0906 19-06-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18145, current rewards: 38.32457, mean: 0.08331
[32m[0906 19-06-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18074, current rewards: 43.81926, mean: 0.08592
[32m[0906 19-06-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18019, current rewards: 49.38279, mean: 0.08818
[32m[0906 19-07-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17940, current rewards: 54.99123, mean: 0.09015
[32m[0906 19-07-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17857, current rewards: 60.58994, mean: 0.09180
[32m[0906 19-07-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17788, current rewards: 66.19999, mean: 0.09324
[32m[0906 19-07-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17741, current rewards: 71.80556, mean: 0.09448
[32m[0906 19-07-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17721, current rewards: 77.41090, mean: 0.09557
[32m[0906 19-07-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17703, current rewards: 83.02036, mean: 0.09654
[32m[0906 19-07-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17690, current rewards: 88.68812, mean: 0.09746
[32m[0906 19-08-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17708, current rewards: 94.30215, mean: 0.09823
[32m[0906 19-08-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17720, current rewards: 99.36732, mean: 0.09838
[32m[0906 19-08-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17737, current rewards: 104.88416, mean: 0.09895
[32m[0906 19-08-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17775, current rewards: 110.37156, mean: 0.09943
[32m[0906 19-08-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17802, current rewards: 115.85338, mean: 0.09987
[32m[0906 19-08-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17828, current rewards: 121.34177, mean: 0.10028
[32m[0906 19-09-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17853, current rewards: 126.82334, mean: 0.10065
[32m[0906 19-09-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17873, current rewards: 132.08637, mean: 0.10083
[32m[0906 19-09-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17893, current rewards: 137.54371, mean: 0.10114
[32m[0906 19-09-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17912, current rewards: 142.99624, mean: 0.10142
[32m[0906 19-09-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17931, current rewards: 148.45558, mean: 0.10168
[32m[0906 19-09-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17948, current rewards: 153.90376, mean: 0.10192
[32m[0906 19-09-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17963, current rewards: 137.42625, mean: 0.08809
[32m[0906 19-10-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17975, current rewards: 144.80447, mean: 0.08994
[32m[0906 19-10-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17990, current rewards: 152.19424, mean: 0.09168
[32m[0906 19-10-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18003, current rewards: 159.74164, mean: 0.09342
[32m[0906 19-10-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18016, current rewards: 167.16507, mean: 0.09498
[32m[0906 19-10-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18029, current rewards: 174.57865, mean: 0.09645
[32m[0906 19-10-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18041, current rewards: 181.98707, mean: 0.09784
[32m[0906 19-11-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18051, current rewards: 189.39677, mean: 0.09916
[32m[0906 19-11-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18061, current rewards: 196.81530, mean: 0.10042
[32m[0906 19-11-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18069, current rewards: 204.23082, mean: 0.10161
[32m[0906 19-11-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18078, current rewards: 211.64271, mean: 0.10274
[32m[0906 19-11-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18085, current rewards: 221.16855, mean: 0.10482
[32m[0906 19-11-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18092, current rewards: 215.89495, mean: 0.09995
[32m[0906 19-11-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18101, current rewards: 221.66679, mean: 0.10030
[32m[0906 19-12-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18108, current rewards: 227.43588, mean: 0.10064
[32m[0906 19-12-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18112, current rewards: 233.20949, mean: 0.10096
[32m[0906 19-12-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18119, current rewards: 238.98221, mean: 0.10126
[32m[0906 19-12-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18125, current rewards: 244.75287, mean: 0.10156
[32m[0906 19-12-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18132, current rewards: 250.52829, mean: 0.10184
[32m[0906 19-12-52 @Agent.py:117][0m Average action selection time: 0.1814
[32m[0906 19-12-52 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-12-52 @MBExp.py:227][0m Rewards obtained: [255.14335961730018], Lows: [11], Highs: [21], Total time: 18278.376748000002
[32m[0906 19-14-16 @MBExp.py:144][0m ####################################################################
[32m[0906 19-14-16 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 19-14-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17939, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-14-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17984, current rewards: -7.10613, mean: -0.11844
[32m[0906 19-14-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18052, current rewards: -1.74417, mean: -0.01586
[32m[0906 19-14-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18183, current rewards: 3.61206, mean: 0.02258
[32m[0906 19-14-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18278, current rewards: 8.96930, mean: 0.04271
[32m[0906 19-15-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18321, current rewards: 14.33207, mean: 0.05512
[32m[0906 19-15-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18282, current rewards: 19.68914, mean: 0.06351
[32m[0906 19-15-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18239, current rewards: 25.04903, mean: 0.06958
[32m[0906 19-15-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18202, current rewards: 7.87877, mean: 0.01922
[32m[0906 19-15-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18154, current rewards: 6.98588, mean: 0.01519
[32m[0906 19-15-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18079, current rewards: 18.06494, mean: 0.03542
[32m[0906 19-15-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18022, current rewards: 29.12299, mean: 0.05201
[32m[0906 19-16-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17944, current rewards: 40.16964, mean: 0.06585
[32m[0906 19-16-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17866, current rewards: 51.25811, mean: 0.07766
[32m[0906 19-16-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17795, current rewards: 62.33603, mean: 0.08780
[32m[0906 19-16-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17736, current rewards: 66.76172, mean: 0.08784
[32m[0906 19-16-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17715, current rewards: 57.63571, mean: 0.07116
[32m[0906 19-16-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17698, current rewards: 64.43533, mean: 0.07492
[32m[0906 19-16-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17682, current rewards: 70.79053, mean: 0.07779
[32m[0906 19-17-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17694, current rewards: 77.13436, mean: 0.08035
[32m[0906 19-17-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17709, current rewards: 83.47575, mean: 0.08265
[32m[0906 19-17-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17720, current rewards: 68.41983, mean: 0.06455
[32m[0906 19-17-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17756, current rewards: 74.09495, mean: 0.06675
[32m[0906 19-17-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17788, current rewards: 79.76788, mean: 0.06877
[32m[0906 19-17-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17815, current rewards: 85.43671, mean: 0.07061
[32m[0906 19-18-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17841, current rewards: 90.33920, mean: 0.07170
[32m[0906 19-18-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17863, current rewards: 95.84773, mean: 0.07317
[32m[0906 19-18-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17884, current rewards: 101.35795, mean: 0.07453
[32m[0906 19-18-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17900, current rewards: 105.75848, mean: 0.07501
[32m[0906 19-18-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17920, current rewards: 101.14387, mean: 0.06928
[32m[0906 19-18-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17935, current rewards: 106.61902, mean: 0.07061
[32m[0906 19-18-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17952, current rewards: 112.09188, mean: 0.07185
[32m[0906 19-19-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17969, current rewards: 117.56719, mean: 0.07302
[32m[0906 19-19-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17986, current rewards: 124.64332, mean: 0.07509
[32m[0906 19-19-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17998, current rewards: 130.21311, mean: 0.07615
[32m[0906 19-19-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18007, current rewards: 135.77807, mean: 0.07715
[32m[0906 19-19-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18018, current rewards: 141.34816, mean: 0.07809
[32m[0906 19-19-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18027, current rewards: 146.90726, mean: 0.07898
[32m[0906 19-20-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18034, current rewards: 152.47096, mean: 0.07983
[32m[0906 19-20-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18044, current rewards: 158.03015, mean: 0.08063
[32m[0906 19-20-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18051, current rewards: 163.59695, mean: 0.08139
[32m[0906 19-20-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18059, current rewards: 170.23928, mean: 0.08264
[32m[0906 19-20-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18067, current rewards: 175.86690, mean: 0.08335
[32m[0906 19-20-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18074, current rewards: 181.47008, mean: 0.08401
[32m[0906 19-20-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18080, current rewards: 176.21296, mean: 0.07973
[32m[0906 19-21-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18087, current rewards: 182.38372, mean: 0.08070
[32m[0906 19-21-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18095, current rewards: 188.54644, mean: 0.08162
[32m[0906 19-21-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18101, current rewards: 194.71217, mean: 0.08251
[32m[0906 19-21-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18107, current rewards: 200.87961, mean: 0.08335
[32m[0906 19-21-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18112, current rewards: 206.83932, mean: 0.08408
[32m[0906 19-21-50 @Agent.py:117][0m Average action selection time: 0.1812
[32m[0906 19-21-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-21-50 @MBExp.py:227][0m Rewards obtained: [211.21328510799174], Lows: [31], Highs: [42], Total time: 18732.024078000002
[32m[0906 19-23-16 @MBExp.py:144][0m ####################################################################
[32m[0906 19-23-16 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 19-23-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18234, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-23-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18083, current rewards: -26.49526, mean: -0.44159
[32m[0906 19-23-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18053, current rewards: -21.97161, mean: -0.19974
[32m[0906 19-23-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18203, current rewards: -17.44886, mean: -0.10906
[32m[0906 19-23-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18249, current rewards: -12.92921, mean: -0.06157
[32m[0906 19-24-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18279, current rewards: -8.40732, mean: -0.03234
[32m[0906 19-24-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18247, current rewards: -3.88306, mean: -0.01253
[32m[0906 19-24-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18202, current rewards: 0.63965, mean: 0.00178
[32m[0906 19-24-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18169, current rewards: 4.82396, mean: 0.01177
[32m[0906 19-24-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18135, current rewards: 9.33336, mean: 0.02029
[32m[0906 19-24-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18069, current rewards: 13.84891, mean: 0.02715
[32m[0906 19-24-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18013, current rewards: -2.04366, mean: -0.00365
[32m[0906 19-25-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17933, current rewards: 3.19026, mean: 0.00523
[32m[0906 19-25-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17854, current rewards: 8.42911, mean: 0.01277
[32m[0906 19-25-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17786, current rewards: 13.65958, mean: 0.01924
[32m[0906 19-25-31 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17730, current rewards: 18.88723, mean: 0.02485
[32m[0906 19-25-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17700, current rewards: 24.12323, mean: 0.02978
[32m[0906 19-25-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17682, current rewards: 29.35903, mean: 0.03414
[32m[0906 19-25-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17668, current rewards: 34.58891, mean: 0.03801
[32m[0906 19-26-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17664, current rewards: 39.82405, mean: 0.04148
[32m[0906 19-26-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17681, current rewards: 24.95804, mean: 0.02471
[32m[0906 19-26-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17692, current rewards: 29.67006, mean: 0.02799
[32m[0906 19-26-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17721, current rewards: 34.38504, mean: 0.03098
[32m[0906 19-26-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17753, current rewards: 39.09702, mean: 0.03370
[32m[0906 19-26-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17783, current rewards: 43.95618, mean: 0.03633
[32m[0906 19-27-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17808, current rewards: 48.68068, mean: 0.03864
[32m[0906 19-27-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17832, current rewards: 53.40202, mean: 0.04076
[32m[0906 19-27-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17852, current rewards: 47.20845, mean: 0.03471
[32m[0906 19-27-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17875, current rewards: 51.90997, mean: 0.03682
[32m[0906 19-27-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17896, current rewards: 56.62597, mean: 0.03878
[32m[0906 19-27-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17913, current rewards: 61.34095, mean: 0.04062
[32m[0906 19-27-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17929, current rewards: 66.05596, mean: 0.04234
[32m[0906 19-28-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17946, current rewards: 72.08535, mean: 0.04477
[32m[0906 19-28-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17960, current rewards: 78.86885, mean: 0.04751
[32m[0906 19-28-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17974, current rewards: 84.35931, mean: 0.04933
[32m[0906 19-28-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17987, current rewards: 89.84902, mean: 0.05105
[32m[0906 19-28-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17996, current rewards: 95.33970, mean: 0.05267
[32m[0906 19-28-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18004, current rewards: 100.83152, mean: 0.05421
[32m[0906 19-29-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18013, current rewards: 94.47557, mean: 0.04946
[32m[0906 19-29-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18024, current rewards: 99.15839, mean: 0.05059
[32m[0906 19-29-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18031, current rewards: 103.84585, mean: 0.05166
[32m[0906 19-29-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18040, current rewards: 108.35463, mean: 0.05260
[32m[0906 19-29-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18052, current rewards: 113.03718, mean: 0.05357
[32m[0906 19-29-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18059, current rewards: 117.72167, mean: 0.05450
[32m[0906 19-29-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18067, current rewards: 122.40977, mean: 0.05539
[32m[0906 19-30-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18075, current rewards: 127.09336, mean: 0.05624
[32m[0906 19-30-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18081, current rewards: 131.77642, mean: 0.05705
[32m[0906 19-30-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18087, current rewards: 141.33177, mean: 0.05989
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18093, current rewards: 146.49764, mean: 0.06079
[32m[0906 19-30-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18101, current rewards: 150.87005, mean: 0.06133
[32m[0906 19-30-50 @Agent.py:117][0m Average action selection time: 0.1811
[32m[0906 19-30-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-30-50 @MBExp.py:227][0m Rewards obtained: [154.92287825352747], Lows: [31], Highs: [30], Total time: 19185.337811
[32m[0906 19-32-18 @MBExp.py:144][0m ####################################################################
[32m[0906 19-32-18 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 19-32-20 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17873, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-32-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17906, current rewards: -6.16824, mean: -0.10280
[32m[0906 19-32-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17894, current rewards: -0.95099, mean: -0.00865
[32m[0906 19-32-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18059, current rewards: 4.26950, mean: 0.02668
[32m[0906 19-32-56 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18170, current rewards: 9.48574, mean: 0.04517
[32m[0906 19-33-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18199, current rewards: 14.70100, mean: 0.05654
[32m[0906 19-33-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18187, current rewards: 19.91410, mean: 0.06424
[32m[0906 19-33-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18156, current rewards: 24.85492, mean: 0.06904
[32m[0906 19-33-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18135, current rewards: 30.07438, mean: 0.07335
[32m[0906 19-33-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18108, current rewards: 35.28590, mean: 0.07671
[32m[0906 19-33-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18046, current rewards: 40.49214, mean: 0.07940
[32m[0906 19-33-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17987, current rewards: 28.07272, mean: 0.05013
[32m[0906 19-34-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17913, current rewards: 33.42932, mean: 0.05480
[32m[0906 19-34-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17832, current rewards: 38.78161, mean: 0.05876
[32m[0906 19-34-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17766, current rewards: 44.12969, mean: 0.06215
[32m[0906 19-34-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17707, current rewards: 49.68783, mean: 0.06538
[32m[0906 19-34-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17670, current rewards: 55.79114, mean: 0.06888
[32m[0906 19-34-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17658, current rewards: 39.85920, mean: 0.04635
[32m[0906 19-34-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17644, current rewards: 42.10178, mean: 0.04627
[32m[0906 19-35-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17634, current rewards: 46.74490, mean: 0.04869
[32m[0906 19-35-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17650, current rewards: 51.38829, mean: 0.05088
[32m[0906 19-35-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17666, current rewards: 56.03026, mean: 0.05286
[32m[0906 19-35-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17687, current rewards: 60.67790, mean: 0.05466
[32m[0906 19-35-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17722, current rewards: 65.32057, mean: 0.05631
[32m[0906 19-35-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17759, current rewards: 69.84202, mean: 0.05772
[32m[0906 19-36-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17789, current rewards: 74.48413, mean: 0.05911
[32m[0906 19-36-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17819, current rewards: 79.12072, mean: 0.06040
[32m[0906 19-36-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17841, current rewards: 62.88589, mean: 0.04624
[32m[0906 19-36-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17862, current rewards: 67.87415, mean: 0.04814
[32m[0906 19-36-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17885, current rewards: 72.86221, mean: 0.04991
[32m[0906 19-36-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17904, current rewards: 77.84903, mean: 0.05156
[32m[0906 19-36-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17919, current rewards: 82.83562, mean: 0.05310
[32m[0906 19-37-07 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17936, current rewards: 90.34898, mean: 0.05612
[32m[0906 19-37-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17949, current rewards: 98.15749, mean: 0.05913
[32m[0906 19-37-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17963, current rewards: 105.90419, mean: 0.06193
[32m[0906 19-37-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17975, current rewards: 113.81726, mean: 0.06467
[32m[0906 19-37-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17984, current rewards: 121.75926, mean: 0.06727
[32m[0906 19-37-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17999, current rewards: 110.98912, mean: 0.05967
[32m[0906 19-38-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18015, current rewards: 119.77778, mean: 0.06271
[32m[0906 19-38-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18024, current rewards: 128.56645, mean: 0.06560
[32m[0906 19-38-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18033, current rewards: 136.29848, mean: 0.06781
[32m[0906 19-38-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18040, current rewards: 142.75730, mean: 0.06930
[32m[0906 19-38-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18048, current rewards: 149.21613, mean: 0.07072
[32m[0906 19-38-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18056, current rewards: 155.67495, mean: 0.07207
[32m[0906 19-38-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18063, current rewards: 162.13377, mean: 0.07336
[32m[0906 19-39-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18071, current rewards: 168.59260, mean: 0.07460
[32m[0906 19-39-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18080, current rewards: 138.91777, mean: 0.06014
[32m[0906 19-39-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18088, current rewards: 88.91777, mean: 0.03768
[32m[0906 19-39-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18095, current rewards: 38.91777, mean: 0.01615
[32m[0906 19-39-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18103, current rewards: -11.08223, mean: -0.00450
[32m[0906 19-39-52 @Agent.py:117][0m Average action selection time: 0.1811
[32m[0906 19-39-52 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-39-52 @MBExp.py:227][0m Rewards obtained: [-51.08222819484928], Lows: [34], Highs: [245], Total time: 19638.748718000003
[32m[0906 19-41-22 @MBExp.py:144][0m ####################################################################
[32m[0906 19-41-22 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 19-41-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17924, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-41-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17958, current rewards: -5.01144, mean: -0.08352
[32m[0906 19-41-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17974, current rewards: 0.38109, mean: 0.00346
[32m[0906 19-41-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18073, current rewards: 5.77241, mean: 0.03608
[32m[0906 19-42-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18177, current rewards: 11.16002, mean: 0.05314
[32m[0906 19-42-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18246, current rewards: 16.55214, mean: 0.06366
[32m[0906 19-42-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18247, current rewards: 21.95277, mean: 0.07082
[32m[0906 19-42-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18203, current rewards: 28.04484, mean: 0.07790
[32m[0906 19-42-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18169, current rewards: 33.80365, mean: 0.08245
[32m[0906 19-42-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18142, current rewards: 39.56695, mean: 0.08602
[32m[0906 19-42-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18070, current rewards: 22.13827, mean: 0.04341
[32m[0906 19-43-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18013, current rewards: 27.44374, mean: 0.04901
[32m[0906 19-43-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17936, current rewards: 32.69001, mean: 0.05359
[32m[0906 19-43-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17853, current rewards: 37.92967, mean: 0.05747
[32m[0906 19-43-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17778, current rewards: 43.17471, mean: 0.06081
[32m[0906 19-43-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17716, current rewards: 47.52810, mean: 0.06254
[32m[0906 19-43-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17663, current rewards: 41.90956, mean: 0.05174
[32m[0906 19-43-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17648, current rewards: 46.86008, mean: 0.05449
[32m[0906 19-44-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17636, current rewards: 51.78154, mean: 0.05690
[32m[0906 19-44-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17624, current rewards: 56.70407, mean: 0.05907
[32m[0906 19-44-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17638, current rewards: 61.62921, mean: 0.06102
[32m[0906 19-44-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17655, current rewards: 66.55211, mean: 0.06279
[32m[0906 19-44-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17676, current rewards: 71.47540, mean: 0.06439
[32m[0906 19-44-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17711, current rewards: 76.40206, mean: 0.06586
[32m[0906 19-44-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17741, current rewards: 81.29305, mean: 0.06718
[32m[0906 19-45-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17772, current rewards: 86.21412, mean: 0.06842
[32m[0906 19-45-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17801, current rewards: 91.13700, mean: 0.06957
[32m[0906 19-45-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17824, current rewards: 96.06478, mean: 0.07064
[32m[0906 19-45-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17846, current rewards: 100.98930, mean: 0.07162
[32m[0906 19-45-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17864, current rewards: 105.91491, mean: 0.07254
[32m[0906 19-45-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17884, current rewards: 110.84128, mean: 0.07340
[32m[0906 19-46-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17901, current rewards: 115.77113, mean: 0.07421
[32m[0906 19-46-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17919, current rewards: 121.83883, mean: 0.07568
[32m[0906 19-46-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17937, current rewards: 105.61781, mean: 0.06363
[32m[0906 19-46-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17955, current rewards: 110.70318, mean: 0.06474
[32m[0906 19-46-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17968, current rewards: 115.78161, mean: 0.06579
[32m[0906 19-46-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17982, current rewards: 120.86677, mean: 0.06678
[32m[0906 19-46-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17993, current rewards: 125.94261, mean: 0.06771
[32m[0906 19-47-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18004, current rewards: 131.02214, mean: 0.06860
[32m[0906 19-47-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18014, current rewards: 136.10064, mean: 0.06944
[32m[0906 19-47-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18024, current rewards: 140.58064, mean: 0.06994
[32m[0906 19-47-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18032, current rewards: 122.22221, mean: 0.05933
[32m[0906 19-47-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18042, current rewards: 127.18805, mean: 0.06028
[32m[0906 19-47-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18048, current rewards: 132.23201, mean: 0.06122
[32m[0906 19-48-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18056, current rewards: 137.27530, mean: 0.06212
[32m[0906 19-48-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18063, current rewards: 142.32061, mean: 0.06297
[32m[0906 19-48-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18071, current rewards: 147.36264, mean: 0.06379
[32m[0906 19-48-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18079, current rewards: 152.40490, mean: 0.06458
[32m[0906 19-48-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18087, current rewards: 157.45568, mean: 0.06533
[32m[0906 19-48-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18093, current rewards: 153.22431, mean: 0.06229
[32m[0906 19-48-56 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0906 19-48-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-48-56 @MBExp.py:227][0m Rewards obtained: [157.23861761809437], Lows: [32], Highs: [30], Total time: 20091.897073000004
[32m[0906 19-50-29 @MBExp.py:144][0m ####################################################################
[32m[0906 19-50-29 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 19-50-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18041, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-50-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18033, current rewards: -7.03592, mean: -0.11727
[32m[0906 19-50-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17999, current rewards: -1.37038, mean: -0.01246
[32m[0906 19-50-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18050, current rewards: 4.29293, mean: 0.02683
[32m[0906 19-51-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18150, current rewards: 9.96413, mean: 0.04745
[32m[0906 19-51-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18211, current rewards: 15.62724, mean: 0.06010
[32m[0906 19-51-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18221, current rewards: 21.29383, mean: 0.06869
[32m[0906 19-51-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18182, current rewards: 27.92432, mean: 0.07757
[32m[0906 19-51-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18153, current rewards: 33.62832, mean: 0.08202
[32m[0906 19-51-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18132, current rewards: 39.32791, mean: 0.08550
[32m[0906 19-52-01 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18062, current rewards: 45.02567, mean: 0.08829
[32m[0906 19-52-10 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18005, current rewards: 50.71976, mean: 0.09057
[32m[0906 19-52-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17927, current rewards: 56.42048, mean: 0.09249
[32m[0906 19-52-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17846, current rewards: 56.54994, mean: 0.08568
[32m[0906 19-52-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17776, current rewards: 56.58405, mean: 0.07970
[32m[0906 19-52-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17718, current rewards: 63.00476, mean: 0.08290
[32m[0906 19-52-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17667, current rewards: 68.59289, mean: 0.08468
[32m[0906 19-53-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17639, current rewards: 74.18118, mean: 0.08626
[32m[0906 19-53-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17626, current rewards: 79.07493, mean: 0.08690
[32m[0906 19-53-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17616, current rewards: 84.28963, mean: 0.08780
[32m[0906 19-53-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17615, current rewards: 89.51667, mean: 0.08863
[32m[0906 19-53-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17631, current rewards: 94.73897, mean: 0.08938
[32m[0906 19-53-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17646, current rewards: 99.48067, mean: 0.08962
[32m[0906 19-53-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17680, current rewards: 104.27302, mean: 0.08989
[32m[0906 19-54-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17716, current rewards: 108.95188, mean: 0.09004
[32m[0906 19-54-13 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17744, current rewards: 113.93461, mean: 0.09042
[32m[0906 19-54-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17776, current rewards: 118.91171, mean: 0.09077
[32m[0906 19-54-31 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17802, current rewards: 123.89124, mean: 0.09110
[32m[0906 19-54-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17828, current rewards: 128.40502, mean: 0.09107
[32m[0906 19-54-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17854, current rewards: 135.19101, mean: 0.09260
[32m[0906 19-54-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17873, current rewards: 140.33589, mean: 0.09294
[32m[0906 19-55-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17890, current rewards: 145.48068, mean: 0.09326
[32m[0906 19-55-17 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17908, current rewards: 150.57126, mean: 0.09352
[32m[0906 19-55-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17924, current rewards: 155.70323, mean: 0.09380
[32m[0906 19-55-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17938, current rewards: 160.83942, mean: 0.09406
[32m[0906 19-55-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17949, current rewards: 165.96485, mean: 0.09430
[32m[0906 19-55-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17964, current rewards: 171.10262, mean: 0.09453
[32m[0906 19-56-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17977, current rewards: 176.23759, mean: 0.09475
[32m[0906 19-56-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17987, current rewards: 181.36775, mean: 0.09496
[32m[0906 19-56-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17998, current rewards: 186.50216, mean: 0.09515
[32m[0906 19-56-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18009, current rewards: 191.99864, mean: 0.09552
[32m[0906 19-56-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18017, current rewards: 197.15973, mean: 0.09571
[32m[0906 19-56-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18028, current rewards: 202.32923, mean: 0.09589
[32m[0906 19-56-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18040, current rewards: 207.49901, mean: 0.09606
[32m[0906 19-57-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18051, current rewards: 212.66845, mean: 0.09623
[32m[0906 19-57-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18057, current rewards: 194.48979, mean: 0.08606
[32m[0906 19-57-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18067, current rewards: 199.79863, mean: 0.08649
[32m[0906 19-57-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18075, current rewards: 205.17022, mean: 0.08694
[32m[0906 19-57-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18084, current rewards: 210.90720, mean: 0.08751
[32m[0906 19-57-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18093, current rewards: 216.31808, mean: 0.08793
[32m[0906 19-58-02 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0906 19-58-02 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-58-02 @MBExp.py:227][0m Rewards obtained: [220.643646664157], Lows: [11], Highs: [22], Total time: 20545.101709000002
[32m[0906 19-59-37 @MBExp.py:144][0m ####################################################################
[32m[0906 19-59-37 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 19-59-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17944, current rewards: 0.88554, mean: 0.08855
[32m[0906 19-59-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17960, current rewards: 7.49000, mean: 0.12483
[32m[0906 19-59-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17979, current rewards: 13.80543, mean: 0.12550
[32m[0906 20-00-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18009, current rewards: 20.12085, mean: 0.12576
[32m[0906 20-00-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18141, current rewards: 26.43628, mean: 0.12589
[32m[0906 20-00-24 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18176, current rewards: 32.75170, mean: 0.12597
[32m[0906 20-00-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18216, current rewards: 38.78836, mean: 0.12512
[32m[0906 20-00-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18180, current rewards: 44.35150, mean: 0.12320
[32m[0906 20-00-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18157, current rewards: 49.91465, mean: 0.12174
[32m[0906 20-01-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18143, current rewards: 36.58633, mean: 0.07954
[32m[0906 20-01-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18094, current rewards: -13.41367, mean: -0.02630
[32m[0906 20-01-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18029, current rewards: -63.41367, mean: -0.11324
[32m[0906 20-01-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17958, current rewards: -113.41367, mean: -0.18592
[32m[0906 20-01-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17876, current rewards: -163.41367, mean: -0.24760
[32m[0906 20-01-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17808, current rewards: -213.41367, mean: -0.30058
[32m[0906 20-01-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17748, current rewards: -263.41367, mean: -0.34660
[32m[0906 20-02-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17690, current rewards: -313.41367, mean: -0.38693
[32m[0906 20-02-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17651, current rewards: -363.41367, mean: -0.42257
[32m[0906 20-02-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17638, current rewards: -413.41367, mean: -0.45430
[32m[0906 20-02-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17629, current rewards: -463.41367, mean: -0.48272
[32m[0906 20-02-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17615, current rewards: -513.41367, mean: -0.50833
[32m[0906 20-02-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17629, current rewards: -563.41367, mean: -0.53152
[32m[0906 20-02-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17646, current rewards: -613.41367, mean: -0.55262
[32m[0906 20-03-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17677, current rewards: -663.41367, mean: -0.57191
[32m[0906 20-03-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17717, current rewards: -713.41367, mean: -0.58960
[32m[0906 20-03-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17750, current rewards: -763.41367, mean: -0.60588
[32m[0906 20-03-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17776, current rewards: -813.41367, mean: -0.62093
[32m[0906 20-03-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17802, current rewards: -863.41367, mean: -0.63486
[32m[0906 20-03-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17824, current rewards: -913.41367, mean: -0.64781
[32m[0906 20-03-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17848, current rewards: -963.41367, mean: -0.65987
[32m[0906 20-04-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17867, current rewards: -1013.41367, mean: -0.67113
[32m[0906 20-04-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17886, current rewards: -1063.41367, mean: -0.68168
[32m[0906 20-04-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17901, current rewards: -1113.41367, mean: -0.69156
[32m[0906 20-04-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17918, current rewards: -1163.41367, mean: -0.70085
[32m[0906 20-04-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17934, current rewards: -1213.41367, mean: -0.70960
[32m[0906 20-04-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17948, current rewards: -1263.41367, mean: -0.71785
[32m[0906 20-05-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17963, current rewards: -1313.41367, mean: -0.72564
[32m[0906 20-05-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17977, current rewards: -1363.41367, mean: -0.73302
[32m[0906 20-05-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17991, current rewards: -1413.41367, mean: -0.74001
[32m[0906 20-05-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18002, current rewards: -1463.41367, mean: -0.74664
[32m[0906 20-05-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18013, current rewards: -1513.41367, mean: -0.75294
[32m[0906 20-05-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18024, current rewards: -1563.41367, mean: -0.75894
[32m[0906 20-05-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18033, current rewards: -1613.41367, mean: -0.76465
[32m[0906 20-06-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18042, current rewards: -1663.41367, mean: -0.77010
[32m[0906 20-06-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18050, current rewards: -1713.41367, mean: -0.77530
[32m[0906 20-06-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18059, current rewards: -1763.41367, mean: -0.78027
[32m[0906 20-06-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18065, current rewards: -1813.41367, mean: -0.78503
[32m[0906 20-06-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18073, current rewards: -1863.41367, mean: -0.78958
[32m[0906 20-06-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18079, current rewards: -1913.41367, mean: -0.79395
[32m[0906 20-07-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18087, current rewards: -1963.41367, mean: -0.79814
[32m[0906 20-07-10 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0906 20-07-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-07-10 @MBExp.py:227][0m Rewards obtained: [-2003.413670917424], Lows: [0], Highs: [2057], Total time: 20998.062928000003
[32m[0906 20-08-47 @MBExp.py:144][0m ####################################################################
[32m[0906 20-08-47 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 20-08-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18019, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-08-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17978, current rewards: -4.86294, mean: -0.08105
[32m[0906 20-09-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17987, current rewards: 0.48925, mean: 0.00445
[32m[0906 20-09-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17976, current rewards: 5.83827, mean: 0.03649
[32m[0906 20-09-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18101, current rewards: 11.19009, mean: 0.05329
[32m[0906 20-09-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18172, current rewards: -4.68585, mean: -0.01802
[32m[0906 20-09-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18218, current rewards: 0.24174, mean: 0.00078
[32m[0906 20-09-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18182, current rewards: 5.53887, mean: 0.01539
[32m[0906 20-10-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18152, current rewards: 10.83144, mean: 0.02642
[32m[0906 20-10-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18127, current rewards: 16.12147, mean: 0.03505
[32m[0906 20-10-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18074, current rewards: 21.41708, mean: 0.04199
[32m[0906 20-10-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18015, current rewards: 26.71264, mean: 0.04770
[32m[0906 20-10-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17948, current rewards: 32.00614, mean: 0.05247
[32m[0906 20-10-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17863, current rewards: 37.29938, mean: 0.05651
[32m[0906 20-10-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17791, current rewards: 41.75539, mean: 0.05881
[32m[0906 20-11-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17733, current rewards: 38.18932, mean: 0.05025
[32m[0906 20-11-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17678, current rewards: 17.77033, mean: 0.02194
[32m[0906 20-11-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17631, current rewards: 22.96474, mean: 0.02670
[32m[0906 20-11-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17612, current rewards: 28.17050, mean: 0.03096
[32m[0906 20-11-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17603, current rewards: 33.37243, mean: 0.03476
[32m[0906 20-11-45 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17593, current rewards: 38.58177, mean: 0.03820
[32m[0906 20-11-54 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17598, current rewards: 43.78485, mean: 0.04131
[32m[0906 20-12-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17615, current rewards: 49.92419, mean: 0.04498
[32m[0906 20-12-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17635, current rewards: 55.82706, mean: 0.04813
[32m[0906 20-12-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17674, current rewards: 60.12351, mean: 0.04969
[32m[0906 20-12-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17702, current rewards: 64.42589, mean: 0.05113
[32m[0906 20-12-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17731, current rewards: 68.72466, mean: 0.05246
[32m[0906 20-12-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17755, current rewards: 74.18751, mean: 0.05455
[32m[0906 20-12-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17782, current rewards: 80.69917, mean: 0.05723
[32m[0906 20-13-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17807, current rewards: 86.58317, mean: 0.05930
[32m[0906 20-13-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17830, current rewards: 92.47633, mean: 0.06124
[32m[0906 20-13-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17849, current rewards: 97.54432, mean: 0.06253
[32m[0906 20-13-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17867, current rewards: 103.13480, mean: 0.06406
[32m[0906 20-13-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17886, current rewards: 84.99753, mean: 0.05120
[32m[0906 20-13-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17904, current rewards: 89.63381, mean: 0.05242
[32m[0906 20-14-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17917, current rewards: 94.26837, mean: 0.05356
[32m[0906 20-14-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17931, current rewards: 98.90395, mean: 0.05464
[32m[0906 20-14-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17942, current rewards: 103.54142, mean: 0.05567
[32m[0906 20-14-30 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17953, current rewards: 108.17584, mean: 0.05664
[32m[0906 20-14-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17965, current rewards: 113.27112, mean: 0.05779
[32m[0906 20-14-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17976, current rewards: 117.95013, mean: 0.05868
[32m[0906 20-14-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17985, current rewards: 122.56524, mean: 0.05950
[32m[0906 20-15-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17996, current rewards: 127.17871, mean: 0.06027
[32m[0906 20-15-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18005, current rewards: 111.10800, mean: 0.05144
[32m[0906 20-15-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18014, current rewards: 116.35268, mean: 0.05265
[32m[0906 20-15-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18022, current rewards: 121.59737, mean: 0.05380
[32m[0906 20-15-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18033, current rewards: 126.84206, mean: 0.05491
[32m[0906 20-15-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18040, current rewards: 131.91698, mean: 0.05590
[32m[0906 20-16-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18047, current rewards: 135.04290, mean: 0.05603
[32m[0906 20-16-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18056, current rewards: 138.16098, mean: 0.05616
[32m[0906 20-16-19 @Agent.py:117][0m Average action selection time: 0.1806
[32m[0906 20-16-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-16-19 @MBExp.py:227][0m Rewards obtained: [140.6554345960136], Lows: [42], Highs: [20], Total time: 21450.285258000004
[32m[0906 20-17-59 @MBExp.py:144][0m ####################################################################
[32m[0906 20-17-59 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 20-18-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17944, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-18-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17934, current rewards: -6.19364, mean: -0.10323
[32m[0906 20-18-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17930, current rewards: -0.31572, mean: -0.00287
[32m[0906 20-18-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17967, current rewards: 5.56709, mean: 0.03479
[32m[0906 20-18-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18056, current rewards: 11.44751, mean: 0.05451
[32m[0906 20-18-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18147, current rewards: 17.33211, mean: 0.06666
[32m[0906 20-18-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18209, current rewards: -2.40821, mean: -0.00777
[32m[0906 20-19-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18194, current rewards: 4.65253, mean: 0.01292
[32m[0906 20-19-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18163, current rewards: 11.08613, mean: 0.02704
[32m[0906 20-19-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18142, current rewards: 17.50574, mean: 0.03806
[32m[0906 20-19-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18098, current rewards: 23.93214, mean: 0.04693
[32m[0906 20-19-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18037, current rewards: 30.35852, mean: 0.05421
[32m[0906 20-19-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17967, current rewards: 36.77840, mean: 0.06029
[32m[0906 20-19-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17885, current rewards: 43.21025, mean: 0.06547
[32m[0906 20-20-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17813, current rewards: 49.39596, mean: 0.06957
[32m[0906 20-20-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17749, current rewards: 44.35395, mean: 0.05836
[32m[0906 20-20-22 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17691, current rewards: 48.86301, mean: 0.06032
[32m[0906 20-20-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17641, current rewards: 54.03773, mean: 0.06283
[32m[0906 20-20-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17605, current rewards: 59.21236, mean: 0.06507
[32m[0906 20-20-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17596, current rewards: 64.39038, mean: 0.06707
[32m[0906 20-20-56 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17586, current rewards: 69.56627, mean: 0.06888
[32m[0906 20-21-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17577, current rewards: 74.74191, mean: 0.07051
[32m[0906 20-21-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17595, current rewards: 79.93413, mean: 0.07201
[32m[0906 20-21-23 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17611, current rewards: 85.31252, mean: 0.07355
[32m[0906 20-21-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17648, current rewards: 90.49270, mean: 0.07479
[32m[0906 20-21-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17682, current rewards: 95.68078, mean: 0.07594
[32m[0906 20-21-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17707, current rewards: 100.86918, mean: 0.07700
[32m[0906 20-22-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17735, current rewards: 89.85619, mean: 0.06607
[32m[0906 20-22-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17764, current rewards: 87.36580, mean: 0.06196
[32m[0906 20-22-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17788, current rewards: 93.28968, mean: 0.06390
[32m[0906 20-22-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17809, current rewards: 99.21225, mean: 0.06570
[32m[0906 20-22-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17830, current rewards: 105.13366, mean: 0.06739
[32m[0906 20-22-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17846, current rewards: 111.05564, mean: 0.06898
[32m[0906 20-22-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17863, current rewards: 116.97229, mean: 0.07047
[32m[0906 20-23-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17879, current rewards: 122.88747, mean: 0.07186
[32m[0906 20-23-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17893, current rewards: 128.81102, mean: 0.07319
[32m[0906 20-23-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17907, current rewards: 134.73395, mean: 0.07444
[32m[0906 20-23-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17921, current rewards: 140.65175, mean: 0.07562
[32m[0906 20-23-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17934, current rewards: 146.56837, mean: 0.07674
[32m[0906 20-23-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17946, current rewards: 153.97416, mean: 0.07856
[32m[0906 20-24-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17955, current rewards: 159.55119, mean: 0.07938
[32m[0906 20-24-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17968, current rewards: 165.13769, mean: 0.08016
[32m[0906 20-24-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17977, current rewards: 171.08425, mean: 0.08108
[32m[0906 20-24-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17985, current rewards: 178.54695, mean: 0.08266
[32m[0906 20-24-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17994, current rewards: 186.06641, mean: 0.08419
[32m[0906 20-24-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18002, current rewards: 193.57681, mean: 0.08565
[32m[0906 20-24-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18011, current rewards: 201.09183, mean: 0.08705
[32m[0906 20-25-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18018, current rewards: 209.83286, mean: 0.08891
[32m[0906 20-25-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18025, current rewards: 218.20990, mean: 0.09054
[32m[0906 20-25-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18032, current rewards: 226.56161, mean: 0.09210
[32m[0906 20-25-30 @Agent.py:117][0m Average action selection time: 0.1804
[32m[0906 20-25-30 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-25-30 @MBExp.py:227][0m Rewards obtained: [233.24576389281341], Lows: [22], Highs: [30], Total time: 21901.909662000002
[32m[0906 20-27-11 @MBExp.py:144][0m ####################################################################
[32m[0906 20-27-11 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 20-27-13 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18008, current rewards: 1.20711, mean: 0.12071
[32m[0906 20-27-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17973, current rewards: 6.71444, mean: 0.11191
[32m[0906 20-27-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17975, current rewards: 13.57125, mean: 0.12338
[32m[0906 20-27-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17954, current rewards: 20.42760, mean: 0.12767
[32m[0906 20-27-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18020, current rewards: 27.28094, mean: 0.12991
[32m[0906 20-27-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18110, current rewards: 34.13014, mean: 0.13127
[32m[0906 20-28-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18161, current rewards: 40.52257, mean: 0.13072
[32m[0906 20-28-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18174, current rewards: 47.33345, mean: 0.13148
[32m[0906 20-28-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18158, current rewards: 54.14059, mean: 0.13205
[32m[0906 20-28-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18133, current rewards: 60.94927, mean: 0.13250
[32m[0906 20-28-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18101, current rewards: 67.75439, mean: 0.13285
[32m[0906 20-28-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18037, current rewards: 74.55765, mean: 0.13314
[32m[0906 20-29-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17978, current rewards: 81.36502, mean: 0.13339
[32m[0906 20-29-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17897, current rewards: 77.43567, mean: 0.11733
[32m[0906 20-29-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17825, current rewards: 88.59948, mean: 0.12479
[32m[0906 20-29-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17759, current rewards: 96.37788, mean: 0.12681
[32m[0906 20-29-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17703, current rewards: 104.13924, mean: 0.12857
[32m[0906 20-29-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17650, current rewards: 111.91259, mean: 0.13013
[32m[0906 20-29-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17608, current rewards: 119.67466, mean: 0.13151
[32m[0906 20-30-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17596, current rewards: 127.44851, mean: 0.13276
[32m[0906 20-30-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17588, current rewards: 112.82421, mean: 0.11171
[32m[0906 20-30-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17579, current rewards: 116.22035, mean: 0.10964
[32m[0906 20-30-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17593, current rewards: 119.45566, mean: 0.10762
[32m[0906 20-30-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17611, current rewards: 122.73256, mean: 0.10580
[32m[0906 20-30-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17635, current rewards: 126.02276, mean: 0.10415
[32m[0906 20-30-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17670, current rewards: 108.92493, mean: 0.08645
[32m[0906 20-31-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17701, current rewards: 117.00600, mean: 0.08932
[32m[0906 20-31-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17729, current rewards: 125.00637, mean: 0.09192
[32m[0906 20-31-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17755, current rewards: 133.01200, mean: 0.09433
[32m[0906 20-31-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17780, current rewards: 141.02132, mean: 0.09659
[32m[0906 20-31-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17803, current rewards: 148.78667, mean: 0.09853
[32m[0906 20-31-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17822, current rewards: 156.77375, mean: 0.10050
[32m[0906 20-31-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17842, current rewards: 164.74382, mean: 0.10233
[32m[0906 20-32-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17859, current rewards: 151.30207, mean: 0.09115
[32m[0906 20-32-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17875, current rewards: 159.61481, mean: 0.09334
[32m[0906 20-32-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17893, current rewards: 167.80268, mean: 0.09534
[32m[0906 20-32-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17910, current rewards: 175.98626, mean: 0.09723
[32m[0906 20-32-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17924, current rewards: 184.17934, mean: 0.09902
[32m[0906 20-32-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17938, current rewards: 191.88069, mean: 0.10046
[32m[0906 20-33-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17951, current rewards: 198.72842, mean: 0.10139
[32m[0906 20-33-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17962, current rewards: 194.72618, mean: 0.09688
[32m[0906 20-33-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17974, current rewards: 200.36262, mean: 0.09726
[32m[0906 20-33-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17985, current rewards: 206.00364, mean: 0.09763
[32m[0906 20-33-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17996, current rewards: 211.64062, mean: 0.09798
[32m[0906 20-33-50 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18004, current rewards: 217.28593, mean: 0.09832
[32m[0906 20-33-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18014, current rewards: 222.91828, mean: 0.09864
[32m[0906 20-34-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18022, current rewards: 228.54789, mean: 0.09894
[32m[0906 20-34-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18029, current rewards: 238.26389, mean: 0.10096
[32m[0906 20-34-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18036, current rewards: 244.34519, mean: 0.10139
[32m[0906 20-34-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18047, current rewards: 250.39535, mean: 0.10179
[32m[0906 20-34-43 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0906 20-34-43 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-34-43 @MBExp.py:227][0m Rewards obtained: [255.23377227623251], Lows: [30], Highs: [20], Total time: 22353.976012000003
[32m[0906 20-36-27 @MBExp.py:144][0m ####################################################################
[32m[0906 20-36-27 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 20-36-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18032, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-36-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18075, current rewards: -12.59046, mean: -0.20984
[32m[0906 20-36-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18072, current rewards: -6.40045, mean: -0.05819
[32m[0906 20-36-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18042, current rewards: -0.21085, mean: -0.00132
[32m[0906 20-37-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18058, current rewards: 5.97535, mean: 0.02845
[32m[0906 20-37-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18147, current rewards: 12.16527, mean: 0.04679
[32m[0906 20-37-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18186, current rewards: -2.85918, mean: -0.00922
[32m[0906 20-37-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18193, current rewards: 3.95161, mean: 0.01098
[32m[0906 20-37-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18163, current rewards: 10.74995, mean: 0.02622
[32m[0906 20-37-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18140, current rewards: 17.55434, mean: 0.03816
[32m[0906 20-37-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18114, current rewards: 24.36174, mean: 0.04777
[32m[0906 20-38-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18047, current rewards: 31.17064, mean: 0.05566
[32m[0906 20-38-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17995, current rewards: 37.97352, mean: 0.06225
[32m[0906 20-38-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17903, current rewards: 44.78284, mean: 0.06785
[32m[0906 20-38-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17828, current rewards: 50.78022, mean: 0.07152
[32m[0906 20-38-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17768, current rewards: 51.18710, mean: 0.06735
[32m[0906 20-38-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17714, current rewards: 42.39295, mean: 0.05234
[32m[0906 20-38-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17663, current rewards: 48.23968, mean: 0.05609
[32m[0906 20-39-07 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17618, current rewards: 54.08433, mean: 0.05943
[32m[0906 20-39-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17589, current rewards: 59.93296, mean: 0.06243
[32m[0906 20-39-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17579, current rewards: 65.78001, mean: 0.06513
[32m[0906 20-39-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17572, current rewards: 71.62962, mean: 0.06758
[32m[0906 20-39-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17572, current rewards: 81.37460, mean: 0.07331
[32m[0906 20-39-51 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17592, current rewards: 87.61826, mean: 0.07553
[32m[0906 20-40-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17612, current rewards: 93.77421, mean: 0.07750
[32m[0906 20-40-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17650, current rewards: 99.93012, mean: 0.07931
[32m[0906 20-40-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17684, current rewards: 92.15917, mean: 0.07035
[32m[0906 20-40-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17713, current rewards: 97.95229, mean: 0.07202
[32m[0906 20-40-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17741, current rewards: 103.76600, mean: 0.07359
[32m[0906 20-40-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17767, current rewards: 109.58370, mean: 0.07506
[32m[0906 20-40-56 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17795, current rewards: 115.31219, mean: 0.07637
[32m[0906 20-41-05 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17816, current rewards: 120.05727, mean: 0.07696
[32m[0906 20-41-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17835, current rewards: 125.81175, mean: 0.07814
[32m[0906 20-41-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17854, current rewards: 131.56218, mean: 0.07925
[32m[0906 20-41-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17869, current rewards: 137.32077, mean: 0.08030
[32m[0906 20-41-42 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17884, current rewards: 143.07958, mean: 0.08130
[32m[0906 20-41-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17900, current rewards: 148.81810, mean: 0.08222
[32m[0906 20-42-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17912, current rewards: 154.56520, mean: 0.08310
[32m[0906 20-42-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18005, current rewards: 160.31566, mean: 0.08393
[32m[0906 20-42-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18020, current rewards: 146.25081, mean: 0.07462
[32m[0906 20-42-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18030, current rewards: 152.09956, mean: 0.07567
[32m[0906 20-42-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18038, current rewards: 158.22658, mean: 0.07681
[32m[0906 20-42-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18047, current rewards: 164.34738, mean: 0.07789
[32m[0906 20-42-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18054, current rewards: 170.46485, mean: 0.07892
[32m[0906 20-43-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18062, current rewards: 176.58167, mean: 0.07990
[32m[0906 20-43-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18069, current rewards: 182.70095, mean: 0.08084
[32m[0906 20-43-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18075, current rewards: 188.81873, mean: 0.08174
[32m[0906 20-43-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18082, current rewards: 194.40057, mean: 0.08237
[32m[0906 20-43-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18090, current rewards: 200.42478, mean: 0.08316
[32m[0906 20-43-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18096, current rewards: 206.43312, mean: 0.08392
[32m[0906 20-44-00 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0906 20-44-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-44-00 @MBExp.py:227][0m Rewards obtained: [211.2363520819292], Lows: [30], Highs: [31], Total time: 22807.195136000002
[32m[0906 20-45-45 @MBExp.py:144][0m ####################################################################
[32m[0906 20-45-45 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 20-45-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17991, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-45-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17966, current rewards: -4.72160, mean: -0.07869
[32m[0906 20-46-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17957, current rewards: 0.30291, mean: 0.00275
[32m[0906 20-46-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17942, current rewards: 5.32635, mean: 0.03329
[32m[0906 20-46-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17939, current rewards: 10.34766, mean: 0.04927
[32m[0906 20-46-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18038, current rewards: 15.36986, mean: 0.05911
[32m[0906 20-46-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18101, current rewards: 21.70535, mean: 0.07002
[32m[0906 20-46-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18154, current rewards: 27.57043, mean: 0.07658
[32m[0906 20-47-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18129, current rewards: 13.86914, mean: 0.03383
[32m[0906 20-47-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18111, current rewards: 19.59627, mean: 0.04260
[32m[0906 20-47-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18094, current rewards: 25.34583, mean: 0.04970
[32m[0906 20-47-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18036, current rewards: 31.09234, mean: 0.05552
[32m[0906 20-47-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17982, current rewards: 36.83688, mean: 0.06039
[32m[0906 20-47-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17899, current rewards: 42.58733, mean: 0.06453
[32m[0906 20-47-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17825, current rewards: 48.12521, mean: 0.06778
[32m[0906 20-48-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17758, current rewards: 43.21700, mean: 0.05686
[32m[0906 20-48-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17701, current rewards: 50.13499, mean: 0.06190
[32m[0906 20-48-17 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17651, current rewards: 56.93129, mean: 0.06620
[32m[0906 20-48-26 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17602, current rewards: 63.72450, mean: 0.07003
[32m[0906 20-48-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17563, current rewards: 70.51113, mean: 0.07345
[32m[0906 20-48-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17550, current rewards: 77.31151, mean: 0.07655
[32m[0906 20-48-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17545, current rewards: 84.11397, mean: 0.07935
[32m[0906 20-49-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17536, current rewards: 90.90150, mean: 0.08189
[32m[0906 20-49-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17550, current rewards: 97.69959, mean: 0.08422
[32m[0906 20-49-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17566, current rewards: 80.11020, mean: 0.06621
[32m[0906 20-49-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17600, current rewards: 86.42562, mean: 0.06859
[32m[0906 20-49-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17631, current rewards: 92.74105, mean: 0.07079
[32m[0906 20-49-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17663, current rewards: 99.05647, mean: 0.07284
[32m[0906 20-49-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17694, current rewards: 105.37190, mean: 0.07473
[32m[0906 20-50-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17724, current rewards: 111.68732, mean: 0.07650
[32m[0906 20-50-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17748, current rewards: 117.78012, mean: 0.07800
[32m[0906 20-50-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17769, current rewards: 123.69799, mean: 0.07929
[32m[0906 20-50-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17788, current rewards: 129.61587, mean: 0.08051
[32m[0906 20-50-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17809, current rewards: 112.04823, mean: 0.06750
[32m[0906 20-50-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17826, current rewards: 62.04823, mean: 0.03629
[32m[0906 20-51-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17844, current rewards: 12.04823, mean: 0.00685
[32m[0906 20-51-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17858, current rewards: -37.95177, mean: -0.02097
[32m[0906 20-51-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17873, current rewards: -87.95177, mean: -0.04729
[32m[0906 20-51-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17887, current rewards: -137.95177, mean: -0.07223
[32m[0906 20-51-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17900, current rewards: -187.95177, mean: -0.09589
[32m[0906 20-51-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17910, current rewards: -237.95177, mean: -0.11838
[32m[0906 20-51-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17920, current rewards: -287.95177, mean: -0.13978
[32m[0906 20-52-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17935, current rewards: -337.95177, mean: -0.16017
[32m[0906 20-52-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17945, current rewards: -387.95177, mean: -0.17961
[32m[0906 20-52-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17954, current rewards: -437.95177, mean: -0.19817
[32m[0906 20-52-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17964, current rewards: -487.95177, mean: -0.21591
[32m[0906 20-52-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17971, current rewards: -537.95177, mean: -0.23288
[32m[0906 20-52-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17979, current rewards: -587.95177, mean: -0.24913
[32m[0906 20-52-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17987, current rewards: -637.95177, mean: -0.26471
[32m[0906 20-53-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17996, current rewards: -687.95177, mean: -0.27966
[32m[0906 20-53-16 @Agent.py:117][0m Average action selection time: 0.1800
[32m[0906 20-53-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-53-16 @MBExp.py:227][0m Rewards obtained: [-727.9517654482279], Lows: [17], Highs: [891], Total time: 23257.962833
[32m[0906 20-55-03 @MBExp.py:144][0m ####################################################################
[32m[0906 20-55-03 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 20-55-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17695, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-55-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17879, current rewards: -5.16408, mean: -0.08607
[32m[0906 20-55-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17877, current rewards: 0.29780, mean: 0.00271
[32m[0906 20-55-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17892, current rewards: 5.75236, mean: 0.03595
[32m[0906 20-55-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17905, current rewards: 11.20849, mean: 0.05337
[32m[0906 20-55-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17987, current rewards: 15.94218, mean: 0.06132
[32m[0906 20-56-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18053, current rewards: 21.29484, mean: 0.06869
[32m[0906 20-56-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18100, current rewards: 26.64573, mean: 0.07402
[32m[0906 20-56-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18101, current rewards: 31.99491, mean: 0.07804
[32m[0906 20-56-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18086, current rewards: 37.34115, mean: 0.08118
[32m[0906 20-56-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18064, current rewards: 42.68594, mean: 0.08370
[32m[0906 20-56-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18019, current rewards: 48.02803, mean: 0.08576
[32m[0906 20-56-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17964, current rewards: 53.37198, mean: 0.08750
[32m[0906 20-57-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17886, current rewards: 58.85585, mean: 0.08918
[32m[0906 20-57-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17810, current rewards: 45.29372, mean: 0.06379
[32m[0906 20-57-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17744, current rewards: 50.61571, mean: 0.06660
[32m[0906 20-57-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17687, current rewards: 55.93022, mean: 0.06905
[32m[0906 20-57-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17634, current rewards: 61.24558, mean: 0.07122
[32m[0906 20-57-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17593, current rewards: 66.57109, mean: 0.07316
[32m[0906 20-57-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17558, current rewards: 71.89387, mean: 0.07489
[32m[0906 20-58-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17536, current rewards: 77.21904, mean: 0.07645
[32m[0906 20-58-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17528, current rewards: 82.66631, mean: 0.07799
[32m[0906 20-58-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17523, current rewards: 87.99014, mean: 0.07927
[32m[0906 20-58-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17527, current rewards: 92.17920, mean: 0.07946
[32m[0906 20-58-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17544, current rewards: 78.30881, mean: 0.06472
[32m[0906 20-58-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17570, current rewards: 83.76139, mean: 0.06648
[32m[0906 20-58-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17605, current rewards: 89.21764, mean: 0.06811
[32m[0906 20-59-04 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17636, current rewards: 94.67021, mean: 0.06961
[32m[0906 20-59-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17665, current rewards: 88.77573, mean: 0.06296
[32m[0906 20-59-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17690, current rewards: 87.50024, mean: 0.05993
[32m[0906 20-59-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17715, current rewards: 91.79911, mean: 0.06079
[32m[0906 20-59-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17737, current rewards: 96.39477, mean: 0.06179
[32m[0906 20-59-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17756, current rewards: 100.99082, mean: 0.06273
[32m[0906 20-59-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17777, current rewards: 105.58803, mean: 0.06361
[32m[0906 21-00-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17795, current rewards: 110.18388, mean: 0.06444
[32m[0906 21-00-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17813, current rewards: 114.77882, mean: 0.06522
[32m[0906 21-00-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17835, current rewards: 119.37746, mean: 0.06595
[32m[0906 21-00-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17850, current rewards: 123.97210, mean: 0.06665
[32m[0906 21-00-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17865, current rewards: 132.19984, mean: 0.06921
[32m[0906 21-00-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17876, current rewards: 141.60568, mean: 0.07225
[32m[0906 21-01-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17889, current rewards: 150.97419, mean: 0.07511
[32m[0906 21-01-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17900, current rewards: 160.31214, mean: 0.07782
[32m[0906 21-01-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17911, current rewards: 141.83580, mean: 0.06722
[32m[0906 21-01-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17922, current rewards: 147.72689, mean: 0.06839
[32m[0906 21-01-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17933, current rewards: 153.35813, mean: 0.06939
[32m[0906 21-01-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17942, current rewards: 158.98669, mean: 0.07035
[32m[0906 21-01-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17951, current rewards: 165.45612, mean: 0.07163
[32m[0906 21-02-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17962, current rewards: 171.01692, mean: 0.07246
[32m[0906 21-02-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17970, current rewards: 162.05892, mean: 0.06724
[32m[0906 21-02-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17979, current rewards: 166.94237, mean: 0.06786
[32m[0906 21-02-34 @Agent.py:117][0m Average action selection time: 0.1799
[32m[0906 21-02-34 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-02-34 @MBExp.py:227][0m Rewards obtained: [171.31541462422138], Lows: [28], Highs: [50], Total time: 23708.356736
[32m[0906 21-04-23 @MBExp.py:144][0m ####################################################################
[32m[0906 21-04-23 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 21-04-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19021, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-04-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19078, current rewards: -45.59846, mean: -0.75997
[32m[0906 21-04-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18943, current rewards: -101.56088, mean: -0.92328
[32m[0906 21-04-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18884, current rewards: -162.03834, mean: -1.01274
[32m[0906 21-05-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18811, current rewards: -232.86400, mean: -1.10888
[32m[0906 21-05-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18717, current rewards: -255.21292, mean: -0.98159
[32m[0906 21-05-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18668, current rewards: -243.74778, mean: -0.78628
[32m[0906 21-05-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18625, current rewards: -233.72864, mean: -0.64925
[32m[0906 21-05-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18549, current rewards: -223.66577, mean: -0.54553
[32m[0906 21-05-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18478, current rewards: -213.56814, mean: -0.46428
[32m[0906 21-05-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18419, current rewards: -203.50426, mean: -0.39903
[32m[0906 21-06-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18337, current rewards: -193.44028, mean: -0.34543
[32m[0906 21-06-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18258, current rewards: -183.39654, mean: -0.30065
[32m[0906 21-06-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18200, current rewards: -227.19910, mean: -0.34424
[32m[0906 21-06-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18116, current rewards: -285.97809, mean: -0.40279
[32m[0906 21-06-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18030, current rewards: -295.19037, mean: -0.38841
[32m[0906 21-06-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17958, current rewards: -289.37539, mean: -0.35725
[32m[0906 21-06-58 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17893, current rewards: -283.56194, mean: -0.32972
[32m[0906 21-07-06 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17833, current rewards: -277.75007, mean: -0.30522
[32m[0906 21-07-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17780, current rewards: -271.93294, mean: -0.28326
[32m[0906 21-07-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17735, current rewards: -266.11700, mean: -0.26348
[32m[0906 21-07-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17719, current rewards: -260.30199, mean: -0.24557
[32m[0906 21-07-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17704, current rewards: -275.26191, mean: -0.24798
[32m[0906 21-07-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17692, current rewards: -269.42800, mean: -0.23227
[32m[0906 21-07-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17702, current rewards: -263.59363, mean: -0.21785
[32m[0906 21-08-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17720, current rewards: -257.76082, mean: -0.20457
[32m[0906 21-08-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17749, current rewards: -251.92503, mean: -0.19231
[32m[0906 21-08-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17772, current rewards: -246.08767, mean: -0.18095
[32m[0906 21-08-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17795, current rewards: -240.25319, mean: -0.17039
[32m[0906 21-08-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17815, current rewards: -232.18842, mean: -0.15903
[32m[0906 21-08-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17840, current rewards: -268.63830, mean: -0.17791
[32m[0906 21-09-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17858, current rewards: -318.63830, mean: -0.20426
[32m[0906 21-09-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17876, current rewards: -368.63830, mean: -0.22897
[32m[0906 21-09-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17891, current rewards: -418.63830, mean: -0.25219
[32m[0906 21-09-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17904, current rewards: -468.63830, mean: -0.27406
[32m[0906 21-09-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17918, current rewards: -518.63830, mean: -0.29468
[32m[0906 21-09-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17931, current rewards: -568.63830, mean: -0.31416
[32m[0906 21-09-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17943, current rewards: -618.63830, mean: -0.33260
[32m[0906 21-10-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17954, current rewards: -668.63830, mean: -0.35007
[32m[0906 21-10-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17965, current rewards: -718.63830, mean: -0.36665
[32m[0906 21-10-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17977, current rewards: -768.63830, mean: -0.38241
[32m[0906 21-10-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17987, current rewards: -818.63830, mean: -0.39740
[32m[0906 21-10-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17995, current rewards: -868.63830, mean: -0.41168
[32m[0906 21-10-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18003, current rewards: -918.63830, mean: -0.42530
[32m[0906 21-11-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18013, current rewards: -968.63830, mean: -0.43830
[32m[0906 21-11-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18020, current rewards: -1018.63830, mean: -0.45072
[32m[0906 21-11-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18027, current rewards: -1068.63830, mean: -0.46261
[32m[0906 21-11-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18033, current rewards: -1118.63830, mean: -0.47400
[32m[0906 21-11-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18038, current rewards: -1168.63830, mean: -0.48491
[32m[0906 21-11-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18043, current rewards: -1218.63830, mean: -0.49538
[32m[0906 21-11-55 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0906 21-11-55 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-11-55 @MBExp.py:227][0m Rewards obtained: [-1258.638303309697], Lows: [205], Highs: [1048], Total time: 24160.298858000002
[32m[0906 21-13-47 @MBExp.py:144][0m ####################################################################
[32m[0906 21-13-47 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 21-13-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17856, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-13-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17910, current rewards: -4.52012, mean: -0.07534
[32m[0906 21-14-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17917, current rewards: 1.10810, mean: 0.01007
[32m[0906 21-14-16 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17920, current rewards: 6.73699, mean: 0.04211
[32m[0906 21-14-25 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17928, current rewards: 12.80526, mean: 0.06098
[32m[0906 21-14-34 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18001, current rewards: 18.43599, mean: 0.07091
[32m[0906 21-14-43 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18077, current rewards: 24.06034, mean: 0.07761
[32m[0906 21-14-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18122, current rewards: 21.17088, mean: 0.05881
[32m[0906 21-15-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18116, current rewards: 29.60858, mean: 0.07222
[32m[0906 21-15-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18106, current rewards: 37.46214, mean: 0.08144
[32m[0906 21-15-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18086, current rewards: 45.29976, mean: 0.08882
[32m[0906 21-15-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18041, current rewards: 28.20665, mean: 0.05037
[32m[0906 21-15-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17986, current rewards: 32.95973, mean: 0.05403
[32m[0906 21-15-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17909, current rewards: 38.34367, mean: 0.05810
[32m[0906 21-15-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17834, current rewards: 43.63478, mean: 0.06146
[32m[0906 21-16-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17769, current rewards: 48.92555, mean: 0.06438
[32m[0906 21-16-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17712, current rewards: 54.21782, mean: 0.06694
[32m[0906 21-16-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17658, current rewards: 59.50612, mean: 0.06919
[32m[0906 21-16-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17614, current rewards: 64.79626, mean: 0.07120
[32m[0906 21-16-36 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17574, current rewards: 70.08268, mean: 0.07300
[32m[0906 21-16-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17539, current rewards: 64.83602, mean: 0.06419
[32m[0906 21-16-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17524, current rewards: 53.40582, mean: 0.05038
[32m[0906 21-17-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17519, current rewards: 58.99835, mean: 0.05315
[32m[0906 21-17-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17516, current rewards: 64.59014, mean: 0.05568
[32m[0906 21-17-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17530, current rewards: 70.18438, mean: 0.05800
[32m[0906 21-17-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17548, current rewards: 75.78201, mean: 0.06014
[32m[0906 21-17-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17582, current rewards: 81.37913, mean: 0.06212
[32m[0906 21-17-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17615, current rewards: 86.97526, mean: 0.06395
[32m[0906 21-17-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17644, current rewards: 92.56740, mean: 0.06565
[32m[0906 21-18-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17670, current rewards: 87.48016, mean: 0.05992
[32m[0906 21-18-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17699, current rewards: 94.57298, mean: 0.06263
[32m[0906 21-18-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17721, current rewards: 101.21218, mean: 0.06488
[32m[0906 21-18-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17741, current rewards: 107.84590, mean: 0.06699
[32m[0906 21-18-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17760, current rewards: 87.60682, mean: 0.05278
[32m[0906 21-18-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17780, current rewards: 95.68110, mean: 0.05595
[32m[0906 21-19-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17799, current rewards: 103.75539, mean: 0.05895
[32m[0906 21-19-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17813, current rewards: 111.82968, mean: 0.06178
[32m[0906 21-19-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17835, current rewards: 119.14655, mean: 0.06406
[32m[0906 21-19-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17850, current rewards: 125.19182, mean: 0.06555
[32m[0906 21-19-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17865, current rewards: 131.23708, mean: 0.06696
[32m[0906 21-19-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17877, current rewards: 90.20433, mean: 0.04488
[32m[0906 21-19-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17889, current rewards: 40.20433, mean: 0.01952
[32m[0906 21-20-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17901, current rewards: -9.79567, mean: -0.00464
[32m[0906 21-20-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17913, current rewards: -59.79567, mean: -0.02768
[32m[0906 21-20-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17924, current rewards: -109.79567, mean: -0.04968
[32m[0906 21-20-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17936, current rewards: -159.79567, mean: -0.07071
[32m[0906 21-20-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17946, current rewards: -209.79567, mean: -0.09082
[32m[0906 21-20-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17956, current rewards: -259.79567, mean: -0.11008
[32m[0906 21-21-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17965, current rewards: -309.79567, mean: -0.12855
[32m[0906 21-21-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17973, current rewards: -359.79567, mean: -0.14626
[32m[0906 21-21-17 @Agent.py:117][0m Average action selection time: 0.1798
[32m[0906 21-21-17 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-21-17 @MBExp.py:227][0m Rewards obtained: [-399.79567497702425], Lows: [35], Highs: [567], Total time: 24610.529270000003
[32m[0906 21-23-11 @MBExp.py:144][0m ####################################################################
[32m[0906 21-23-11 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 21-23-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17808, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-23-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17931, current rewards: -5.61796, mean: -0.09363
[32m[0906 21-23-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17990, current rewards: -1.00507, mean: -0.00914
[32m[0906 21-23-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17989, current rewards: 3.59740, mean: 0.02248
[32m[0906 21-23-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17962, current rewards: 8.19526, mean: 0.03903
[32m[0906 21-23-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17984, current rewards: -9.39966, mean: -0.03615
[32m[0906 21-24-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18060, current rewards: -2.15681, mean: -0.00696
[32m[0906 21-24-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18109, current rewards: 4.60723, mean: 0.01280
[32m[0906 21-24-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18124, current rewards: 11.37126, mean: 0.02773
[32m[0906 21-24-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18104, current rewards: -26.14065, mean: -0.05683
[32m[0906 21-24-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18086, current rewards: -76.14065, mean: -0.14930
[32m[0906 21-24-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18050, current rewards: -126.14065, mean: -0.22525
[32m[0906 21-25-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17991, current rewards: -176.14065, mean: -0.28876
[32m[0906 21-25-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17916, current rewards: -226.14065, mean: -0.34264
[32m[0906 21-25-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17839, current rewards: -276.14065, mean: -0.38893
[32m[0906 21-25-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17769, current rewards: -326.14065, mean: -0.42913
[32m[0906 21-25-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17710, current rewards: -376.14065, mean: -0.46437
[32m[0906 21-25-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17661, current rewards: -426.14065, mean: -0.49551
[32m[0906 21-25-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17614, current rewards: -476.14065, mean: -0.52323
[32m[0906 21-26-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17570, current rewards: -526.14065, mean: -0.54806
[32m[0906 21-26-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17532, current rewards: -576.14065, mean: -0.57044
[32m[0906 21-26-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17500, current rewards: -626.14065, mean: -0.59070
[32m[0906 21-26-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17494, current rewards: -676.14065, mean: -0.60914
[32m[0906 21-26-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17486, current rewards: -726.14065, mean: -0.62598
[32m[0906 21-26-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17484, current rewards: -776.14065, mean: -0.64144
[32m[0906 21-26-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17500, current rewards: -826.14065, mean: -0.65567
[32m[0906 21-27-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17526, current rewards: -876.14065, mean: -0.66881
[32m[0906 21-27-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17562, current rewards: -926.14065, mean: -0.68099
[32m[0906 21-27-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17594, current rewards: -976.14065, mean: -0.69230
[32m[0906 21-27-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17620, current rewards: -1026.14065, mean: -0.70284
[32m[0906 21-27-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17650, current rewards: -1076.14065, mean: -0.71268
[32m[0906 21-27-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17678, current rewards: -1126.14065, mean: -0.72189
[32m[0906 21-27-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17700, current rewards: -1176.14065, mean: -0.73052
[32m[0906 21-28-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17719, current rewards: -1226.14065, mean: -0.73864
[32m[0906 21-28-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17738, current rewards: -1276.14065, mean: -0.74628
[32m[0906 21-28-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17759, current rewards: -1326.14065, mean: -0.75349
[32m[0906 21-28-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17776, current rewards: -1376.14065, mean: -0.76030
[32m[0906 21-28-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17790, current rewards: -1426.14065, mean: -0.76674
[32m[0906 21-28-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17804, current rewards: -1476.14065, mean: -0.77285
[32m[0906 21-29-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17820, current rewards: -1526.14065, mean: -0.77864
[32m[0906 21-29-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17835, current rewards: -1523.02257, mean: -0.75772
[32m[0906 21-29-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17848, current rewards: -1519.90450, mean: -0.73782
[32m[0906 21-29-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17864, current rewards: -1516.78643, mean: -0.71886
[32m[0906 21-29-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17876, current rewards: -1513.66835, mean: -0.70077
[32m[0906 21-29-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17888, current rewards: -1510.55028, mean: -0.68351
[32m[0906 21-29-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17901, current rewards: -1507.69892, mean: -0.66712
[32m[0906 21-30-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17912, current rewards: -1505.11170, mean: -0.65156
[32m[0906 21-30-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17922, current rewards: -1502.52448, mean: -0.63666
[32m[0906 21-30-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17932, current rewards: -1499.93725, mean: -0.62238
[32m[0906 21-30-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17939, current rewards: -1513.12619, mean: -0.61509
[32m[0906 21-30-40 @Agent.py:117][0m Average action selection time: 0.1795
[32m[0906 21-30-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-30-40 @MBExp.py:227][0m Rewards obtained: [-1553.1261936006636], Lows: [11], Highs: [1604], Total time: 25059.885341
[32m[0906 21-32-36 @MBExp.py:144][0m ####################################################################
[32m[0906 21-32-36 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 21-32-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17783, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-32-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17852, current rewards: -10.16060, mean: -0.16934
[32m[0906 21-32-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17876, current rewards: -3.36130, mean: -0.03056
[32m[0906 21-33-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17871, current rewards: 3.44535, mean: 0.02153
[32m[0906 21-33-13 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17868, current rewards: 10.47624, mean: 0.04989
[32m[0906 21-33-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17884, current rewards: 17.25022, mean: 0.06635
[32m[0906 21-33-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17978, current rewards: 24.01759, mean: 0.07748
[32m[0906 21-33-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18039, current rewards: 30.77865, mean: 0.08550
[32m[0906 21-33-50 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18080, current rewards: 37.54837, mean: 0.09158
[32m[0906 21-33-59 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18071, current rewards: 44.30942, mean: 0.09632
[32m[0906 21-34-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18061, current rewards: 51.07419, mean: 0.10015
[32m[0906 21-34-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18044, current rewards: 56.80081, mean: 0.10143
[32m[0906 21-34-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17986, current rewards: 64.99675, mean: 0.10655
[32m[0906 21-34-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17920, current rewards: 71.02444, mean: 0.10761
[32m[0906 21-34-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17837, current rewards: 77.05994, mean: 0.10854
[32m[0906 21-34-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17770, current rewards: 83.09354, mean: 0.10933
[32m[0906 21-34-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17710, current rewards: 89.11819, mean: 0.11002
[32m[0906 21-35-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17659, current rewards: 95.15037, mean: 0.11064
[32m[0906 21-35-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17609, current rewards: 101.18593, mean: 0.11119
[32m[0906 21-35-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17565, current rewards: 107.22170, mean: 0.11169
[32m[0906 21-35-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17527, current rewards: 106.59163, mean: 0.10554
[32m[0906 21-35-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17492, current rewards: 112.08793, mean: 0.10574
[32m[0906 21-35-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17477, current rewards: 117.58088, mean: 0.10593
[32m[0906 21-35-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17472, current rewards: 123.07446, mean: 0.10610
[32m[0906 21-36-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17471, current rewards: 128.56238, mean: 0.10625
[32m[0906 21-36-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17483, current rewards: 97.93901, mean: 0.07773
[32m[0906 21-36-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17503, current rewards: 107.55412, mean: 0.08210
[32m[0906 21-36-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17539, current rewards: 117.15526, mean: 0.08614
[32m[0906 21-36-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17572, current rewards: 126.75631, mean: 0.08990
[32m[0906 21-36-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17603, current rewards: 136.35444, mean: 0.09339
[32m[0906 21-37-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17630, current rewards: 135.22424, mean: 0.08955
[32m[0906 21-37-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17652, current rewards: 138.19522, mean: 0.08859
[32m[0906 21-37-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17676, current rewards: 143.43779, mean: 0.08909
[32m[0906 21-37-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17695, current rewards: 148.68393, mean: 0.08957
[32m[0906 21-37-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17717, current rewards: 153.93023, mean: 0.09002
[32m[0906 21-37-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17735, current rewards: 138.32287, mean: 0.07859
[32m[0906 21-37-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17754, current rewards: 144.71666, mean: 0.07995
[32m[0906 21-38-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17772, current rewards: 151.10856, mean: 0.08124
[32m[0906 21-38-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17792, current rewards: 157.50668, mean: 0.08246
[32m[0906 21-38-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17808, current rewards: 163.90182, mean: 0.08362
[32m[0906 21-38-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17823, current rewards: 170.29146, mean: 0.08472
[32m[0906 21-38-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17838, current rewards: 154.84933, mean: 0.07517
[32m[0906 21-38-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17851, current rewards: 160.82088, mean: 0.07622
[32m[0906 21-39-02 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17864, current rewards: 166.79754, mean: 0.07722
[32m[0906 21-39-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17875, current rewards: 172.51283, mean: 0.07806
[32m[0906 21-39-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17886, current rewards: 178.48327, mean: 0.07897
[32m[0906 21-39-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17896, current rewards: 184.48723, mean: 0.07986
[32m[0906 21-39-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17908, current rewards: 190.50108, mean: 0.08072
[32m[0906 21-39-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17918, current rewards: 184.95290, mean: 0.07674
[32m[0906 21-39-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17927, current rewards: 190.21853, mean: 0.07732
[32m[0906 21-40-05 @Agent.py:117][0m Average action selection time: 0.1794
[32m[0906 21-40-05 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-40-05 @MBExp.py:227][0m Rewards obtained: [194.42797148536047], Lows: [38], Highs: [46], Total time: 25508.991197
[32m[0906 21-42-02 @MBExp.py:144][0m ####################################################################
[32m[0906 21-42-02 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 21-42-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17911, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-42-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17953, current rewards: -6.16781, mean: -0.10280
[32m[0906 21-42-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17977, current rewards: -0.43688, mean: -0.00397
[32m[0906 21-42-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17984, current rewards: 5.29698, mean: 0.03311
[32m[0906 21-42-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17976, current rewards: 11.03494, mean: 0.05255
[32m[0906 21-42-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17969, current rewards: 16.77186, mean: 0.06451
[32m[0906 21-42-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18031, current rewards: 22.51289, mean: 0.07262
[32m[0906 21-43-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18075, current rewards: 28.25357, mean: 0.07848
[32m[0906 21-43-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18110, current rewards: 33.99499, mean: 0.08291
[32m[0906 21-43-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18139, current rewards: 39.73070, mean: 0.08637
[32m[0906 21-43-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18122, current rewards: 45.65670, mean: 0.08952
[32m[0906 21-43-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18100, current rewards: 52.42875, mean: 0.09362
[32m[0906 21-43-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18045, current rewards: 58.25986, mean: 0.09551
[32m[0906 21-44-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17980, current rewards: 64.09918, mean: 0.09712
[32m[0906 21-44-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17895, current rewards: 71.09430, mean: 0.10013
[32m[0906 21-44-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17825, current rewards: 76.88484, mean: 0.10116
[32m[0906 21-44-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17767, current rewards: 82.63345, mean: 0.10202
[32m[0906 21-44-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17714, current rewards: 88.38208, mean: 0.10277
[32m[0906 21-44-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17662, current rewards: 94.12001, mean: 0.10343
[32m[0906 21-44-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17617, current rewards: 99.73803, mean: 0.10389
[32m[0906 21-45-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17578, current rewards: 105.66890, mean: 0.10462
[32m[0906 21-45-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17543, current rewards: 111.59218, mean: 0.10528
[32m[0906 21-45-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17511, current rewards: 117.52044, mean: 0.10587
[32m[0906 21-45-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17484, current rewards: 123.43809, mean: 0.10641
[32m[0906 21-45-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17480, current rewards: 129.36963, mean: 0.10692
[32m[0906 21-45-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17485, current rewards: 114.48439, mean: 0.09086
[32m[0906 21-45-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17504, current rewards: 120.47389, mean: 0.09196
[32m[0906 21-46-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17534, current rewards: 130.15337, mean: 0.09570
[32m[0906 21-46-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17569, current rewards: 136.12026, mean: 0.09654
[32m[0906 21-46-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17598, current rewards: 142.08736, mean: 0.09732
[32m[0906 21-46-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17626, current rewards: 148.06035, mean: 0.09805
[32m[0906 21-46-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17655, current rewards: 154.04004, mean: 0.09874
[32m[0906 21-46-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17680, current rewards: 142.71429, mean: 0.08864
[32m[0906 21-46-57 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17702, current rewards: 155.19852, mean: 0.09349
[32m[0906 21-47-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17721, current rewards: 167.59757, mean: 0.09801
[32m[0906 21-47-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17741, current rewards: 178.88645, mean: 0.10164
[32m[0906 21-47-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17758, current rewards: 188.49057, mean: 0.10414
[32m[0906 21-47-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17775, current rewards: 199.27673, mean: 0.10714
[32m[0906 21-47-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17791, current rewards: 209.92453, mean: 0.10991
[32m[0906 21-47-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17807, current rewards: 220.51125, mean: 0.11251
[32m[0906 21-48-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17820, current rewards: 231.07518, mean: 0.11496
[32m[0906 21-48-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17834, current rewards: 241.59588, mean: 0.11728
[32m[0906 21-48-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17846, current rewards: 252.10585, mean: 0.11948
[32m[0906 21-48-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17858, current rewards: 262.56753, mean: 0.12156
[32m[0906 21-48-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17872, current rewards: 273.06157, mean: 0.12356
[32m[0906 21-48-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17885, current rewards: 283.57058, mean: 0.12547
[32m[0906 21-48-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17894, current rewards: 294.10026, mean: 0.12732
[32m[0906 21-49-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17902, current rewards: 301.68405, mean: 0.12783
[32m[0906 21-49-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17911, current rewards: 300.89497, mean: 0.12485
[32m[0906 21-49-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17921, current rewards: 301.20895, mean: 0.12244
[32m[0906 21-49-31 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0906 21-49-31 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-49-31 @MBExp.py:227][0m Rewards obtained: [300.55140155361147], Lows: [20], Highs: [26], Total time: 25957.973259
[32m[0906 21-51-31 @MBExp.py:144][0m ####################################################################
[32m[0906 21-51-31 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 21-51-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17753, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-51-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17864, current rewards: -4.95429, mean: -0.08257
[32m[0906 21-51-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17887, current rewards: 0.35052, mean: 0.00319
[32m[0906 21-52-00 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17883, current rewards: 5.65725, mean: 0.03536
[32m[0906 21-52-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17890, current rewards: 10.96400, mean: 0.05221
[32m[0906 21-52-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17895, current rewards: 16.26715, mean: 0.06257
[32m[0906 21-52-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17971, current rewards: 21.57000, mean: 0.06958
[32m[0906 21-52-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18037, current rewards: 6.04722, mean: 0.01680
[32m[0906 21-52-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18078, current rewards: 11.95621, mean: 0.02916
[32m[0906 21-52-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18119, current rewards: 17.84269, mean: 0.03879
[32m[0906 21-53-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18110, current rewards: 24.73268, mean: 0.04850
[32m[0906 21-53-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18088, current rewards: 30.43198, mean: 0.05434
[32m[0906 21-53-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18043, current rewards: 36.13669, mean: 0.05924
[32m[0906 21-53-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17987, current rewards: 41.84437, mean: 0.06340
[32m[0906 21-53-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17905, current rewards: 47.54496, mean: 0.06696
[32m[0906 21-53-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17834, current rewards: 53.24397, mean: 0.07006
[32m[0906 21-53-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17768, current rewards: 58.94062, mean: 0.07277
[32m[0906 21-54-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17712, current rewards: 64.64150, mean: 0.07516
[32m[0906 21-54-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17660, current rewards: 70.69660, mean: 0.07769
[32m[0906 21-54-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17616, current rewards: 65.51967, mean: 0.06825
[32m[0906 21-54-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17576, current rewards: 71.00560, mean: 0.07030
[32m[0906 21-54-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17541, current rewards: 76.49321, mean: 0.07216
[32m[0906 21-54-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17509, current rewards: 81.97680, mean: 0.07385
[32m[0906 21-54-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17480, current rewards: 87.46506, mean: 0.07540
[32m[0906 21-55-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17470, current rewards: 92.94949, mean: 0.07682
[32m[0906 21-55-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17465, current rewards: 98.44234, mean: 0.07813
[32m[0906 21-55-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17481, current rewards: 103.39459, mean: 0.07893
[32m[0906 21-55-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17501, current rewards: 108.89083, mean: 0.08007
[32m[0906 21-55-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17538, current rewards: 114.45439, mean: 0.08117
[32m[0906 21-55-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17568, current rewards: 120.01917, mean: 0.08220
[32m[0906 21-55-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17593, current rewards: 126.43851, mean: 0.08373
[32m[0906 21-56-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17619, current rewards: 131.44490, mean: 0.08426
[32m[0906 21-56-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17644, current rewards: 136.54032, mean: 0.08481
[32m[0906 21-56-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17664, current rewards: 141.63696, mean: 0.08532
[32m[0906 21-56-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17686, current rewards: 146.72700, mean: 0.08581
[32m[0906 21-56-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17707, current rewards: 154.17046, mean: 0.08760
[32m[0906 21-56-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17725, current rewards: 159.30889, mean: 0.08802
[32m[0906 21-57-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17745, current rewards: 164.45036, mean: 0.08841
[32m[0906 21-57-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17763, current rewards: 169.59024, mean: 0.08879
[32m[0906 21-57-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17778, current rewards: 174.72829, mean: 0.08915
[32m[0906 21-57-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17791, current rewards: 179.87031, mean: 0.08949
[32m[0906 21-57-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17805, current rewards: 165.23035, mean: 0.08021
[32m[0906 21-57-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17818, current rewards: 171.65319, mean: 0.08135
[32m[0906 21-57-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17831, current rewards: 178.53368, mean: 0.08265
[32m[0906 21-58-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17842, current rewards: 184.84911, mean: 0.08364
[32m[0906 21-58-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17852, current rewards: 191.16453, mean: 0.08459
[32m[0906 21-58-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17862, current rewards: 155.80654, mean: 0.06745
[32m[0906 21-58-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17873, current rewards: 105.80654, mean: 0.04483
[32m[0906 21-58-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17884, current rewards: 55.80654, mean: 0.02316
[32m[0906 21-58-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17894, current rewards: 5.80654, mean: 0.00236
[32m[0906 21-58-59 @Agent.py:117][0m Average action selection time: 0.1790
[32m[0906 21-58-59 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-58-59 @MBExp.py:227][0m Rewards obtained: [-34.19345902814635], Lows: [22], Highs: [247], Total time: 26406.207066
[32m[0906 22-01-01 @MBExp.py:144][0m ####################################################################
[32m[0906 22-01-01 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 22-01-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17891, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-01-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17984, current rewards: -9.78870, mean: -0.16315
[32m[0906 22-01-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18003, current rewards: -0.82221, mean: -0.00747
[32m[0906 22-01-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17979, current rewards: 5.19194, mean: 0.03245
[32m[0906 22-01-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17979, current rewards: 11.20783, mean: 0.05337
[32m[0906 22-01-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17957, current rewards: 17.21978, mean: 0.06623
[32m[0906 22-01-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17996, current rewards: 23.23289, mean: 0.07494
[32m[0906 22-02-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18048, current rewards: -3.54248, mean: -0.00984
[32m[0906 22-02-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18093, current rewards: 1.72587, mean: 0.00421
[32m[0906 22-02-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18120, current rewards: 6.99560, mean: 0.01521
[32m[0906 22-02-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18148, current rewards: 13.00579, mean: 0.02550
[32m[0906 22-02-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18127, current rewards: 18.29728, mean: 0.03267
[32m[0906 22-02-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18094, current rewards: 23.58630, mean: 0.03867
[32m[0906 22-03-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18039, current rewards: 28.86361, mean: 0.04373
[32m[0906 22-03-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17956, current rewards: 34.14337, mean: 0.04809
[32m[0906 22-03-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17878, current rewards: 39.42825, mean: 0.05188
[32m[0906 22-03-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17809, current rewards: 20.99917, mean: 0.02592
[32m[0906 22-03-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17748, current rewards: 26.67699, mean: 0.03102
[32m[0906 22-03-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17696, current rewards: 32.27884, mean: 0.03547
[32m[0906 22-03-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17650, current rewards: 37.93705, mean: 0.03952
[32m[0906 22-03-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17609, current rewards: 43.60702, mean: 0.04318
[32m[0906 22-04-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17571, current rewards: 49.26255, mean: 0.04647
[32m[0906 22-04-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17536, current rewards: 54.92381, mean: 0.04948
[32m[0906 22-04-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17506, current rewards: 59.30456, mean: 0.05112
[32m[0906 22-04-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17481, current rewards: 63.81833, mean: 0.05274
[32m[0906 22-04-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17477, current rewards: 68.33294, mean: 0.05423
[32m[0906 22-04-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17481, current rewards: 72.47429, mean: 0.05532
[32m[0906 22-04-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17500, current rewards: 77.03820, mean: 0.05665
[32m[0906 22-05-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17530, current rewards: 81.60383, mean: 0.05788
[32m[0906 22-05-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17560, current rewards: 69.43954, mean: 0.04756
[32m[0906 22-05-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17592, current rewards: 72.34613, mean: 0.04791
[32m[0906 22-05-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17621, current rewards: 78.84604, mean: 0.05054
[32m[0906 22-05-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17642, current rewards: 85.35697, mean: 0.05302
[32m[0906 22-05-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17667, current rewards: 91.85648, mean: 0.05534
[32m[0906 22-06-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17687, current rewards: 98.35940, mean: 0.05752
[32m[0906 22-06-13 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17705, current rewards: 104.86856, mean: 0.05958
[32m[0906 22-06-22 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17722, current rewards: 111.37432, mean: 0.06153
[32m[0906 22-06-31 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17743, current rewards: 117.88495, mean: 0.06338
[32m[0906 22-06-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17760, current rewards: 113.53173, mean: 0.05944
[32m[0906 22-06-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17778, current rewards: 119.16933, mean: 0.06080
[32m[0906 22-06-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17792, current rewards: 124.81846, mean: 0.06210
[32m[0906 22-07-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17808, current rewards: 130.46254, mean: 0.06333
[32m[0906 22-07-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17821, current rewards: 135.46127, mean: 0.06420
[32m[0906 22-07-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17835, current rewards: 140.92261, mean: 0.06524
[32m[0906 22-07-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17850, current rewards: 146.57513, mean: 0.06632
[32m[0906 22-07-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17863, current rewards: 152.23049, mean: 0.06736
[32m[0906 22-07-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17875, current rewards: 157.88913, mean: 0.06835
[32m[0906 22-08-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17888, current rewards: 163.54607, mean: 0.06930
[32m[0906 22-08-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17899, current rewards: 169.20403, mean: 0.07021
[32m[0906 22-08-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17910, current rewards: 174.85988, mean: 0.07108
[32m[0906 22-08-30 @Agent.py:117][0m Average action selection time: 0.1792
[32m[0906 22-08-30 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-08-30 @MBExp.py:227][0m Rewards obtained: [179.3825406130103], Lows: [34], Highs: [32], Total time: 26854.864781
[32m[0906 22-10-34 @MBExp.py:144][0m ####################################################################
[32m[0906 22-10-34 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 22-10-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18973, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-10-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18085, current rewards: -5.16531, mean: -0.08609
[32m[0906 22-10-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18011, current rewards: 0.78458, mean: 0.00713
[32m[0906 22-11-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17972, current rewards: 6.72699, mean: 0.04204
[32m[0906 22-11-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17958, current rewards: 12.67342, mean: 0.06035
[32m[0906 22-11-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17959, current rewards: 18.61846, mean: 0.07161
[32m[0906 22-11-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17968, current rewards: 24.56712, mean: 0.07925
[32m[0906 22-11-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18035, current rewards: 30.51152, mean: 0.08475
[32m[0906 22-11-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18086, current rewards: 36.45480, mean: 0.08891
[32m[0906 22-11-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18114, current rewards: 44.94924, mean: 0.09772
[32m[0906 22-12-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18134, current rewards: 50.96996, mean: 0.09994
[32m[0906 22-12-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18119, current rewards: 57.03306, mean: 0.10184
[32m[0906 22-12-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18091, current rewards: 63.10184, mean: 0.10345
[32m[0906 22-12-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18036, current rewards: 69.17193, mean: 0.10481
[32m[0906 22-12-41 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17958, current rewards: 54.26396, mean: 0.07643
[32m[0906 22-12-50 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17881, current rewards: 59.58686, mean: 0.07840
[32m[0906 22-12-58 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17815, current rewards: 64.89573, mean: 0.08012
[32m[0906 22-13-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17756, current rewards: 70.13724, mean: 0.08155
[32m[0906 22-13-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17705, current rewards: 64.21266, mean: 0.07056
[32m[0906 22-13-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17658, current rewards: 69.95288, mean: 0.07287
[32m[0906 22-13-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17616, current rewards: 75.69102, mean: 0.07494
[32m[0906 22-13-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17575, current rewards: 81.42862, mean: 0.07682
[32m[0906 22-13-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17541, current rewards: 87.17133, mean: 0.07853
[32m[0906 22-13-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17510, current rewards: 92.91221, mean: 0.08010
[32m[0906 22-14-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17482, current rewards: 98.64879, mean: 0.08153
[32m[0906 22-14-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17467, current rewards: 104.39113, mean: 0.08285
[32m[0906 22-14-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17463, current rewards: 112.65534, mean: 0.08600
[32m[0906 22-14-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17480, current rewards: 118.39160, mean: 0.08705
[32m[0906 22-14-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17503, current rewards: 124.16198, mean: 0.08806
[32m[0906 22-14-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17536, current rewards: 129.92510, mean: 0.08899
[32m[0906 22-14-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17563, current rewards: 135.68959, mean: 0.08986
[32m[0906 22-15-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17591, current rewards: 141.45743, mean: 0.09068
[32m[0906 22-15-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17616, current rewards: 144.56293, mean: 0.08979
[32m[0906 22-15-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17641, current rewards: 150.22089, mean: 0.09049
[32m[0906 22-15-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17662, current rewards: 155.76702, mean: 0.09109
[32m[0906 22-15-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17683, current rewards: 161.29326, mean: 0.09164
[32m[0906 22-15-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17706, current rewards: 166.93005, mean: 0.09223
[32m[0906 22-16-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17726, current rewards: 172.96895, mean: 0.09299
[32m[0906 22-16-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17743, current rewards: 179.00063, mean: 0.09372
[32m[0906 22-16-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17761, current rewards: 185.02688, mean: 0.09440
[32m[0906 22-16-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17775, current rewards: 191.04406, mean: 0.09505
[32m[0906 22-16-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17787, current rewards: 197.07044, mean: 0.09567
[32m[0906 22-16-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17801, current rewards: 203.09075, mean: 0.09625
[32m[0906 22-16-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17813, current rewards: 210.19918, mean: 0.09731
[32m[0906 22-17-08 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17826, current rewards: 216.34139, mean: 0.09789
[32m[0906 22-17-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17836, current rewards: 222.48479, mean: 0.09844
[32m[0906 22-17-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17848, current rewards: 228.62702, mean: 0.09897
[32m[0906 22-17-36 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17858, current rewards: 213.00948, mean: 0.09026
[32m[0906 22-17-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17869, current rewards: 218.71807, mean: 0.09075
[32m[0906 22-17-54 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17879, current rewards: 224.43297, mean: 0.09123
[32m[0906 22-18-01 @Agent.py:117][0m Average action selection time: 0.1789
[32m[0906 22-18-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-18-02 @MBExp.py:227][0m Rewards obtained: [227.8905943393593], Lows: [22], Highs: [21], Total time: 27302.803165
[32m[0906 22-20-07 @MBExp.py:144][0m ####################################################################
[32m[0906 22-20-07 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 22-20-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17850, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-20-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17894, current rewards: -2.82783, mean: -0.04713
[32m[0906 22-20-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17884, current rewards: 5.69020, mean: 0.05173
[32m[0906 22-20-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17874, current rewards: 14.25887, mean: 0.08912
[32m[0906 22-20-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17872, current rewards: 0.17289, mean: 0.00082
[32m[0906 22-20-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17869, current rewards: 6.93970, mean: 0.02669
[32m[0906 22-21-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17871, current rewards: 13.71849, mean: 0.04425
[32m[0906 22-21-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17940, current rewards: 20.49447, mean: 0.05693
[32m[0906 22-21-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17992, current rewards: 27.26970, mean: 0.06651
[32m[0906 22-21-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18028, current rewards: 32.44038, mean: 0.07052
[32m[0906 22-21-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18055, current rewards: 40.22833, mean: 0.07888
[32m[0906 22-21-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18051, current rewards: 48.97906, mean: 0.08746
[32m[0906 22-21-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18035, current rewards: 57.73823, mean: 0.09465
[32m[0906 22-22-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17979, current rewards: 66.46046, mean: 0.10070
[32m[0906 22-22-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17918, current rewards: 51.75033, mean: 0.07289
[32m[0906 22-22-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17846, current rewards: 56.99819, mean: 0.07500
[32m[0906 22-22-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17780, current rewards: 62.23280, mean: 0.07683
[32m[0906 22-22-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17718, current rewards: 67.53351, mean: 0.07853
[32m[0906 22-22-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17664, current rewards: 84.80804, mean: 0.09320
[32m[0906 22-22-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17618, current rewards: 91.86266, mean: 0.09569
[32m[0906 22-23-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17579, current rewards: 78.81499, mean: 0.07803
[32m[0906 22-23-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17541, current rewards: 85.57903, mean: 0.08073
[32m[0906 22-23-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17506, current rewards: 92.34307, mean: 0.08319
[32m[0906 22-23-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17473, current rewards: 99.10711, mean: 0.08544
[32m[0906 22-23-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17445, current rewards: 105.87114, mean: 0.08750
[32m[0906 22-23-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17420, current rewards: 105.82350, mean: 0.08399
[32m[0906 22-23-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17417, current rewards: 55.82350, mean: 0.04261
[32m[0906 22-24-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17426, current rewards: 5.82350, mean: 0.00428
[32m[0906 22-24-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17446, current rewards: -44.17650, mean: -0.03133
[32m[0906 22-24-23 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17485, current rewards: -94.17650, mean: -0.06450
[32m[0906 22-24-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17515, current rewards: -144.17650, mean: -0.09548
[32m[0906 22-24-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17540, current rewards: -194.17650, mean: -0.12447
[32m[0906 22-24-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17566, current rewards: -244.17650, mean: -0.15166
[32m[0906 22-25-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17591, current rewards: -294.17650, mean: -0.17721
[32m[0906 22-25-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17616, current rewards: -344.17650, mean: -0.20127
[32m[0906 22-25-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17637, current rewards: -394.17650, mean: -0.22396
[32m[0906 22-25-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17654, current rewards: -444.17650, mean: -0.24540
[32m[0906 22-25-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17674, current rewards: -494.17650, mean: -0.26569
[32m[0906 22-25-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17691, current rewards: -544.17650, mean: -0.28491
[32m[0906 22-25-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17708, current rewards: -594.17650, mean: -0.30315
[32m[0906 22-26-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17723, current rewards: -644.17650, mean: -0.32049
[32m[0906 22-26-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17736, current rewards: -694.17650, mean: -0.33698
[32m[0906 22-26-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17752, current rewards: -744.17650, mean: -0.35269
[32m[0906 22-26-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17768, current rewards: -794.17650, mean: -0.36767
[32m[0906 22-26-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17780, current rewards: -844.17650, mean: -0.38198
[32m[0906 22-26-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17792, current rewards: -894.17650, mean: -0.39565
[32m[0906 22-26-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17803, current rewards: -944.17650, mean: -0.40873
[32m[0906 22-27-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17815, current rewards: -994.17650, mean: -0.42126
[32m[0906 22-27-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17825, current rewards: -1044.17650, mean: -0.43327
[32m[0906 22-27-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17835, current rewards: -1055.01643, mean: -0.42887
[32m[0906 22-27-34 @Agent.py:117][0m Average action selection time: 0.1784
[32m[0906 22-27-34 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-27-34 @MBExp.py:227][0m Rewards obtained: [-1047.5496791909852], Lows: [31], Highs: [1184], Total time: 27749.604424
[32m[0906 22-29-42 @MBExp.py:144][0m ####################################################################
[32m[0906 22-29-42 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 22-29-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17780, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-29-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17838, current rewards: -5.61167, mean: -0.09353
[32m[0906 22-30-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17852, current rewards: -0.25319, mean: -0.00230
[32m[0906 22-30-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17873, current rewards: 5.09551, mean: 0.03185
[32m[0906 22-30-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17860, current rewards: 10.44574, mean: 0.04974
[32m[0906 22-30-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17869, current rewards: 15.80431, mean: 0.06079
[32m[0906 22-30-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17886, current rewards: 21.16079, mean: 0.06826
[32m[0906 22-30-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17941, current rewards: 26.51884, mean: 0.07366
[32m[0906 22-30-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18005, current rewards: 31.87427, mean: 0.07774
[32m[0906 22-31-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18056, current rewards: 37.37720, mean: 0.08125
[32m[0906 22-31-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18085, current rewards: 43.63974, mean: 0.08557
[32m[0906 22-31-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18094, current rewards: 28.59519, mean: 0.05106
[32m[0906 22-31-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18076, current rewards: 36.78892, mean: 0.06031
[32m[0906 22-31-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18030, current rewards: 45.18232, mean: 0.06846
[32m[0906 22-31-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17978, current rewards: 53.59038, mean: 0.07548
[32m[0906 22-31-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17900, current rewards: 62.01402, mean: 0.08160
[32m[0906 22-32-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17830, current rewards: 70.42746, mean: 0.08695
[32m[0906 22-32-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17769, current rewards: 59.34222, mean: 0.06900
[32m[0906 22-32-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17716, current rewards: 65.33335, mean: 0.07179
[32m[0906 22-32-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17667, current rewards: 75.23469, mean: 0.07837
[32m[0906 22-32-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17625, current rewards: 85.10181, mean: 0.08426
[32m[0906 22-32-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17591, current rewards: 94.96597, mean: 0.08959
[32m[0906 22-32-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17554, current rewards: 104.81933, mean: 0.09443
[32m[0906 22-33-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17520, current rewards: 100.88193, mean: 0.08697
[32m[0906 22-33-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17491, current rewards: 106.42454, mean: 0.08795
[32m[0906 22-33-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17462, current rewards: 112.00646, mean: 0.08889
[32m[0906 22-33-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17449, current rewards: 117.58679, mean: 0.08976
[32m[0906 22-33-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17444, current rewards: 123.16378, mean: 0.09056
[32m[0906 22-33-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17461, current rewards: 128.12125, mean: 0.09087
[32m[0906 22-33-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17482, current rewards: 133.48673, mean: 0.09143
[32m[0906 22-34-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17514, current rewards: 138.85672, mean: 0.09196
[32m[0906 22-34-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17540, current rewards: 144.22632, mean: 0.09245
[32m[0906 22-34-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17566, current rewards: 136.41364, mean: 0.08473
[32m[0906 22-34-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17590, current rewards: 143.14169, mean: 0.08623
[32m[0906 22-34-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17614, current rewards: 148.09761, mean: 0.08661
[32m[0906 22-34-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17638, current rewards: 153.58770, mean: 0.08727
[32m[0906 22-35-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17660, current rewards: 159.08301, mean: 0.08789
[32m[0906 22-35-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17678, current rewards: 164.57750, mean: 0.08848
[32m[0906 22-35-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17697, current rewards: 170.07826, mean: 0.08905
[32m[0906 22-35-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17714, current rewards: 175.56810, mean: 0.08958
[32m[0906 22-35-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17730, current rewards: 181.06037, mean: 0.09008
[32m[0906 22-35-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17743, current rewards: 186.55481, mean: 0.09056
[32m[0906 22-35-57 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17757, current rewards: 193.28307, mean: 0.09160
[32m[0906 22-36-06 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17771, current rewards: 198.82832, mean: 0.09205
[32m[0906 22-36-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17783, current rewards: 204.37536, mean: 0.09248
[32m[0906 22-36-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17795, current rewards: 195.14035, mean: 0.08635
[32m[0906 22-36-34 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17806, current rewards: 196.65736, mean: 0.08513
[32m[0906 22-36-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17817, current rewards: 204.73914, mean: 0.08675
[32m[0906 22-36-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17830, current rewards: 212.83951, mean: 0.08832
[32m[0906 22-37-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17842, current rewards: 220.93242, mean: 0.08981
[32m[0906 22-37-09 @Agent.py:117][0m Average action selection time: 0.1785
[32m[0906 22-37-09 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-37-09 @MBExp.py:227][0m Rewards obtained: [227.4046437413736], Lows: [32], Highs: [31], Total time: 28196.599504
[32m[0906 22-39-19 @MBExp.py:144][0m ####################################################################
[32m[0906 22-39-19 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 22-39-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19105, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-39-30 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18284, current rewards: -31.59665, mean: -0.52661
[32m[0906 22-39-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18097, current rewards: -25.65778, mean: -0.23325
[32m[0906 22-39-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18049, current rewards: -19.89470, mean: -0.12434
[32m[0906 22-39-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18003, current rewards: -14.12368, mean: -0.06726
[32m[0906 22-40-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17973, current rewards: -31.15568, mean: -0.11983
[32m[0906 22-40-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17971, current rewards: -23.59105, mean: -0.07610
[32m[0906 22-40-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17959, current rewards: -4.64049, mean: -0.01289
[32m[0906 22-40-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18023, current rewards: 9.92335, mean: 0.02420
[32m[0906 22-40-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18073, current rewards: 24.17601, mean: 0.05256
[32m[0906 22-40-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18090, current rewards: 35.23681, mean: 0.06909
[32m[0906 22-41-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18107, current rewards: 23.98149, mean: 0.04282
[32m[0906 22-41-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18131, current rewards: 29.80484, mean: 0.04886
[32m[0906 22-41-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18090, current rewards: 34.98419, mean: 0.05301
[32m[0906 22-41-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18038, current rewards: 40.14318, mean: 0.05654
[32m[0906 22-41-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17956, current rewards: 45.30234, mean: 0.05961
[32m[0906 22-41-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17884, current rewards: 50.46145, mean: 0.06230
[32m[0906 22-41-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17820, current rewards: 55.25553, mean: 0.06425
[32m[0906 22-42-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17764, current rewards: 59.62037, mean: 0.06552
[32m[0906 22-42-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17715, current rewards: 64.60089, mean: 0.06729
[32m[0906 22-42-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17669, current rewards: 69.57947, mean: 0.06889
[32m[0906 22-42-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17626, current rewards: 74.56056, mean: 0.07034
[32m[0906 22-42-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17587, current rewards: 79.54078, mean: 0.07166
[32m[0906 22-42-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17552, current rewards: 84.52212, mean: 0.07286
[32m[0906 22-42-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17519, current rewards: 89.50266, mean: 0.07397
[32m[0906 22-43-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17488, current rewards: 79.55819, mean: 0.06314
[32m[0906 22-43-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17461, current rewards: 91.29660, mean: 0.06969
[32m[0906 22-43-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17459, current rewards: 97.28456, mean: 0.07153
[32m[0906 22-43-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17468, current rewards: 103.27756, mean: 0.07325
[32m[0906 22-43-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17485, current rewards: 105.91052, mean: 0.07254
[32m[0906 22-43-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17519, current rewards: 104.90974, mean: 0.06948
[32m[0906 22-43-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17547, current rewards: 83.40982, mean: 0.05347
[32m[0906 22-44-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17570, current rewards: 54.53509, mean: 0.03387
[32m[0906 22-44-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17594, current rewards: 26.26350, mean: 0.01582
[32m[0906 22-44-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17617, current rewards: -0.10596, mean: -0.00006
[32m[0906 22-44-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17636, current rewards: -31.32322, mean: -0.01780
[32m[0906 22-44-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17655, current rewards: -78.92047, mean: -0.04360
[32m[0906 22-44-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17675, current rewards: -124.21138, mean: -0.06678
[32m[0906 22-44-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17693, current rewards: -169.41308, mean: -0.08870
[32m[0906 22-45-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17710, current rewards: -212.72310, mean: -0.10853
[32m[0906 22-45-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17728, current rewards: -207.68479, mean: -0.10333
[32m[0906 22-45-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17745, current rewards: -203.94589, mean: -0.09900
[32m[0906 22-45-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17760, current rewards: -200.20304, mean: -0.09488
[32m[0906 22-45-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17773, current rewards: -195.85157, mean: -0.09067
[32m[0906 22-45-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17785, current rewards: -212.84030, mean: -0.09631
[32m[0906 22-46-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17799, current rewards: -206.84614, mean: -0.09152
[32m[0906 22-46-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17811, current rewards: -200.90695, mean: -0.08697
[32m[0906 22-46-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17823, current rewards: -194.97740, mean: -0.08262
[32m[0906 22-46-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17833, current rewards: -189.04292, mean: -0.07844
[32m[0906 22-46-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17843, current rewards: -183.10716, mean: -0.07443
[32m[0906 22-46-46 @Agent.py:117][0m Average action selection time: 0.1785
[32m[0906 22-46-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-46-46 @MBExp.py:227][0m Rewards obtained: [-200.68215198727577], Lows: [242], Highs: [42], Total time: 28643.63406
[32m[0906 22-48-58 @MBExp.py:144][0m ####################################################################
[32m[0906 22-48-58 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 22-49-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17767, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-49-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17848, current rewards: -63.57554, mean: -1.05959
[32m[0906 22-49-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17869, current rewards: -64.65134, mean: -0.58774
[32m[0906 22-49-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17893, current rewards: -81.58381, mean: -0.50990
[32m[0906 22-49-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17905, current rewards: -77.67673, mean: -0.36989
[32m[0906 22-49-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17909, current rewards: -71.50975, mean: -0.27504
[32m[0906 22-49-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17896, current rewards: -64.73082, mean: -0.20881
[32m[0906 22-50-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17894, current rewards: -59.36651, mean: -0.16491
[32m[0906 22-50-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17949, current rewards: -60.02235, mean: -0.14640
[32m[0906 22-50-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18008, current rewards: -57.84280, mean: -0.12575
[32m[0906 22-50-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18042, current rewards: -68.84302, mean: -0.13499
[32m[0906 22-50-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18062, current rewards: -117.98800, mean: -0.21069
[32m[0906 22-50-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18054, current rewards: -173.05250, mean: -0.28369
[32m[0906 22-50-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18036, current rewards: -205.81079, mean: -0.31183
[32m[0906 22-51-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17996, current rewards: -252.52321, mean: -0.35567
[32m[0906 22-51-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17925, current rewards: -291.98236, mean: -0.38419
[32m[0906 22-51-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17851, current rewards: -319.92084, mean: -0.39496
[32m[0906 22-51-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17791, current rewards: -330.05763, mean: -0.38379
[32m[0906 22-51-40 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17737, current rewards: -370.94900, mean: -0.40764
[32m[0906 22-51-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17686, current rewards: -405.65258, mean: -0.42255
[32m[0906 22-51-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17641, current rewards: -400.49278, mean: -0.39653
[32m[0906 22-52-05 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17599, current rewards: -395.71107, mean: -0.37331
[32m[0906 22-52-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17561, current rewards: -412.22452, mean: -0.37137
[32m[0906 22-52-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17528, current rewards: -406.82778, mean: -0.35071
[32m[0906 22-52-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17496, current rewards: -401.35548, mean: -0.33170
[32m[0906 22-52-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17468, current rewards: -395.88272, mean: -0.31419
[32m[0906 22-52-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17440, current rewards: -390.48484, mean: -0.29808
[32m[0906 22-52-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17422, current rewards: -385.69538, mean: -0.28360
[32m[0906 22-53-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17421, current rewards: -380.09263, mean: -0.26957
[32m[0906 22-53-13 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17437, current rewards: -375.08416, mean: -0.25691
[32m[0906 22-53-22 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17463, current rewards: -370.11850, mean: -0.24511
[32m[0906 22-53-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17495, current rewards: -365.14619, mean: -0.23407
[32m[0906 22-53-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17526, current rewards: -360.18515, mean: -0.22372
[32m[0906 22-53-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17553, current rewards: -355.21560, mean: -0.21399
[32m[0906 22-53-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17577, current rewards: -350.25044, mean: -0.20482
[32m[0906 22-54-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17600, current rewards: -344.39887, mean: -0.19568
[32m[0906 22-54-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17623, current rewards: -339.07430, mean: -0.18733
[32m[0906 22-54-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17645, current rewards: -333.75087, mean: -0.17944
[32m[0906 22-54-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17663, current rewards: -328.42700, mean: -0.17195
[32m[0906 22-54-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17682, current rewards: -362.89004, mean: -0.18515
[32m[0906 22-54-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17700, current rewards: -357.65911, mean: -0.17794
[32m[0906 22-55-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17717, current rewards: -352.43102, mean: -0.17108
[32m[0906 22-55-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17733, current rewards: -347.20275, mean: -0.16455
[32m[0906 22-55-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17748, current rewards: -342.09487, mean: -0.15838
[32m[0906 22-55-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17761, current rewards: -336.88360, mean: -0.15244
[32m[0906 22-55-41 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17775, current rewards: -342.99527, mean: -0.15177
[32m[0906 22-55-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17791, current rewards: -337.72019, mean: -0.14620
[32m[0906 22-55-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17804, current rewards: -332.44241, mean: -0.14087
[32m[0906 22-56-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17816, current rewards: -327.16934, mean: -0.13575
[32m[0906 22-56-18 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17827, current rewards: -321.89692, mean: -0.13085
[32m[0906 22-56-25 @Agent.py:117][0m Average action selection time: 0.1784
[32m[0906 22-56-25 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-56-25 @MBExp.py:227][0m Rewards obtained: [-317.68150715459757], Lows: [235], Highs: [109], Total time: 29090.300502000002
[32m[0906 22-58-39 @MBExp.py:144][0m ####################################################################
[32m[0906 22-58-39 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 22-58-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17787, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-58-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17915, current rewards: -5.46174, mean: -0.09103
[32m[0906 22-58-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17891, current rewards: 4.07327, mean: 0.03703
[32m[0906 22-59-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17906, current rewards: 9.86433, mean: 0.06165
[32m[0906 22-59-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17901, current rewards: 15.65222, mean: 0.07453
[32m[0906 22-59-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17902, current rewards: 21.44097, mean: 0.08247
[32m[0906 22-59-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17899, current rewards: 27.22612, mean: 0.08783
[32m[0906 22-59-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17896, current rewards: 33.01343, mean: 0.09170
[32m[0906 22-59-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17937, current rewards: 38.79915, mean: 0.09463
[32m[0906 23-00-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18003, current rewards: 44.58854, mean: 0.09693
[32m[0906 23-00-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18030, current rewards: 37.97545, mean: 0.07446
[32m[0906 23-00-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18055, current rewards: 42.90602, mean: 0.07662
[32m[0906 23-00-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18056, current rewards: 48.21756, mean: 0.07905
[32m[0906 23-00-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18045, current rewards: 53.53019, mean: 0.08111
[32m[0906 23-00-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17996, current rewards: 58.84004, mean: 0.08287
[32m[0906 23-00-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17930, current rewards: 64.15243, mean: 0.08441
[32m[0906 23-01-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17861, current rewards: 69.46619, mean: 0.08576
[32m[0906 23-01-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17797, current rewards: 74.77295, mean: 0.08695
[32m[0906 23-01-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17737, current rewards: 79.57069, mean: 0.08744
[32m[0906 23-01-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17686, current rewards: 84.71337, mean: 0.08824
[32m[0906 23-01-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17642, current rewards: 88.82260, mean: 0.08794
[32m[0906 23-01-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17600, current rewards: 92.92932, mean: 0.08767
[32m[0906 23-01-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17563, current rewards: 97.03302, mean: 0.08742
[32m[0906 23-02-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17533, current rewards: 101.13981, mean: 0.08719
[32m[0906 23-02-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17504, current rewards: 105.24592, mean: 0.08698
[32m[0906 23-02-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17477, current rewards: 88.56188, mean: 0.07029
[32m[0906 23-02-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17450, current rewards: 40.19722, mean: 0.03068
[32m[0906 23-02-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17426, current rewards: -12.55263, mean: -0.00923
[32m[0906 23-02-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17421, current rewards: -91.64086, mean: -0.06499
[32m[0906 23-02-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17426, current rewards: -144.11981, mean: -0.09871
[32m[0906 23-03-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17443, current rewards: -209.80431, mean: -0.13894
[32m[0906 23-03-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17476, current rewards: -271.79077, mean: -0.17422
[32m[0906 23-03-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17507, current rewards: -340.13446, mean: -0.21126
[32m[0906 23-03-31 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17530, current rewards: -394.43740, mean: -0.23761
[32m[0906 23-03-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17554, current rewards: -464.34065, mean: -0.27154
[32m[0906 23-03-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17578, current rewards: -536.78881, mean: -0.30499
[32m[0906 23-03-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17600, current rewards: -604.95757, mean: -0.33423
[32m[0906 23-04-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17623, current rewards: -679.50377, mean: -0.36532
[32m[0906 23-04-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17644, current rewards: -747.68666, mean: -0.39146
[32m[0906 23-04-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17664, current rewards: -826.48137, mean: -0.42167
[32m[0906 23-04-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17680, current rewards: -875.62027, mean: -0.43563
[32m[0906 23-04-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17697, current rewards: -869.84256, mean: -0.42225
[32m[0906 23-04-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17713, current rewards: -864.25450, mean: -0.40960
[32m[0906 23-05-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17727, current rewards: -859.04367, mean: -0.39771
[32m[0906 23-05-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17741, current rewards: -853.55923, mean: -0.38623
[32m[0906 23-05-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17755, current rewards: -858.62030, mean: -0.37992
[32m[0906 23-05-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17767, current rewards: -853.19614, mean: -0.36935
[32m[0906 23-05-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17779, current rewards: -847.77057, mean: -0.35922
[32m[0906 23-05-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17791, current rewards: -842.34467, mean: -0.34952
[32m[0906 23-05-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17802, current rewards: -836.92231, mean: -0.34021
[32m[0906 23-06-05 @Agent.py:117][0m Average action selection time: 0.1781
[32m[0906 23-06-05 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-06-05 @MBExp.py:227][0m Rewards obtained: [-832.5850144261428], Lows: [514], Highs: [40], Total time: 29536.321537000003
[32m[0906 23-08-21 @MBExp.py:144][0m ####################################################################
[32m[0906 23-08-21 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 23-08-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17802, current rewards: 0.75927, mean: 0.07593
[32m[0906 23-08-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18069, current rewards: -60.71808, mean: -1.01197
[32m[0906 23-08-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17980, current rewards: -54.05149, mean: -0.49138
[32m[0906 23-08-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17947, current rewards: -48.00623, mean: -0.30004
[32m[0906 23-08-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17922, current rewards: -41.96096, mean: -0.19981
[32m[0906 23-09-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17919, current rewards: -35.91570, mean: -0.13814
[32m[0906 23-09-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17906, current rewards: -29.87043, mean: -0.09636
[32m[0906 23-09-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17896, current rewards: -23.82517, mean: -0.06618
[32m[0906 23-09-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17920, current rewards: -17.77990, mean: -0.04337
[32m[0906 23-09-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17978, current rewards: -11.73463, mean: -0.02551
[32m[0906 23-09-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18021, current rewards: -22.97613, mean: -0.04505
[32m[0906 23-10-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18049, current rewards: -72.97613, mean: -0.13031
[32m[0906 23-10-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18066, current rewards: -122.97613, mean: -0.20160
[32m[0906 23-10-21 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18053, current rewards: -172.97613, mean: -0.26209
[32m[0906 23-10-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18020, current rewards: -222.97613, mean: -0.31405
[32m[0906 23-10-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17959, current rewards: -272.97613, mean: -0.35918
[32m[0906 23-10-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17884, current rewards: -322.97613, mean: -0.39874
[32m[0906 23-10-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17818, current rewards: -372.97613, mean: -0.43369
[32m[0906 23-11-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17760, current rewards: -422.97613, mean: -0.46481
[32m[0906 23-11-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17707, current rewards: -472.97613, mean: -0.49268
[32m[0906 23-11-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17661, current rewards: -522.97613, mean: -0.51780
[32m[0906 23-11-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17619, current rewards: -572.97613, mean: -0.54054
[32m[0906 23-11-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17578, current rewards: -622.97613, mean: -0.56124
[32m[0906 23-11-45 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17543, current rewards: -672.97613, mean: -0.58015
[32m[0906 23-11-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17510, current rewards: -722.97613, mean: -0.59750
[32m[0906 23-12-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17482, current rewards: -772.97613, mean: -0.61347
[32m[0906 23-12-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17456, current rewards: -822.97613, mean: -0.62823
[32m[0906 23-12-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17429, current rewards: -872.97613, mean: -0.64189
[32m[0906 23-12-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17410, current rewards: -922.97613, mean: -0.65459
[32m[0906 23-12-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17411, current rewards: -972.97613, mean: -0.66642
[32m[0906 23-12-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17426, current rewards: -1022.97613, mean: -0.67747
[32m[0906 23-12-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17451, current rewards: -1072.97613, mean: -0.68781
[32m[0906 23-13-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17481, current rewards: -1122.97613, mean: -0.69750
[32m[0906 23-13-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17508, current rewards: -1172.97613, mean: -0.70661
[32m[0906 23-13-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17532, current rewards: -1222.97613, mean: -0.71519
[32m[0906 23-13-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17555, current rewards: -1272.97613, mean: -0.72328
[32m[0906 23-13-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17578, current rewards: -1322.97613, mean: -0.73093
[32m[0906 23-13-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17599, current rewards: -1372.97613, mean: -0.73816
[32m[0906 23-13-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17620, current rewards: -1422.97613, mean: -0.74501
[32m[0906 23-14-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17640, current rewards: -1472.97613, mean: -0.75152
[32m[0906 23-14-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17656, current rewards: -1522.97613, mean: -0.75770
[32m[0906 23-14-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17673, current rewards: -1572.97613, mean: -0.76358
[32m[0906 23-14-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17689, current rewards: -1622.97613, mean: -0.76918
[32m[0906 23-14-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17707, current rewards: -1672.97613, mean: -0.77453
[32m[0906 23-14-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17721, current rewards: -1722.97613, mean: -0.77963
[32m[0906 23-15-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17735, current rewards: -1772.97613, mean: -0.78450
[32m[0906 23-15-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17745, current rewards: -1822.97613, mean: -0.78917
[32m[0906 23-15-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17759, current rewards: -1872.97613, mean: -0.79363
[32m[0906 23-15-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17770, current rewards: -1922.97613, mean: -0.79792
[32m[0906 23-15-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17781, current rewards: -1972.97613, mean: -0.80202
[32m[0906 23-15-47 @Agent.py:117][0m Average action selection time: 0.1779
[32m[0906 23-15-47 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-15-47 @MBExp.py:227][0m Rewards obtained: [-2012.9761305400134], Lows: [33], Highs: [2005], Total time: 29981.837542000005
[32m[0906 23-18-05 @MBExp.py:144][0m ####################################################################
[32m[0906 23-18-05 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 23-18-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17676, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-18-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17814, current rewards: -25.79778, mean: -0.42996
[32m[0906 23-18-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17879, current rewards: -19.53164, mean: -0.17756
[32m[0906 23-18-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17885, current rewards: -12.21685, mean: -0.07636
[32m[0906 23-18-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17890, current rewards: -4.91332, mean: -0.02340
[32m[0906 23-18-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17909, current rewards: -10.50712, mean: -0.04041
[32m[0906 23-19-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17903, current rewards: -12.65230, mean: -0.04081
[32m[0906 23-19-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17899, current rewards: -6.65514, mean: -0.01849
[32m[0906 23-19-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17893, current rewards: -0.64727, mean: -0.00158
[32m[0906 23-19-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17934, current rewards: 5.35469, mean: 0.01164
[32m[0906 23-19-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17978, current rewards: 13.78276, mean: 0.02703
[32m[0906 23-19-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18012, current rewards: 19.59639, mean: 0.03499
[32m[0906 23-19-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18037, current rewards: 25.40972, mean: 0.04166
[32m[0906 23-20-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18031, current rewards: 31.22540, mean: 0.04731
[32m[0906 23-20-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18010, current rewards: 15.61529, mean: 0.02199
[32m[0906 23-20-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17966, current rewards: 20.31652, mean: 0.02673
[32m[0906 23-20-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17912, current rewards: 25.01564, mean: 0.03088
[32m[0906 23-20-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17847, current rewards: 29.71654, mean: 0.03455
[32m[0906 23-20-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17787, current rewards: 13.47378, mean: 0.01481
[32m[0906 23-20-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17736, current rewards: 18.39670, mean: 0.01916
[32m[0906 23-21-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17690, current rewards: 23.87382, mean: 0.02364
[32m[0906 23-21-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17645, current rewards: 29.34921, mean: 0.02769
[32m[0906 23-21-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17603, current rewards: 34.82780, mean: 0.03138
[32m[0906 23-21-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17568, current rewards: 40.30703, mean: 0.03475
[32m[0906 23-21-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17534, current rewards: 45.78716, mean: 0.03784
[32m[0906 23-21-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17502, current rewards: 51.26293, mean: 0.04068
[32m[0906 23-21-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17476, current rewards: 56.74127, mean: 0.04331
[32m[0906 23-22-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17451, current rewards: 63.43531, mean: 0.04664
[32m[0906 23-22-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17427, current rewards: 68.93337, mean: 0.04889
[32m[0906 23-22-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17419, current rewards: 74.43238, mean: 0.05098
[32m[0906 23-22-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17423, current rewards: 79.93381, mean: 0.05294
[32m[0906 23-22-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17440, current rewards: 85.43249, mean: 0.05476
[32m[0906 23-22-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17460, current rewards: 79.98217, mean: 0.04968
[32m[0906 23-22-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17490, current rewards: 85.61171, mean: 0.05157
[32m[0906 23-23-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17522, current rewards: 91.16711, mean: 0.05331
[32m[0906 23-23-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17550, current rewards: 96.61280, mean: 0.05489
[32m[0906 23-23-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17571, current rewards: 102.16766, mean: 0.05645
[32m[0906 23-23-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17593, current rewards: 107.72650, mean: 0.05792
[32m[0906 23-23-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17613, current rewards: 113.28513, mean: 0.05931
[32m[0906 23-23-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17633, current rewards: 118.84017, mean: 0.06063
[32m[0906 23-24-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17652, current rewards: 124.39859, mean: 0.06189
[32m[0906 23-24-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17671, current rewards: 129.95572, mean: 0.06309
[32m[0906 23-24-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17687, current rewards: 135.51231, mean: 0.06422
[32m[0906 23-24-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17700, current rewards: 140.82362, mean: 0.06520
[32m[0906 23-24-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17717, current rewards: 146.39770, mean: 0.06624
[32m[0906 23-24-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17728, current rewards: 151.98361, mean: 0.06725
[32m[0906 23-24-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17742, current rewards: 157.57079, mean: 0.06821
[32m[0906 23-25-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17759, current rewards: 142.79892, mean: 0.06051
[32m[0906 23-25-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17772, current rewards: 149.21789, mean: 0.06192
[32m[0906 23-25-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17784, current rewards: 155.16131, mean: 0.06307
[32m[0906 23-25-31 @Agent.py:117][0m Average action selection time: 0.1779
[32m[0906 23-25-31 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-25-31 @MBExp.py:227][0m Rewards obtained: [159.91145423514993], Lows: [50], Highs: [21], Total time: 30427.436112000003
[32m[0906 23-27-51 @MBExp.py:144][0m ####################################################################
[32m[0906 23-27-51 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 23-27-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17873, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-28-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17890, current rewards: -7.70260, mean: -0.12838
[32m[0906 23-28-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17876, current rewards: -2.02865, mean: -0.01844
[32m[0906 23-28-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17892, current rewards: 4.27075, mean: 0.02669
[32m[0906 23-28-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17892, current rewards: 10.57984, mean: 0.05038
[32m[0906 23-28-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17884, current rewards: 16.87713, mean: 0.06491
[32m[0906 23-28-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17877, current rewards: 23.19233, mean: 0.07481
[32m[0906 23-28-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17886, current rewards: 29.48694, mean: 0.08191
[32m[0906 23-29-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17887, current rewards: 35.78936, mean: 0.08729
[32m[0906 23-29-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17958, current rewards: -31.83164, mean: -0.06920
[32m[0906 23-29-23 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18012, current rewards: -86.34874, mean: -0.16931
[32m[0906 23-29-32 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18047, current rewards: -141.53451, mean: -0.25274
[32m[0906 23-29-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18067, current rewards: -204.75814, mean: -0.33567
[32m[0906 23-29-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18078, current rewards: -250.46733, mean: -0.37950
[32m[0906 23-30-00 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18064, current rewards: -300.54862, mean: -0.42331
[32m[0906 23-30-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18016, current rewards: -346.73273, mean: -0.45623
[32m[0906 23-30-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17968, current rewards: -400.84364, mean: -0.49487
[32m[0906 23-30-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17899, current rewards: -395.65199, mean: -0.46006
[32m[0906 23-30-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17834, current rewards: -388.05052, mean: -0.42643
[32m[0906 23-30-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17778, current rewards: -382.32756, mean: -0.39826
[32m[0906 23-30-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17727, current rewards: -376.60300, mean: -0.37287
[32m[0906 23-30-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17681, current rewards: -370.88324, mean: -0.34989
[32m[0906 23-31-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17640, current rewards: -365.15861, mean: -0.32897
[32m[0906 23-31-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17601, current rewards: -359.43696, mean: -0.30986
[32m[0906 23-31-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17568, current rewards: -353.71643, mean: -0.29233
[32m[0906 23-31-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17537, current rewards: -354.68426, mean: -0.28150
[32m[0906 23-31-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17505, current rewards: -362.99830, mean: -0.27710
[32m[0906 23-31-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17476, current rewards: -364.29212, mean: -0.26786
[32m[0906 23-31-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17453, current rewards: -358.42548, mean: -0.25420
[32m[0906 23-32-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17427, current rewards: -353.33452, mean: -0.24201
[32m[0906 23-32-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17424, current rewards: -348.24558, mean: -0.23063
[32m[0906 23-32-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17436, current rewards: -343.16256, mean: -0.21998
[32m[0906 23-32-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17449, current rewards: -338.06579, mean: -0.20998
[32m[0906 23-32-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17485, current rewards: -395.36763, mean: -0.23817
[32m[0906 23-32-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17511, current rewards: -454.70844, mean: -0.26591
[32m[0906 23-33-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17535, current rewards: -516.98857, mean: -0.29374
[32m[0906 23-33-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17560, current rewards: -579.36997, mean: -0.32009
[32m[0906 23-33-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17579, current rewards: -639.69755, mean: -0.34392
[32m[0906 23-33-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17602, current rewards: -682.28424, mean: -0.35722
[32m[0906 23-33-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17626, current rewards: -676.68293, mean: -0.34525
[32m[0906 23-33-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17643, current rewards: -671.02367, mean: -0.33384
[32m[0906 23-33-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17659, current rewards: -665.37137, mean: -0.32300
[32m[0906 23-34-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17674, current rewards: -659.48210, mean: -0.31255
[32m[0906 23-34-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17691, current rewards: -651.87661, mean: -0.30179
[32m[0906 23-34-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17704, current rewards: -646.11423, mean: -0.29236
[32m[0906 23-34-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17719, current rewards: -640.35169, mean: -0.28334
[32m[0906 23-34-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17732, current rewards: -634.58168, mean: -0.27471
[32m[0906 23-34-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17743, current rewards: -628.81211, mean: -0.26645
[32m[0906 23-35-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17754, current rewards: -623.04511, mean: -0.25852
[32m[0906 23-35-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17766, current rewards: -617.06307, mean: -0.25084
[32m[0906 23-35-16 @Agent.py:117][0m Average action selection time: 0.1777
[32m[0906 23-35-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-35-16 @MBExp.py:227][0m Rewards obtained: [-612.1807040846871], Lows: [424], Highs: [31], Total time: 30872.556608000003
[32m[0906 23-37-39 @MBExp.py:144][0m ####################################################################
[32m[0906 23-37-39 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 23-37-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17870, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-37-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17922, current rewards: -5.50899, mean: -0.09182
[32m[0906 23-37-58 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17894, current rewards: 0.09834, mean: 0.00089
[32m[0906 23-38-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17889, current rewards: 5.71813, mean: 0.03574
[32m[0906 23-38-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17867, current rewards: 11.32911, mean: 0.05395
[32m[0906 23-38-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17869, current rewards: 16.94024, mean: 0.06515
[32m[0906 23-38-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17863, current rewards: 22.55628, mean: 0.07276
[32m[0906 23-38-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17861, current rewards: 28.17244, mean: 0.07826
[32m[0906 23-38-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17856, current rewards: 33.78326, mean: 0.08240
[32m[0906 23-39-01 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17873, current rewards: 18.61974, mean: 0.04048
[32m[0906 23-39-10 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17929, current rewards: 24.44031, mean: 0.04792
[32m[0906 23-39-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17968, current rewards: 30.27793, mean: 0.05407
[32m[0906 23-39-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17994, current rewards: 36.10495, mean: 0.05919
[32m[0906 23-39-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18022, current rewards: 41.93697, mean: 0.06354
[32m[0906 23-39-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18026, current rewards: 47.76831, mean: 0.06728
[32m[0906 23-39-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17996, current rewards: 53.60185, mean: 0.07053
[32m[0906 23-40-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17954, current rewards: 59.42701, mean: 0.07337
[32m[0906 23-40-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17886, current rewards: 65.25066, mean: 0.07587
[32m[0906 23-40-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17824, current rewards: 50.44664, mean: 0.05544
[32m[0906 23-40-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17769, current rewards: 57.44585, mean: 0.05984
[32m[0906 23-40-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17720, current rewards: 64.47380, mean: 0.06384
[32m[0906 23-40-46 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17675, current rewards: 71.49846, mean: 0.06745
[32m[0906 23-40-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17635, current rewards: 78.51769, mean: 0.07074
[32m[0906 23-41-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17597, current rewards: 85.53658, mean: 0.07374
[32m[0906 23-41-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17562, current rewards: 92.56783, mean: 0.07650
[32m[0906 23-41-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17531, current rewards: 99.46756, mean: 0.07894
[32m[0906 23-41-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17502, current rewards: 106.45372, mean: 0.08126
[32m[0906 23-41-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17472, current rewards: 101.01620, mean: 0.07428
[32m[0906 23-41-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17446, current rewards: 105.65680, mean: 0.07493
[32m[0906 23-41-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17426, current rewards: 110.29945, mean: 0.07555
[32m[0906 23-42-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17409, current rewards: 114.93999, mean: 0.07612
[32m[0906 23-42-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17411, current rewards: 119.57480, mean: 0.07665
[32m[0906 23-42-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17428, current rewards: 124.21389, mean: 0.07715
[32m[0906 23-42-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17455, current rewards: 106.32197, mean: 0.06405
[32m[0906 23-42-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17487, current rewards: 89.99130, mean: 0.05263
[32m[0906 23-42-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17515, current rewards: 79.06235, mean: 0.04492
[32m[0906 23-42-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17539, current rewards: 80.84922, mean: 0.04467
[32m[0906 23-43-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17563, current rewards: 60.32051, mean: 0.03243
[32m[0906 23-43-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17589, current rewards: 37.79320, mean: 0.01979
[32m[0906 23-43-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17611, current rewards: 32.48876, mean: 0.01658
[32m[0906 23-43-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17634, current rewards: 23.12417, mean: 0.01150
[32m[0906 23-43-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17659, current rewards: 22.00963, mean: 0.01068
[32m[0906 23-43-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17676, current rewards: 9.35141, mean: 0.00443
[32m[0906 23-44-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17695, current rewards: 22.96025, mean: 0.01063
[32m[0906 23-44-11 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17708, current rewards: 36.25991, mean: 0.01641
[32m[0906 23-44-20 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17723, current rewards: 49.58283, mean: 0.02194
[32m[0906 23-44-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17736, current rewards: 62.92095, mean: 0.02724
[32m[0906 23-44-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17749, current rewards: 73.98054, mean: 0.03135
[32m[0906 23-44-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17760, current rewards: 54.05986, mean: 0.02243
[32m[0906 23-44-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17773, current rewards: 58.72204, mean: 0.02387
[32m[0906 23-45-04 @Agent.py:117][0m Average action selection time: 0.1778
[32m[0906 23-45-04 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-45-04 @MBExp.py:227][0m Rewards obtained: [62.383331147091646], Lows: [107], Highs: [59], Total time: 31317.892141000004
[32m[0906 23-47-29 @MBExp.py:144][0m ####################################################################
[32m[0906 23-47-29 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 23-47-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17842, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-47-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17916, current rewards: -27.46852, mean: -0.45781
[32m[0906 23-47-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17870, current rewards: -21.96845, mean: -0.19971
[32m[0906 23-47-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17881, current rewards: -16.46842, mean: -0.10293
[32m[0906 23-48-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17882, current rewards: -10.97176, mean: -0.05225
[32m[0906 23-48-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17900, current rewards: -5.47234, mean: -0.02105
[32m[0906 23-48-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17895, current rewards: -10.90370, mean: -0.03517
[32m[0906 23-48-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17888, current rewards: 4.20566, mean: 0.01168
[32m[0906 23-48-42 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17878, current rewards: 23.61684, mean: 0.05760
[32m[0906 23-48-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17878, current rewards: 51.56787, mean: 0.11210
[32m[0906 23-49-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17929, current rewards: 77.69423, mean: 0.15234
[32m[0906 23-49-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17969, current rewards: 104.02169, mean: 0.18575
[32m[0906 23-49-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17999, current rewards: 130.31803, mean: 0.21364
[32m[0906 23-49-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18018, current rewards: 156.60180, mean: 0.23728
[32m[0906 23-49-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18025, current rewards: 182.89850, mean: 0.25760
[32m[0906 23-49-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18005, current rewards: 209.30901, mean: 0.27541
[32m[0906 23-49-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17965, current rewards: 202.90939, mean: 0.25051
[32m[0906 23-50-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17921, current rewards: 213.06244, mean: 0.24775
[32m[0906 23-50-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17859, current rewards: 246.27570, mean: 0.27063
[32m[0906 23-50-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17806, current rewards: 243.60757, mean: 0.25376
[32m[0906 23-50-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17759, current rewards: 190.70880, mean: 0.18882
[32m[0906 23-50-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17712, current rewards: 147.18097, mean: 0.13885
[32m[0906 23-50-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17668, current rewards: 113.34269, mean: 0.10211
[32m[0906 23-50-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17629, current rewards: 82.33285, mean: 0.07098
[32m[0906 23-51-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17591, current rewards: 56.98855, mean: 0.04710
[32m[0906 23-51-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17557, current rewards: 15.35864, mean: 0.01219
[32m[0906 23-51-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17526, current rewards: -19.87025, mean: -0.01517
[32m[0906 23-51-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17497, current rewards: -54.76223, mean: -0.04027
[32m[0906 23-51-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17469, current rewards: -49.22216, mean: -0.03491
[32m[0906 23-51-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17447, current rewards: -43.97400, mean: -0.03012
[32m[0906 23-51-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17424, current rewards: -38.72869, mean: -0.02565
[32m[0906 23-52-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17418, current rewards: -33.48251, mean: -0.02146
[32m[0906 23-52-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17429, current rewards: -28.23627, mean: -0.01754
[32m[0906 23-52-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17446, current rewards: -23.10959, mean: -0.01392
[32m[0906 23-52-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17467, current rewards: -17.36973, mean: -0.01016
[32m[0906 23-52-37 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17495, current rewards: -32.47002, mean: -0.01845
[32m[0906 23-52-46 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17521, current rewards: -26.46361, mean: -0.01462
[32m[0906 23-52-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17543, current rewards: -20.45802, mean: -0.01100
[32m[0906 23-53-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17565, current rewards: -14.44954, mean: -0.00757
[32m[0906 23-53-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17584, current rewards: -8.44305, mean: -0.00431
[32m[0906 23-53-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17604, current rewards: -2.43589, mean: -0.00121
[32m[0906 23-53-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17623, current rewards: 9.78008, mean: 0.00475
[32m[0906 23-53-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17640, current rewards: 18.22194, mean: 0.00864
[32m[0906 23-53-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17656, current rewards: 10.19803, mean: 0.00472
[32m[0906 23-54-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17672, current rewards: -39.80197, mean: -0.01801
[32m[0906 23-54-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17687, current rewards: -89.80197, mean: -0.03974
[32m[0906 23-54-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17700, current rewards: -139.80197, mean: -0.06052
[32m[0906 23-54-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17716, current rewards: -189.80197, mean: -0.08042
[32m[0906 23-54-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17729, current rewards: -224.82985, mean: -0.09329
[32m[0906 23-54-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17741, current rewards: -214.43503, mean: -0.08717
[32m[0906 23-54-53 @Agent.py:117][0m Average action selection time: 0.1775
[32m[0906 23-54-53 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-54-53 @MBExp.py:227][0m Rewards obtained: [-208.78088504091653], Lows: [219], Highs: [293], Total time: 31762.419169000004
[32m[0906 23-57-20 @MBExp.py:144][0m ####################################################################
[32m[0906 23-57-20 @MBExp.py:145][0m Starting training iteration 71.
[32m[0906 23-57-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28463, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-57-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20390, current rewards: -34.95036, mean: -0.58251
[32m[0906 23-57-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19268, current rewards: -26.34828, mean: -0.23953
[32m[0906 23-57-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18824, current rewards: -17.63931, mean: -0.11025
[32m[0906 23-57-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18593, current rewards: -8.94362, mean: -0.04259
[32m[0906 23-58-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18459, current rewards: -0.27431, mean: -0.00106
[32m[0906 23-58-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18367, current rewards: 8.44501, mean: 0.02724
[32m[0906 23-58-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18288, current rewards: 17.13322, mean: 0.04759
[32m[0906 23-58-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18240, current rewards: 28.23218, mean: 0.06886
[32m[0906 23-58-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18215, current rewards: 36.71144, mean: 0.07981
[32m[0906 23-58-53 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18196, current rewards: 38.55304, mean: 0.07559
[32m[0906 23-59-02 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18213, current rewards: -61.44696, mean: -0.10973
[32m[0906 23-59-11 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18224, current rewards: -161.44696, mean: -0.26467
[32m[0906 23-59-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18231, current rewards: -261.44696, mean: -0.39613
[32m[0906 23-59-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18228, current rewards: -361.44696, mean: -0.50908
[32m[0906 23-59-38 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18196, current rewards: -461.44696, mean: -0.60717
[32m[0906 23-59-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18144, current rewards: -561.44696, mean: -0.69314
[32m[0906 23-59-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18092, current rewards: -661.44696, mean: -0.76912
[32m[0907 00-00-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18018, current rewards: -761.44696, mean: -0.83675
[32m[0907 00-00-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17951, current rewards: -861.44696, mean: -0.89734
[32m[0907 00-00-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17891, current rewards: -961.44696, mean: -0.95193
[32m[0907 00-00-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17834, current rewards: -1061.44696, mean: -1.00137
[32m[0907 00-00-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17786, current rewards: -1161.44696, mean: -1.04635
[32m[0907 00-00-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17743, current rewards: -1261.44696, mean: -1.08745
[32m[0907 00-00-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17702, current rewards: -1361.44696, mean: -1.12516
[32m[0907 00-01-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17664, current rewards: -1461.44696, mean: -1.15988
[32m[0907 00-01-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17628, current rewards: -1561.44696, mean: -1.19194
[32m[0907 00-01-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17594, current rewards: -1661.44696, mean: -1.22165
[32m[0907 00-01-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17565, current rewards: -1761.44696, mean: -1.24925
[32m[0907 00-01-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17537, current rewards: -1861.44696, mean: -1.27496
[32m[0907 00-01-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17511, current rewards: -1961.44696, mean: -1.29897
[32m[0907 00-01-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17495, current rewards: -2061.44696, mean: -1.32144
[32m[0907 00-02-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17498, current rewards: -2161.44696, mean: -1.34251
[32m[0907 00-02-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17510, current rewards: -2261.44696, mean: -1.36232
[32m[0907 00-02-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17525, current rewards: -2361.44696, mean: -1.38096
[32m[0907 00-02-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17550, current rewards: -2461.44696, mean: -1.39855
[32m[0907 00-02-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17575, current rewards: -2561.44696, mean: -1.41516
[32m[0907 00-02-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17598, current rewards: -2661.44696, mean: -1.43089
[32m[0907 00-02-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17622, current rewards: -2761.44696, mean: -1.44578
[32m[0907 00-03-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17641, current rewards: -2861.44696, mean: -1.45992
[32m[0907 00-03-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17661, current rewards: -2961.44696, mean: -1.47336
[32m[0907 00-03-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17679, current rewards: -3061.44696, mean: -1.48614
[32m[0907 00-03-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17697, current rewards: -3161.44696, mean: -1.49832
[32m[0907 00-03-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17710, current rewards: -3261.44696, mean: -1.50993
[32m[0907 00-03-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17723, current rewards: -3361.44696, mean: -1.52102
[32m[0907 00-04-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17736, current rewards: -3461.44696, mean: -1.53161
[32m[0907 00-04-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17749, current rewards: -3561.44696, mean: -1.54175
[32m[0907 00-04-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17760, current rewards: -3661.44696, mean: -1.55146
[32m[0907 00-04-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17773, current rewards: -3761.44696, mean: -1.56077
[32m[0907 00-04-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17785, current rewards: -3861.44696, mean: -1.56969
[32m[0907 00-04-45 @Agent.py:117][0m Average action selection time: 0.1779
[32m[0907 00-04-45 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-04-45 @MBExp.py:227][0m Rewards obtained: [-3941.4469626981245], Lows: [2008], Highs: [10], Total time: 32208.004386000004
[32m[0907 00-07-14 @MBExp.py:144][0m ####################################################################
[32m[0907 00-07-14 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 00-07-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29477, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-07-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20006, current rewards: -3.55746, mean: -0.05929
[32m[0907 00-07-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19021, current rewards: 2.95030, mean: 0.02682
[32m[0907 00-07-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18659, current rewards: 9.45968, mean: 0.05912
[32m[0907 00-07-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18454, current rewards: 15.96333, mean: 0.07602
[32m[0907 00-08-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18340, current rewards: 22.47299, mean: 0.08643
[32m[0907 00-08-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18263, current rewards: 28.98253, mean: 0.09349
[32m[0907 00-08-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18208, current rewards: 37.89120, mean: 0.10525
[32m[0907 00-08-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18169, current rewards: 44.80392, mean: 0.10928
[32m[0907 00-08-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18145, current rewards: 51.62542, mean: 0.11223
[32m[0907 00-08-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18116, current rewards: 58.44393, mean: 0.11460
[32m[0907 00-08-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18140, current rewards: 65.26779, mean: 0.11655
[32m[0907 00-09-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18160, current rewards: 72.08944, mean: 0.11818
[32m[0907 00-09-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18180, current rewards: 78.90363, mean: 0.11955
[32m[0907 00-09-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18179, current rewards: 85.72197, mean: 0.12074
[32m[0907 00-09-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18166, current rewards: 50.48859, mean: 0.06643
[32m[0907 00-09-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18112, current rewards: 59.58937, mean: 0.07357
[32m[0907 00-09-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18065, current rewards: 66.11446, mean: 0.07688
[32m[0907 00-09-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17994, current rewards: 72.61675, mean: 0.07980
[32m[0907 00-10-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17929, current rewards: 79.12573, mean: 0.08242
[32m[0907 00-10-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17866, current rewards: 85.64210, mean: 0.08479
[32m[0907 00-10-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17840, current rewards: 51.98017, mean: 0.04904
[32m[0907 00-10-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18002, current rewards: 7.58547, mean: 0.00683
[32m[0907 00-10-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18277, current rewards: -1.15915, mean: -0.00100
[32m[0907 00-10-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18232, current rewards: -11.75130, mean: -0.00971
[32m[0907 00-11-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18174, current rewards: -4.47709, mean: -0.00355
[32m[0907 00-11-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18120, current rewards: -48.74966, mean: -0.03721
[32m[0907 00-11-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18071, current rewards: -98.74966, mean: -0.07261
[32m[0907 00-11-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18022, current rewards: -148.74966, mean: -0.10550
[32m[0907 00-11-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17978, current rewards: -198.74966, mean: -0.13613
[32m[0907 00-11-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17935, current rewards: -248.74966, mean: -0.16473
[32m[0907 00-11-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17912, current rewards: -298.74966, mean: -0.19151
[32m[0907 00-12-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17907, current rewards: -348.74966, mean: -0.21661
[32m[0907 00-12-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17906, current rewards: -398.74966, mean: -0.24021
[32m[0907 00-12-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17915, current rewards: -448.74966, mean: -0.26243
[32m[0907 00-12-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17929, current rewards: -498.74966, mean: -0.28338
[32m[0907 00-12-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17941, current rewards: -548.74966, mean: -0.30318
[32m[0907 00-12-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17954, current rewards: -598.74966, mean: -0.32191
[32m[0907 00-12-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17965, current rewards: -648.74966, mean: -0.33966
[32m[0907 00-13-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17973, current rewards: -698.74966, mean: -0.35650
[32m[0907 00-13-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17986, current rewards: -748.74966, mean: -0.37251
[32m[0907 00-13-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17997, current rewards: -798.74966, mean: -0.38774
[32m[0907 00-13-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18005, current rewards: -848.74966, mean: -0.40225
[32m[0907 00-13-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18013, current rewards: -898.74966, mean: -0.41609
[32m[0907 00-13-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18020, current rewards: -948.74966, mean: -0.42930
[32m[0907 00-14-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18027, current rewards: -998.74966, mean: -0.44192
[32m[0907 00-14-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18033, current rewards: -1048.74966, mean: -0.45400
[32m[0907 00-14-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18039, current rewards: -1098.74966, mean: -0.46557
[32m[0907 00-14-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18044, current rewards: -1148.74966, mean: -0.47666
[32m[0907 00-14-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18048, current rewards: -1198.74966, mean: -0.48730
[32m[0907 00-14-46 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 00-14-46 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-14-46 @MBExp.py:227][0m Rewards obtained: [-1238.7496628777435], Lows: [83], Highs: [1256], Total time: 32660.039082000003
[32m[0907 00-17-17 @MBExp.py:144][0m ####################################################################
[32m[0907 00-17-17 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 00-17-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17753, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-17-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17916, current rewards: -58.05826, mean: -0.96764
[32m[0907 00-17-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17913, current rewards: -128.50802, mean: -1.16825
[32m[0907 00-17-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17928, current rewards: -196.27367, mean: -1.22671
[32m[0907 00-17-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17899, current rewards: -272.22643, mean: -1.29632
[32m[0907 00-18-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17882, current rewards: -340.96433, mean: -1.31140
[32m[0907 00-18-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17919, current rewards: -411.64734, mean: -1.32789
[32m[0907 00-18-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17904, current rewards: -480.05319, mean: -1.33348
[32m[0907 00-18-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17930, current rewards: -545.80527, mean: -1.33123
[32m[0907 00-18-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17974, current rewards: -614.05484, mean: -1.33490
[32m[0907 00-18-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17991, current rewards: -685.67057, mean: -1.34445
[32m[0907 00-18-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18044, current rewards: -767.15892, mean: -1.36993
[32m[0907 00-19-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18089, current rewards: -837.95066, mean: -1.37369
[32m[0907 00-19-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18124, current rewards: -921.38376, mean: -1.39604
[32m[0907 00-19-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18124, current rewards: -999.06859, mean: -1.40714
[32m[0907 00-19-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18107, current rewards: -1081.84658, mean: -1.42348
[32m[0907 00-19-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18092, current rewards: -1159.34262, mean: -1.43129
[32m[0907 00-19-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18037, current rewards: -1241.23343, mean: -1.44329
[32m[0907 00-20-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17965, current rewards: -1318.43674, mean: -1.44883
[32m[0907 00-20-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17902, current rewards: -1398.04106, mean: -1.45629
[32m[0907 00-20-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17858, current rewards: -1477.69139, mean: -1.46306
[32m[0907 00-20-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17860, current rewards: -1546.07441, mean: -1.45856
[32m[0907 00-20-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17849, current rewards: -1601.03607, mean: -1.44237
[32m[0907 00-20-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17799, current rewards: -1595.77117, mean: -1.37566
[32m[0907 00-20-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17753, current rewards: -1590.76381, mean: -1.31468
[32m[0907 00-21-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17711, current rewards: -1585.75968, mean: -1.25854
[32m[0907 00-21-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17675, current rewards: -1580.75340, mean: -1.20668
[32m[0907 00-21-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17653, current rewards: -1634.65303, mean: -1.20195
[32m[0907 00-21-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17661, current rewards: -1707.92451, mean: -1.21129
[32m[0907 00-21-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17643, current rewards: -1780.00293, mean: -1.21918
[32m[0907 00-21-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17651, current rewards: -1853.03799, mean: -1.22718
[32m[0907 00-21-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17658, current rewards: -1927.20737, mean: -1.23539
[32m[0907 00-22-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17661, current rewards: -1996.15743, mean: -1.23985
[32m[0907 00-22-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17689, current rewards: -2069.93125, mean: -1.24695
[32m[0907 00-22-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17728, current rewards: -2148.99648, mean: -1.25672
[32m[0907 00-22-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17753, current rewards: -2229.98225, mean: -1.26704
[32m[0907 00-22-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17781, current rewards: -2302.77397, mean: -1.27225
[32m[0907 00-22-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17810, current rewards: -2371.05993, mean: -1.27476
[32m[0907 00-22-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17837, current rewards: -2447.86341, mean: -1.28160
[32m[0907 00-23-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17871, current rewards: -2511.25217, mean: -1.28125
[32m[0907 00-23-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17882, current rewards: -2531.05549, mean: -1.25923
[32m[0907 00-23-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17895, current rewards: -2549.20181, mean: -1.23748
[32m[0907 00-23-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17905, current rewards: -2569.16127, mean: -1.21761
[32m[0907 00-23-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17917, current rewards: -2589.11359, mean: -1.19866
[32m[0907 00-23-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17927, current rewards: -2607.27669, mean: -1.17976
[32m[0907 00-24-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17936, current rewards: -2629.60126, mean: -1.16354
[32m[0907 00-24-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17943, current rewards: -2654.26468, mean: -1.14903
[32m[0907 00-24-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17950, current rewards: -2684.59692, mean: -1.13754
[32m[0907 00-24-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17957, current rewards: -2684.18609, mean: -1.11377
[32m[0907 00-24-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17963, current rewards: -2685.85846, mean: -1.09181
[32m[0907 00-24-47 @Agent.py:117][0m Average action selection time: 0.1797
[32m[0907 00-24-47 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-24-47 @MBExp.py:227][0m Rewards obtained: [-2687.56289932156], Lows: [1371], Highs: [128], Total time: 33110.024926000006
[32m[0907 00-27-20 @MBExp.py:144][0m ####################################################################
[32m[0907 00-27-20 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 00-27-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17735, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-27-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17855, current rewards: -2.72352, mean: -0.04539
[32m[0907 00-27-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17837, current rewards: 4.80287, mean: 0.04366
[32m[0907 00-27-48 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17841, current rewards: 12.32796, mean: 0.07705
[32m[0907 00-27-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17862, current rewards: -78.82518, mean: -0.37536
[32m[0907 00-28-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17887, current rewards: -123.36185, mean: -0.47447
[32m[0907 00-28-15 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17877, current rewards: -108.96483, mean: -0.35150
[32m[0907 00-28-24 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17872, current rewards: -84.38503, mean: -0.23440
[32m[0907 00-28-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17871, current rewards: -57.02433, mean: -0.13908
[32m[0907 00-28-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17873, current rewards: -29.66032, mean: -0.06448
[32m[0907 00-28-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17894, current rewards: -26.97407, mean: -0.05289
[32m[0907 00-29-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17906, current rewards: -30.72951, mean: -0.05487
[32m[0907 00-29-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17985, current rewards: -54.55078, mean: -0.08943
[32m[0907 00-29-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18009, current rewards: -54.06806, mean: -0.08192
[32m[0907 00-29-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18020, current rewards: -86.22161, mean: -0.12144
[32m[0907 00-29-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18013, current rewards: -96.43831, mean: -0.12689
[32m[0907 00-29-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17976, current rewards: -114.71952, mean: -0.14163
[32m[0907 00-29-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17948, current rewards: -131.61446, mean: -0.15304
[32m[0907 00-30-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17933, current rewards: -161.36756, mean: -0.17733
[32m[0907 00-30-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17888, current rewards: -179.58543, mean: -0.18707
[32m[0907 00-30-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17831, current rewards: -189.54291, mean: -0.18767
[32m[0907 00-30-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17790, current rewards: -192.93975, mean: -0.18202
[32m[0907 00-30-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17745, current rewards: -192.80927, mean: -0.17370
[32m[0907 00-30-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17720, current rewards: -215.09306, mean: -0.18543
[32m[0907 00-30-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17679, current rewards: -251.22839, mean: -0.20763
[32m[0907 00-31-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17641, current rewards: -240.06932, mean: -0.19053
[32m[0907 00-31-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17607, current rewards: -229.18895, mean: -0.17495
[32m[0907 00-31-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17574, current rewards: -218.33756, mean: -0.16054
[32m[0907 00-31-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17544, current rewards: -207.45265, mean: -0.14713
[32m[0907 00-31-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17517, current rewards: -196.63877, mean: -0.13468
[32m[0907 00-31-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17492, current rewards: -193.07279, mean: -0.12786
[32m[0907 00-31-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17477, current rewards: -201.39906, mean: -0.12910
[32m[0907 00-32-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17476, current rewards: -192.57292, mean: -0.11961
[32m[0907 00-32-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17494, current rewards: -183.74945, mean: -0.11069
[32m[0907 00-32-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17521, current rewards: -174.92719, mean: -0.10230
[32m[0907 00-32-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17547, current rewards: -166.10175, mean: -0.09438
[32m[0907 00-32-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17572, current rewards: -157.28864, mean: -0.08690
[32m[0907 00-32-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17593, current rewards: -148.47969, mean: -0.07983
[32m[0907 00-32-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17613, current rewards: -139.61588, mean: -0.07310
[32m[0907 00-33-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17656, current rewards: -199.37644, mean: -0.10172
[32m[0907 00-33-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17673, current rewards: -211.30974, mean: -0.10513
[32m[0907 00-33-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17689, current rewards: -214.68821, mean: -0.10422
[32m[0907 00-33-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17705, current rewards: -217.44291, mean: -0.10305
[32m[0907 00-33-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17720, current rewards: -218.15448, mean: -0.10100
[32m[0907 00-33-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17735, current rewards: -221.01524, mean: -0.10001
[32m[0907 00-34-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17748, current rewards: -221.66074, mean: -0.09808
[32m[0907 00-34-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17763, current rewards: -224.50034, mean: -0.09719
[32m[0907 00-34-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17779, current rewards: -225.06687, mean: -0.09537
[32m[0907 00-34-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17792, current rewards: -227.80619, mean: -0.09453
[32m[0907 00-34-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17804, current rewards: -253.00455, mean: -0.10285
[32m[0907 00-34-46 @Agent.py:117][0m Average action selection time: 0.1781
[32m[0907 00-34-46 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-34-46 @MBExp.py:227][0m Rewards obtained: [-245.93534038979627], Lows: [325], Highs: [70], Total time: 33556.128747
[32m[0907 00-37-21 @MBExp.py:144][0m ####################################################################
[32m[0907 00-37-21 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 00-37-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17833, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-37-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19935, current rewards: -38.26168, mean: -0.63769
[32m[0907 00-37-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19966, current rewards: -56.03047, mean: -0.50937
[32m[0907 00-37-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20103, current rewards: -74.33256, mean: -0.46458
[32m[0907 00-38-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20165, current rewards: -95.24333, mean: -0.45354
[32m[0907 00-38-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20208, current rewards: -113.61851, mean: -0.43699
[32m[0907 00-38-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20528, current rewards: -120.37346, mean: -0.38830
[32m[0907 00-38-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20548, current rewards: -131.33563, mean: -0.36482
[32m[0907 00-38-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20614, current rewards: -148.07340, mean: -0.36115
[32m[0907 00-38-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20768, current rewards: -172.80871, mean: -0.37567
[32m[0907 00-39-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20903, current rewards: -197.86157, mean: -0.38796
[32m[0907 00-39-19 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20949, current rewards: -203.02158, mean: -0.36254
[32m[0907 00-39-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20868, current rewards: -196.27294, mean: -0.32176
[32m[0907 00-39-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.20701, current rewards: -190.00167, mean: -0.28788
[32m[0907 00-39-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.20555, current rewards: -183.96491, mean: -0.25911
[32m[0907 00-39-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.20382, current rewards: -177.40926, mean: -0.23343
[32m[0907 00-40-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.20266, current rewards: -171.02564, mean: -0.21114
[32m[0907 00-40-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.20154, current rewards: -164.67418, mean: -0.19148
[32m[0907 00-40-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.20082, current rewards: -158.15956, mean: -0.17380
[32m[0907 00-40-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19994, current rewards: -151.76201, mean: -0.15809
[32m[0907 00-40-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19901, current rewards: -145.30910, mean: -0.14387
[32m[0907 00-40-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19822, current rewards: -138.85840, mean: -0.13100
[32m[0907 00-41-02 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19816, current rewards: -138.17495, mean: -0.12448
[32m[0907 00-41-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19823, current rewards: -133.20462, mean: -0.11483
[32m[0907 00-41-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19695, current rewards: -194.62721, mean: -0.16085
[32m[0907 00-41-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19577, current rewards: -256.87126, mean: -0.20387
[32m[0907 00-41-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19470, current rewards: -314.57335, mean: -0.24013
[32m[0907 00-41-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19370, current rewards: -374.54719, mean: -0.27540
[32m[0907 00-41-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19275, current rewards: -434.51234, mean: -0.30816
[32m[0907 00-42-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19200, current rewards: -479.72997, mean: -0.32858
[32m[0907 00-42-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19156, current rewards: -468.99590, mean: -0.31059
[32m[0907 00-42-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19123, current rewards: -462.71928, mean: -0.29661
[32m[0907 00-42-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19103, current rewards: -456.80140, mean: -0.28373
[32m[0907 00-42-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19082, current rewards: -450.88352, mean: -0.27162
[32m[0907 00-42-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19061, current rewards: -444.96564, mean: -0.26021
[32m[0907 00-42-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19043, current rewards: -452.46806, mean: -0.25708
[32m[0907 00-43-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19023, current rewards: -502.46806, mean: -0.27761
[32m[0907 00-43-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.19005, current rewards: -552.46806, mean: -0.29703
[32m[0907 00-43-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18986, current rewards: -602.46806, mean: -0.31543
[32m[0907 00-43-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18966, current rewards: -652.46806, mean: -0.33289
[32m[0907 00-43-43 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18950, current rewards: -702.46806, mean: -0.34949
[32m[0907 00-43-52 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18936, current rewards: -752.46806, mean: -0.36528
[32m[0907 00-44-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18922, current rewards: -802.46806, mean: -0.38032
[32m[0907 00-44-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18908, current rewards: -852.46806, mean: -0.39466
[32m[0907 00-44-20 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18897, current rewards: -902.46806, mean: -0.40836
[32m[0907 00-44-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18886, current rewards: -952.46806, mean: -0.42145
[32m[0907 00-44-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18873, current rewards: -1002.46806, mean: -0.43397
[32m[0907 00-44-47 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18866, current rewards: -1052.46806, mean: -0.44596
[32m[0907 00-44-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18855, current rewards: -1102.46806, mean: -0.45746
[32m[0907 00-45-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18844, current rewards: -1152.46806, mean: -0.46848
[32m[0907 00-45-13 @Agent.py:117][0m Average action selection time: 0.1884
[32m[0907 00-45-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-45-13 @MBExp.py:227][0m Rewards obtained: [-1192.4680586750756], Lows: [252], Highs: [872], Total time: 34027.799210000005
[32m[0907 00-47-49 @MBExp.py:144][0m ####################################################################
[32m[0907 00-47-49 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 00-47-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17876, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-48-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17867, current rewards: -109.00000, mean: -1.81667
[32m[0907 00-48-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17836, current rewards: -209.00000, mean: -1.90000
[32m[0907 00-48-18 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17848, current rewards: -309.00000, mean: -1.93125
[32m[0907 00-48-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17864, current rewards: -409.00000, mean: -1.94762
[32m[0907 00-48-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17865, current rewards: -509.00000, mean: -1.95769
[32m[0907 00-48-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17861, current rewards: -609.00000, mean: -1.96452
[32m[0907 00-48-53 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17858, current rewards: -709.00000, mean: -1.96944
[32m[0907 00-49-02 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17864, current rewards: -809.00000, mean: -1.97317
[32m[0907 00-49-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17913, current rewards: -909.00000, mean: -1.97609
[32m[0907 00-49-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17957, current rewards: -1009.00000, mean: -1.97843
[32m[0907 00-49-30 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17982, current rewards: -1109.00000, mean: -1.98036
[32m[0907 00-49-39 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17960, current rewards: -1209.00000, mean: -1.98197
[32m[0907 00-49-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17908, current rewards: -1309.00000, mean: -1.98333
[32m[0907 00-49-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17831, current rewards: -1409.00000, mean: -1.98451
[32m[0907 00-50-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17759, current rewards: -1509.00000, mean: -1.98553
[32m[0907 00-50-13 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17695, current rewards: -1609.00000, mean: -1.98642
[32m[0907 00-50-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17642, current rewards: -1709.00000, mean: -1.98721
[32m[0907 00-50-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17594, current rewards: -1809.00000, mean: -1.98791
[32m[0907 00-50-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17552, current rewards: -1909.00000, mean: -1.98854
[32m[0907 00-50-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17514, current rewards: -2009.00000, mean: -1.98911
[32m[0907 00-50-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17476, current rewards: -2109.00000, mean: -1.98962
[32m[0907 00-51-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17445, current rewards: -2209.00000, mean: -1.99009
[32m[0907 00-51-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17415, current rewards: -2309.00000, mean: -1.99052
[32m[0907 00-51-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17386, current rewards: -2409.00000, mean: -1.99091
[32m[0907 00-51-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17360, current rewards: -2509.00000, mean: -1.99127
[32m[0907 00-51-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17337, current rewards: -2609.00000, mean: -1.99160
[32m[0907 00-51-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17316, current rewards: -2709.00000, mean: -1.99191
[32m[0907 00-51-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17295, current rewards: -2809.00000, mean: -1.99220
[32m[0907 00-52-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17276, current rewards: -2909.00000, mean: -1.99247
[32m[0907 00-52-10 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17279, current rewards: -3009.00000, mean: -1.99272
[32m[0907 00-52-19 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17300, current rewards: -3109.00000, mean: -1.99295
[32m[0907 00-52-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17333, current rewards: -3209.00000, mean: -1.99317
[32m[0907 00-52-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17366, current rewards: -3309.00000, mean: -1.99337
[32m[0907 00-52-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17395, current rewards: -3409.00000, mean: -1.99357
[32m[0907 00-52-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17419, current rewards: -3509.00000, mean: -1.99375
[32m[0907 00-53-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17445, current rewards: -3609.00000, mean: -1.99392
[32m[0907 00-53-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17472, current rewards: -3709.00000, mean: -1.99409
[32m[0907 00-53-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17492, current rewards: -3809.00000, mean: -1.99424
[32m[0907 00-53-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17514, current rewards: -3909.00000, mean: -1.99439
[32m[0907 00-53-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17534, current rewards: -4009.00000, mean: -1.99453
[32m[0907 00-53-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17552, current rewards: -4109.00000, mean: -1.99466
[32m[0907 00-54-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17568, current rewards: -4209.00000, mean: -1.99479
[32m[0907 00-54-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17586, current rewards: -4309.00000, mean: -1.99491
[32m[0907 00-54-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17603, current rewards: -4409.00000, mean: -1.99502
[32m[0907 00-54-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17617, current rewards: -4509.00000, mean: -1.99513
[32m[0907 00-54-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17632, current rewards: -4609.00000, mean: -1.99524
[32m[0907 00-54-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17646, current rewards: -4709.00000, mean: -1.99534
[32m[0907 00-54-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17658, current rewards: -4809.00000, mean: -1.99544
[32m[0907 00-55-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17672, current rewards: -4909.00000, mean: -1.99553
[32m[0907 00-55-12 @Agent.py:117][0m Average action selection time: 0.1768
[32m[0907 00-55-12 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-55-12 @MBExp.py:227][0m Rewards obtained: [-4989], Lows: [2489], Highs: [11], Total time: 34470.665589000004
[32m[0907 00-57-50 @MBExp.py:144][0m ####################################################################
[32m[0907 00-57-50 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 00-57-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28442, current rewards: 0.83778, mean: 0.08378
[32m[0907 00-58-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19598, current rewards: -81.64206, mean: -1.36070
[32m[0907 00-58-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18797, current rewards: -132.94277, mean: -1.20857
[32m[0907 00-58-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18499, current rewards: -186.41359, mean: -1.16508
[32m[0907 00-58-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18678, current rewards: -237.18020, mean: -1.12943
[32m[0907 00-58-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18515, current rewards: -337.18020, mean: -1.29685
[32m[0907 00-58-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18399, current rewards: -437.18020, mean: -1.41026
[32m[0907 00-58-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18327, current rewards: -537.18020, mean: -1.49217
[32m[0907 00-59-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18272, current rewards: -637.18020, mean: -1.55410
[32m[0907 00-59-14 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18274, current rewards: -734.62803, mean: -1.59702
[32m[0907 00-59-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18283, current rewards: -740.59650, mean: -1.45215
[32m[0907 00-59-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18296, current rewards: -734.51593, mean: -1.31164
[32m[0907 00-59-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18268, current rewards: -728.43525, mean: -1.19416
[32m[0907 00-59-51 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18191, current rewards: -722.36248, mean: -1.09449
[32m[0907 00-59-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18130, current rewards: -716.28457, mean: -1.00885
[32m[0907 01-00-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18074, current rewards: -757.43364, mean: -0.99662
[32m[0907 01-00-16 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17991, current rewards: -850.06284, mean: -1.04946
[32m[0907 01-00-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17920, current rewards: -950.06284, mean: -1.10472
[32m[0907 01-00-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17854, current rewards: -1050.06284, mean: -1.15392
[32m[0907 01-00-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17794, current rewards: -1150.06284, mean: -1.19798
[32m[0907 01-00-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17738, current rewards: -1250.06284, mean: -1.23769
[32m[0907 01-00-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17694, current rewards: -1350.06284, mean: -1.27364
[32m[0907 01-01-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17653, current rewards: -1450.06284, mean: -1.30636
[32m[0907 01-01-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17611, current rewards: -1550.06284, mean: -1.33626
[32m[0907 01-01-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17571, current rewards: -1650.06284, mean: -1.36369
[32m[0907 01-01-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17542, current rewards: -1750.06284, mean: -1.38894
[32m[0907 01-01-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17510, current rewards: -1850.06284, mean: -1.41226
[32m[0907 01-01-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17480, current rewards: -1950.06284, mean: -1.43387
[32m[0907 01-01-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17454, current rewards: -2050.06284, mean: -1.45395
[32m[0907 01-02-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17429, current rewards: -2150.06284, mean: -1.47265
[32m[0907 01-02-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17412, current rewards: -2250.06284, mean: -1.49011
[32m[0907 01-02-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17422, current rewards: -2350.06284, mean: -1.50645
[32m[0907 01-02-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17435, current rewards: -2450.06284, mean: -1.52178
[32m[0907 01-02-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17447, current rewards: -2550.06284, mean: -1.53618
[32m[0907 01-02-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17473, current rewards: -2650.06284, mean: -1.54974
[32m[0907 01-02-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17498, current rewards: -2750.06284, mean: -1.56254
[32m[0907 01-03-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17521, current rewards: -2850.06284, mean: -1.57462
[32m[0907 01-03-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17543, current rewards: -2950.06284, mean: -1.58606
[32m[0907 01-03-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17563, current rewards: -3047.59116, mean: -1.59560
[32m[0907 01-03-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17585, current rewards: -3083.01291, mean: -1.57297
[32m[0907 01-03-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17607, current rewards: -3079.34477, mean: -1.53201
[32m[0907 01-03-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17625, current rewards: -3076.75850, mean: -1.49357
[32m[0907 01-04-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17642, current rewards: -3073.76425, mean: -1.45676
[32m[0907 01-04-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17657, current rewards: -3070.63259, mean: -1.42159
[32m[0907 01-04-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17673, current rewards: -3066.93917, mean: -1.38776
[32m[0907 01-04-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17688, current rewards: -3063.59400, mean: -1.35557
[32m[0907 01-04-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17703, current rewards: -3068.27566, mean: -1.32826
[32m[0907 01-04-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17716, current rewards: -3076.89208, mean: -1.30377
[32m[0907 01-04-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17731, current rewards: -3080.57857, mean: -1.27825
[32m[0907 01-05-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17745, current rewards: -3088.88818, mean: -1.25565
[32m[0907 01-05-15 @Agent.py:117][0m Average action selection time: 0.1776
[32m[0907 01-05-15 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-05-15 @MBExp.py:227][0m Rewards obtained: [-3093.297334157416], Lows: [1658], Highs: [21], Total time: 34915.334703
[32m[0907 01-07-55 @MBExp.py:144][0m ####################################################################
[32m[0907 01-07-55 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 01-07-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17791, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-08-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17846, current rewards: -36.11802, mean: -0.60197
[32m[0907 01-08-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17843, current rewards: -28.41765, mean: -0.25834
[32m[0907 01-08-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17837, current rewards: -20.68945, mean: -0.12931
[32m[0907 01-08-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17848, current rewards: -13.02662, mean: -0.06203
[32m[0907 01-08-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17853, current rewards: -6.02313, mean: -0.02317
[32m[0907 01-08-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17853, current rewards: 1.66407, mean: 0.00537
[32m[0907 01-09-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17853, current rewards: 9.37068, mean: 0.02603
[32m[0907 01-09-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17854, current rewards: 17.08731, mean: 0.04168
[32m[0907 01-09-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17894, current rewards: 5.40272, mean: 0.01175
[32m[0907 01-09-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17946, current rewards: 9.89184, mean: 0.01940
[32m[0907 01-09-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17972, current rewards: 14.65808, mean: 0.02618
[32m[0907 01-09-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17984, current rewards: 19.41774, mean: 0.03183
[32m[0907 01-09-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17982, current rewards: 23.94275, mean: 0.03628
[32m[0907 01-10-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17956, current rewards: 29.08201, mean: 0.04096
[32m[0907 01-10-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17915, current rewards: 34.22617, mean: 0.04503
[32m[0907 01-10-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17848, current rewards: 39.36644, mean: 0.04860
[32m[0907 01-10-28 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17784, current rewards: 44.50967, mean: 0.05176
[32m[0907 01-10-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17722, current rewards: 49.65846, mean: 0.05457
[32m[0907 01-10-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17670, current rewards: 54.80084, mean: 0.05708
[32m[0907 01-10-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17624, current rewards: 59.94469, mean: 0.05935
[32m[0907 01-11-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17581, current rewards: 64.98055, mean: 0.06130
[32m[0907 01-11-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17543, current rewards: 70.18822, mean: 0.06323
[32m[0907 01-11-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17507, current rewards: 43.08059, mean: 0.03714
[32m[0907 01-11-27 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17475, current rewards: 51.18794, mean: 0.04230
[32m[0907 01-11-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17447, current rewards: 59.17702, mean: 0.04697
[32m[0907 01-11-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17419, current rewards: 67.16492, mean: 0.05127
[32m[0907 01-11-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17392, current rewards: 75.14074, mean: 0.05525
[32m[0907 01-12-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17370, current rewards: 83.12420, mean: 0.05895
[32m[0907 01-12-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17349, current rewards: 63.58590, mean: 0.04355
[32m[0907 01-12-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17327, current rewards: 9.42954, mean: 0.00624
[32m[0907 01-12-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17321, current rewards: -40.57050, mean: -0.02601
[32m[0907 01-12-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17321, current rewards: -82.25111, mean: -0.05109
[32m[0907 01-12-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17333, current rewards: -130.11957, mean: -0.07839
[32m[0907 01-12-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17352, current rewards: -184.27823, mean: -0.10777
[32m[0907 01-13-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17382, current rewards: -230.12316, mean: -0.13075
[32m[0907 01-13-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17410, current rewards: -244.77373, mean: -0.13523
[32m[0907 01-13-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17436, current rewards: -236.46263, mean: -0.12713
[32m[0907 01-13-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17460, current rewards: -230.14196, mean: -0.12049
[32m[0907 01-13-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17486, current rewards: -223.88365, mean: -0.11423
[32m[0907 01-13-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17507, current rewards: -217.62594, mean: -0.10827
[32m[0907 01-13-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17528, current rewards: -211.36391, mean: -0.10260
[32m[0907 01-14-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17547, current rewards: -205.10896, mean: -0.09721
[32m[0907 01-14-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17567, current rewards: -198.85863, mean: -0.09206
[32m[0907 01-14-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17586, current rewards: -221.63187, mean: -0.10029
[32m[0907 01-14-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17602, current rewards: -273.34244, mean: -0.12095
[32m[0907 01-14-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17617, current rewards: -328.71569, mean: -0.14230
[32m[0907 01-14-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17631, current rewards: -384.35311, mean: -0.16286
[32m[0907 01-15-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17646, current rewards: -438.01949, mean: -0.18175
[32m[0907 01-15-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17660, current rewards: -488.59578, mean: -0.19862
[32m[0907 01-15-18 @Agent.py:117][0m Average action selection time: 0.1767
[32m[0907 01-15-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-15-18 @MBExp.py:227][0m Rewards obtained: [-536.7360059288678], Lows: [403], Highs: [22], Total time: 35357.875456
[32m[0907 01-18-00 @MBExp.py:144][0m ####################################################################
[32m[0907 01-18-00 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 01-18-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17655, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-18-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17781, current rewards: -28.44697, mean: -0.47412
[32m[0907 01-18-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17985, current rewards: -65.98390, mean: -0.59985
[32m[0907 01-18-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17945, current rewards: -80.30931, mean: -0.50193
[32m[0907 01-18-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17916, current rewards: -74.73932, mean: -0.35590
[32m[0907 01-18-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17900, current rewards: -69.79373, mean: -0.26844
[32m[0907 01-18-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17895, current rewards: -64.85007, mean: -0.20919
[32m[0907 01-19-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17889, current rewards: -59.90802, mean: -0.16641
[32m[0907 01-19-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17882, current rewards: -54.96459, mean: -0.13406
[32m[0907 01-19-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17897, current rewards: -50.02111, mean: -0.10874
[32m[0907 01-19-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17954, current rewards: -45.07595, mean: -0.08838
[32m[0907 01-19-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17995, current rewards: -40.13242, mean: -0.07167
[32m[0907 01-19-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18015, current rewards: -33.45823, mean: -0.05485
[32m[0907 01-19-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18015, current rewards: -27.93610, mean: -0.04233
[32m[0907 01-20-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18003, current rewards: -29.35092, mean: -0.04134
[32m[0907 01-20-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18052, current rewards: -54.39648, mean: -0.07157
[32m[0907 01-20-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18140, current rewards: -61.89953, mean: -0.07642
[32m[0907 01-20-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18139, current rewards: -99.38343, mean: -0.11556
[32m[0907 01-20-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18121, current rewards: -145.95743, mean: -0.16039
[32m[0907 01-20-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18141, current rewards: -186.99240, mean: -0.19478
[32m[0907 01-21-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18143, current rewards: -223.21138, mean: -0.22100
[32m[0907 01-21-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18177, current rewards: -244.20872, mean: -0.23039
[32m[0907 01-21-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18213, current rewards: -265.52051, mean: -0.23921
[32m[0907 01-21-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18205, current rewards: -309.52848, mean: -0.26683
[32m[0907 01-21-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18144, current rewards: -301.05958, mean: -0.24881
[32m[0907 01-21-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18089, current rewards: -292.74434, mean: -0.23234
[32m[0907 01-21-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18038, current rewards: -284.43355, mean: -0.21712
[32m[0907 01-22-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17990, current rewards: -276.11283, mean: -0.20302
[32m[0907 01-22-13 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17947, current rewards: -267.79858, mean: -0.18993
[32m[0907 01-22-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17905, current rewards: -269.36142, mean: -0.18449
[32m[0907 01-22-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17866, current rewards: -260.08900, mean: -0.17224
[32m[0907 01-22-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17843, current rewards: -250.78761, mean: -0.16076
[32m[0907 01-22-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17825, current rewards: -241.49140, mean: -0.14999
[32m[0907 01-22-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17812, current rewards: -232.18333, mean: -0.13987
[32m[0907 01-23-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17812, current rewards: -229.44186, mean: -0.13418
[32m[0907 01-23-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17828, current rewards: -238.46321, mean: -0.13549
[32m[0907 01-23-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17841, current rewards: -228.42997, mean: -0.12620
[32m[0907 01-23-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17855, current rewards: -218.98802, mean: -0.11774
[32m[0907 01-23-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17866, current rewards: -208.73380, mean: -0.10928
[32m[0907 01-23-51 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17878, current rewards: -196.33230, mean: -0.10017
[32m[0907 01-24-00 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17889, current rewards: -205.54033, mean: -0.10226
[32m[0907 01-24-09 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17902, current rewards: -199.48889, mean: -0.09684
[32m[0907 01-24-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17910, current rewards: -193.96904, mean: -0.09193
[32m[0907 01-24-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17920, current rewards: -188.44946, mean: -0.08725
[32m[0907 01-24-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17932, current rewards: -182.92659, mean: -0.08277
[32m[0907 01-24-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17941, current rewards: -177.41440, mean: -0.07850
[32m[0907 01-24-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17951, current rewards: -171.89316, mean: -0.07441
[32m[0907 01-25-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17958, current rewards: -166.36614, mean: -0.07049
[32m[0907 01-25-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17965, current rewards: -160.85213, mean: -0.06674
[32m[0907 01-25-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17996, current rewards: -171.52684, mean: -0.06973
[32m[0907 01-25-32 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 01-25-32 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-25-32 @MBExp.py:227][0m Rewards obtained: [-170.576012168242], Lows: [231], Highs: [58], Total time: 35809.92836
[32m[0907 01-28-17 @MBExp.py:144][0m ####################################################################
[32m[0907 01-28-17 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 01-28-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19107, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-28-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18344, current rewards: -92.26440, mean: -1.53774
[32m[0907 01-28-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18163, current rewards: -192.26440, mean: -1.74786
[32m[0907 01-28-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18117, current rewards: -292.26440, mean: -1.82665
[32m[0907 01-28-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18107, current rewards: -392.26440, mean: -1.86793
[32m[0907 01-29-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18070, current rewards: -492.26440, mean: -1.89332
[32m[0907 01-29-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18040, current rewards: -592.26440, mean: -1.91053
[32m[0907 01-29-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18023, current rewards: -692.26440, mean: -1.92296
[32m[0907 01-29-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18012, current rewards: -792.26440, mean: -1.93235
[32m[0907 01-29-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18062, current rewards: -892.26440, mean: -1.93971
[32m[0907 01-29-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18110, current rewards: -992.26440, mean: -1.94562
[32m[0907 01-29-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18139, current rewards: -1092.26440, mean: -1.95047
[32m[0907 01-30-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18150, current rewards: -1192.26440, mean: -1.95453
[32m[0907 01-30-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18137, current rewards: -1292.26440, mean: -1.95798
[32m[0907 01-30-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18131, current rewards: -1392.26440, mean: -1.96094
[32m[0907 01-30-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18117, current rewards: -1492.26440, mean: -1.96351
[32m[0907 01-30-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18074, current rewards: -1592.26440, mean: -1.96576
[32m[0907 01-30-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18013, current rewards: -1692.26440, mean: -1.96775
[32m[0907 01-31-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17945, current rewards: -1792.26440, mean: -1.96952
[32m[0907 01-31-09 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17882, current rewards: -1892.26440, mean: -1.97111
[32m[0907 01-31-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17826, current rewards: -1992.26440, mean: -1.97254
[32m[0907 01-31-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17775, current rewards: -2092.26440, mean: -1.97383
[32m[0907 01-31-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17727, current rewards: -2192.26440, mean: -1.97501
[32m[0907 01-31-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17683, current rewards: -2292.26440, mean: -1.97609
[32m[0907 01-31-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17640, current rewards: -2392.26440, mean: -1.97708
[32m[0907 01-31-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17604, current rewards: -2492.26440, mean: -1.97799
[32m[0907 01-32-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17573, current rewards: -2592.26440, mean: -1.97883
[32m[0907 01-32-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17538, current rewards: -2692.26440, mean: -1.97961
[32m[0907 01-32-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17509, current rewards: -2792.26440, mean: -1.98033
[32m[0907 01-32-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17483, current rewards: -2892.26440, mean: -1.98100
[32m[0907 01-32-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17456, current rewards: -2992.26440, mean: -1.98163
[32m[0907 01-32-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17438, current rewards: -3092.26440, mean: -1.98222
[32m[0907 01-32-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17437, current rewards: -3192.26440, mean: -1.98277
[32m[0907 01-33-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17435, current rewards: -3292.26440, mean: -1.98329
[32m[0907 01-33-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17431, current rewards: -3392.26440, mean: -1.98378
[32m[0907 01-33-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17441, current rewards: -3492.26440, mean: -1.98424
[32m[0907 01-33-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17463, current rewards: -3592.26440, mean: -1.98468
[32m[0907 01-33-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17489, current rewards: -3692.26440, mean: -1.98509
[32m[0907 01-33-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17512, current rewards: -3792.26440, mean: -1.98548
[32m[0907 01-34-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17536, current rewards: -3892.26440, mean: -1.98585
[32m[0907 01-34-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17556, current rewards: -3992.26440, mean: -1.98620
[32m[0907 01-34-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17575, current rewards: -4092.26440, mean: -1.98654
[32m[0907 01-34-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17591, current rewards: -4192.26440, mean: -1.98686
[32m[0907 01-34-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17609, current rewards: -4292.26440, mean: -1.98716
[32m[0907 01-34-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17624, current rewards: -4392.26440, mean: -1.98745
[32m[0907 01-34-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17640, current rewards: -4492.26440, mean: -1.98773
[32m[0907 01-35-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17658, current rewards: -4592.26440, mean: -1.98799
[32m[0907 01-35-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17672, current rewards: -4692.26440, mean: -1.98825
[32m[0907 01-35-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17686, current rewards: -4792.26440, mean: -1.98849
[32m[0907 01-35-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17698, current rewards: -4892.26440, mean: -1.98873
[32m[0907 01-35-40 @Agent.py:117][0m Average action selection time: 0.1771
[32m[0907 01-35-40 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-35-40 @MBExp.py:227][0m Rewards obtained: [-4972.264396692373], Lows: [2479], Highs: [15], Total time: 36253.441023
[32m[0907 01-38-27 @MBExp.py:144][0m ####################################################################
[32m[0907 01-38-27 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 01-38-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.22481, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-38-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18631, current rewards: -44.03707, mean: -0.73395
[32m[0907 01-38-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18275, current rewards: -34.47952, mean: -0.31345
[32m[0907 01-38-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18136, current rewards: -25.74898, mean: -0.16093
[32m[0907 01-39-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18061, current rewards: -16.12750, mean: -0.07680
[32m[0907 01-39-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18037, current rewards: -6.49611, mean: -0.02499
[32m[0907 01-39-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18019, current rewards: 3.13806, mean: 0.01012
[32m[0907 01-39-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17996, current rewards: 12.74521, mean: 0.03540
[32m[0907 01-39-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17966, current rewards: -35.32473, mean: -0.08616
[32m[0907 01-39-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18007, current rewards: -73.90959, mean: -0.16067
[32m[0907 01-39-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18042, current rewards: -119.74482, mean: -0.23479
[32m[0907 01-40-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18062, current rewards: -161.86421, mean: -0.28904
[32m[0907 01-40-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18076, current rewards: -202.87315, mean: -0.33258
[32m[0907 01-40-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18060, current rewards: -247.53198, mean: -0.37505
[32m[0907 01-40-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18046, current rewards: -300.94406, mean: -0.42386
[32m[0907 01-40-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18037, current rewards: -347.90082, mean: -0.45776
[32m[0907 01-40-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18002, current rewards: -388.32004, mean: -0.47941
[32m[0907 01-41-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17963, current rewards: -431.97552, mean: -0.50230
[32m[0907 01-41-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17925, current rewards: -464.43011, mean: -0.51036
[32m[0907 01-41-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17896, current rewards: -458.56121, mean: -0.47767
[32m[0907 01-41-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17843, current rewards: -451.46691, mean: -0.44700
[32m[0907 01-41-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17791, current rewards: -445.85126, mean: -0.42061
[32m[0907 01-41-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17744, current rewards: -440.23437, mean: -0.39661
[32m[0907 01-41-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17705, current rewards: -473.76517, mean: -0.40842
[32m[0907 01-42-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17799, current rewards: -521.34963, mean: -0.43087
[32m[0907 01-42-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17858, current rewards: -579.56504, mean: -0.45997
[32m[0907 01-42-22 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17953, current rewards: -638.17758, mean: -0.48716
[32m[0907 01-42-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18014, current rewards: -700.96410, mean: -0.51541
[32m[0907 01-42-42 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18078, current rewards: -780.72763, mean: -0.55371
[32m[0907 01-42-51 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18039, current rewards: -838.41222, mean: -0.57425
[32m[0907 01-42-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17995, current rewards: -831.68337, mean: -0.55078
[32m[0907 01-43-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17969, current rewards: -824.54464, mean: -0.52855
[32m[0907 01-43-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17948, current rewards: -817.20652, mean: -0.50758
[32m[0907 01-43-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17931, current rewards: -809.88900, mean: -0.48788
[32m[0907 01-43-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17922, current rewards: -802.73110, mean: -0.46943
[32m[0907 01-43-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17921, current rewards: -795.39322, mean: -0.45193
[32m[0907 01-43-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17920, current rewards: -789.01377, mean: -0.43592
[32m[0907 01-44-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17944, current rewards: -835.75531, mean: -0.44933
[32m[0907 01-44-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17975, current rewards: -904.41160, mean: -0.47351
[32m[0907 01-44-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18020, current rewards: -964.22662, mean: -0.49195
[32m[0907 01-44-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18041, current rewards: -1007.15747, mean: -0.50107
[32m[0907 01-44-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18081, current rewards: -1069.98805, mean: -0.51941
[32m[0907 01-44-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18108, current rewards: -1107.90062, mean: -0.52507
[32m[0907 01-44-59 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18135, current rewards: -1166.80434, mean: -0.54019
[32m[0907 01-45-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18171, current rewards: -1230.44847, mean: -0.55676
[32m[0907 01-45-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18207, current rewards: -1288.07344, mean: -0.56994
[32m[0907 01-45-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18250, current rewards: -1337.54662, mean: -0.57902
[32m[0907 01-45-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18275, current rewards: -1364.01050, mean: -0.57797
[32m[0907 01-45-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18276, current rewards: -1354.56329, mean: -0.56206
[32m[0907 01-45-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18278, current rewards: -1345.15777, mean: -0.54681
[32m[0907 01-46-04 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0907 01-46-04 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-46-05 @MBExp.py:227][0m Rewards obtained: [-1337.612843174999], Lows: [782], Highs: [61], Total time: 36711.205596
[32m[0907 01-48-53 @MBExp.py:144][0m ####################################################################
[32m[0907 01-48-53 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 01-48-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.22479, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-49-04 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18621, current rewards: -11.30800, mean: -0.18847
[32m[0907 01-49-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18264, current rewards: -6.04138, mean: -0.05492
[32m[0907 01-49-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18139, current rewards: -0.87720, mean: -0.00548
[32m[0907 01-49-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18059, current rewards: 4.39453, mean: 0.02093
[32m[0907 01-49-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18016, current rewards: 9.66750, mean: 0.03718
[32m[0907 01-49-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18012, current rewards: 14.93904, mean: 0.04819
[32m[0907 01-49-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17998, current rewards: 20.21028, mean: 0.05614
[32m[0907 01-50-07 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18058, current rewards: 16.70513, mean: 0.04074
[32m[0907 01-50-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18088, current rewards: 25.67035, mean: 0.05581
[32m[0907 01-50-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18114, current rewards: 34.68141, mean: 0.06800
[32m[0907 01-50-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18109, current rewards: 45.41206, mean: 0.08109
[32m[0907 01-50-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18092, current rewards: 54.14763, mean: 0.08877
[32m[0907 01-50-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18080, current rewards: 62.87753, mean: 0.09527
[32m[0907 01-51-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18061, current rewards: 71.60373, mean: 0.10085
[32m[0907 01-51-10 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18012, current rewards: 80.32125, mean: 0.10569
[32m[0907 01-51-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17968, current rewards: 56.92235, mean: 0.07027
[32m[0907 01-51-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17928, current rewards: 62.16704, mean: 0.07229
[32m[0907 01-51-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17895, current rewards: 67.41173, mean: 0.07408
[32m[0907 01-51-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17864, current rewards: 43.28234, mean: 0.04509
[32m[0907 01-51-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17814, current rewards: -6.71766, mean: -0.00665
[32m[0907 01-52-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17759, current rewards: -56.71766, mean: -0.05351
[32m[0907 01-52-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17710, current rewards: -106.71766, mean: -0.09614
[32m[0907 01-52-18 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17666, current rewards: -156.71766, mean: -0.13510
[32m[0907 01-52-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17629, current rewards: -206.71766, mean: -0.17084
[32m[0907 01-52-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17592, current rewards: -256.71766, mean: -0.20374
[32m[0907 01-52-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17558, current rewards: -306.71766, mean: -0.23414
[32m[0907 01-52-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17528, current rewards: -356.71766, mean: -0.26229
[32m[0907 01-53-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17499, current rewards: -406.71766, mean: -0.28845
[32m[0907 01-53-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17473, current rewards: -456.71766, mean: -0.31282
[32m[0907 01-53-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17448, current rewards: -506.71766, mean: -0.33557
[32m[0907 01-53-25 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17444, current rewards: -556.71766, mean: -0.35687
[32m[0907 01-53-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17442, current rewards: -606.71766, mean: -0.37684
[32m[0907 01-53-42 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17439, current rewards: -656.71766, mean: -0.39561
[32m[0907 01-53-51 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17448, current rewards: -706.71766, mean: -0.41329
[32m[0907 01-54-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17463, current rewards: -756.71766, mean: -0.42995
[32m[0907 01-54-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17476, current rewards: -806.71766, mean: -0.44570
[32m[0907 01-54-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17486, current rewards: -856.71766, mean: -0.46060
[32m[0907 01-54-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17497, current rewards: -906.71766, mean: -0.47472
[32m[0907 01-54-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17513, current rewards: -956.71766, mean: -0.48812
[32m[0907 01-54-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17534, current rewards: -1006.71766, mean: -0.50085
[32m[0907 01-54-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17556, current rewards: -1056.71766, mean: -0.51297
[32m[0907 01-55-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17577, current rewards: -1106.71766, mean: -0.52451
[32m[0907 01-55-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17594, current rewards: -1156.71766, mean: -0.53552
[32m[0907 01-55-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17610, current rewards: -1206.71766, mean: -0.54603
[32m[0907 01-55-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17624, current rewards: -1256.71766, mean: -0.55607
[32m[0907 01-55-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17639, current rewards: -1306.71766, mean: -0.56568
[32m[0907 01-55-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17652, current rewards: -1356.71766, mean: -0.57488
[32m[0907 01-55-59 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17667, current rewards: -1406.71766, mean: -0.58370
[32m[0907 01-56-08 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17684, current rewards: -1448.93882, mean: -0.58900
[32m[0907 01-56-16 @Agent.py:117][0m Average action selection time: 0.1769
[32m[0907 01-56-16 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-56-16 @MBExp.py:227][0m Rewards obtained: [-1444.4883057669658], Lows: [19], Highs: [1539], Total time: 37154.394993
[32m[0907 01-59-06 @MBExp.py:144][0m ####################################################################
[32m[0907 01-59-06 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 01-59-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.22650, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-59-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18625, current rewards: -74.86939, mean: -1.24782
[32m[0907 01-59-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18352, current rewards: -137.27180, mean: -1.24793
[32m[0907 01-59-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18191, current rewards: -195.94343, mean: -1.22465
[32m[0907 01-59-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18167, current rewards: -269.68723, mean: -1.28422
[32m[0907 01-59-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18133, current rewards: -331.02771, mean: -1.27318
[32m[0907 02-00-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18145, current rewards: -394.02820, mean: -1.27106
[32m[0907 02-00-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18121, current rewards: -393.92118, mean: -1.09423
[32m[0907 02-00-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18177, current rewards: -385.13252, mean: -0.93935
[32m[0907 02-00-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18193, current rewards: -376.34386, mean: -0.81814
[32m[0907 02-00-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18208, current rewards: -368.26124, mean: -0.72208
[32m[0907 02-00-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18216, current rewards: -363.48063, mean: -0.64907
[32m[0907 02-00-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18229, current rewards: -358.70002, mean: -0.58803
[32m[0907 02-01-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18198, current rewards: -353.91940, mean: -0.53624
[32m[0907 02-01-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18175, current rewards: -349.13879, mean: -0.49174
[32m[0907 02-01-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18121, current rewards: -344.35818, mean: -0.45310
[32m[0907 02-01-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18069, current rewards: -391.07135, mean: -0.48280
[32m[0907 02-01-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18024, current rewards: -441.07135, mean: -0.51287
[32m[0907 02-01-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17986, current rewards: -491.07135, mean: -0.53964
[32m[0907 02-01-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17953, current rewards: -541.07135, mean: -0.56362
[32m[0907 02-02-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17909, current rewards: -591.07135, mean: -0.58522
[32m[0907 02-02-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17852, current rewards: -641.07135, mean: -0.60478
[32m[0907 02-02-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17805, current rewards: -691.07135, mean: -0.62259
[32m[0907 02-02-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17761, current rewards: -741.07135, mean: -0.63885
[32m[0907 02-02-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17717, current rewards: -791.07135, mean: -0.65378
[32m[0907 02-02-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17678, current rewards: -841.07135, mean: -0.66752
[32m[0907 02-02-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17644, current rewards: -891.07135, mean: -0.68021
[32m[0907 02-03-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17611, current rewards: -941.07135, mean: -0.69196
[32m[0907 02-03-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17579, current rewards: -991.07135, mean: -0.70289
[32m[0907 02-03-22 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17549, current rewards: -1041.07135, mean: -0.71306
[32m[0907 02-03-31 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17522, current rewards: -1091.07135, mean: -0.72256
[32m[0907 02-03-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17497, current rewards: -1141.07135, mean: -0.73146
[32m[0907 02-03-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17477, current rewards: -1191.07135, mean: -0.73980
[32m[0907 02-03-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17474, current rewards: -1241.07135, mean: -0.74763
[32m[0907 02-04-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17475, current rewards: -1291.07135, mean: -0.75501
[32m[0907 02-04-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17488, current rewards: -1341.07135, mean: -0.76197
[32m[0907 02-04-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17501, current rewards: -1391.07135, mean: -0.76855
[32m[0907 02-04-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17514, current rewards: -1441.07135, mean: -0.77477
[32m[0907 02-04-41 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17522, current rewards: -1491.07135, mean: -0.78067
[32m[0907 02-04-50 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17530, current rewards: -1541.07135, mean: -0.78626
[32m[0907 02-04-59 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17549, current rewards: -1591.07135, mean: -0.79158
[32m[0907 02-05-08 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17570, current rewards: -1641.07135, mean: -0.79664
[32m[0907 02-05-18 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17588, current rewards: -1691.07135, mean: -0.80146
[32m[0907 02-05-27 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17605, current rewards: -1741.07135, mean: -0.80605
[32m[0907 02-05-36 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17621, current rewards: -1791.07135, mean: -0.81044
[32m[0907 02-05-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17637, current rewards: -1841.07135, mean: -0.81463
[32m[0907 02-05-54 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17653, current rewards: -1874.13607, mean: -0.81131
[32m[0907 02-06-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17669, current rewards: -1871.21333, mean: -0.79289
[32m[0907 02-06-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17682, current rewards: -1868.29059, mean: -0.77522
[32m[0907 02-06-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17694, current rewards: -1865.36784, mean: -0.75828
[32m[0907 02-06-29 @Agent.py:117][0m Average action selection time: 0.1771
[32m[0907 02-06-29 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-06-29 @MBExp.py:227][0m Rewards obtained: [-1863.0296512288758], Lows: [205], Highs: [1543], Total time: 37597.835489000005
[32m[0907 02-09-22 @MBExp.py:144][0m ####################################################################
[32m[0907 02-09-22 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 02-09-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17791, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-09-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18688, current rewards: -74.44737, mean: -1.24079
[32m[0907 02-09-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18738, current rewards: -113.74225, mean: -1.03402
[32m[0907 02-09-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18679, current rewards: -170.44719, mean: -1.06529
[32m[0907 02-10-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18785, current rewards: -227.04952, mean: -1.08119
[32m[0907 02-10-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18688, current rewards: -285.99041, mean: -1.09996
[32m[0907 02-10-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18672, current rewards: -347.20537, mean: -1.12002
[32m[0907 02-10-29 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18616, current rewards: -400.27907, mean: -1.11189
[32m[0907 02-10-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18791, current rewards: -478.01443, mean: -1.16589
[32m[0907 02-10-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18752, current rewards: -472.72090, mean: -1.02765
[32m[0907 02-10-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18706, current rewards: -469.75293, mean: -0.92108
[32m[0907 02-11-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18673, current rewards: -467.07188, mean: -0.83406
[32m[0907 02-11-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18641, current rewards: -464.39083, mean: -0.76130
[32m[0907 02-11-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18581, current rewards: -461.70977, mean: -0.69956
[32m[0907 02-11-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18517, current rewards: -459.02872, mean: -0.64652
[32m[0907 02-11-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18431, current rewards: -456.34767, mean: -0.60046
[32m[0907 02-11-50 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18360, current rewards: -453.66662, mean: -0.56008
[32m[0907 02-11-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18297, current rewards: -450.98557, mean: -0.52440
[32m[0907 02-12-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18241, current rewards: -485.18125, mean: -0.53317
[32m[0907 02-12-16 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18195, current rewards: -535.18125, mean: -0.55748
[32m[0907 02-12-25 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18134, current rewards: -585.18125, mean: -0.57939
[32m[0907 02-12-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18067, current rewards: -635.18125, mean: -0.59923
[32m[0907 02-12-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18005, current rewards: -685.18125, mean: -0.61728
[32m[0907 02-12-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17955, current rewards: -735.18125, mean: -0.63378
[32m[0907 02-12-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17905, current rewards: -785.18125, mean: -0.64891
[32m[0907 02-13-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17860, current rewards: -835.18125, mean: -0.66284
[32m[0907 02-13-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17817, current rewards: -885.18125, mean: -0.67571
[32m[0907 02-13-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17777, current rewards: -935.18125, mean: -0.68763
[32m[0907 02-13-32 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17739, current rewards: -985.18125, mean: -0.69871
[32m[0907 02-13-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17705, current rewards: -1035.18125, mean: -0.70903
[32m[0907 02-13-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17673, current rewards: -1085.18125, mean: -0.71866
[32m[0907 02-13-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17643, current rewards: -1135.18125, mean: -0.72768
[32m[0907 02-14-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17614, current rewards: -1185.18125, mean: -0.73614
[32m[0907 02-14-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17604, current rewards: -1235.18125, mean: -0.74409
[32m[0907 02-14-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17601, current rewards: -1285.18125, mean: -0.75157
[32m[0907 02-14-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17610, current rewards: -1335.18125, mean: -0.75863
[32m[0907 02-14-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17616, current rewards: -1385.18125, mean: -0.76529
[32m[0907 02-14-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17625, current rewards: -1435.18125, mean: -0.77160
[32m[0907 02-14-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17633, current rewards: -1485.18125, mean: -0.77758
[32m[0907 02-15-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17641, current rewards: -1535.18125, mean: -0.78326
[32m[0907 02-15-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17657, current rewards: -1585.18125, mean: -0.78865
[32m[0907 02-15-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17672, current rewards: -1635.18125, mean: -0.79378
[32m[0907 02-15-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17687, current rewards: -1685.18125, mean: -0.79866
[32m[0907 02-15-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17701, current rewards: -1735.18125, mean: -0.80332
[32m[0907 02-15-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17716, current rewards: -1785.18125, mean: -0.80777
[32m[0907 02-16-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17731, current rewards: -1835.18125, mean: -0.81203
[32m[0907 02-16-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17743, current rewards: -1885.18125, mean: -0.81610
[32m[0907 02-16-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17756, current rewards: -1935.18125, mean: -0.81999
[32m[0907 02-16-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17768, current rewards: -1985.18125, mean: -0.82373
[32m[0907 02-16-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17780, current rewards: -2035.18125, mean: -0.82731
[32m[0907 02-16-47 @Agent.py:117][0m Average action selection time: 0.1779
[32m[0907 02-16-47 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-16-47 @MBExp.py:227][0m Rewards obtained: [-2075.1812531984015], Lows: [256], Highs: [1636], Total time: 38043.29360800001
[32m[0907 02-19-41 @MBExp.py:144][0m ####################################################################
[32m[0907 02-19-41 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 02-19-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17731, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-19-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17763, current rewards: -33.53748, mean: -0.55896
[32m[0907 02-20-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17784, current rewards: -58.17905, mean: -0.52890
[32m[0907 02-20-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17809, current rewards: -84.68601, mean: -0.52929
[32m[0907 02-20-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17806, current rewards: -115.72051, mean: -0.55105
[32m[0907 02-20-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17810, current rewards: -130.77737, mean: -0.50299
[32m[0907 02-20-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17811, current rewards: -151.93674, mean: -0.49012
[32m[0907 02-20-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17825, current rewards: -166.49017, mean: -0.46247
[32m[0907 02-20-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17901, current rewards: -187.77883, mean: -0.45800
[32m[0907 02-21-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17945, current rewards: -203.99680, mean: -0.44347
[32m[0907 02-21-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17987, current rewards: -237.01693, mean: -0.46474
[32m[0907 02-21-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18019, current rewards: -261.69817, mean: -0.46732
[32m[0907 02-21-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18041, current rewards: -259.54136, mean: -0.42548
[32m[0907 02-21-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18071, current rewards: -255.00086, mean: -0.38636
[32m[0907 02-21-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18058, current rewards: -250.43808, mean: -0.35273
[32m[0907 02-21-58 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18010, current rewards: -245.89321, mean: -0.32354
[32m[0907 02-22-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17968, current rewards: -241.15527, mean: -0.29772
[32m[0907 02-22-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17930, current rewards: -245.44669, mean: -0.28540
[32m[0907 02-22-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17908, current rewards: -261.95623, mean: -0.28786
[32m[0907 02-22-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17900, current rewards: -268.90015, mean: -0.28010
[32m[0907 02-22-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17859, current rewards: -279.13874, mean: -0.27637
[32m[0907 02-22-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17823, current rewards: -296.76969, mean: -0.27997
[32m[0907 02-23-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17836, current rewards: -319.06515, mean: -0.28745
[32m[0907 02-23-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17817, current rewards: -358.94185, mean: -0.30943
[32m[0907 02-23-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17795, current rewards: -372.14873, mean: -0.30756
[32m[0907 02-23-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17797, current rewards: -399.05011, mean: -0.31671
[32m[0907 02-23-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17757, current rewards: -391.09083, mean: -0.29854
[32m[0907 02-23-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17718, current rewards: -383.21324, mean: -0.28177
[32m[0907 02-23-51 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17682, current rewards: -375.32730, mean: -0.26619
[32m[0907 02-23-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17649, current rewards: -379.25559, mean: -0.25976
[32m[0907 02-24-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17686, current rewards: -397.35313, mean: -0.26315
[32m[0907 02-24-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17694, current rewards: -413.68787, mean: -0.26518
[32m[0907 02-24-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17742, current rewards: -430.34134, mean: -0.26729
[32m[0907 02-24-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17779, current rewards: -436.87025, mean: -0.26317
[32m[0907 02-24-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17824, current rewards: -455.16340, mean: -0.26618
[32m[0907 02-24-56 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17850, current rewards: -458.63841, mean: -0.26059
[32m[0907 02-25-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17852, current rewards: -445.46889, mean: -0.24612
[32m[0907 02-25-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17853, current rewards: -441.26962, mean: -0.23724
[32m[0907 02-25-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17856, current rewards: -437.08637, mean: -0.22884
[32m[0907 02-25-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17859, current rewards: -432.90538, mean: -0.22087
[32m[0907 02-25-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17874, current rewards: -428.72163, mean: -0.21329
[32m[0907 02-25-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17885, current rewards: -424.52757, mean: -0.20608
[32m[0907 02-26-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17902, current rewards: -420.31974, mean: -0.19920
[32m[0907 02-26-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17921, current rewards: -416.12606, mean: -0.19265
[32m[0907 02-26-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17939, current rewards: -411.93014, mean: -0.18639
[32m[0907 02-26-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17955, current rewards: -407.73656, mean: -0.18041
[32m[0907 02-26-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17971, current rewards: -403.54300, mean: -0.17469
[32m[0907 02-26-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17987, current rewards: -416.02039, mean: -0.17628
[32m[0907 02-26-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18001, current rewards: -415.64808, mean: -0.17247
[32m[0907 02-27-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18014, current rewards: -410.91967, mean: -0.16704
[32m[0907 02-27-13 @Agent.py:117][0m Average action selection time: 0.1802
[32m[0907 02-27-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-27-13 @MBExp.py:227][0m Rewards obtained: [-407.1359195979142], Lows: [295], Highs: [100], Total time: 38494.72250000001
[32m[0907 02-30-13 @MBExp.py:144][0m ####################################################################
[32m[0907 02-30-13 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 02-30-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18106, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-30-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18178, current rewards: -106.80730, mean: -1.78012
[32m[0907 02-30-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18196, current rewards: -206.80730, mean: -1.88007
[32m[0907 02-30-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18200, current rewards: -306.80730, mean: -1.91755
[32m[0907 02-30-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18198, current rewards: -406.80730, mean: -1.93718
[32m[0907 02-31-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18200, current rewards: -506.80730, mean: -1.94926
[32m[0907 02-31-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18206, current rewards: -606.80730, mean: -1.95744
[32m[0907 02-31-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18203, current rewards: -706.80730, mean: -1.96335
[32m[0907 02-31-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18255, current rewards: -806.80730, mean: -1.96782
[32m[0907 02-31-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18306, current rewards: -906.80730, mean: -1.97132
[32m[0907 02-31-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18347, current rewards: -1006.80730, mean: -1.97413
[32m[0907 02-31-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18388, current rewards: -1106.80730, mean: -1.97644
[32m[0907 02-32-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18413, current rewards: -1206.80730, mean: -1.97837
[32m[0907 02-32-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18438, current rewards: -1306.80730, mean: -1.98001
[32m[0907 02-32-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18399, current rewards: -1406.80730, mean: -1.98142
[32m[0907 02-32-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18352, current rewards: -1506.80730, mean: -1.98264
[32m[0907 02-32-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18309, current rewards: -1606.80730, mean: -1.98371
[32m[0907 02-32-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18277, current rewards: -1706.80730, mean: -1.98466
[32m[0907 02-32-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18242, current rewards: -1806.80730, mean: -1.98550
[32m[0907 02-33-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18211, current rewards: -1906.80730, mean: -1.98626
[32m[0907 02-33-16 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18185, current rewards: -2006.80730, mean: -1.98694
[32m[0907 02-33-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18160, current rewards: -2106.80730, mean: -1.98755
[32m[0907 02-33-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18119, current rewards: -2206.80730, mean: -1.98811
[32m[0907 02-33-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18075, current rewards: -2306.80730, mean: -1.98863
[32m[0907 02-33-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18033, current rewards: -2406.80730, mean: -1.98910
[32m[0907 02-34-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17994, current rewards: -2506.80730, mean: -1.98953
[32m[0907 02-34-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17958, current rewards: -2606.80730, mean: -1.98993
[32m[0907 02-34-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17924, current rewards: -2706.80730, mean: -1.99030
[32m[0907 02-34-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17893, current rewards: -2806.80730, mean: -1.99064
[32m[0907 02-34-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17864, current rewards: -2906.80730, mean: -1.99096
[32m[0907 02-34-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17835, current rewards: -3006.80730, mean: -1.99126
[32m[0907 02-34-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17812, current rewards: -3106.80730, mean: -1.99154
[32m[0907 02-34-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17789, current rewards: -3206.80730, mean: -1.99181
[32m[0907 02-35-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17767, current rewards: -3306.80730, mean: -1.99205
[32m[0907 02-35-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17755, current rewards: -3406.80730, mean: -1.99228
[32m[0907 02-35-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17770, current rewards: -3506.80730, mean: -1.99250
[32m[0907 02-35-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17785, current rewards: -3606.80730, mean: -1.99271
[32m[0907 02-35-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17799, current rewards: -3706.80730, mean: -1.99291
[32m[0907 02-35-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17811, current rewards: -3806.80730, mean: -1.99309
[32m[0907 02-36-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17823, current rewards: -3906.80730, mean: -1.99327
[32m[0907 02-36-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17833, current rewards: -4006.80730, mean: -1.99344
[32m[0907 02-36-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17845, current rewards: -4106.80730, mean: -1.99360
[32m[0907 02-36-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17858, current rewards: -4206.80730, mean: -1.99375
[32m[0907 02-36-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17878, current rewards: -4306.80730, mean: -1.99389
[32m[0907 02-36-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17899, current rewards: -4406.80730, mean: -1.99403
[32m[0907 02-36-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17917, current rewards: -4506.80730, mean: -1.99416
[32m[0907 02-37-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17936, current rewards: -4606.80730, mean: -1.99429
[32m[0907 02-37-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17955, current rewards: -4706.80730, mean: -1.99441
[32m[0907 02-37-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17971, current rewards: -4806.80730, mean: -1.99453
[32m[0907 02-37-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17988, current rewards: -4906.80730, mean: -1.99464
[32m[0907 02-37-43 @Agent.py:117][0m Average action selection time: 0.1800
[32m[0907 02-37-43 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-37-43 @MBExp.py:227][0m Rewards obtained: [-4986.80729531126], Lows: [2488], Highs: [11], Total time: 38945.51103800001
[32m[0907 02-40-45 @MBExp.py:144][0m ####################################################################
[32m[0907 02-40-45 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 02-40-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19199, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-40-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18332, current rewards: -31.19336, mean: -0.51989
[32m[0907 02-41-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18294, current rewards: -54.66059, mean: -0.49691
[32m[0907 02-41-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18250, current rewards: -57.14330, mean: -0.35715
[32m[0907 02-41-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18247, current rewards: -83.19628, mean: -0.39617
[32m[0907 02-41-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18238, current rewards: -111.04022, mean: -0.42708
[32m[0907 02-41-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18220, current rewards: -137.35489, mean: -0.44308
[32m[0907 02-41-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18212, current rewards: -237.35489, mean: -0.65932
[32m[0907 02-42-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18214, current rewards: -329.64391, mean: -0.80401
[32m[0907 02-42-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18274, current rewards: -326.01808, mean: -0.70873
[32m[0907 02-42-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18316, current rewards: -323.05791, mean: -0.63345
[32m[0907 02-42-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18343, current rewards: -320.09775, mean: -0.57160
[32m[0907 02-42-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18372, current rewards: -317.13758, mean: -0.51990
[32m[0907 02-42-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18394, current rewards: -336.42068, mean: -0.50973
[32m[0907 02-42-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18385, current rewards: -386.42068, mean: -0.54425
[32m[0907 02-43-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18337, current rewards: -436.42068, mean: -0.57424
[32m[0907 02-43-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18295, current rewards: -486.42068, mean: -0.60052
[32m[0907 02-43-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18258, current rewards: -536.42068, mean: -0.62374
[32m[0907 02-43-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18224, current rewards: -586.42068, mean: -0.64442
[32m[0907 02-43-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18193, current rewards: -636.42068, mean: -0.66294
[32m[0907 02-43-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18166, current rewards: -686.42068, mean: -0.67962
[32m[0907 02-43-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18142, current rewards: -736.42068, mean: -0.69474
[32m[0907 02-44-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18119, current rewards: -786.42068, mean: -0.70849
[32m[0907 02-44-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18076, current rewards: -836.42068, mean: -0.72105
[32m[0907 02-44-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18034, current rewards: -886.42068, mean: -0.73258
[32m[0907 02-44-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17995, current rewards: -936.42068, mean: -0.74319
[32m[0907 02-44-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17957, current rewards: -986.42068, mean: -0.75299
[32m[0907 02-44-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17924, current rewards: -1036.42068, mean: -0.76207
[32m[0907 02-44-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17894, current rewards: -1086.42068, mean: -0.77051
[32m[0907 02-45-06 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17865, current rewards: -1136.42068, mean: -0.77837
[32m[0907 02-45-15 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17837, current rewards: -1186.42068, mean: -0.78571
[32m[0907 02-45-24 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17810, current rewards: -1236.42068, mean: -0.79258
[32m[0907 02-45-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17784, current rewards: -1286.42068, mean: -0.79902
[32m[0907 02-45-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17762, current rewards: -1336.42068, mean: -0.80507
[32m[0907 02-45-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17743, current rewards: -1386.42068, mean: -0.81077
[32m[0907 02-45-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17747, current rewards: -1436.42068, mean: -0.81615
[32m[0907 02-46-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17762, current rewards: -1486.42068, mean: -0.82123
[32m[0907 02-46-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17773, current rewards: -1536.42068, mean: -0.82603
[32m[0907 02-46-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17785, current rewards: -1586.42068, mean: -0.83059
[32m[0907 02-46-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17795, current rewards: -1636.42068, mean: -0.83491
[32m[0907 02-46-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17806, current rewards: -1686.42068, mean: -0.83902
[32m[0907 02-46-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17816, current rewards: -1736.42068, mean: -0.84292
[32m[0907 02-47-02 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17826, current rewards: -1786.42068, mean: -0.84664
[32m[0907 02-47-11 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17838, current rewards: -1836.42068, mean: -0.85019
[32m[0907 02-47-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17859, current rewards: -1886.42068, mean: -0.85358
[32m[0907 02-47-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17879, current rewards: -1936.42068, mean: -0.85682
[32m[0907 02-47-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17897, current rewards: -1986.42068, mean: -0.85992
[32m[0907 02-47-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17914, current rewards: -2036.42068, mean: -0.86289
[32m[0907 02-47-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17931, current rewards: -2086.42068, mean: -0.86573
[32m[0907 02-48-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17947, current rewards: -2136.42068, mean: -0.86846
[32m[0907 02-48-15 @Agent.py:117][0m Average action selection time: 0.1796
[32m[0907 02-48-15 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-48-15 @MBExp.py:227][0m Rewards obtained: [-2176.4206804462283], Lows: [155], Highs: [1909], Total time: 39395.31603600001
[32m[0907 02-51-19 @MBExp.py:144][0m ####################################################################
[32m[0907 02-51-19 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 02-51-22 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.21832, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-51-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18817, current rewards: -11.59949, mean: -0.19332
[32m[0907 02-51-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18577, current rewards: -3.35811, mean: -0.03053
[32m[0907 02-51-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18482, current rewards: 4.87950, mean: 0.03050
[32m[0907 02-51-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18428, current rewards: 13.12464, mean: 0.06250
[32m[0907 02-52-07 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18383, current rewards: 21.36620, mean: 0.08218
[32m[0907 02-52-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18362, current rewards: 29.59950, mean: 0.09548
[32m[0907 02-52-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18450, current rewards: 9.70075, mean: 0.02695
[32m[0907 02-52-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18449, current rewards: 9.33943, mean: 0.02278
[32m[0907 02-52-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18435, current rewards: 17.35647, mean: 0.03773
[32m[0907 02-52-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18472, current rewards: 25.37567, mean: 0.04976
[32m[0907 02-53-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18497, current rewards: 33.40135, mean: 0.05965
[32m[0907 02-53-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18508, current rewards: 18.05086, mean: 0.02959
[32m[0907 02-53-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18602, current rewards: -4.44746, mean: -0.00674
[32m[0907 02-53-32 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18626, current rewards: -32.65213, mean: -0.04599
[32m[0907 02-53-41 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18656, current rewards: -62.34560, mean: -0.08203
[32m[0907 02-53-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18667, current rewards: -82.23725, mean: -0.10153
[32m[0907 02-54-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18697, current rewards: -96.64271, mean: -0.11238
[32m[0907 02-54-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18724, current rewards: -122.99932, mean: -0.13516
[32m[0907 02-54-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18720, current rewards: -149.21317, mean: -0.15543
[32m[0907 02-54-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18758, current rewards: -173.90515, mean: -0.17218
[32m[0907 02-54-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18855, current rewards: -187.54379, mean: -0.17693
[32m[0907 02-54-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18831, current rewards: -200.68451, mean: -0.18080
[32m[0907 02-54-58 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18780, current rewards: -194.37885, mean: -0.16757
[32m[0907 02-55-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18747, current rewards: -187.93217, mean: -0.15532
[32m[0907 02-55-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18705, current rewards: -181.27618, mean: -0.14387
[32m[0907 02-55-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18641, current rewards: -173.85766, mean: -0.13272
[32m[0907 02-55-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18583, current rewards: -166.41389, mean: -0.12236
[32m[0907 02-55-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18526, current rewards: -159.00481, mean: -0.11277
[32m[0907 02-55-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18474, current rewards: -151.57172, mean: -0.10382
[32m[0907 02-55-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18426, current rewards: -144.12897, mean: -0.09545
[32m[0907 02-56-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18379, current rewards: -136.68828, mean: -0.08762
[32m[0907 02-56-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18336, current rewards: -129.26469, mean: -0.08029
[32m[0907 02-56-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18297, current rewards: -121.83807, mean: -0.07340
[32m[0907 02-56-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18261, current rewards: -114.41796, mean: -0.06691
[32m[0907 02-56-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18242, current rewards: -107.01341, mean: -0.06080
[32m[0907 02-56-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18236, current rewards: -121.12078, mean: -0.06692
[32m[0907 02-56-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18220, current rewards: -164.46980, mean: -0.08842
[32m[0907 02-57-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18206, current rewards: -214.46980, mean: -0.11229
[32m[0907 02-57-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18199, current rewards: -264.46980, mean: -0.13493
[32m[0907 02-57-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18200, current rewards: -275.39221, mean: -0.13701
[32m[0907 02-57-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18201, current rewards: -270.34234, mean: -0.13123
[32m[0907 02-57-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18202, current rewards: -266.39346, mean: -0.12625
[32m[0907 02-57-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18203, current rewards: -316.39346, mean: -0.14648
[32m[0907 02-58-02 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18203, current rewards: -366.39346, mean: -0.16579
[32m[0907 02-58-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18216, current rewards: -416.39346, mean: -0.18424
[32m[0907 02-58-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18229, current rewards: -466.39346, mean: -0.20190
[32m[0907 02-58-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18239, current rewards: -516.39346, mean: -0.21881
[32m[0907 02-58-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18249, current rewards: -566.39346, mean: -0.23502
[32m[0907 02-58-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18259, current rewards: -616.39346, mean: -0.25057
[32m[0907 02-58-57 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0907 02-58-57 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-58-57 @MBExp.py:227][0m Rewards obtained: [-656.3934588318831], Lows: [51], Highs: [796], Total time: 39852.804720000015
[32m[0907 03-02-03 @MBExp.py:144][0m ####################################################################
[32m[0907 03-02-03 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 03-02-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20507, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-02-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18771, current rewards: -37.83996, mean: -0.63067
[32m[0907 03-02-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19043, current rewards: -62.30758, mean: -0.56643
[32m[0907 03-02-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19369, current rewards: -82.58551, mean: -0.51616
[32m[0907 03-02-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19468, current rewards: -83.83770, mean: -0.39923
[32m[0907 03-02-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19713, current rewards: -100.26764, mean: -0.38564
[32m[0907 03-03-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19663, current rewards: -106.65946, mean: -0.34406
[32m[0907 03-03-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19738, current rewards: -125.10155, mean: -0.34750
[32m[0907 03-03-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19704, current rewards: -151.80002, mean: -0.37024
[32m[0907 03-03-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19752, current rewards: -163.28704, mean: -0.35497
[32m[0907 03-03-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19710, current rewards: -209.51747, mean: -0.41082
[32m[0907 03-03-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19644, current rewards: -247.05740, mean: -0.44117
[32m[0907 03-04-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19565, current rewards: -289.60828, mean: -0.47477
[32m[0907 03-04-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19498, current rewards: -338.97366, mean: -0.51360
[32m[0907 03-04-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19426, current rewards: -382.77738, mean: -0.53912
[32m[0907 03-04-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19345, current rewards: -440.77109, mean: -0.57996
[32m[0907 03-04-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19310, current rewards: -498.16297, mean: -0.61502
[32m[0907 03-04-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19263, current rewards: -566.76503, mean: -0.65903
[32m[0907 03-04-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19251, current rewards: -616.96084, mean: -0.67798
[32m[0907 03-05-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19209, current rewards: -655.84072, mean: -0.68317
[32m[0907 03-05-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19250, current rewards: -692.21572, mean: -0.68536
[32m[0907 03-05-27 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19203, current rewards: -726.20665, mean: -0.68510
[32m[0907 03-05-36 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19200, current rewards: -758.65889, mean: -0.68348
[32m[0907 03-05-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19179, current rewards: -806.53432, mean: -0.69529
[32m[0907 03-05-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19101, current rewards: -841.92360, mean: -0.69580
[32m[0907 03-06-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19050, current rewards: -879.76934, mean: -0.69823
[32m[0907 03-06-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18999, current rewards: -921.86607, mean: -0.70371
[32m[0907 03-06-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18952, current rewards: -953.82133, mean: -0.70134
[32m[0907 03-06-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18913, current rewards: -994.69682, mean: -0.70546
[32m[0907 03-06-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18920, current rewards: -1032.15610, mean: -0.70696
[32m[0907 03-06-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18885, current rewards: -1070.90422, mean: -0.70921
[32m[0907 03-06-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18842, current rewards: -1108.50012, mean: -0.71058
[32m[0907 03-07-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18807, current rewards: -1129.89251, mean: -0.70180
[32m[0907 03-07-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18753, current rewards: -1126.09960, mean: -0.67837
[32m[0907 03-07-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18704, current rewards: -1120.43458, mean: -0.65522
[32m[0907 03-07-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18674, current rewards: -1114.76362, mean: -0.63339
[32m[0907 03-07-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18646, current rewards: -1109.09234, mean: -0.61276
[32m[0907 03-07-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18620, current rewards: -1103.41530, mean: -0.59323
[32m[0907 03-07-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18594, current rewards: -1097.73914, mean: -0.57473
[32m[0907 03-08-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18574, current rewards: -1096.67173, mean: -0.55953
[32m[0907 03-08-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18577, current rewards: -1113.22874, mean: -0.55385
[32m[0907 03-08-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18579, current rewards: -1123.50879, mean: -0.54539
[32m[0907 03-08-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18574, current rewards: -1142.07040, mean: -0.54127
[32m[0907 03-08-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18572, current rewards: -1160.31520, mean: -0.53718
[32m[0907 03-08-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18586, current rewards: -1178.34061, mean: -0.53319
[32m[0907 03-09-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18597, current rewards: -1204.62128, mean: -0.53302
[32m[0907 03-09-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18600, current rewards: -1230.09321, mean: -0.53251
[32m[0907 03-09-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18602, current rewards: -1224.65658, mean: -0.51892
[32m[0907 03-09-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18604, current rewards: -1219.11583, mean: -0.50586
[32m[0907 03-09-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18614, current rewards: -1213.38820, mean: -0.49325
[32m[0907 03-09-49 @Agent.py:117][0m Average action selection time: 0.1862
[32m[0907 03-09-49 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-09-49 @MBExp.py:227][0m Rewards obtained: [-1208.1509783898011], Lows: [703], Highs: [116], Total time: 40319.00764300001
[32m[0907 03-12-58 @MBExp.py:144][0m ####################################################################
[32m[0907 03-12-58 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 03-12-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18041, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-13-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18196, current rewards: -48.45250, mean: -0.80754
[32m[0907 03-13-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18200, current rewards: -104.67203, mean: -0.95156
[32m[0907 03-13-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18204, current rewards: -146.19361, mean: -0.91371
[32m[0907 03-13-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18212, current rewards: -136.42554, mean: -0.64965
[32m[0907 03-13-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18211, current rewards: -126.66267, mean: -0.48716
[32m[0907 03-13-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18201, current rewards: -117.42417, mean: -0.37879
[32m[0907 03-14-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18206, current rewards: -107.74721, mean: -0.29930
[32m[0907 03-14-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18217, current rewards: -98.06162, mean: -0.23917
[32m[0907 03-14-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18278, current rewards: -110.29950, mean: -0.23978
[32m[0907 03-14-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18329, current rewards: -126.59362, mean: -0.24822
[32m[0907 03-14-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18358, current rewards: -121.17416, mean: -0.21638
[32m[0907 03-14-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18385, current rewards: -115.75632, mean: -0.18976
[32m[0907 03-14-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18400, current rewards: -110.33601, mean: -0.16718
[32m[0907 03-15-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18386, current rewards: -105.10139, mean: -0.14803
[32m[0907 03-15-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18373, current rewards: -99.69014, mean: -0.13117
[32m[0907 03-15-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18362, current rewards: -94.28109, mean: -0.11640
[32m[0907 03-15-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18354, current rewards: -88.87110, mean: -0.10334
[32m[0907 03-15-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18339, current rewards: -83.46332, mean: -0.09172
[32m[0907 03-15-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18302, current rewards: -78.05474, mean: -0.08131
[32m[0907 03-16-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18271, current rewards: -86.01524, mean: -0.08516
[32m[0907 03-16-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18241, current rewards: -80.63357, mean: -0.07607
[32m[0907 03-16-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18211, current rewards: -75.69334, mean: -0.06819
[32m[0907 03-16-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18162, current rewards: -70.25684, mean: -0.06057
[32m[0907 03-16-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18115, current rewards: -64.84918, mean: -0.05359
[32m[0907 03-16-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18074, current rewards: -59.44393, mean: -0.04718
[32m[0907 03-16-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18035, current rewards: -54.02688, mean: -0.04124
[32m[0907 03-17-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17999, current rewards: -48.62402, mean: -0.03575
[32m[0907 03-17-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17966, current rewards: -43.20535, mean: -0.03064
[32m[0907 03-17-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17935, current rewards: -37.79489, mean: -0.02589
[32m[0907 03-17-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17905, current rewards: -31.65579, mean: -0.02096
[32m[0907 03-17-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17876, current rewards: -25.60476, mean: -0.01641
[32m[0907 03-17-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17850, current rewards: -89.16113, mean: -0.05538
[32m[0907 03-17-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17827, current rewards: -153.61201, mean: -0.09254
[32m[0907 03-18-03 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17805, current rewards: -206.91066, mean: -0.12100
[32m[0907 03-18-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17793, current rewards: -269.65253, mean: -0.15321
[32m[0907 03-18-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17789, current rewards: -317.81623, mean: -0.17559
[32m[0907 03-18-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17785, current rewards: -376.18905, mean: -0.20225
[32m[0907 03-18-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17782, current rewards: -449.61122, mean: -0.23540
[32m[0907 03-18-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17780, current rewards: -493.84496, mean: -0.25196
[32m[0907 03-18-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17788, current rewards: -551.86307, mean: -0.27456
[32m[0907 03-19-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17799, current rewards: -573.95441, mean: -0.27862
[32m[0907 03-19-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17809, current rewards: -597.41834, mean: -0.28314
[32m[0907 03-19-23 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17819, current rewards: -590.47734, mean: -0.27337
[32m[0907 03-19-32 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17838, current rewards: -583.33662, mean: -0.26395
[32m[0907 03-19-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17858, current rewards: -576.21331, mean: -0.25496
[32m[0907 03-19-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17874, current rewards: -569.06798, mean: -0.24635
[32m[0907 03-20-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17889, current rewards: -557.30273, mean: -0.23615
[32m[0907 03-20-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17907, current rewards: -549.79301, mean: -0.22813
[32m[0907 03-20-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17923, current rewards: -543.01678, mean: -0.22074
[32m[0907 03-20-27 @Agent.py:117][0m Average action selection time: 0.1794
[32m[0907 03-20-27 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-20-27 @MBExp.py:227][0m Rewards obtained: [-537.6032708012773], Lows: [421], Highs: [32], Total time: 40768.22367800001
[32m[0907 03-23-37 @MBExp.py:144][0m ####################################################################
[32m[0907 03-23-37 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 03-23-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19288, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-23-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18396, current rewards: -15.15824, mean: -0.25264
[32m[0907 03-23-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18309, current rewards: -6.13330, mean: -0.05576
[32m[0907 03-24-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18276, current rewards: 2.93244, mean: 0.01833
[32m[0907 03-24-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18261, current rewards: 11.97405, mean: 0.05702
[32m[0907 03-24-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18244, current rewards: 21.03377, mean: 0.08090
[32m[0907 03-24-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18239, current rewards: 33.81087, mean: 0.10907
[32m[0907 03-24-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18233, current rewards: 43.18360, mean: 0.11995
[32m[0907 03-24-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18231, current rewards: 27.59573, mean: 0.06731
[32m[0907 03-25-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18286, current rewards: 33.43403, mean: 0.07268
[32m[0907 03-25-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18331, current rewards: 39.26697, mean: 0.07699
[32m[0907 03-25-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18367, current rewards: 45.10837, mean: 0.08055
[32m[0907 03-25-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18397, current rewards: 50.95170, mean: 0.08353
[32m[0907 03-25-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18417, current rewards: 56.79318, mean: 0.08605
[32m[0907 03-25-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18424, current rewards: 62.39297, mean: 0.08788
[32m[0907 03-25-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18413, current rewards: 68.32222, mean: 0.08990
[32m[0907 03-26-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18404, current rewards: 74.24644, mean: 0.09166
[32m[0907 03-26-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18392, current rewards: 80.15723, mean: 0.09321
[32m[0907 03-26-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18381, current rewards: 86.06685, mean: 0.09458
[32m[0907 03-26-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18374, current rewards: 91.98054, mean: 0.09581
[32m[0907 03-26-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18335, current rewards: 76.47569, mean: 0.07572
[32m[0907 03-26-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18300, current rewards: 81.81384, mean: 0.07718
[32m[0907 03-27-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18272, current rewards: 89.64454, mean: 0.08076
[32m[0907 03-27-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18247, current rewards: 100.03880, mean: 0.08624
[32m[0907 03-27-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18221, current rewards: 104.96908, mean: 0.08675
[32m[0907 03-27-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18176, current rewards: 94.80185, mean: 0.07524
[32m[0907 03-27-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18134, current rewards: 100.31192, mean: 0.07657
[32m[0907 03-27-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18095, current rewards: 105.78734, mean: 0.07778
[32m[0907 03-27-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18058, current rewards: 111.26710, mean: 0.07891
[32m[0907 03-28-01 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18024, current rewards: 116.74614, mean: 0.07996
[32m[0907 03-28-09 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17993, current rewards: 122.22118, mean: 0.08094
[32m[0907 03-28-18 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17962, current rewards: 127.50312, mean: 0.08173
[32m[0907 03-28-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17935, current rewards: 132.99204, mean: 0.08260
[32m[0907 03-28-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17908, current rewards: 125.82387, mean: 0.07580
[32m[0907 03-28-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17884, current rewards: 127.32541, mean: 0.07446
[32m[0907 03-28-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17862, current rewards: 140.48791, mean: 0.07982
[32m[0907 03-29-01 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17854, current rewards: 153.63222, mean: 0.08488
[32m[0907 03-29-10 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17849, current rewards: 166.79874, mean: 0.08968
[32m[0907 03-29-19 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17844, current rewards: 166.20375, mean: 0.08702
[32m[0907 03-29-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17840, current rewards: 175.93271, mean: 0.08976
[32m[0907 03-29-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17836, current rewards: 174.01251, mean: 0.08657
[32m[0907 03-29-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17839, current rewards: 173.06943, mean: 0.08401
[32m[0907 03-29-54 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17848, current rewards: 166.35775, mean: 0.07884
[32m[0907 03-30-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17859, current rewards: 164.27822, mean: 0.07605
[32m[0907 03-30-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17867, current rewards: 166.83820, mean: 0.07549
[32m[0907 03-30-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17880, current rewards: 150.78710, mean: 0.06672
[32m[0907 03-30-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17893, current rewards: 160.48517, mean: 0.06947
[32m[0907 03-30-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17910, current rewards: 159.91274, mean: 0.06776
[32m[0907 03-30-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17927, current rewards: 170.58875, mean: 0.07078
[32m[0907 03-30-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17943, current rewards: 182.38352, mean: 0.07414
[32m[0907 03-31-07 @Agent.py:117][0m Average action selection time: 0.1796
[32m[0907 03-31-07 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-31-07 @MBExp.py:227][0m Rewards obtained: [191.83004352342158], Lows: [77], Highs: [36], Total time: 41217.93961700001
[32m[0907 03-34-19 @MBExp.py:144][0m ####################################################################
[32m[0907 03-34-19 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 03-34-21 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17976, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-34-31 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19436, current rewards: -99.11822, mean: -1.65197
[32m[0907 03-34-40 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18964, current rewards: -181.41332, mean: -1.64921
[32m[0907 03-34-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18729, current rewards: -192.32527, mean: -1.20203
[32m[0907 03-34-58 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18614, current rewards: -185.93999, mean: -0.88543
[32m[0907 03-35-08 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18535, current rewards: -179.43809, mean: -0.69015
[32m[0907 03-35-17 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18486, current rewards: -172.59829, mean: -0.55677
[32m[0907 03-35-26 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18453, current rewards: -166.19925, mean: -0.46166
[32m[0907 03-35-35 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18420, current rewards: -159.80132, mean: -0.38976
[32m[0907 03-35-44 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18446, current rewards: -185.96446, mean: -0.40427
[32m[0907 03-35-54 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18477, current rewards: -257.86456, mean: -0.50562
[32m[0907 03-36-03 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18501, current rewards: -345.04641, mean: -0.61615
[32m[0907 03-36-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18519, current rewards: -420.30094, mean: -0.68902
[32m[0907 03-36-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18528, current rewards: -486.84724, mean: -0.73765
[32m[0907 03-36-31 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18534, current rewards: -567.35586, mean: -0.79909
[32m[0907 03-36-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18508, current rewards: -643.25188, mean: -0.84638
[32m[0907 03-36-49 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18508, current rewards: -719.27228, mean: -0.88799
[32m[0907 03-36-59 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18490, current rewards: -793.43311, mean: -0.92260
[32m[0907 03-37-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18474, current rewards: -873.75975, mean: -0.96018
[32m[0907 03-37-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18459, current rewards: -952.73267, mean: -0.99243
[32m[0907 03-37-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18446, current rewards: -1038.13930, mean: -1.02786
[32m[0907 03-37-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18421, current rewards: -1115.67131, mean: -1.05252
[32m[0907 03-37-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18390, current rewards: -1124.09294, mean: -1.01270
[32m[0907 03-37-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18358, current rewards: -1117.84406, mean: -0.96366
[32m[0907 03-38-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18328, current rewards: -1111.63492, mean: -0.91871
[32m[0907 03-38-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18284, current rewards: -1105.42638, mean: -0.87732
[32m[0907 03-38-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18239, current rewards: -1099.21983, mean: -0.83910
[32m[0907 03-38-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18194, current rewards: -1093.01607, mean: -0.80369
[32m[0907 03-38-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18152, current rewards: -1086.80881, mean: -0.77079
[32m[0907 03-38-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18115, current rewards: -1104.39914, mean: -0.75644
[32m[0907 03-38-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18079, current rewards: -1099.39252, mean: -0.72807
[32m[0907 03-39-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18047, current rewards: -1130.99336, mean: -0.72500
[32m[0907 03-39-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18021, current rewards: -1176.71640, mean: -0.73088
[32m[0907 03-39-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17994, current rewards: -1213.48555, mean: -0.73102
[32m[0907 03-39-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17965, current rewards: -1241.02290, mean: -0.72574
[32m[0907 03-39-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17939, current rewards: -1280.22126, mean: -0.72740
[32m[0907 03-39-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17921, current rewards: -1279.39267, mean: -0.70685
[32m[0907 03-39-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17918, current rewards: -1312.69933, mean: -0.70575
[32m[0907 03-40-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17911, current rewards: -1346.71005, mean: -0.70508
[32m[0907 03-40-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17907, current rewards: -1383.49944, mean: -0.70587
[32m[0907 03-40-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17901, current rewards: -1404.53688, mean: -0.69877
[32m[0907 03-40-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17896, current rewards: -1401.47731, mean: -0.68033
[32m[0907 03-40-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17890, current rewards: -1398.50516, mean: -0.66280
[32m[0907 03-40-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17897, current rewards: -1395.52420, mean: -0.64608
[32m[0907 03-40-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17905, current rewards: -1392.54798, mean: -0.63011
[32m[0907 03-41-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17913, current rewards: -1389.56841, mean: -0.61485
[32m[0907 03-41-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17921, current rewards: -1410.89519, mean: -0.61078
[32m[0907 03-41-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17938, current rewards: -1450.66257, mean: -0.61469
[32m[0907 03-41-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17955, current rewards: -1489.09889, mean: -0.61788
[32m[0907 03-41-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17969, current rewards: -1533.13348, mean: -0.62322
[32m[0907 03-41-49 @Agent.py:117][0m Average action selection time: 0.1798
[32m[0907 03-41-49 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-41-50 @MBExp.py:227][0m Rewards obtained: [-1568.6479086339616], Lows: [908], Highs: [44], Total time: 41668.293049000014
[32m[0907 03-45-05 @MBExp.py:144][0m ####################################################################
[32m[0907 03-45-05 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 03-45-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18235, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-45-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18211, current rewards: -15.24331, mean: -0.25406
[32m[0907 03-45-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18207, current rewards: -11.38127, mean: -0.10347
[32m[0907 03-45-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18212, current rewards: -7.52442, mean: -0.04703
[32m[0907 03-45-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18216, current rewards: -3.66635, mean: -0.01746
[32m[0907 03-45-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18220, current rewards: 1.52715, mean: 0.00587
[32m[0907 03-46-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18219, current rewards: 5.69250, mean: 0.01836
[32m[0907 03-46-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18213, current rewards: 9.78324, mean: 0.02718
[32m[0907 03-46-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18210, current rewards: 13.87430, mean: 0.03384
[32m[0907 03-46-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18213, current rewards: 17.96714, mean: 0.03906
[32m[0907 03-46-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18211, current rewards: 22.05697, mean: 0.04325
[32m[0907 03-46-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18250, current rewards: 26.14822, mean: 0.04669
[32m[0907 03-46-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18292, current rewards: 30.23847, mean: 0.04957
[32m[0907 03-47-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18323, current rewards: 21.28284, mean: 0.03225
[32m[0907 03-47-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18358, current rewards: 28.14227, mean: 0.03964
[32m[0907 03-47-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18383, current rewards: 35.77665, mean: 0.04707
[32m[0907 03-47-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18389, current rewards: 43.41474, mean: 0.05360
[32m[0907 03-47-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18379, current rewards: 51.04913, mean: 0.05936
[32m[0907 03-47-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18366, current rewards: 58.67267, mean: 0.06448
[32m[0907 03-48-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18356, current rewards: 66.30343, mean: 0.06907
[32m[0907 03-48-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18351, current rewards: 73.92039, mean: 0.07319
[32m[0907 03-48-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18344, current rewards: 81.56662, mean: 0.07695
[32m[0907 03-48-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18310, current rewards: 91.69813, mean: 0.08261
[32m[0907 03-48-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18282, current rewards: 99.64738, mean: 0.08590
[32m[0907 03-48-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18254, current rewards: 107.59348, mean: 0.08892
[32m[0907 03-48-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18217, current rewards: 86.37247, mean: 0.06855
[32m[0907 03-49-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18171, current rewards: 91.39377, mean: 0.06977
[32m[0907 03-49-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18131, current rewards: 96.35098, mean: 0.07085
[32m[0907 03-49-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18093, current rewards: 101.30820, mean: 0.07185
[32m[0907 03-49-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18058, current rewards: 84.28252, mean: 0.05773
[32m[0907 03-49-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18023, current rewards: 34.28252, mean: 0.02270
[32m[0907 03-49-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17991, current rewards: -15.71748, mean: -0.01008
[32m[0907 03-49-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17962, current rewards: -65.71748, mean: -0.04082
[32m[0907 03-50-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17936, current rewards: -115.71748, mean: -0.06971
[32m[0907 03-50-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17910, current rewards: -165.71748, mean: -0.09691
[32m[0907 03-50-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17885, current rewards: -215.71748, mean: -0.12257
[32m[0907 03-50-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17862, current rewards: -265.71748, mean: -0.14681
[32m[0907 03-50-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17841, current rewards: -315.71748, mean: -0.16974
[32m[0907 03-50-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17822, current rewards: -365.71748, mean: -0.19148
[32m[0907 03-50-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17817, current rewards: -415.71748, mean: -0.21210
[32m[0907 03-51-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17812, current rewards: -465.71748, mean: -0.23170
[32m[0907 03-51-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17809, current rewards: -515.71748, mean: -0.25035
[32m[0907 03-51-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17805, current rewards: -565.71748, mean: -0.26811
[32m[0907 03-51-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17803, current rewards: -615.71748, mean: -0.28505
[32m[0907 03-51-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17814, current rewards: -665.71748, mean: -0.30123
[32m[0907 03-51-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17821, current rewards: -715.71748, mean: -0.31669
[32m[0907 03-51-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17830, current rewards: -765.71748, mean: -0.33148
[32m[0907 03-52-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17843, current rewards: -815.71748, mean: -0.34564
[32m[0907 03-52-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17862, current rewards: -865.71748, mean: -0.35922
[32m[0907 03-52-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17880, current rewards: -915.71748, mean: -0.37224
[32m[0907 03-52-33 @Agent.py:117][0m Average action selection time: 0.1789
[32m[0907 03-52-33 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-52-33 @MBExp.py:227][0m Rewards obtained: [-955.7174790346231], Lows: [21], Highs: [1082], Total time: 42116.46195100001
[32m[0907 03-55-51 @MBExp.py:144][0m ####################################################################
[32m[0907 03-55-51 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 03-55-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30169, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-56-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.30078, current rewards: -46.90450, mean: -0.78174
[32m[0907 03-56-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.30168, current rewards: -90.59558, mean: -0.82360
[32m[0907 03-56-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.29636, current rewards: -133.19455, mean: -0.83247
[32m[0907 03-56-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.26911, current rewards: -221.92400, mean: -1.05678
[32m[0907 03-56-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.25242, current rewards: -321.92400, mean: -1.23817
[32m[0907 03-57-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.24100, current rewards: -421.92400, mean: -1.36105
[32m[0907 03-57-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.23279, current rewards: -521.92400, mean: -1.44979
[32m[0907 03-57-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.22664, current rewards: -621.92400, mean: -1.51689
[32m[0907 03-57-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.22222, current rewards: -721.92400, mean: -1.56940
[32m[0907 03-57-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.21875, current rewards: -821.92400, mean: -1.61162
[32m[0907 03-57-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.21595, current rewards: -921.92400, mean: -1.64629
[32m[0907 03-58-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.21358, current rewards: -1021.92400, mean: -1.67529
[32m[0907 03-58-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.21157, current rewards: -1121.92400, mean: -1.69988
[32m[0907 03-58-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.20988, current rewards: -1221.92400, mean: -1.72102
[32m[0907 03-58-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.20801, current rewards: -1321.92400, mean: -1.73937
[32m[0907 03-58-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.20639, current rewards: -1421.92400, mean: -1.75546
[32m[0907 03-58-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.20498, current rewards: -1521.92400, mean: -1.76968
[32m[0907 03-58-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.20374, current rewards: -1621.92400, mean: -1.78233
[32m[0907 03-59-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.20259, current rewards: -1721.92400, mean: -1.79367
[32m[0907 03-59-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.20152, current rewards: -1821.92400, mean: -1.80389
[32m[0907 03-59-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.20034, current rewards: -1921.92400, mean: -1.81314
[32m[0907 03-59-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19927, current rewards: -2021.92400, mean: -1.82155
[32m[0907 03-59-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19827, current rewards: -2121.92400, mean: -1.82924
[32m[0907 03-59-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19738, current rewards: -2221.92400, mean: -1.83630
[32m[0907 03-59-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19641, current rewards: -2321.92400, mean: -1.84280
[32m[0907 04-00-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19684, current rewards: -2406.31391, mean: -1.83688
[32m[0907 04-00-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19989, current rewards: -2425.18684, mean: -1.78323
[32m[0907 04-00-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.20205, current rewards: -2454.12386, mean: -1.74051
[32m[0907 04-00-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.20283, current rewards: -2518.16613, mean: -1.72477
[32m[0907 04-01-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.20518, current rewards: -2568.35816, mean: -1.70090
[32m[0907 04-01-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.20652, current rewards: -2595.00091, mean: -1.66346
[32m[0907 04-01-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.20850, current rewards: -2606.92926, mean: -1.61921
[32m[0907 04-01-37 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.20870, current rewards: -2675.02778, mean: -1.61146
[32m[0907 04-01-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.21089, current rewards: -2712.94013, mean: -1.58651
[32m[0907 04-02-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.21025, current rewards: -2762.94013, mean: -1.56985
[32m[0907 04-02-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.20933, current rewards: -2812.94013, mean: -1.55411
[32m[0907 04-02-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.20846, current rewards: -2862.94013, mean: -1.53922
[32m[0907 04-02-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.20769, current rewards: -2912.94013, mean: -1.52510
[32m[0907 04-02-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.20706, current rewards: -2961.89075, mean: -1.51117
[32m[0907 04-02-48 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.20744, current rewards: -2964.41756, mean: -1.47483
[32m[0907 04-03-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.20798, current rewards: -2961.58674, mean: -1.43766
[32m[0907 04-03-10 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.20800, current rewards: -2958.88615, mean: -1.40232
[32m[0907 04-03-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.20752, current rewards: -2958.49957, mean: -1.36968
[32m[0907 04-03-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.20798, current rewards: -2955.76911, mean: -1.33745
[32m[0907 04-03-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.20813, current rewards: -2956.25508, mean: -1.30808
[32m[0907 04-03-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.20768, current rewards: -2955.90682, mean: -1.27961
[32m[0907 04-04-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.20724, current rewards: -3005.90682, mean: -1.27369
[32m[0907 04-04-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.20685, current rewards: -3055.90682, mean: -1.26801
[32m[0907 04-04-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.20645, current rewards: -3105.90682, mean: -1.26256
[32m[0907 04-04-27 @Agent.py:117][0m Average action selection time: 0.2062
[32m[0907 04-04-27 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-04-27 @MBExp.py:227][0m Rewards obtained: [-3145.906819889974], Lows: [1284], Highs: [633], Total time: 42632.69367700001
[32m[0907 04-07-45 @MBExp.py:144][0m ####################################################################
[32m[0907 04-07-45 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 04-07-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.24681, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-07-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.22504, current rewards: -72.46806, mean: -1.20780
[32m[0907 04-08-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.21992, current rewards: -135.80059, mean: -1.23455
[32m[0907 04-08-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.22241, current rewards: -178.09611, mean: -1.11310
[32m[0907 04-08-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.22551, current rewards: -225.88202, mean: -1.07563
[32m[0907 04-08-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.23428, current rewards: -268.09260, mean: -1.03113
[32m[0907 04-09-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.24123, current rewards: -310.16692, mean: -1.00054
[32m[0907 04-09-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.24222, current rewards: -337.65849, mean: -0.93794
[32m[0907 04-09-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.24397, current rewards: -381.11417, mean: -0.92955
[32m[0907 04-09-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.24602, current rewards: -419.16775, mean: -0.91123
[32m[0907 04-09-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.24528, current rewards: -457.10849, mean: -0.89629
[32m[0907 04-10-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.24300, current rewards: -521.00846, mean: -0.93037
[32m[0907 04-10-12 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.24099, current rewards: -553.89643, mean: -0.90803
[32m[0907 04-10-22 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.23735, current rewards: -558.40164, mean: -0.84606
[32m[0907 04-10-30 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.23307, current rewards: -552.67185, mean: -0.77841
[32m[0907 04-10-39 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.22933, current rewards: -547.62046, mean: -0.72055
[32m[0907 04-10-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.22589, current rewards: -542.63641, mean: -0.66992
[32m[0907 04-10-57 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.22290, current rewards: -556.54329, mean: -0.64714
[32m[0907 04-11-08 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.22329, current rewards: -602.50247, mean: -0.66209
[32m[0907 04-11-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.22399, current rewards: -653.30170, mean: -0.68052
[32m[0907 04-11-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.22135, current rewards: -753.30170, mean: -0.74584
[32m[0907 04-11-37 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.21895, current rewards: -853.30170, mean: -0.80500
[32m[0907 04-11-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.21676, current rewards: -953.30170, mean: -0.85883
[32m[0907 04-11-54 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.21476, current rewards: -1053.30170, mean: -0.90802
[32m[0907 04-12-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.21293, current rewards: -1153.30170, mean: -0.95314
[32m[0907 04-12-11 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.21127, current rewards: -1253.30170, mean: -0.99468
[32m[0907 04-12-20 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.20971, current rewards: -1353.30170, mean: -1.03305
[32m[0907 04-12-28 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.20826, current rewards: -1453.30170, mean: -1.06860
[32m[0907 04-12-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.20707, current rewards: -1553.30170, mean: -1.10163
[32m[0907 04-12-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.20601, current rewards: -1653.30170, mean: -1.13240
[32m[0907 04-12-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.20503, current rewards: -1753.30170, mean: -1.16113
[32m[0907 04-13-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.20410, current rewards: -1853.30170, mean: -1.18801
[32m[0907 04-13-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.20326, current rewards: -1953.30170, mean: -1.21323
[32m[0907 04-13-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.20246, current rewards: -2053.30170, mean: -1.23693
[32m[0907 04-13-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.20171, current rewards: -2153.30170, mean: -1.25924
[32m[0907 04-13-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.20103, current rewards: -2253.30170, mean: -1.28029
[32m[0907 04-13-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.20051, current rewards: -2353.30170, mean: -1.30017
[32m[0907 04-13-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.20003, current rewards: -2453.30170, mean: -1.31898
[32m[0907 04-14-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19966, current rewards: -2553.30170, mean: -1.33681
[32m[0907 04-14-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.19934, current rewards: -2653.30170, mean: -1.35373
[32m[0907 04-14-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.19906, current rewards: -2753.30170, mean: -1.36980
[32m[0907 04-14-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19877, current rewards: -2853.30170, mean: -1.38510
[32m[0907 04-14-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19849, current rewards: -2953.30170, mean: -1.39967
[32m[0907 04-14-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19823, current rewards: -3053.30170, mean: -1.41357
[32m[0907 04-15-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19797, current rewards: -3153.30170, mean: -1.42683
[32m[0907 04-15-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19771, current rewards: -3253.30170, mean: -1.43951
[32m[0907 04-15-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19748, current rewards: -3353.30170, mean: -1.45165
[32m[0907 04-15-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19726, current rewards: -3453.30170, mean: -1.46326
[32m[0907 04-15-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19704, current rewards: -3553.30170, mean: -1.47440
[32m[0907 04-15-50 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19683, current rewards: -3653.30170, mean: -1.48508
[32m[0907 04-15-57 @Agent.py:117][0m Average action selection time: 0.1966
[32m[0907 04-15-57 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-15-57 @MBExp.py:227][0m Rewards obtained: [-3733.3016966620244], Lows: [1695], Highs: [398], Total time: 43125.02657200001
[32m[0907 04-19-16 @MBExp.py:144][0m ####################################################################
[32m[0907 04-19-16 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 04-19-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20010, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-19-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19186, current rewards: -14.62489, mean: -0.24375
[32m[0907 04-19-38 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19289, current rewards: -34.01934, mean: -0.30927
[32m[0907 04-19-47 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19219, current rewards: -40.55885, mean: -0.25349
[32m[0907 04-19-57 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19181, current rewards: -44.72111, mean: -0.21296
[32m[0907 04-20-06 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19157, current rewards: -53.31436, mean: -0.20506
[32m[0907 04-20-16 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19066, current rewards: -69.01900, mean: -0.22264
[32m[0907 04-20-25 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18956, current rewards: -86.94566, mean: -0.24152
[32m[0907 04-20-34 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18873, current rewards: -119.96778, mean: -0.29260
[32m[0907 04-20-43 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18807, current rewards: -151.78971, mean: -0.32998
[32m[0907 04-20-52 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18751, current rewards: -180.64042, mean: -0.35420
[32m[0907 04-21-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18700, current rewards: -198.54012, mean: -0.35454
[32m[0907 04-21-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18663, current rewards: -192.31144, mean: -0.31526
[32m[0907 04-21-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18630, current rewards: -185.47103, mean: -0.28102
[32m[0907 04-21-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18565, current rewards: -178.89701, mean: -0.25197
[32m[0907 04-21-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18501, current rewards: -205.94909, mean: -0.27099
[32m[0907 04-21-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18411, current rewards: -238.89025, mean: -0.29493
[32m[0907 04-21-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18345, current rewards: -276.99530, mean: -0.32209
[32m[0907 04-22-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18294, current rewards: -310.79645, mean: -0.34153
[32m[0907 04-22-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18251, current rewards: -342.41981, mean: -0.35669
[32m[0907 04-22-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18196, current rewards: -375.09325, mean: -0.37138
[32m[0907 04-22-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18142, current rewards: -408.98205, mean: -0.38583
[32m[0907 04-22-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18098, current rewards: -445.25713, mean: -0.40113
[32m[0907 04-22-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18053, current rewards: -464.81060, mean: -0.40070
[32m[0907 04-22-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18041, current rewards: -493.63621, mean: -0.40796
[32m[0907 04-23-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18014, current rewards: -530.95640, mean: -0.42139
[32m[0907 04-23-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17977, current rewards: -577.74188, mean: -0.44102
[32m[0907 04-23-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17943, current rewards: -627.74188, mean: -0.46157
[32m[0907 04-23-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17912, current rewards: -677.74188, mean: -0.48067
[32m[0907 04-23-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17911, current rewards: -729.60498, mean: -0.49973
[32m[0907 04-23-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17926, current rewards: -732.94976, mean: -0.48540
[32m[0907 04-23-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17926, current rewards: -731.31726, mean: -0.46879
[32m[0907 04-24-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17919, current rewards: -748.80397, mean: -0.46510
[32m[0907 04-24-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17914, current rewards: -798.80397, mean: -0.48121
[32m[0907 04-24-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17907, current rewards: -848.80397, mean: -0.49638
[32m[0907 04-24-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17900, current rewards: -898.80397, mean: -0.51068
[32m[0907 04-24-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17900, current rewards: -948.80397, mean: -0.52420
[32m[0907 04-24-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17908, current rewards: -998.80397, mean: -0.53699
[32m[0907 04-24-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17924, current rewards: -1001.16572, mean: -0.52417
[32m[0907 04-25-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17943, current rewards: -995.30401, mean: -0.50781
[32m[0907 04-25-18 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17966, current rewards: -988.98460, mean: -0.49203
[32m[0907 04-25-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17985, current rewards: -985.10643, mean: -0.47821
[32m[0907 04-25-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18004, current rewards: -978.52873, mean: -0.46376
[32m[0907 04-25-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18020, current rewards: -971.50877, mean: -0.44977
[32m[0907 04-25-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18035, current rewards: -1000.97427, mean: -0.45293
[32m[0907 04-26-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18048, current rewards: -1049.92618, mean: -0.46457
[32m[0907 04-26-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18063, current rewards: -1099.92618, mean: -0.47616
[32m[0907 04-26-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18075, current rewards: -1149.92618, mean: -0.48726
[32m[0907 04-26-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18088, current rewards: -1199.92618, mean: -0.49789
[32m[0907 04-26-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18099, current rewards: -1249.92618, mean: -0.50810
[32m[0907 04-26-50 @Agent.py:117][0m Average action selection time: 0.1811
[32m[0907 04-26-50 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-26-50 @MBExp.py:227][0m Rewards obtained: [-1289.9261792027878], Lows: [72], Highs: [1280], Total time: 43578.58668500001
[32m[0907 04-30-11 @MBExp.py:144][0m ####################################################################
[32m[0907 04-30-11 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 04-30-14 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.29003, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-30-23 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20482, current rewards: -38.50304, mean: -0.64172
[32m[0907 04-30-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19655, current rewards: -33.35745, mean: -0.30325
[32m[0907 04-30-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19349, current rewards: -28.23736, mean: -0.17648
[32m[0907 04-30-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19188, current rewards: -23.11556, mean: -0.11007
[32m[0907 04-31-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19077, current rewards: -17.99614, mean: -0.06922
[32m[0907 04-31-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18998, current rewards: -12.22629, mean: -0.03944
[32m[0907 04-31-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18886, current rewards: -32.24339, mean: -0.08956
[32m[0907 04-31-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18803, current rewards: -23.89533, mean: -0.05828
[32m[0907 04-31-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18744, current rewards: -14.78563, mean: -0.03214
[32m[0907 04-31-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18694, current rewards: -5.68297, mean: -0.01114
[32m[0907 04-31-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18649, current rewards: 3.42238, mean: 0.00611
[32m[0907 04-32-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18615, current rewards: 12.51926, mean: 0.02052
[32m[0907 04-32-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18590, current rewards: 16.90571, mean: 0.02561
[32m[0907 04-32-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18538, current rewards: -3.69642, mean: -0.00521
[32m[0907 04-32-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18474, current rewards: -23.98450, mean: -0.03156
[32m[0907 04-32-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18386, current rewards: -47.46098, mean: -0.05859
[32m[0907 04-32-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18311, current rewards: -64.96576, mean: -0.07554
[32m[0907 04-32-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18242, current rewards: -89.52431, mean: -0.09838
[32m[0907 04-33-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18180, current rewards: -111.98649, mean: -0.11665
[32m[0907 04-33-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18123, current rewards: -136.66373, mean: -0.13531
[32m[0907 04-33-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18074, current rewards: -156.81039, mean: -0.14793
[32m[0907 04-33-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18043, current rewards: -184.07171, mean: -0.16583
[32m[0907 04-33-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17998, current rewards: -196.79993, mean: -0.16966
[32m[0907 04-33-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17960, current rewards: -207.52313, mean: -0.17151
[32m[0907 04-33-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17925, current rewards: -217.11447, mean: -0.17231
[32m[0907 04-34-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17892, current rewards: -230.82972, mean: -0.17621
[32m[0907 04-34-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17862, current rewards: -242.49837, mean: -0.17831
[32m[0907 04-34-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17837, current rewards: -258.46274, mean: -0.18331
[32m[0907 04-34-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17819, current rewards: -267.83496, mean: -0.18345
[32m[0907 04-34-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17814, current rewards: -280.52906, mean: -0.18578
[32m[0907 04-34-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17809, current rewards: -317.81017, mean: -0.20372
[32m[0907 04-34-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17804, current rewards: -359.38782, mean: -0.22322
[32m[0907 04-35-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17801, current rewards: -398.87626, mean: -0.24029
[32m[0907 04-35-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17796, current rewards: -430.92202, mean: -0.25200
[32m[0907 04-35-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17793, current rewards: -444.68067, mean: -0.25266
[32m[0907 04-35-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17789, current rewards: -438.73745, mean: -0.24240
[32m[0907 04-35-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17798, current rewards: -432.79649, mean: -0.23269
[32m[0907 04-35-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17812, current rewards: -426.84943, mean: -0.22348
[32m[0907 04-36-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17838, current rewards: -420.90769, mean: -0.21475
[32m[0907 04-36-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17862, current rewards: -414.96209, mean: -0.20645
[32m[0907 04-36-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17884, current rewards: -409.01180, mean: -0.19855
[32m[0907 04-36-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17904, current rewards: -403.06874, mean: -0.19103
[32m[0907 04-36-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17923, current rewards: -397.12561, mean: -0.18385
[32m[0907 04-36-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17941, current rewards: -391.18227, mean: -0.17701
[32m[0907 04-36-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17958, current rewards: -385.23408, mean: -0.17046
[32m[0907 04-37-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17975, current rewards: -379.28778, mean: -0.16419
[32m[0907 04-37-16 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17989, current rewards: -373.40800, mean: -0.15822
[32m[0907 04-37-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18004, current rewards: -367.45209, mean: -0.15247
[32m[0907 04-37-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18018, current rewards: -361.49766, mean: -0.14695
[32m[0907 04-37-42 @Agent.py:117][0m Average action selection time: 0.1803
[32m[0907 04-37-42 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-37-43 @MBExp.py:227][0m Rewards obtained: [-356.7288702305214], Lows: [51], Highs: [482], Total time: 44030.12972900001
[32m[0907 04-41-06 @MBExp.py:144][0m ####################################################################
[32m[0907 04-41-06 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 04-41-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18785, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-41-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18792, current rewards: -35.66994, mean: -0.59450
[32m[0907 04-41-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18762, current rewards: -48.37737, mean: -0.43979
[32m[0907 04-41-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18716, current rewards: -59.84792, mean: -0.37405
[32m[0907 04-41-46 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18700, current rewards: -74.84044, mean: -0.35638
[32m[0907 04-41-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18698, current rewards: -85.42172, mean: -0.32855
[32m[0907 04-42-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18690, current rewards: -99.32626, mean: -0.32041
[32m[0907 04-42-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18687, current rewards: -121.63429, mean: -0.33787
[32m[0907 04-42-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18678, current rewards: -138.68447, mean: -0.33825
[32m[0907 04-42-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18629, current rewards: -153.58554, mean: -0.33388
[32m[0907 04-42-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18591, current rewards: -171.53179, mean: -0.33634
[32m[0907 04-42-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18559, current rewards: -191.14119, mean: -0.34132
[32m[0907 04-43-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18528, current rewards: -206.14587, mean: -0.33794
[32m[0907 04-43-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18508, current rewards: -227.15028, mean: -0.34417
[32m[0907 04-43-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18563, current rewards: -263.26013, mean: -0.37079
[32m[0907 04-43-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18502, current rewards: -258.63018, mean: -0.34030
[32m[0907 04-43-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18416, current rewards: -253.96682, mean: -0.31354
[32m[0907 04-43-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18340, current rewards: -249.29783, mean: -0.28988
[32m[0907 04-43-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18271, current rewards: -244.63000, mean: -0.26882
[32m[0907 04-44-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18207, current rewards: -239.96104, mean: -0.24996
[32m[0907 04-44-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18152, current rewards: -235.29470, mean: -0.23297
[32m[0907 04-44-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18103, current rewards: -230.62642, mean: -0.21757
[32m[0907 04-44-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18055, current rewards: -225.76461, mean: -0.20339
[32m[0907 04-44-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18013, current rewards: -221.10403, mean: -0.19061
[32m[0907 04-44-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17974, current rewards: -216.44397, mean: -0.17888
[32m[0907 04-44-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17936, current rewards: -211.78678, mean: -0.16808
[32m[0907 04-45-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17904, current rewards: -219.21167, mean: -0.16734
[32m[0907 04-45-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17882, current rewards: -230.29186, mean: -0.16933
[32m[0907 04-45-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17853, current rewards: -223.17829, mean: -0.15828
[32m[0907 04-45-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17826, current rewards: -218.77449, mean: -0.14985
[32m[0907 04-45-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17801, current rewards: -228.39304, mean: -0.15125
[32m[0907 04-45-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17778, current rewards: -229.77051, mean: -0.14729
[32m[0907 04-45-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17772, current rewards: -224.89788, mean: -0.13969
[32m[0907 04-46-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17769, current rewards: -220.07518, mean: -0.13258
[32m[0907 04-46-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17766, current rewards: -215.52584, mean: -0.12604
[32m[0907 04-46-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17762, current rewards: -210.56995, mean: -0.11964
[32m[0907 04-46-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17759, current rewards: -206.31279, mean: -0.11398
[32m[0907 04-46-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17762, current rewards: -202.71889, mean: -0.10899
[32m[0907 04-46-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17775, current rewards: -208.08529, mean: -0.10895
[32m[0907 04-46-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17805, current rewards: -220.19892, mean: -0.11235
[32m[0907 04-47-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17833, current rewards: -237.06555, mean: -0.11794
[32m[0907 04-47-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17858, current rewards: -229.26832, mean: -0.11130
[32m[0907 04-47-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17879, current rewards: -221.33839, mean: -0.10490
[32m[0907 04-47-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17898, current rewards: -213.41605, mean: -0.09880
[32m[0907 04-47-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17918, current rewards: -205.49271, mean: -0.09298
[32m[0907 04-47-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17934, current rewards: -197.56644, mean: -0.08742
[32m[0907 04-48-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17952, current rewards: -189.58767, mean: -0.08207
[32m[0907 04-48-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17969, current rewards: -183.55802, mean: -0.07778
[32m[0907 04-48-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17984, current rewards: -174.77309, mean: -0.07252
[32m[0907 04-48-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17999, current rewards: -165.98327, mean: -0.06747
[32m[0907 04-48-37 @Agent.py:117][0m Average action selection time: 0.1801
[32m[0907 04-48-37 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-48-37 @MBExp.py:227][0m Rewards obtained: [-158.9532269561338], Lows: [71], Highs: [280], Total time: 44481.23893100001
[32m[0907 04-52-04 @MBExp.py:144][0m ####################################################################
[32m[0907 04-52-04 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 04-52-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18093, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-52-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20781, current rewards: -57.21187, mean: -0.95353
[32m[0907 04-52-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19997, current rewards: -55.34823, mean: -0.50317
[32m[0907 04-52-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19599, current rewards: -48.18551, mean: -0.30116
[32m[0907 04-52-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19399, current rewards: -41.01683, mean: -0.19532
[32m[0907 04-52-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19267, current rewards: -33.84281, mean: -0.13016
[32m[0907 04-53-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19177, current rewards: -26.67142, mean: -0.08604
[32m[0907 04-53-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19293, current rewards: -56.10092, mean: -0.15584
[32m[0907 04-53-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19545, current rewards: -65.87523, mean: -0.16067
[32m[0907 04-53-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19482, current rewards: -157.36295, mean: -0.34209
[32m[0907 04-53-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19356, current rewards: -257.36295, mean: -0.50463
[32m[0907 04-53-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19260, current rewards: -357.36295, mean: -0.63815
[32m[0907 04-54-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19177, current rewards: -457.36295, mean: -0.74978
[32m[0907 04-54-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19105, current rewards: -557.36295, mean: -0.84449
[32m[0907 04-54-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19037, current rewards: -657.36295, mean: -0.92586
[32m[0907 04-54-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18939, current rewards: -757.36295, mean: -0.99653
[32m[0907 04-54-36 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18822, current rewards: -857.36295, mean: -1.05847
[32m[0907 04-54-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18725, current rewards: -957.36295, mean: -1.11321
[32m[0907 04-54-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18634, current rewards: -1057.36295, mean: -1.16194
[32m[0907 04-55-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18552, current rewards: -1157.36295, mean: -1.20559
[32m[0907 04-55-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18477, current rewards: -1257.36295, mean: -1.24491
[32m[0907 04-55-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18410, current rewards: -1357.36295, mean: -1.28053
[32m[0907 04-55-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18352, current rewards: -1457.36295, mean: -1.31294
[32m[0907 04-55-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18297, current rewards: -1557.36295, mean: -1.34255
[32m[0907 04-55-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18244, current rewards: -1657.36295, mean: -1.36972
[32m[0907 04-55-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18198, current rewards: -1757.36295, mean: -1.39473
[32m[0907 04-56-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18155, current rewards: -1857.36295, mean: -1.41783
[32m[0907 04-56-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18114, current rewards: -1957.36295, mean: -1.43924
[32m[0907 04-56-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18074, current rewards: -2057.36295, mean: -1.45912
[32m[0907 04-56-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18039, current rewards: -2157.36295, mean: -1.47765
[32m[0907 04-56-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18007, current rewards: -2257.36295, mean: -1.49494
[32m[0907 04-56-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17977, current rewards: -2357.36295, mean: -1.51113
[32m[0907 04-56-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17948, current rewards: -2457.36295, mean: -1.52631
[32m[0907 04-57-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17939, current rewards: -2557.36295, mean: -1.54058
[32m[0907 04-57-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17931, current rewards: -2657.36295, mean: -1.55401
[32m[0907 04-57-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17923, current rewards: -2757.36295, mean: -1.56668
[32m[0907 04-57-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17916, current rewards: -2857.36295, mean: -1.57865
[32m[0907 04-57-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17910, current rewards: -2957.36295, mean: -1.58998
[32m[0907 04-57-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17911, current rewards: -3057.36295, mean: -1.60071
[32m[0907 04-57-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17928, current rewards: -3157.36295, mean: -1.61090
[32m[0907 04-58-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17950, current rewards: -3257.36295, mean: -1.62058
[32m[0907 04-58-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17969, current rewards: -3357.36295, mean: -1.62979
[32m[0907 04-58-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17986, current rewards: -3457.36295, mean: -1.63856
[32m[0907 04-58-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18001, current rewards: -3557.36295, mean: -1.64693
[32m[0907 04-58-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18019, current rewards: -3657.36295, mean: -1.65492
[32m[0907 04-58-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18035, current rewards: -3757.36295, mean: -1.66255
[32m[0907 04-59-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18050, current rewards: -3857.36295, mean: -1.66985
[32m[0907 04-59-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18064, current rewards: -3957.36295, mean: -1.67685
[32m[0907 04-59-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18077, current rewards: -4057.36295, mean: -1.68355
[32m[0907 04-59-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18091, current rewards: -4157.36295, mean: -1.68998
[32m[0907 04-59-37 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0907 04-59-37 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-59-37 @MBExp.py:227][0m Rewards obtained: [-4237.362954509904], Lows: [2136], Highs: [16], Total time: 44934.68634400001
[32m[0907 05-03-05 @MBExp.py:144][0m ####################################################################
[32m[0907 05-03-05 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 05-03-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.30285, current rewards: 0.62621, mean: 0.06262
[32m[0907 05-03-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.24722, current rewards: -62.98317, mean: -1.04972
[32m[0907 05-03-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.22784, current rewards: -122.13506, mean: -1.11032
[32m[0907 05-03-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.21522, current rewards: -222.13506, mean: -1.38834
[32m[0907 05-03-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20856, current rewards: -322.13506, mean: -1.53398
[32m[0907 05-03-59 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20440, current rewards: -422.13506, mean: -1.62360
[32m[0907 05-04-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20157, current rewards: -522.13506, mean: -1.68431
[32m[0907 05-04-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19955, current rewards: -622.13506, mean: -1.72815
[32m[0907 05-04-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19806, current rewards: -722.13506, mean: -1.76131
[32m[0907 05-04-36 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19680, current rewards: -822.13506, mean: -1.78725
[32m[0907 05-04-45 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19536, current rewards: -922.13506, mean: -1.80811
[32m[0907 05-04-54 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19420, current rewards: -1022.13506, mean: -1.82524
[32m[0907 05-05-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19325, current rewards: -1122.13506, mean: -1.83957
[32m[0907 05-05-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19244, current rewards: -1222.13506, mean: -1.85172
[32m[0907 05-05-22 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19163, current rewards: -1322.13506, mean: -1.86216
[32m[0907 05-05-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19064, current rewards: -1422.13506, mean: -1.87123
[32m[0907 05-05-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18978, current rewards: -1522.13506, mean: -1.87918
[32m[0907 05-05-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18903, current rewards: -1622.13506, mean: -1.88620
[32m[0907 05-05-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18833, current rewards: -1722.13506, mean: -1.89246
[32m[0907 05-06-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18771, current rewards: -1822.13506, mean: -1.89806
[32m[0907 05-06-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18686, current rewards: -1922.13506, mean: -1.90310
[32m[0907 05-06-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18613, current rewards: -2022.13506, mean: -1.90767
[32m[0907 05-06-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18543, current rewards: -2122.13506, mean: -1.91183
[32m[0907 05-06-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18482, current rewards: -2222.13506, mean: -1.91563
[32m[0907 05-06-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18421, current rewards: -2322.13506, mean: -1.91912
[32m[0907 05-06-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18369, current rewards: -2422.13506, mean: -1.92233
[32m[0907 05-07-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18321, current rewards: -2522.13506, mean: -1.92529
[32m[0907 05-07-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18278, current rewards: -2622.13506, mean: -1.92804
[32m[0907 05-07-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18235, current rewards: -2722.13506, mean: -1.93059
[32m[0907 05-07-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18194, current rewards: -2822.13506, mean: -1.93297
[32m[0907 05-07-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18157, current rewards: -2922.13506, mean: -1.93519
[32m[0907 05-07-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18124, current rewards: -3022.13506, mean: -1.93727
[32m[0907 05-07-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18093, current rewards: -3122.13506, mean: -1.93921
[32m[0907 05-08-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18068, current rewards: -3222.13506, mean: -1.94105
[32m[0907 05-08-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18057, current rewards: -3322.13506, mean: -1.94277
[32m[0907 05-08-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18047, current rewards: -3422.13506, mean: -1.94439
[32m[0907 05-08-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18037, current rewards: -3522.13506, mean: -1.94593
[32m[0907 05-08-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18026, current rewards: -3622.13506, mean: -1.94738
[32m[0907 05-08-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18025, current rewards: -3722.13506, mean: -1.94876
[32m[0907 05-08-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18032, current rewards: -3822.13506, mean: -1.95007
[32m[0907 05-09-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18039, current rewards: -3922.13506, mean: -1.95131
[32m[0907 05-09-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18044, current rewards: -4022.13506, mean: -1.95249
[32m[0907 05-09-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18050, current rewards: -4122.13506, mean: -1.95362
[32m[0907 05-09-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18060, current rewards: -4222.13506, mean: -1.95469
[32m[0907 05-09-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18079, current rewards: -4322.13506, mean: -1.95572
[32m[0907 05-09-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18095, current rewards: -4422.13506, mean: -1.95670
[32m[0907 05-10-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18111, current rewards: -4522.13506, mean: -1.95763
[32m[0907 05-10-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18125, current rewards: -4622.13506, mean: -1.95853
[32m[0907 05-10-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18139, current rewards: -4722.13506, mean: -1.95939
[32m[0907 05-10-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18152, current rewards: -4822.13506, mean: -1.96022
[32m[0907 05-10-40 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0907 05-10-40 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-10-40 @MBExp.py:227][0m Rewards obtained: [-4902.135060983949], Lows: [2446], Highs: [14], Total time: 45389.55484600001
[32m[0907 05-14-10 @MBExp.py:144][0m ####################################################################
[32m[0907 05-14-10 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 05-14-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19365, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-14-22 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18869, current rewards: -97.57905, mean: -1.62632
[32m[0907 05-14-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19180, current rewards: -197.57905, mean: -1.79617
[32m[0907 05-14-41 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19062, current rewards: -191.28604, mean: -1.19554
[32m[0907 05-14-50 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18993, current rewards: -186.05539, mean: -0.88598
[32m[0907 05-15-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18941, current rewards: -180.83041, mean: -0.69550
[32m[0907 05-15-09 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18914, current rewards: -175.60633, mean: -0.56647
[32m[0907 05-15-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18883, current rewards: -220.90827, mean: -0.61363
[32m[0907 05-15-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18874, current rewards: -320.90827, mean: -0.78270
[32m[0907 05-15-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18858, current rewards: -420.90827, mean: -0.91502
[32m[0907 05-15-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18839, current rewards: -520.90827, mean: -1.02139
[32m[0907 05-15-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18786, current rewards: -620.90827, mean: -1.10876
[32m[0907 05-16-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18745, current rewards: -720.90827, mean: -1.18182
[32m[0907 05-16-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18706, current rewards: -820.90827, mean: -1.24380
[32m[0907 05-16-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18676, current rewards: -920.90827, mean: -1.29705
[32m[0907 05-16-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18605, current rewards: -1020.90827, mean: -1.34330
[32m[0907 05-16-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18546, current rewards: -1120.90827, mean: -1.38384
[32m[0907 05-16-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18493, current rewards: -1220.90827, mean: -1.41966
[32m[0907 05-16-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18449, current rewards: -1320.90827, mean: -1.45155
[32m[0907 05-17-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18429, current rewards: -1420.90827, mean: -1.48011
[32m[0907 05-17-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18478, current rewards: -1520.90827, mean: -1.50585
[32m[0907 05-17-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18449, current rewards: -1620.90827, mean: -1.52916
[32m[0907 05-17-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18429, current rewards: -1720.90827, mean: -1.55037
[32m[0907 05-17-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18397, current rewards: -1820.90827, mean: -1.56975
[32m[0907 05-17-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18411, current rewards: -1920.90827, mean: -1.58753
[32m[0907 05-18-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18369, current rewards: -2020.90827, mean: -1.60390
[32m[0907 05-18-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18364, current rewards: -2120.90827, mean: -1.61901
[32m[0907 05-18-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18358, current rewards: -2220.90827, mean: -1.63302
[32m[0907 05-18-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18433, current rewards: -2318.70154, mean: -1.64447
[32m[0907 05-18-41 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18510, current rewards: -2418.70154, mean: -1.65664
[32m[0907 05-18-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18599, current rewards: -2502.02490, mean: -1.65697
[32m[0907 05-19-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18658, current rewards: -2589.57326, mean: -1.65998
[32m[0907 05-19-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18765, current rewards: -2689.57326, mean: -1.67054
[32m[0907 05-19-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18878, current rewards: -2789.57326, mean: -1.68047
[32m[0907 05-19-35 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18962, current rewards: -2879.59043, mean: -1.68397
[32m[0907 05-19-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19068, current rewards: -2979.59043, mean: -1.69295
[32m[0907 05-19-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19186, current rewards: -3077.30674, mean: -1.70017
[32m[0907 05-20-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.19282, current rewards: -3175.09992, mean: -1.70704
[32m[0907 05-20-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19420, current rewards: -3272.80186, mean: -1.71351
[32m[0907 05-20-34 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.19559, current rewards: -3370.55499, mean: -1.71967
[32m[0907 05-20-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.19602, current rewards: -3470.55499, mean: -1.72664
[32m[0907 05-20-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19696, current rewards: -3559.02919, mean: -1.72768
[32m[0907 05-21-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19687, current rewards: -3587.34958, mean: -1.70017
[32m[0907 05-21-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19676, current rewards: -3650.52740, mean: -1.69006
[32m[0907 05-21-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19668, current rewards: -3715.82808, mean: -1.68137
[32m[0907 05-21-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19667, current rewards: -3798.26813, mean: -1.68065
[32m[0907 05-21-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19669, current rewards: -3878.05802, mean: -1.67881
[32m[0907 05-21-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19659, current rewards: -3978.05802, mean: -1.68562
[32m[0907 05-22-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19649, current rewards: -4078.05802, mean: -1.69214
[32m[0907 05-22-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19635, current rewards: -4178.05802, mean: -1.69840
[32m[0907 05-22-21 @Agent.py:117][0m Average action selection time: 0.1962
[32m[0907 05-22-21 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-22-22 @MBExp.py:227][0m Rewards obtained: [-4258.058022156679], Lows: [2154], Highs: [11], Total time: 45880.918941
[32m[0907 05-25-55 @MBExp.py:144][0m ####################################################################
[32m[0907 05-25-55 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 05-25-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20730, current rewards: 1.02396, mean: 0.10240
[32m[0907 05-26-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21243, current rewards: -45.27159, mean: -0.75453
[32m[0907 05-26-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20340, current rewards: -145.27159, mean: -1.32065
[32m[0907 05-26-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20326, current rewards: -245.27159, mean: -1.53295
[32m[0907 05-26-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20325, current rewards: -345.27159, mean: -1.64415
[32m[0907 05-26-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20347, current rewards: -445.27159, mean: -1.71258
[32m[0907 05-26-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20496, current rewards: -545.27159, mean: -1.75894
[32m[0907 05-27-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20492, current rewards: -645.27159, mean: -1.79242
[32m[0907 05-27-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20471, current rewards: -745.27159, mean: -1.81774
[32m[0907 05-27-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20382, current rewards: -831.05155, mean: -1.80663
[32m[0907 05-27-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20365, current rewards: -931.05155, mean: -1.82559
[32m[0907 05-27-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20320, current rewards: -1031.05155, mean: -1.84116
[32m[0907 05-27-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20308, current rewards: -1131.05155, mean: -1.85418
[32m[0907 05-28-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.20301, current rewards: -1231.05155, mean: -1.86523
[32m[0907 05-28-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.20143, current rewards: -1331.05155, mean: -1.87472
[32m[0907 05-28-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19979, current rewards: -1431.05155, mean: -1.88296
[32m[0907 05-28-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19825, current rewards: -1531.05155, mean: -1.89019
[32m[0907 05-28-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19669, current rewards: -1631.05155, mean: -1.89657
[32m[0907 05-28-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19529, current rewards: -1731.05155, mean: -1.90225
[32m[0907 05-29-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19404, current rewards: -1831.05155, mean: -1.90735
[32m[0907 05-29-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19291, current rewards: -1931.05155, mean: -1.91193
[32m[0907 05-29-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19188, current rewards: -2031.05155, mean: -1.91609
[32m[0907 05-29-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19095, current rewards: -2131.05155, mean: -1.91987
[32m[0907 05-29-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19010, current rewards: -2231.05155, mean: -1.92332
[32m[0907 05-29-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18935, current rewards: -2331.05155, mean: -1.92649
[32m[0907 05-29-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18864, current rewards: -2431.05155, mean: -1.92941
[32m[0907 05-30-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18797, current rewards: -2531.05155, mean: -1.93210
[32m[0907 05-30-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18745, current rewards: -2631.05155, mean: -1.93460
[32m[0907 05-30-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18691, current rewards: -2731.05155, mean: -1.93692
[32m[0907 05-30-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18646, current rewards: -2831.05155, mean: -1.93908
[32m[0907 05-30-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18620, current rewards: -2931.05155, mean: -1.94109
[32m[0907 05-30-45 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18595, current rewards: -3031.05155, mean: -1.94298
[32m[0907 05-30-54 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18571, current rewards: -3131.05155, mean: -1.94475
[32m[0907 05-31-03 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18547, current rewards: -3231.05155, mean: -1.94642
[32m[0907 05-31-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18524, current rewards: -3331.05155, mean: -1.94798
[32m[0907 05-31-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18517, current rewards: -3431.05155, mean: -1.94946
[32m[0907 05-31-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18515, current rewards: -3524.97096, mean: -1.94750
[32m[0907 05-31-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18509, current rewards: -3624.97096, mean: -1.94891
[32m[0907 05-31-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18504, current rewards: -3724.97096, mean: -1.95025
[32m[0907 05-31-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18497, current rewards: -3824.97096, mean: -1.95152
[32m[0907 05-32-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18496, current rewards: -3924.97096, mean: -1.95272
[32m[0907 05-32-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18506, current rewards: -4024.97096, mean: -1.95387
[32m[0907 05-32-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18514, current rewards: -4124.97096, mean: -1.95496
[32m[0907 05-32-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18522, current rewards: -4224.97096, mean: -1.95601
[32m[0907 05-32-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18527, current rewards: -4324.97096, mean: -1.95700
[32m[0907 05-32-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18533, current rewards: -4424.97096, mean: -1.95795
[32m[0907 05-33-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18534, current rewards: -4524.97096, mean: -1.95886
[32m[0907 05-33-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18528, current rewards: -4624.97096, mean: -1.95973
[32m[0907 05-33-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18523, current rewards: -4724.97096, mean: -1.96057
[32m[0907 05-33-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18519, current rewards: -4824.97096, mean: -1.96137
[32m[0907 05-33-38 @Agent.py:117][0m Average action selection time: 0.1852
[32m[0907 05-33-38 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-33-38 @MBExp.py:227][0m Rewards obtained: [-4904.970957000759], Lows: [2457], Highs: [1], Total time: 46344.670644000005
[32m[0907 05-37-14 @MBExp.py:144][0m ####################################################################
[32m[0907 05-37-14 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 05-37-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18798, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-37-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19049, current rewards: -71.20923, mean: -1.18682
[32m[0907 05-37-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19128, current rewards: -122.11255, mean: -1.11011
[32m[0907 05-37-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19018, current rewards: -188.77239, mean: -1.17983
[32m[0907 05-37-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18948, current rewards: -263.15711, mean: -1.25313
[32m[0907 05-38-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18931, current rewards: -352.72055, mean: -1.35662
[32m[0907 05-38-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18863, current rewards: -437.95990, mean: -1.41277
[32m[0907 05-38-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19018, current rewards: -469.99946, mean: -1.30555
[32m[0907 05-38-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18976, current rewards: -510.86998, mean: -1.24602
[32m[0907 05-38-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18929, current rewards: -552.49540, mean: -1.20108
[32m[0907 05-38-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18998, current rewards: -620.83408, mean: -1.21732
[32m[0907 05-39-01 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19028, current rewards: -645.95007, mean: -1.15348
[32m[0907 05-39-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18980, current rewards: -682.76547, mean: -1.11929
[32m[0907 05-39-20 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18956, current rewards: -723.11284, mean: -1.09563
[32m[0907 05-39-29 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18869, current rewards: -790.65705, mean: -1.11360
[32m[0907 05-39-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18789, current rewards: -881.74400, mean: -1.16019
[32m[0907 05-39-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18695, current rewards: -981.74400, mean: -1.21203
[32m[0907 05-39-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18606, current rewards: -1081.74400, mean: -1.25784
[32m[0907 05-40-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18527, current rewards: -1181.74400, mean: -1.29862
[32m[0907 05-40-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: -1281.74400, mean: -1.33515
[32m[0907 05-40-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18420, current rewards: -1381.74400, mean: -1.36806
[32m[0907 05-40-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18362, current rewards: -1407.13352, mean: -1.32748
[32m[0907 05-40-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18308, current rewards: -1408.59142, mean: -1.26900
[32m[0907 05-40-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18257, current rewards: -1401.82738, mean: -1.20847
[32m[0907 05-40-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18210, current rewards: -1395.06334, mean: -1.15294
[32m[0907 05-41-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18165, current rewards: -1443.92806, mean: -1.14597
[32m[0907 05-41-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18125, current rewards: -1493.92806, mean: -1.14040
[32m[0907 05-41-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18088, current rewards: -1543.92806, mean: -1.13524
[32m[0907 05-41-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18055, current rewards: -1593.92806, mean: -1.13045
[32m[0907 05-41-38 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18024, current rewards: -1643.92806, mean: -1.12598
[32m[0907 05-41-47 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18008, current rewards: -1693.92806, mean: -1.12181
[32m[0907 05-41-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17999, current rewards: -1743.92806, mean: -1.11790
[32m[0907 05-42-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17992, current rewards: -1793.92806, mean: -1.11424
[32m[0907 05-42-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17983, current rewards: -1843.92806, mean: -1.11080
[32m[0907 05-42-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17975, current rewards: -1893.92806, mean: -1.10756
[32m[0907 05-42-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17984, current rewards: -1943.92806, mean: -1.10450
[32m[0907 05-42-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17994, current rewards: -1993.92806, mean: -1.10162
[32m[0907 05-42-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18002, current rewards: -2043.92806, mean: -1.09889
[32m[0907 05-42-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18009, current rewards: -2093.92806, mean: -1.09630
[32m[0907 05-43-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18018, current rewards: -2143.92806, mean: -1.09384
[32m[0907 05-43-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18027, current rewards: -2193.92806, mean: -1.09151
[32m[0907 05-43-27 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18045, current rewards: -2243.92806, mean: -1.08929
[32m[0907 05-43-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18061, current rewards: -2293.92806, mean: -1.08717
[32m[0907 05-43-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18077, current rewards: -2343.92806, mean: -1.08515
[32m[0907 05-43-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18092, current rewards: -2393.92806, mean: -1.08323
[32m[0907 05-44-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18109, current rewards: -2443.92806, mean: -1.08138
[32m[0907 05-44-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18115, current rewards: -2493.92806, mean: -1.07962
[32m[0907 05-44-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18119, current rewards: -2543.92806, mean: -1.07794
[32m[0907 05-44-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18122, current rewards: -2593.92806, mean: -1.07632
[32m[0907 05-44-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18126, current rewards: -2643.92806, mean: -1.07477
[32m[0907 05-44-48 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0907 05-44-48 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-44-48 @MBExp.py:227][0m Rewards obtained: [-2683.9280616490933], Lows: [629], Highs: [1489], Total time: 46798.752295000006
[32m[0907 05-48-27 @MBExp.py:144][0m ####################################################################
[32m[0907 05-48-27 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 05-48-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18761, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-48-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20095, current rewards: -50.04295, mean: -0.83405
[32m[0907 05-48-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19454, current rewards: -100.04295, mean: -0.90948
[32m[0907 05-48-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19211, current rewards: -150.04295, mean: -0.93777
[32m[0907 05-49-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19120, current rewards: -200.04295, mean: -0.95259
[32m[0907 05-49-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19030, current rewards: -250.04295, mean: -0.96170
[32m[0907 05-49-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18910, current rewards: -300.04295, mean: -0.96788
[32m[0907 05-49-35 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18817, current rewards: -350.04295, mean: -0.97234
[32m[0907 05-49-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18748, current rewards: -397.91312, mean: -0.97052
[32m[0907 05-49-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18697, current rewards: -394.66723, mean: -0.85797
[32m[0907 05-50-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18656, current rewards: -391.42135, mean: -0.76749
[32m[0907 05-50-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18578, current rewards: -388.17546, mean: -0.69317
[32m[0907 05-50-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18509, current rewards: -384.96488, mean: -0.63109
[32m[0907 05-50-29 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18446, current rewards: -382.54511, mean: -0.57961
[32m[0907 05-50-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18395, current rewards: -380.13048, mean: -0.53540
[32m[0907 05-50-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18350, current rewards: -377.71584, mean: -0.49699
[32m[0907 05-50-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18287, current rewards: -423.52267, mean: -0.52287
[32m[0907 05-51-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18221, current rewards: -473.52267, mean: -0.55061
[32m[0907 05-51-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18159, current rewards: -523.52267, mean: -0.57530
[32m[0907 05-51-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18104, current rewards: -573.52267, mean: -0.59742
[32m[0907 05-51-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18052, current rewards: -623.52267, mean: -0.61735
[32m[0907 05-51-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18005, current rewards: -673.52267, mean: -0.63540
[32m[0907 05-51-46 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17965, current rewards: -723.52267, mean: -0.65182
[32m[0907 05-51-55 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17929, current rewards: -773.52267, mean: -0.66683
[32m[0907 05-52-04 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17898, current rewards: -823.52267, mean: -0.68060
[32m[0907 05-52-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17867, current rewards: -873.52267, mean: -0.69327
[32m[0907 05-52-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17838, current rewards: -923.52267, mean: -0.70498
[32m[0907 05-52-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17813, current rewards: -973.52267, mean: -0.71583
[32m[0907 05-52-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17789, current rewards: -1023.52267, mean: -0.72590
[32m[0907 05-52-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17766, current rewards: -1073.52267, mean: -0.73529
[32m[0907 05-52-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17747, current rewards: -1123.52267, mean: -0.74405
[32m[0907 05-53-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17742, current rewards: -1173.52267, mean: -0.75226
[32m[0907 05-53-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17740, current rewards: -1223.52267, mean: -0.75995
[32m[0907 05-53-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17739, current rewards: -1273.52267, mean: -0.76718
[32m[0907 05-53-30 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17738, current rewards: -1323.52267, mean: -0.77399
[32m[0907 05-53-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17738, current rewards: -1373.52267, mean: -0.78041
[32m[0907 05-53-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17752, current rewards: -1423.52267, mean: -0.78648
[32m[0907 05-53-58 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17766, current rewards: -1473.52267, mean: -0.79222
[32m[0907 05-54-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17780, current rewards: -1523.52267, mean: -0.79766
[32m[0907 05-54-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17794, current rewards: -1573.52267, mean: -0.80282
[32m[0907 05-54-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17806, current rewards: -1623.52267, mean: -0.80772
[32m[0907 05-54-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17829, current rewards: -1673.52267, mean: -0.81239
[32m[0907 05-54-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17853, current rewards: -1723.52267, mean: -0.81684
[32m[0907 05-54-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17872, current rewards: -1773.52267, mean: -0.82108
[32m[0907 05-55-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17894, current rewards: -1823.52267, mean: -0.82512
[32m[0907 05-55-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17911, current rewards: -1873.52267, mean: -0.82899
[32m[0907 05-55-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17924, current rewards: -1923.52267, mean: -0.83269
[32m[0907 05-55-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17931, current rewards: -1973.52267, mean: -0.83624
[32m[0907 05-55-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17939, current rewards: -2023.52267, mean: -0.83964
[32m[0907 05-55-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17945, current rewards: -2073.52267, mean: -0.84290
[32m[0907 05-55-56 @Agent.py:117][0m Average action selection time: 0.1795
[32m[0907 05-55-56 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-55-56 @MBExp.py:227][0m Rewards obtained: [-2113.522665247712], Lows: [10], Highs: [2116], Total time: 47248.397345000005
[32m[0907 05-59-37 @MBExp.py:144][0m ####################################################################
[32m[0907 05-59-37 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 05-59-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18859, current rewards: 0.53581, mean: 0.05358
[32m[0907 05-59-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18785, current rewards: -34.83685, mean: -0.58061
[32m[0907 05-59-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18749, current rewards: -33.49122, mean: -0.30447
[32m[0907 06-00-07 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18743, current rewards: -31.51825, mean: -0.19699
[32m[0907 06-00-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18754, current rewards: -40.18422, mean: -0.19135
[32m[0907 06-00-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18748, current rewards: -47.04596, mean: -0.18095
[32m[0907 06-00-35 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18716, current rewards: -58.98903, mean: -0.19029
[32m[0907 06-00-44 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18665, current rewards: -65.58291, mean: -0.18217
[32m[0907 06-00-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18618, current rewards: -73.10541, mean: -0.17831
[32m[0907 06-01-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18587, current rewards: -68.72127, mean: -0.14939
[32m[0907 06-01-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18565, current rewards: -112.19517, mean: -0.21999
[32m[0907 06-01-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18521, current rewards: -162.19517, mean: -0.28963
[32m[0907 06-01-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18455, current rewards: -212.19517, mean: -0.34786
[32m[0907 06-01-38 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18401, current rewards: -262.19517, mean: -0.39727
[32m[0907 06-01-47 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18351, current rewards: -312.19517, mean: -0.43971
[32m[0907 06-01-56 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18311, current rewards: -362.19517, mean: -0.47657
[32m[0907 06-02-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18272, current rewards: -412.19517, mean: -0.50888
[32m[0907 06-02-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18240, current rewards: -462.19517, mean: -0.53744
[32m[0907 06-02-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18180, current rewards: -512.19517, mean: -0.56285
[32m[0907 06-02-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18126, current rewards: -562.19517, mean: -0.58562
[32m[0907 06-02-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18077, current rewards: -612.19517, mean: -0.60613
[32m[0907 06-02-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18029, current rewards: -662.19517, mean: -0.62471
[32m[0907 06-02-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17990, current rewards: -712.19517, mean: -0.64162
[32m[0907 06-03-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17954, current rewards: -762.19517, mean: -0.65706
[32m[0907 06-03-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17922, current rewards: -812.19517, mean: -0.67124
[32m[0907 06-03-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17889, current rewards: -862.19517, mean: -0.68428
[32m[0907 06-03-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17860, current rewards: -912.19517, mean: -0.69633
[32m[0907 06-03-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17833, current rewards: -962.19517, mean: -0.70750
[32m[0907 06-03-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17809, current rewards: -1012.19517, mean: -0.71787
[32m[0907 06-03-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17786, current rewards: -1062.19517, mean: -0.72753
[32m[0907 06-04-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17763, current rewards: -1112.19517, mean: -0.73655
[32m[0907 06-04-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17748, current rewards: -1162.19517, mean: -0.74500
[32m[0907 06-04-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17748, current rewards: -1212.19517, mean: -0.75292
[32m[0907 06-04-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17747, current rewards: -1262.19517, mean: -0.76036
[32m[0907 06-04-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17744, current rewards: -1312.19517, mean: -0.76737
[32m[0907 06-04-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17742, current rewards: -1362.19517, mean: -0.77397
[32m[0907 06-04-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17745, current rewards: -1412.19517, mean: -0.78022
[32m[0907 06-05-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17762, current rewards: -1462.19517, mean: -0.78613
[32m[0907 06-05-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17774, current rewards: -1512.19517, mean: -0.79173
[32m[0907 06-05-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17787, current rewards: -1562.19517, mean: -0.79704
[32m[0907 06-05-35 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17800, current rewards: -1612.19517, mean: -0.80209
[32m[0907 06-05-44 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17812, current rewards: -1662.19517, mean: -0.80689
[32m[0907 06-05-53 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17824, current rewards: -1712.19517, mean: -0.81147
[32m[0907 06-06-03 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17848, current rewards: -1762.19517, mean: -0.81583
[32m[0907 06-06-12 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17871, current rewards: -1812.19517, mean: -0.82000
[32m[0907 06-06-21 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17891, current rewards: -1862.19517, mean: -0.82398
[32m[0907 06-06-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17904, current rewards: -1912.19517, mean: -0.82779
[32m[0907 06-06-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17913, current rewards: -1962.19517, mean: -0.83144
[32m[0907 06-06-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17921, current rewards: -2012.19517, mean: -0.83494
[32m[0907 06-06-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17929, current rewards: -2062.19517, mean: -0.83829
[32m[0907 06-07-05 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0907 06-07-05 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-07-06 @MBExp.py:227][0m Rewards obtained: [-2102.1951714801767], Lows: [66], Highs: [2034], Total time: 47697.589943000006
[32m[0907 06-10-48 @MBExp.py:144][0m ####################################################################
[32m[0907 06-10-48 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 06-10-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20624, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-11-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19121, current rewards: -23.63596, mean: -0.39393
[32m[0907 06-11-09 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19013, current rewards: -35.32482, mean: -0.32113
[32m[0907 06-11-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18935, current rewards: -50.29906, mean: -0.31437
[32m[0907 06-11-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18887, current rewards: -66.05345, mean: -0.31454
[32m[0907 06-11-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18943, current rewards: -71.53548, mean: -0.27514
[32m[0907 06-11-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18913, current rewards: -67.75378, mean: -0.21856
[32m[0907 06-11-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18863, current rewards: -63.98274, mean: -0.17773
[32m[0907 06-12-05 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18793, current rewards: -60.22592, mean: -0.14689
[32m[0907 06-12-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18738, current rewards: -56.43327, mean: -0.12268
[32m[0907 06-12-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18694, current rewards: -78.54364, mean: -0.15401
[32m[0907 06-12-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18645, current rewards: -85.39183, mean: -0.15249
[32m[0907 06-12-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18565, current rewards: -80.32651, mean: -0.13168
[32m[0907 06-12-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18500, current rewards: -75.94625, mean: -0.11507
[32m[0907 06-12-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18443, current rewards: -71.56410, mean: -0.10079
[32m[0907 06-13-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18395, current rewards: -67.18156, mean: -0.08840
[32m[0907 06-13-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18351, current rewards: -62.79881, mean: -0.07753
[32m[0907 06-13-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18314, current rewards: -58.41430, mean: -0.06792
[32m[0907 06-13-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18257, current rewards: -54.03127, mean: -0.05938
[32m[0907 06-13-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18198, current rewards: -76.21102, mean: -0.07939
[32m[0907 06-13-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18146, current rewards: -77.42354, mean: -0.07666
[32m[0907 06-14-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18099, current rewards: -127.42354, mean: -0.12021
[32m[0907 06-14-09 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18056, current rewards: -177.42354, mean: -0.15984
[32m[0907 06-14-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18016, current rewards: -227.42354, mean: -0.19605
[32m[0907 06-14-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17981, current rewards: -277.42354, mean: -0.22928
[32m[0907 06-14-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17949, current rewards: -314.64818, mean: -0.24972
[32m[0907 06-14-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17921, current rewards: -310.40857, mean: -0.23695
[32m[0907 06-14-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17891, current rewards: -306.08126, mean: -0.22506
[32m[0907 06-15-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17865, current rewards: -301.76080, mean: -0.21401
[32m[0907 06-15-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17843, current rewards: -296.21180, mean: -0.20288
[32m[0907 06-15-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17820, current rewards: -312.19395, mean: -0.20675
[32m[0907 06-15-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17799, current rewards: -362.19395, mean: -0.23218
[32m[0907 06-15-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17779, current rewards: -412.19395, mean: -0.25602
[32m[0907 06-15-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17776, current rewards: -462.19395, mean: -0.27843
[32m[0907 06-15-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17776, current rewards: -512.19395, mean: -0.29953
[32m[0907 06-16-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17776, current rewards: -562.19395, mean: -0.31943
[32m[0907 06-16-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17774, current rewards: -612.19395, mean: -0.33823
[32m[0907 06-16-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17787, current rewards: -662.19395, mean: -0.35602
[32m[0907 06-16-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17800, current rewards: -712.19395, mean: -0.37288
[32m[0907 06-16-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17812, current rewards: -762.19395, mean: -0.38887
[32m[0907 06-16-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17824, current rewards: -812.19395, mean: -0.40408
[32m[0907 06-16-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17835, current rewards: -862.19395, mean: -0.41854
[32m[0907 06-17-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17847, current rewards: -912.19395, mean: -0.43232
[32m[0907 06-17-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17865, current rewards: -962.19395, mean: -0.44546
[32m[0907 06-17-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17886, current rewards: -1012.19395, mean: -0.45801
[32m[0907 06-17-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17906, current rewards: -1062.19395, mean: -0.47000
[32m[0907 06-17-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17921, current rewards: -1112.19395, mean: -0.48147
[32m[0907 06-17-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17930, current rewards: -1162.19395, mean: -0.49246
[32m[0907 06-18-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17938, current rewards: -1212.19395, mean: -0.50299
[32m[0907 06-18-10 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17946, current rewards: -1262.19395, mean: -0.51309
[32m[0907 06-18-18 @Agent.py:117][0m Average action selection time: 0.1795
[32m[0907 06-18-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-18-18 @MBExp.py:227][0m Rewards obtained: [-1302.193953833653], Lows: [44], Highs: [1321], Total time: 48147.28787000001
[32m[0907 06-22-03 @MBExp.py:144][0m ####################################################################
[32m[0907 06-22-03 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 06-22-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18793, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-22-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18861, current rewards: -44.15024, mean: -0.73584
[32m[0907 06-22-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18832, current rewards: -89.71190, mean: -0.81556
[32m[0907 06-22-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18831, current rewards: -130.90268, mean: -0.81814
[32m[0907 06-22-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18807, current rewards: -152.12507, mean: -0.72441
[32m[0907 06-22-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18874, current rewards: -190.01001, mean: -0.73081
[32m[0907 06-23-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18945, current rewards: -213.27981, mean: -0.68800
[32m[0907 06-23-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18954, current rewards: -244.99354, mean: -0.68054
[32m[0907 06-23-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18919, current rewards: -282.90899, mean: -0.69002
[32m[0907 06-23-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18861, current rewards: -315.26556, mean: -0.68536
[32m[0907 06-23-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18804, current rewards: -325.30662, mean: -0.63786
[32m[0907 06-23-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18757, current rewards: -321.30219, mean: -0.57375
[32m[0907 06-23-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18715, current rewards: -317.37199, mean: -0.52028
[32m[0907 06-24-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18683, current rewards: -313.49171, mean: -0.47499
[32m[0907 06-24-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18639, current rewards: -310.03203, mean: -0.43666
[32m[0907 06-24-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18581, current rewards: -306.52568, mean: -0.40332
[32m[0907 06-24-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18527, current rewards: -303.06963, mean: -0.37416
[32m[0907 06-24-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18479, current rewards: -299.58412, mean: -0.34835
[32m[0907 06-24-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18415, current rewards: -296.07680, mean: -0.32536
[32m[0907 06-24-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18358, current rewards: -322.81837, mean: -0.33627
[32m[0907 06-25-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18300, current rewards: -362.46903, mean: -0.35888
[32m[0907 06-25-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18245, current rewards: -387.32926, mean: -0.36540
[32m[0907 06-25-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18197, current rewards: -417.30050, mean: -0.37595
[32m[0907 06-25-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18148, current rewards: -444.82427, mean: -0.38347
[32m[0907 06-25-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18134, current rewards: -487.76515, mean: -0.40311
[32m[0907 06-25-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18094, current rewards: -502.75726, mean: -0.39901
[32m[0907 06-26-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18058, current rewards: -499.32865, mean: -0.38117
[32m[0907 06-26-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18025, current rewards: -495.90075, mean: -0.36463
[32m[0907 06-26-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17994, current rewards: -492.47160, mean: -0.34927
[32m[0907 06-26-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17963, current rewards: -488.78249, mean: -0.33478
[32m[0907 06-26-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17937, current rewards: -485.32257, mean: -0.32141
[32m[0907 06-26-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17912, current rewards: -481.86272, mean: -0.30889
[32m[0907 06-26-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17889, current rewards: -478.40450, mean: -0.29715
[32m[0907 06-27-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17920, current rewards: -484.51687, mean: -0.29188
[32m[0907 06-27-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17919, current rewards: -520.83352, mean: -0.30458
[32m[0907 06-27-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17921, current rewards: -559.16364, mean: -0.31771
[32m[0907 06-27-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17934, current rewards: -605.87924, mean: -0.33474
[32m[0907 06-27-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17930, current rewards: -670.53826, mean: -0.36050
[32m[0907 06-27-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17932, current rewards: -731.60480, mean: -0.38304
[32m[0907 06-27-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17934, current rewards: -803.38931, mean: -0.40989
[32m[0907 06-28-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17943, current rewards: -798.42648, mean: -0.39723
[32m[0907 06-28-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17952, current rewards: -793.59806, mean: -0.38524
[32m[0907 06-28-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17961, current rewards: -788.77257, mean: -0.37383
[32m[0907 06-28-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17972, current rewards: -783.94553, mean: -0.36294
[32m[0907 06-28-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17993, current rewards: -779.11591, mean: -0.35254
[32m[0907 06-28-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18014, current rewards: -773.91092, mean: -0.34244
[32m[0907 06-29-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18027, current rewards: -769.10742, mean: -0.33295
[32m[0907 06-29-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18033, current rewards: -764.31191, mean: -0.32386
[32m[0907 06-29-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18040, current rewards: -759.51253, mean: -0.31515
[32m[0907 06-29-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18047, current rewards: -776.99278, mean: -0.31585
[32m[0907 06-29-35 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 06-29-35 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-29-35 @MBExp.py:227][0m Rewards obtained: [-807.9617167492895], Lows: [501], Highs: [45], Total time: 48599.44579800001
[32m[0907 06-33-22 @MBExp.py:144][0m ####################################################################
[32m[0907 06-33-22 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 06-33-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18712, current rewards: 0.77710, mean: 0.07771
[32m[0907 06-33-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18866, current rewards: 7.13757, mean: 0.11896
[32m[0907 06-33-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18844, current rewards: 12.05350, mean: 0.10958
[32m[0907 06-33-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18801, current rewards: 16.82683, mean: 0.10517
[32m[0907 06-34-01 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18809, current rewards: 21.68807, mean: 0.10328
[32m[0907 06-34-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18800, current rewards: 26.55476, mean: 0.10213
[32m[0907 06-34-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18807, current rewards: 24.83675, mean: 0.08012
[32m[0907 06-34-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18792, current rewards: 17.65536, mean: 0.04904
[32m[0907 06-34-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18786, current rewards: 29.56225, mean: 0.07210
[32m[0907 06-34-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18743, current rewards: 41.99674, mean: 0.09130
[32m[0907 06-34-57 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18696, current rewards: 54.46314, mean: 0.10679
[32m[0907 06-35-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18662, current rewards: 64.44797, mean: 0.11509
[32m[0907 06-35-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18633, current rewards: 62.52571, mean: 0.10250
[32m[0907 06-35-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18606, current rewards: 73.24751, mean: 0.11098
[32m[0907 06-35-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18584, current rewards: 58.87054, mean: 0.08292
[32m[0907 06-35-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18550, current rewards: 46.17774, mean: 0.06076
[32m[0907 06-35-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18497, current rewards: -25.76778, mean: -0.03181
[32m[0907 06-36-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18454, current rewards: -107.98671, mean: -0.12557
[32m[0907 06-36-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18397, current rewards: -207.98671, mean: -0.22856
[32m[0907 06-36-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18333, current rewards: -305.45955, mean: -0.31819
[32m[0907 06-36-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18273, current rewards: -405.45955, mean: -0.40145
[32m[0907 06-36-35 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18223, current rewards: -505.45955, mean: -0.47685
[32m[0907 06-36-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18176, current rewards: -605.45955, mean: -0.54546
[32m[0907 06-36-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18132, current rewards: -705.45955, mean: -0.60815
[32m[0907 06-37-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18088, current rewards: -805.45955, mean: -0.66567
[32m[0907 06-37-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18062, current rewards: -905.45955, mean: -0.71862
[32m[0907 06-37-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18034, current rewards: -1005.45955, mean: -0.76753
[32m[0907 06-37-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18007, current rewards: -1105.45955, mean: -0.81284
[32m[0907 06-37-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17977, current rewards: -1205.45955, mean: -0.85494
[32m[0907 06-37-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17949, current rewards: -1305.45955, mean: -0.89415
[32m[0907 06-37-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17923, current rewards: -1405.45955, mean: -0.93077
[32m[0907 06-38-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17899, current rewards: -1505.45955, mean: -0.96504
[32m[0907 06-38-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17878, current rewards: -1605.45955, mean: -0.99718
[32m[0907 06-38-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17855, current rewards: -1705.45955, mean: -1.02739
[32m[0907 06-38-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17835, current rewards: -1784.13802, mean: -1.04336
[32m[0907 06-38-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17829, current rewards: -1884.13802, mean: -1.07053
[32m[0907 06-38-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17826, current rewards: -1984.13802, mean: -1.09621
[32m[0907 06-38-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17825, current rewards: -2084.13802, mean: -1.12050
[32m[0907 06-39-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17824, current rewards: -2184.13802, mean: -1.14353
[32m[0907 06-39-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17827, current rewards: -2284.13802, mean: -1.16538
[32m[0907 06-39-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17857, current rewards: -2384.13802, mean: -1.18614
[32m[0907 06-39-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17863, current rewards: -2481.96434, mean: -1.20484
[32m[0907 06-39-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17875, current rewards: -2581.96434, mean: -1.22368
[32m[0907 06-39-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17889, current rewards: -2679.24559, mean: -1.24039
[32m[0907 06-39-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17914, current rewards: -2776.48675, mean: -1.25633
[32m[0907 06-40-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17941, current rewards: -2873.92460, mean: -1.27165
[32m[0907 06-40-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17962, current rewards: -2971.33159, mean: -1.28629
[32m[0907 06-40-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17970, current rewards: -2998.73630, mean: -1.27065
[32m[0907 06-40-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17977, current rewards: -2994.82961, mean: -1.24267
[32m[0907 06-40-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17983, current rewards: -2983.70034, mean: -1.21289
[32m[0907 06-40-52 @Agent.py:117][0m Average action selection time: 0.1799
[32m[0907 06-40-52 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-40-53 @MBExp.py:227][0m Rewards obtained: [-2973.365728317989], Lows: [1564], Highs: [13], Total time: 49050.05472900001
[32m[0907 06-44-41 @MBExp.py:144][0m ####################################################################
[32m[0907 06-44-41 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 06-44-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18781, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-44-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18812, current rewards: -60.42847, mean: -1.00714
[32m[0907 06-45-02 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18808, current rewards: -96.62276, mean: -0.87839
[32m[0907 06-45-11 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18803, current rewards: -116.46790, mean: -0.72792
[32m[0907 06-45-21 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18784, current rewards: -142.94286, mean: -0.68068
[32m[0907 06-45-30 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18845, current rewards: -193.39683, mean: -0.74383
[32m[0907 06-45-40 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18827, current rewards: -209.60272, mean: -0.67614
[32m[0907 06-45-49 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18801, current rewards: -214.11494, mean: -0.59476
[32m[0907 06-45-58 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18801, current rewards: -210.09895, mean: -0.51244
[32m[0907 06-46-08 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18801, current rewards: -206.99193, mean: -0.44998
[32m[0907 06-46-17 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18796, current rewards: -203.88527, mean: -0.39978
[32m[0907 06-46-26 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18753, current rewards: -236.91838, mean: -0.42307
[32m[0907 06-46-35 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18717, current rewards: -325.53413, mean: -0.53366
[32m[0907 06-46-45 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18683, current rewards: -418.73106, mean: -0.63444
[32m[0907 06-46-54 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18656, current rewards: -518.73106, mean: -0.73061
[32m[0907 06-47-03 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18624, current rewards: -618.73106, mean: -0.81412
[32m[0907 06-47-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18569, current rewards: -718.73106, mean: -0.88732
[32m[0907 06-47-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18521, current rewards: -818.73106, mean: -0.95201
[32m[0907 06-47-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18465, current rewards: -918.73106, mean: -1.00959
[32m[0907 06-47-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18399, current rewards: -1018.73106, mean: -1.06118
[32m[0907 06-47-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18335, current rewards: -1118.73106, mean: -1.10765
[32m[0907 06-47-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18277, current rewards: -1184.49417, mean: -1.11745
[32m[0907 06-48-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18226, current rewards: -1185.00832, mean: -1.06758
[32m[0907 06-48-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18180, current rewards: -1180.14061, mean: -1.01736
[32m[0907 06-48-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18139, current rewards: -1175.30954, mean: -0.97133
[32m[0907 06-48-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18101, current rewards: -1170.48353, mean: -0.92896
[32m[0907 06-48-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18063, current rewards: -1165.64836, mean: -0.88981
[32m[0907 06-48-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18030, current rewards: -1217.43712, mean: -0.89517
[32m[0907 06-48-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18029, current rewards: -1259.88309, mean: -0.89353
[32m[0907 06-49-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18022, current rewards: -1346.35138, mean: -0.92216
[32m[0907 06-49-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18029, current rewards: -1391.02562, mean: -0.92121
[32m[0907 06-49-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18006, current rewards: -1477.19841, mean: -0.94692
[32m[0907 06-49-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17980, current rewards: -1577.19841, mean: -0.97963
[32m[0907 06-49-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17957, current rewards: -1677.19841, mean: -1.01036
[32m[0907 06-49-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17933, current rewards: -1777.19841, mean: -1.03930
[32m[0907 06-49-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17910, current rewards: -1877.19841, mean: -1.06659
[32m[0907 06-50-05 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17890, current rewards: -1977.19841, mean: -1.09237
[32m[0907 06-50-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17885, current rewards: -2063.06866, mean: -1.10918
[32m[0907 06-50-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17882, current rewards: -2058.17905, mean: -1.07758
[32m[0907 06-50-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17879, current rewards: -2053.89454, mean: -1.04791
[32m[0907 06-50-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17876, current rewards: -2049.55471, mean: -1.01968
[32m[0907 06-50-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17877, current rewards: -2045.20656, mean: -0.99282
[32m[0907 06-50-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17887, current rewards: -2040.84606, mean: -0.96723
[32m[0907 06-51-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17898, current rewards: -2036.47461, mean: -0.94281
[32m[0907 06-51-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17912, current rewards: -2031.27888, mean: -0.91913
[32m[0907 06-51-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17934, current rewards: -2071.56333, mean: -0.91662
[32m[0907 06-51-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17956, current rewards: -2069.10051, mean: -0.89571
[32m[0907 06-51-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17964, current rewards: -2064.23500, mean: -0.87468
[32m[0907 06-51-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17972, current rewards: -2059.37461, mean: -0.85451
[32m[0907 06-52-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17980, current rewards: -2054.51644, mean: -0.83517
[32m[0907 06-52-11 @Agent.py:117][0m Average action selection time: 0.1799
[32m[0907 06-52-11 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-52-12 @MBExp.py:227][0m Rewards obtained: [-2050.6285103840173], Lows: [1059], Highs: [76], Total time: 49500.588934000014
[32m[0907 06-56-03 @MBExp.py:144][0m ####################################################################
[32m[0907 06-56-03 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 06-56-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18743, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-56-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18809, current rewards: -7.50746, mean: -0.12512
[32m[0907 06-56-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18818, current rewards: -4.46945, mean: -0.04063
[32m[0907 06-56-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18785, current rewards: -1.03078, mean: -0.00644
[32m[0907 06-56-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18779, current rewards: 2.38414, mean: 0.01135
[32m[0907 06-56-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18780, current rewards: 5.80446, mean: 0.02232
[32m[0907 06-57-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18773, current rewards: 9.22253, mean: 0.02975
[32m[0907 06-57-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18783, current rewards: 12.64007, mean: 0.03511
[32m[0907 06-57-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18787, current rewards: 16.05748, mean: 0.03916
[32m[0907 06-57-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18783, current rewards: 19.47660, mean: 0.04234
[32m[0907 06-57-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18785, current rewards: 22.89824, mean: 0.04490
[32m[0907 06-57-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18749, current rewards: 26.30552, mean: 0.04697
[32m[0907 06-57-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18709, current rewards: 29.74119, mean: 0.04876
[32m[0907 06-58-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18675, current rewards: 33.17175, mean: 0.05026
[32m[0907 06-58-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18646, current rewards: 36.60398, mean: 0.05155
[32m[0907 06-58-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18678, current rewards: 25.50021, mean: 0.03355
[32m[0907 06-58-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18700, current rewards: -9.02746, mean: -0.01115
[32m[0907 06-58-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18674, current rewards: -40.51076, mean: -0.04711
[32m[0907 06-58-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18707, current rewards: -70.71573, mean: -0.07771
[32m[0907 06-59-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18750, current rewards: -95.88049, mean: -0.09988
[32m[0907 06-59-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18868, current rewards: -113.47776, mean: -0.11235
[32m[0907 06-59-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18888, current rewards: -129.65030, mean: -0.12231
[32m[0907 06-59-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18967, current rewards: -141.68962, mean: -0.12765
[32m[0907 06-59-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19009, current rewards: -158.60310, mean: -0.13673
[32m[0907 06-59-53 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19043, current rewards: -176.69326, mean: -0.14603
[32m[0907 07-00-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19110, current rewards: -193.01225, mean: -0.15318
[32m[0907 07-00-14 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19127, current rewards: -216.07333, mean: -0.16494
[32m[0907 07-00-23 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19090, current rewards: -224.53857, mean: -0.16510
[32m[0907 07-00-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19020, current rewards: -221.35385, mean: -0.15699
[32m[0907 07-00-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18956, current rewards: -218.17250, mean: -0.14943
[32m[0907 07-00-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18896, current rewards: -214.99030, mean: -0.14238
[32m[0907 07-00-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18840, current rewards: -211.80970, mean: -0.13578
[32m[0907 07-01-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18789, current rewards: -208.62925, mean: -0.12958
[32m[0907 07-01-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18740, current rewards: -205.44743, mean: -0.12376
[32m[0907 07-01-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18693, current rewards: -202.26508, mean: -0.11828
[32m[0907 07-01-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18650, current rewards: -198.89043, mean: -0.11301
[32m[0907 07-01-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18623, current rewards: -195.67739, mean: -0.10811
[32m[0907 07-01-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18600, current rewards: -192.46449, mean: -0.10348
[32m[0907 07-01-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18654, current rewards: -208.31675, mean: -0.10907
[32m[0907 07-02-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18813, current rewards: -203.65159, mean: -0.10390
[32m[0907 07-02-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18886, current rewards: -198.93351, mean: -0.09897
[32m[0907 07-02-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18946, current rewards: -194.30741, mean: -0.09432
[32m[0907 07-02-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19044, current rewards: -189.64571, mean: -0.08988
[32m[0907 07-02-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19090, current rewards: -185.06476, mean: -0.08568
[32m[0907 07-03-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19129, current rewards: -180.42105, mean: -0.08164
[32m[0907 07-03-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19183, current rewards: -175.77000, mean: -0.07777
[32m[0907 07-03-27 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19227, current rewards: -171.15187, mean: -0.07409
[32m[0907 07-03-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19243, current rewards: -208.57826, mean: -0.08838
[32m[0907 07-03-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19223, current rewards: -260.84067, mean: -0.10823
[32m[0907 07-03-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19204, current rewards: -308.62483, mean: -0.12546
[32m[0907 07-04-03 @Agent.py:117][0m Average action selection time: 0.1919
[32m[0907 07-04-03 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-04-03 @MBExp.py:227][0m Rewards obtained: [-347.26218386856124], Lows: [157], Highs: [231], Total time: 49981.206848000016
[32m[0907 07-07-57 @MBExp.py:144][0m ####################################################################
[32m[0907 07-07-57 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 07-07-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18599, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-08-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19282, current rewards: -110.00000, mean: -1.83333
[32m[0907 07-08-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19523, current rewards: -210.00000, mean: -1.90909
[32m[0907 07-08-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19585, current rewards: -310.00000, mean: -1.93750
[32m[0907 07-08-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19477, current rewards: -410.00000, mean: -1.95238
[32m[0907 07-08-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19344, current rewards: -510.00000, mean: -1.96154
[32m[0907 07-08-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19256, current rewards: -610.00000, mean: -1.96774
[32m[0907 07-09-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19189, current rewards: -710.00000, mean: -1.97222
[32m[0907 07-09-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19088, current rewards: -810.00000, mean: -1.97561
[32m[0907 07-09-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18992, current rewards: -910.00000, mean: -1.97826
[32m[0907 07-09-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18924, current rewards: -1010.00000, mean: -1.98039
[32m[0907 07-09-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18864, current rewards: -1110.00000, mean: -1.98214
[32m[0907 07-09-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18818, current rewards: -1188.21855, mean: -1.94790
[32m[0907 07-10-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18749, current rewards: -1272.14362, mean: -1.92749
[32m[0907 07-10-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18676, current rewards: -1366.84445, mean: -1.92513
[32m[0907 07-10-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18593, current rewards: -1466.84445, mean: -1.93006
[32m[0907 07-10-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18503, current rewards: -1566.84445, mean: -1.93438
[32m[0907 07-10-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18425, current rewards: -1666.84445, mean: -1.93819
[32m[0907 07-10-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18353, current rewards: -1766.84445, mean: -1.94159
[32m[0907 07-10-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18288, current rewards: -1866.84445, mean: -1.94463
[32m[0907 07-11-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18235, current rewards: -1966.84445, mean: -1.94737
[32m[0907 07-11-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18183, current rewards: -2066.84445, mean: -1.94985
[32m[0907 07-11-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18135, current rewards: -2166.84445, mean: -1.95211
[32m[0907 07-11-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18104, current rewards: -2266.84445, mean: -1.95418
[32m[0907 07-11-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18090, current rewards: -2366.84445, mean: -1.95607
[32m[0907 07-11-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18071, current rewards: -2466.84445, mean: -1.95781
[32m[0907 07-11-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18036, current rewards: -2566.84445, mean: -1.95942
[32m[0907 07-12-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18003, current rewards: -2666.84445, mean: -1.96092
[32m[0907 07-12-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17972, current rewards: -2766.84445, mean: -1.96230
[32m[0907 07-12-19 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17942, current rewards: -2866.84445, mean: -1.96359
[32m[0907 07-12-28 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17917, current rewards: -2966.84445, mean: -1.96480
[32m[0907 07-12-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17891, current rewards: -3066.84445, mean: -1.96593
[32m[0907 07-12-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17867, current rewards: -3166.84445, mean: -1.96698
[32m[0907 07-12-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17844, current rewards: -3266.84445, mean: -1.96798
[32m[0907 07-13-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17823, current rewards: -3366.84445, mean: -1.96891
[32m[0907 07-13-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17820, current rewards: -3466.84445, mean: -1.96980
[32m[0907 07-13-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17815, current rewards: -3566.84445, mean: -1.97063
[32m[0907 07-13-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17811, current rewards: -3666.84445, mean: -1.97142
[32m[0907 07-13-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17809, current rewards: -3766.84445, mean: -1.97217
[32m[0907 07-13-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17807, current rewards: -3866.84445, mean: -1.97288
[32m[0907 07-13-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17820, current rewards: -3966.84445, mean: -1.97355
[32m[0907 07-14-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17831, current rewards: -4066.84445, mean: -1.97420
[32m[0907 07-14-14 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17855, current rewards: -4166.84445, mean: -1.97481
[32m[0907 07-14-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17872, current rewards: -4266.84445, mean: -1.97539
[32m[0907 07-14-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17880, current rewards: -4366.84445, mean: -1.97595
[32m[0907 07-14-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17890, current rewards: -4466.84445, mean: -1.97648
[32m[0907 07-14-51 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17899, current rewards: -4566.84445, mean: -1.97699
[32m[0907 07-15-00 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17908, current rewards: -4666.84445, mean: -1.97748
[32m[0907 07-15-09 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17917, current rewards: -4766.84445, mean: -1.97794
[32m[0907 07-15-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17925, current rewards: -4866.84445, mean: -1.97839
[32m[0907 07-15-26 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0907 07-15-26 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-15-26 @MBExp.py:227][0m Rewards obtained: [-4946.84444861919], Lows: [2472], Highs: [10], Total time: 50430.34113700002
[32m[0907 07-19-22 @MBExp.py:144][0m ####################################################################
[32m[0907 07-19-22 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 07-19-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19914, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-19-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19011, current rewards: -109.00000, mean: -1.81667
[32m[0907 07-19-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18843, current rewards: -209.00000, mean: -1.90000
[32m[0907 07-19-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18803, current rewards: -309.00000, mean: -1.93125
[32m[0907 07-20-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18790, current rewards: -409.00000, mean: -1.94762
[32m[0907 07-20-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18803, current rewards: -509.00000, mean: -1.95769
[32m[0907 07-20-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18793, current rewards: -609.00000, mean: -1.96452
[32m[0907 07-20-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18789, current rewards: -709.00000, mean: -1.96944
[32m[0907 07-20-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18785, current rewards: -809.00000, mean: -1.97317
[32m[0907 07-20-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18736, current rewards: -909.00000, mean: -1.97609
[32m[0907 07-20-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18687, current rewards: -1009.00000, mean: -1.97843
[32m[0907 07-21-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18649, current rewards: -1109.00000, mean: -1.98036
[32m[0907 07-21-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18625, current rewards: -1209.00000, mean: -1.98197
[32m[0907 07-21-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18599, current rewards: -1309.00000, mean: -1.98333
[32m[0907 07-21-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18553, current rewards: -1409.00000, mean: -1.98451
[32m[0907 07-21-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18493, current rewards: -1509.00000, mean: -1.98553
[32m[0907 07-21-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18408, current rewards: -1609.00000, mean: -1.98642
[32m[0907 07-22-00 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18338, current rewards: -1709.00000, mean: -1.98721
[32m[0907 07-22-09 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18272, current rewards: -1809.00000, mean: -1.98791
[32m[0907 07-22-17 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18210, current rewards: -1909.00000, mean: -1.98854
[32m[0907 07-22-26 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18156, current rewards: -2009.00000, mean: -1.98911
[32m[0907 07-22-34 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18107, current rewards: -2109.00000, mean: -1.98962
[32m[0907 07-22-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18065, current rewards: -2209.00000, mean: -1.99009
[32m[0907 07-22-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18024, current rewards: -2309.00000, mean: -1.99052
[32m[0907 07-23-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17987, current rewards: -2409.00000, mean: -1.99091
[32m[0907 07-23-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17951, current rewards: -2509.00000, mean: -1.99127
[32m[0907 07-23-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17916, current rewards: -2609.00000, mean: -1.99160
[32m[0907 07-23-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17888, current rewards: -2709.00000, mean: -1.99191
[32m[0907 07-23-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17860, current rewards: -2809.00000, mean: -1.99220
[32m[0907 07-23-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17835, current rewards: -2909.00000, mean: -1.99247
[32m[0907 07-23-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17810, current rewards: -3009.00000, mean: -1.99272
[32m[0907 07-24-00 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17789, current rewards: -3109.00000, mean: -1.99295
[32m[0907 07-24-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17768, current rewards: -3209.00000, mean: -1.99317
[32m[0907 07-24-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17751, current rewards: -3309.00000, mean: -1.99337
[32m[0907 07-24-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17734, current rewards: -3409.00000, mean: -1.99357
[32m[0907 07-24-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17716, current rewards: -3509.00000, mean: -1.99375
[32m[0907 07-24-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17715, current rewards: -3609.00000, mean: -1.99392
[32m[0907 07-24-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17714, current rewards: -3709.00000, mean: -1.99409
[32m[0907 07-25-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17716, current rewards: -3809.00000, mean: -1.99424
[32m[0907 07-25-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17717, current rewards: -3909.00000, mean: -1.99439
[32m[0907 07-25-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17719, current rewards: -4009.00000, mean: -1.99453
[32m[0907 07-25-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17730, current rewards: -4109.00000, mean: -1.99466
[32m[0907 07-25-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17749, current rewards: -4209.00000, mean: -1.99479
[32m[0907 07-25-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17774, current rewards: -4309.00000, mean: -1.99491
[32m[0907 07-25-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17785, current rewards: -4409.00000, mean: -1.99502
[32m[0907 07-26-05 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17798, current rewards: -4509.00000, mean: -1.99513
[32m[0907 07-26-14 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17809, current rewards: -4609.00000, mean: -1.99524
[32m[0907 07-26-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17819, current rewards: -4709.00000, mean: -1.99534
[32m[0907 07-26-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17830, current rewards: -4809.00000, mean: -1.99544
[32m[0907 07-26-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17840, current rewards: -4909.00000, mean: -1.99553
[32m[0907 07-26-49 @Agent.py:117][0m Average action selection time: 0.1785
[32m[0907 07-26-49 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-26-49 @MBExp.py:227][0m Rewards obtained: [-4989], Lows: [2489], Highs: [11], Total time: 50877.41993500002
[32m[0907 07-30-48 @MBExp.py:144][0m ####################################################################
[32m[0907 07-30-48 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 07-30-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18895, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-31-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20869, current rewards: -54.68434, mean: -0.91141
[32m[0907 07-31-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20560, current rewards: -101.52248, mean: -0.92293
[32m[0907 07-31-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20223, current rewards: -151.52248, mean: -0.94702
[32m[0907 07-31-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19914, current rewards: -201.52248, mean: -0.95963
[32m[0907 07-31-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19753, current rewards: -251.52248, mean: -0.96739
[32m[0907 07-31-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19660, current rewards: -301.52248, mean: -0.97265
[32m[0907 07-31-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19595, current rewards: -351.52248, mean: -0.97645
[32m[0907 07-32-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19614, current rewards: -390.89854, mean: -0.95341
[32m[0907 07-32-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19732, current rewards: -432.45724, mean: -0.94012
[32m[0907 07-32-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19717, current rewards: -477.15135, mean: -0.93559
[32m[0907 07-32-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19708, current rewards: -520.82670, mean: -0.93005
[32m[0907 07-32-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19656, current rewards: -563.41838, mean: -0.92364
[32m[0907 07-32-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19675, current rewards: -603.95665, mean: -0.91509
[32m[0907 07-33-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19653, current rewards: -647.09981, mean: -0.91141
[32m[0907 07-33-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19507, current rewards: -640.17315, mean: -0.84233
[32m[0907 07-33-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19362, current rewards: -651.64202, mean: -0.80450
[32m[0907 07-33-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19231, current rewards: -701.64202, mean: -0.81586
[32m[0907 07-33-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19117, current rewards: -751.64202, mean: -0.82598
[32m[0907 07-33-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19012, current rewards: -801.64202, mean: -0.83504
[32m[0907 07-33-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18919, current rewards: -851.64202, mean: -0.84321
[32m[0907 07-34-07 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18834, current rewards: -901.64202, mean: -0.85061
[32m[0907 07-34-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18756, current rewards: -951.64202, mean: -0.85734
[32m[0907 07-34-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18686, current rewards: -1001.64202, mean: -0.86348
[32m[0907 07-34-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18623, current rewards: -1051.64202, mean: -0.86913
[32m[0907 07-34-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18563, current rewards: -1101.64202, mean: -0.87432
[32m[0907 07-34-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18507, current rewards: -1151.64202, mean: -0.87912
[32m[0907 07-34-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18457, current rewards: -1201.64202, mean: -0.88356
[32m[0907 07-35-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18409, current rewards: -1251.64202, mean: -0.88769
[32m[0907 07-35-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18367, current rewards: -1301.64202, mean: -0.89154
[32m[0907 07-35-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18326, current rewards: -1351.64202, mean: -0.89513
[32m[0907 07-35-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18289, current rewards: -1401.64202, mean: -0.89849
[32m[0907 07-35-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18255, current rewards: -1451.64202, mean: -0.90164
[32m[0907 07-35-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18221, current rewards: -1501.64202, mean: -0.90460
[32m[0907 07-35-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18190, current rewards: -1551.64202, mean: -0.90739
[32m[0907 07-36-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18160, current rewards: -1601.64202, mean: -0.91002
[32m[0907 07-36-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18132, current rewards: -1651.64202, mean: -0.91251
[32m[0907 07-36-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18106, current rewards: -1701.64202, mean: -0.91486
[32m[0907 07-36-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18081, current rewards: -1751.64202, mean: -0.91709
[32m[0907 07-36-42 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18060, current rewards: -1801.64202, mean: -0.91921
[32m[0907 07-36-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18052, current rewards: -1851.64202, mean: -0.92121
[32m[0907 07-37-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18053, current rewards: -1901.64202, mean: -0.92313
[32m[0907 07-37-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18063, current rewards: -1951.64202, mean: -0.92495
[32m[0907 07-37-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18075, current rewards: -2001.64202, mean: -0.92669
[32m[0907 07-37-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18081, current rewards: -2051.64202, mean: -0.92834
[32m[0907 07-37-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18088, current rewards: -2101.64202, mean: -0.92993
[32m[0907 07-37-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18093, current rewards: -2151.64202, mean: -0.93145
[32m[0907 07-37-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18098, current rewards: -2201.64202, mean: -0.93290
[32m[0907 07-38-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18102, current rewards: -2251.64202, mean: -0.93429
[32m[0907 07-38-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18107, current rewards: -2301.64202, mean: -0.93563
[32m[0907 07-38-21 @Agent.py:117][0m Average action selection time: 0.1811
[32m[0907 07-38-21 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-38-21 @MBExp.py:227][0m Rewards obtained: [-2341.642024805796], Lows: [7], Highs: [2343], Total time: 51331.04265000002
[32m[0907 07-42-22 @MBExp.py:144][0m ####################################################################
[32m[0907 07-42-22 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 07-42-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18814, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-42-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19510, current rewards: -55.94790, mean: -0.93246
[32m[0907 07-42-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19169, current rewards: -155.94790, mean: -1.41771
[32m[0907 07-42-52 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19042, current rewards: -255.94790, mean: -1.59967
[32m[0907 07-43-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19001, current rewards: -355.94790, mean: -1.69499
[32m[0907 07-43-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18942, current rewards: -455.94790, mean: -1.75365
[32m[0907 07-43-20 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18899, current rewards: -555.94790, mean: -1.79338
[32m[0907 07-43-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18874, current rewards: -655.94790, mean: -1.82208
[32m[0907 07-43-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18855, current rewards: -755.94790, mean: -1.84378
[32m[0907 07-43-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18841, current rewards: -855.94790, mean: -1.86076
[32m[0907 07-43-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18830, current rewards: -955.94790, mean: -1.87441
[32m[0907 07-44-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18826, current rewards: -1055.94790, mean: -1.88562
[32m[0907 07-44-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18820, current rewards: -1155.94790, mean: -1.89500
[32m[0907 07-44-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18782, current rewards: -1255.94790, mean: -1.90295
[32m[0907 07-44-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18751, current rewards: -1355.94790, mean: -1.90979
[32m[0907 07-44-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18710, current rewards: -1455.94790, mean: -1.91572
[32m[0907 07-44-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18611, current rewards: -1555.94790, mean: -1.92092
[32m[0907 07-45-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18526, current rewards: -1655.94790, mean: -1.92552
[32m[0907 07-45-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18448, current rewards: -1755.94790, mean: -1.92961
[32m[0907 07-45-18 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18383, current rewards: -1855.94790, mean: -1.93328
[32m[0907 07-45-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18326, current rewards: -1955.94790, mean: -1.93658
[32m[0907 07-45-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18269, current rewards: -2055.94790, mean: -1.93957
[32m[0907 07-45-44 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18220, current rewards: -2155.94790, mean: -1.94230
[32m[0907 07-45-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18174, current rewards: -2255.94790, mean: -1.94478
[32m[0907 07-46-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18131, current rewards: -2355.94790, mean: -1.94706
[32m[0907 07-46-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18093, current rewards: -2455.94790, mean: -1.94916
[32m[0907 07-46-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18054, current rewards: -2555.94790, mean: -1.95111
[32m[0907 07-46-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18019, current rewards: -2655.94790, mean: -1.95290
[32m[0907 07-46-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17990, current rewards: -2755.94790, mean: -1.95457
[32m[0907 07-46-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17963, current rewards: -2855.94790, mean: -1.95613
[32m[0907 07-46-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17937, current rewards: -2955.94790, mean: -1.95758
[32m[0907 07-47-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17914, current rewards: -3055.94790, mean: -1.95894
[32m[0907 07-47-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17890, current rewards: -3155.94790, mean: -1.96022
[32m[0907 07-47-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17869, current rewards: -3255.94790, mean: -1.96141
[32m[0907 07-47-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17850, current rewards: -3355.94790, mean: -1.96254
[32m[0907 07-47-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17829, current rewards: -3455.94790, mean: -1.96361
[32m[0907 07-47-44 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17812, current rewards: -3555.94790, mean: -1.96461
[32m[0907 07-47-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17793, current rewards: -3655.94790, mean: -1.96556
[32m[0907 07-48-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17776, current rewards: -3755.94790, mean: -1.96646
[32m[0907 07-48-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17759, current rewards: -3855.94790, mean: -1.96732
[32m[0907 07-48-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17751, current rewards: -3955.94790, mean: -1.96813
[32m[0907 07-48-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17752, current rewards: -4055.94790, mean: -1.96891
[32m[0907 07-48-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17751, current rewards: -4155.94790, mean: -1.96964
[32m[0907 07-48-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17770, current rewards: -4255.94790, mean: -1.97035
[32m[0907 07-48-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17782, current rewards: -4355.94790, mean: -1.97102
[32m[0907 07-49-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17794, current rewards: -4455.94790, mean: -1.97166
[32m[0907 07-49-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17805, current rewards: -4555.94790, mean: -1.97227
[32m[0907 07-49-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17817, current rewards: -4655.94790, mean: -1.97286
[32m[0907 07-49-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17826, current rewards: -4755.94790, mean: -1.97342
[32m[0907 07-49-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17836, current rewards: -4855.94790, mean: -1.97396
[32m[0907 07-49-48 @Agent.py:117][0m Average action selection time: 0.1784
[32m[0907 07-49-48 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-49-49 @MBExp.py:227][0m Rewards obtained: [-4935.947898768991], Lows: [2448], Highs: [41], Total time: 51777.98920700002
[32m[0907 07-53-51 @MBExp.py:144][0m ####################################################################
[32m[0907 07-53-51 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 07-53-53 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20072, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-54-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19024, current rewards: -104.78316, mean: -1.74639
[32m[0907 07-54-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18876, current rewards: -204.78316, mean: -1.86167
[32m[0907 07-54-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18830, current rewards: -304.78316, mean: -1.90489
[32m[0907 07-54-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18819, current rewards: -404.78316, mean: -1.92754
[32m[0907 07-54-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18809, current rewards: -504.78316, mean: -1.94147
[32m[0907 07-54-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18805, current rewards: -604.78316, mean: -1.95091
[32m[0907 07-54-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18811, current rewards: -704.78316, mean: -1.95773
[32m[0907 07-55-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18807, current rewards: -804.78316, mean: -1.96289
[32m[0907 07-55-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18819, current rewards: -904.78316, mean: -1.96692
[32m[0907 07-55-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18987, current rewards: -1002.57543, mean: -1.96583
[32m[0907 07-55-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19154, current rewards: -1102.57543, mean: -1.96888
[32m[0907 07-55-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19151, current rewards: -1202.57543, mean: -1.97144
[32m[0907 07-55-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19119, current rewards: -1302.57543, mean: -1.97360
[32m[0907 07-56-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19072, current rewards: -1402.57543, mean: -1.97546
[32m[0907 07-56-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19064, current rewards: -1502.57543, mean: -1.97707
[32m[0907 07-56-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18991, current rewards: -1602.57543, mean: -1.97849
[32m[0907 07-56-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18891, current rewards: -1702.57543, mean: -1.97974
[32m[0907 07-56-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18853, current rewards: -1802.57543, mean: -1.98085
[32m[0907 07-56-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18763, current rewards: -1902.57543, mean: -1.98185
[32m[0907 07-57-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18686, current rewards: -2002.57543, mean: -1.98275
[32m[0907 07-57-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18614, current rewards: -2102.57543, mean: -1.98356
[32m[0907 07-57-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18547, current rewards: -2202.57543, mean: -1.98430
[32m[0907 07-57-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18486, current rewards: -2302.57543, mean: -1.98498
[32m[0907 07-57-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18430, current rewards: -2402.57543, mean: -1.98560
[32m[0907 07-57-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18380, current rewards: -2502.57543, mean: -1.98617
[32m[0907 07-57-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18336, current rewards: -2594.96969, mean: -1.98089
[32m[0907 07-58-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18291, current rewards: -2694.96969, mean: -1.98160
[32m[0907 07-58-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18251, current rewards: -2794.96969, mean: -1.98225
[32m[0907 07-58-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18213, current rewards: -2894.96969, mean: -1.98286
[32m[0907 07-58-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18176, current rewards: -2994.96969, mean: -1.98342
[32m[0907 07-58-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18145, current rewards: -3094.96969, mean: -1.98395
[32m[0907 07-58-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18114, current rewards: -3194.96969, mean: -1.98445
[32m[0907 07-58-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18086, current rewards: -3294.96969, mean: -1.98492
[32m[0907 07-59-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18059, current rewards: -3394.96969, mean: -1.98536
[32m[0907 07-59-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18035, current rewards: -3494.96969, mean: -1.98578
[32m[0907 07-59-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18011, current rewards: -3594.96969, mean: -1.98617
[32m[0907 07-59-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17989, current rewards: -3694.96969, mean: -1.98654
[32m[0907 07-59-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17967, current rewards: -3794.96969, mean: -1.98690
[32m[0907 07-59-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17947, current rewards: -3894.96969, mean: -1.98723
[32m[0907 07-59-51 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17927, current rewards: -3994.96969, mean: -1.98755
[32m[0907 08-00-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17908, current rewards: -4094.96969, mean: -1.98785
[32m[0907 08-00-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17905, current rewards: -4194.96969, mean: -1.98814
[32m[0907 08-00-18 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17908, current rewards: -4294.96969, mean: -1.98841
[32m[0907 08-00-27 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17918, current rewards: -4394.96969, mean: -1.98867
[32m[0907 08-00-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17926, current rewards: -4494.96969, mean: -1.98892
[32m[0907 08-00-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17936, current rewards: -4594.96969, mean: -1.98916
[32m[0907 08-00-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17944, current rewards: -4694.96969, mean: -1.98939
[32m[0907 08-01-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17953, current rewards: -4794.96969, mean: -1.98961
[32m[0907 08-01-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17961, current rewards: -4894.96969, mean: -1.98983
[32m[0907 08-01-20 @Agent.py:117][0m Average action selection time: 0.1797
[32m[0907 08-01-20 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-01-21 @MBExp.py:227][0m Rewards obtained: [-4974.969694575448], Lows: [2482], Highs: [13], Total time: 52228.03754800002
[32m[0907 08-05-25 @MBExp.py:144][0m ####################################################################
[32m[0907 08-05-25 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 08-05-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20012, current rewards: -7.90061, mean: -0.79006
[32m[0907 08-05-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19391, current rewards: -8.77038, mean: -0.14617
[32m[0907 08-05-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19934, current rewards: -26.67356, mean: -0.24249
[32m[0907 08-05-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20388, current rewards: -55.40395, mean: -0.34627
[32m[0907 08-06-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20257, current rewards: -109.60325, mean: -0.52192
[32m[0907 08-06-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20079, current rewards: -154.40503, mean: -0.59387
[32m[0907 08-06-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19963, current rewards: -158.28895, mean: -0.51061
[32m[0907 08-06-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20048, current rewards: -207.29140, mean: -0.57581
[32m[0907 08-06-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19893, current rewards: -260.62434, mean: -0.63567
[32m[0907 08-06-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19840, current rewards: -334.57919, mean: -0.72735
[32m[0907 08-07-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19849, current rewards: -383.53843, mean: -0.75204
[32m[0907 08-07-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19862, current rewards: -432.76554, mean: -0.77280
[32m[0907 08-07-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19843, current rewards: -492.71310, mean: -0.80773
[32m[0907 08-07-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19767, current rewards: -573.69040, mean: -0.86923
[32m[0907 08-07-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19671, current rewards: -673.69040, mean: -0.94886
[32m[0907 08-07-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19579, current rewards: -773.69040, mean: -1.01801
[32m[0907 08-08-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19467, current rewards: -873.69040, mean: -1.07863
[32m[0907 08-08-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19365, current rewards: -973.69040, mean: -1.13220
[32m[0907 08-08-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19266, current rewards: -1073.69040, mean: -1.17988
[32m[0907 08-08-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19155, current rewards: -1173.69040, mean: -1.22259
[32m[0907 08-08-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19057, current rewards: -1273.69040, mean: -1.26108
[32m[0907 08-08-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18965, current rewards: -1373.69040, mean: -1.29593
[32m[0907 08-08-55 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18886, current rewards: -1473.69040, mean: -1.32765
[32m[0907 08-09-04 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18814, current rewards: -1573.69040, mean: -1.35663
[32m[0907 08-09-13 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18745, current rewards: -1673.69040, mean: -1.38322
[32m[0907 08-09-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18682, current rewards: -1773.69040, mean: -1.40769
[32m[0907 08-09-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18629, current rewards: -1873.69040, mean: -1.43030
[32m[0907 08-09-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18575, current rewards: -1973.69040, mean: -1.45124
[32m[0907 08-09-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18526, current rewards: -2073.69040, mean: -1.47070
[32m[0907 08-09-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18480, current rewards: -2173.69040, mean: -1.48883
[32m[0907 08-10-04 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18438, current rewards: -2273.69040, mean: -1.50576
[32m[0907 08-10-13 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18398, current rewards: -2373.69040, mean: -1.52160
[32m[0907 08-10-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18361, current rewards: -2473.69040, mean: -1.53645
[32m[0907 08-10-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18325, current rewards: -2573.69040, mean: -1.55042
[32m[0907 08-10-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18292, current rewards: -2673.69040, mean: -1.56356
[32m[0907 08-10-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18262, current rewards: -2773.69040, mean: -1.57596
[32m[0907 08-10-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18233, current rewards: -2873.69040, mean: -1.58767
[32m[0907 08-11-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18207, current rewards: -2973.69040, mean: -1.59876
[32m[0907 08-11-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18179, current rewards: -3073.69040, mean: -1.60926
[32m[0907 08-11-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18156, current rewards: -3173.69040, mean: -1.61923
[32m[0907 08-11-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18132, current rewards: -3273.69040, mean: -1.62870
[32m[0907 08-11-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18109, current rewards: -3373.69040, mean: -1.63771
[32m[0907 08-11-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18100, current rewards: -3473.69040, mean: -1.64630
[32m[0907 08-11-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18082, current rewards: -3573.69040, mean: -1.65449
[32m[0907 08-12-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18075, current rewards: -3673.69040, mean: -1.66230
[32m[0907 08-12-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18069, current rewards: -3773.69040, mean: -1.66977
[32m[0907 08-12-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18068, current rewards: -3873.69040, mean: -1.67692
[32m[0907 08-12-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18076, current rewards: -3973.69040, mean: -1.68377
[32m[0907 08-12-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18082, current rewards: -4073.69040, mean: -1.69033
[32m[0907 08-12-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18087, current rewards: -4173.69040, mean: -1.69662
[32m[0907 08-12-58 @Agent.py:117][0m Average action selection time: 0.1809
[32m[0907 08-12-58 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-12-59 @MBExp.py:227][0m Rewards obtained: [-4253.690403896691], Lows: [2128], Highs: [51], Total time: 52681.178673000024
[32m[0907 08-17-06 @MBExp.py:144][0m ####################################################################
[32m[0907 08-17-06 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 08-17-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20072, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-17-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19045, current rewards: -62.88541, mean: -1.04809
[32m[0907 08-17-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18946, current rewards: -106.18972, mean: -0.96536
[32m[0907 08-17-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18921, current rewards: -155.12977, mean: -0.96956
[32m[0907 08-17-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18892, current rewards: -205.12977, mean: -0.97681
[32m[0907 08-17-55 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18889, current rewards: -255.12977, mean: -0.98127
[32m[0907 08-18-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18874, current rewards: -305.12977, mean: -0.98429
[32m[0907 08-18-14 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18860, current rewards: -355.12977, mean: -0.98647
[32m[0907 08-18-23 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18847, current rewards: -405.12977, mean: -0.98812
[32m[0907 08-18-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18833, current rewards: -436.13884, mean: -0.94813
[32m[0907 08-18-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18825, current rewards: -478.74360, mean: -0.93871
[32m[0907 08-18-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18815, current rewards: -522.39123, mean: -0.93284
[32m[0907 08-19-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18807, current rewards: -563.94597, mean: -0.92450
[32m[0907 08-19-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18800, current rewards: -590.46693, mean: -0.89465
[32m[0907 08-19-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18783, current rewards: -599.22791, mean: -0.84398
[32m[0907 08-19-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18749, current rewards: -613.13730, mean: -0.80676
[32m[0907 08-19-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18701, current rewards: -625.95633, mean: -0.77279
[32m[0907 08-19-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18646, current rewards: -659.09814, mean: -0.76639
[32m[0907 08-19-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18596, current rewards: -700.54928, mean: -0.76983
[32m[0907 08-20-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18536, current rewards: -750.54928, mean: -0.78182
[32m[0907 08-20-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18467, current rewards: -800.54928, mean: -0.79262
[32m[0907 08-20-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18406, current rewards: -850.54928, mean: -0.80240
[32m[0907 08-20-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18348, current rewards: -900.54928, mean: -0.81131
[32m[0907 08-20-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18295, current rewards: -950.54928, mean: -0.81944
[32m[0907 08-20-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18247, current rewards: -1000.54928, mean: -0.82690
[32m[0907 08-20-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18202, current rewards: -1045.28695, mean: -0.82959
[32m[0907 08-21-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18159, current rewards: -1042.25182, mean: -0.79561
[32m[0907 08-21-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18122, current rewards: -1039.21439, mean: -0.76413
[32m[0907 08-21-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18087, current rewards: -1036.17696, mean: -0.73488
[32m[0907 08-21-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18054, current rewards: -1033.13953, mean: -0.70763
[32m[0907 08-21-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18022, current rewards: -1075.71429, mean: -0.71239
[32m[0907 08-21-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17992, current rewards: -1125.71429, mean: -0.72161
[32m[0907 08-21-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17965, current rewards: -1175.71429, mean: -0.73026
[32m[0907 08-22-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17941, current rewards: -1225.71429, mean: -0.73838
[32m[0907 08-22-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17919, current rewards: -1275.71429, mean: -0.74603
[32m[0907 08-22-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17897, current rewards: -1325.71429, mean: -0.75325
[32m[0907 08-22-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17876, current rewards: -1375.71429, mean: -0.76006
[32m[0907 08-22-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17856, current rewards: -1425.71429, mean: -0.76651
[32m[0907 08-22-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17836, current rewards: -1475.71429, mean: -0.77263
[32m[0907 08-22-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17819, current rewards: -1525.71429, mean: -0.77843
[32m[0907 08-23-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17802, current rewards: -1575.71429, mean: -0.78394
[32m[0907 08-23-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17786, current rewards: -1625.71429, mean: -0.78918
[32m[0907 08-23-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17770, current rewards: -1675.71429, mean: -0.79418
[32m[0907 08-23-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17768, current rewards: -1725.71429, mean: -0.79894
[32m[0907 08-23-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17770, current rewards: -1775.71429, mean: -0.80349
[32m[0907 08-23-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17769, current rewards: -1825.71429, mean: -0.80784
[32m[0907 08-23-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17767, current rewards: -1875.71429, mean: -0.81200
[32m[0907 08-24-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17771, current rewards: -1925.71429, mean: -0.81598
[32m[0907 08-24-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17783, current rewards: -1975.71429, mean: -0.81980
[32m[0907 08-24-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17794, current rewards: -2025.71429, mean: -0.82346
[32m[0907 08-24-31 @Agent.py:117][0m Average action selection time: 0.1780
[32m[0907 08-24-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-24-31 @MBExp.py:227][0m Rewards obtained: [-2065.7142914386172], Lows: [5], Highs: [2081], Total time: 53127.07786300002
[32m[0907 08-28-40 @MBExp.py:144][0m ####################################################################
[32m[0907 08-28-40 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 08-28-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18800, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-28-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18864, current rewards: -110.00000, mean: -1.83333
[32m[0907 08-29-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18810, current rewards: -210.00000, mean: -1.90909
[32m[0907 08-29-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18793, current rewards: -310.00000, mean: -1.93750
[32m[0907 08-29-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18779, current rewards: -410.00000, mean: -1.95238
[32m[0907 08-29-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18772, current rewards: -510.00000, mean: -1.96154
[32m[0907 08-29-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18770, current rewards: -610.00000, mean: -1.96774
[32m[0907 08-29-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18763, current rewards: -710.00000, mean: -1.97222
[32m[0907 08-29-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18764, current rewards: -810.00000, mean: -1.97561
[32m[0907 08-30-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18764, current rewards: -910.00000, mean: -1.97826
[32m[0907 08-30-16 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18761, current rewards: -1010.00000, mean: -1.98039
[32m[0907 08-30-25 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18749, current rewards: -1110.00000, mean: -1.98214
[32m[0907 08-30-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18745, current rewards: -1210.00000, mean: -1.98361
[32m[0907 08-30-44 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18743, current rewards: -1310.00000, mean: -1.98485
[32m[0907 08-30-53 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18739, current rewards: -1410.00000, mean: -1.98592
[32m[0907 08-31-02 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18733, current rewards: -1510.00000, mean: -1.98684
[32m[0907 08-31-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18705, current rewards: -1610.00000, mean: -1.98765
[32m[0907 08-31-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18641, current rewards: -1710.00000, mean: -1.98837
[32m[0907 08-31-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18589, current rewards: -1810.00000, mean: -1.98901
[32m[0907 08-31-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18542, current rewards: -1910.00000, mean: -1.98958
[32m[0907 08-31-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18468, current rewards: -2010.00000, mean: -1.99010
[32m[0907 08-31-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18404, current rewards: -2110.00000, mean: -1.99057
[32m[0907 08-32-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18346, current rewards: -2210.00000, mean: -1.99099
[32m[0907 08-32-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18294, current rewards: -2310.00000, mean: -1.99138
[32m[0907 08-32-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18248, current rewards: -2410.00000, mean: -1.99174
[32m[0907 08-32-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18201, current rewards: -2510.00000, mean: -1.99206
[32m[0907 08-32-38 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18164, current rewards: -2610.00000, mean: -1.99237
[32m[0907 08-32-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18127, current rewards: -2710.00000, mean: -1.99265
[32m[0907 08-32-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18094, current rewards: -2810.00000, mean: -1.99291
[32m[0907 08-33-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18063, current rewards: -2910.00000, mean: -1.99315
[32m[0907 08-33-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18034, current rewards: -3010.00000, mean: -1.99338
[32m[0907 08-33-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18005, current rewards: -3110.00000, mean: -1.99359
[32m[0907 08-33-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17979, current rewards: -3210.00000, mean: -1.99379
[32m[0907 08-33-38 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17953, current rewards: -3310.00000, mean: -1.99398
[32m[0907 08-33-47 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17929, current rewards: -3410.00000, mean: -1.99415
[32m[0907 08-33-55 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17910, current rewards: -3510.00000, mean: -1.99432
[32m[0907 08-34-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17890, current rewards: -3610.00000, mean: -1.99448
[32m[0907 08-34-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17871, current rewards: -3710.00000, mean: -1.99462
[32m[0907 08-34-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17852, current rewards: -3810.00000, mean: -1.99476
[32m[0907 08-34-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17833, current rewards: -3910.00000, mean: -1.99490
[32m[0907 08-34-38 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17817, current rewards: -4010.00000, mean: -1.99502
[32m[0907 08-34-47 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17802, current rewards: -4110.00000, mean: -1.99515
[32m[0907 08-34-56 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17787, current rewards: -4210.00000, mean: -1.99526
[32m[0907 08-35-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17773, current rewards: -4310.00000, mean: -1.99537
[32m[0907 08-35-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17769, current rewards: -4410.00000, mean: -1.99548
[32m[0907 08-35-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17768, current rewards: -4510.00000, mean: -1.99558
[32m[0907 08-35-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17767, current rewards: -4610.00000, mean: -1.99567
[32m[0907 08-35-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17769, current rewards: -4710.00000, mean: -1.99576
[32m[0907 08-35-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17778, current rewards: -4810.00000, mean: -1.99585
[32m[0907 08-35-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17789, current rewards: -4910.00000, mean: -1.99593
[32m[0907 08-36-05 @Agent.py:117][0m Average action selection time: 0.1780
[32m[0907 08-36-05 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-36-06 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 53572.91936300002
[32m[0907 08-40-17 @MBExp.py:144][0m ####################################################################
[32m[0907 08-40-17 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 08-40-19 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20147, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-40-29 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20740, current rewards: -88.73615, mean: -1.47894
[32m[0907 08-40-39 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19986, current rewards: -176.65208, mean: -1.60593
[32m[0907 08-40-49 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20020, current rewards: -250.96712, mean: -1.56854
[32m[0907 08-40-59 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20225, current rewards: -334.91524, mean: -1.59483
[32m[0907 08-41-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20050, current rewards: -411.33115, mean: -1.58204
[32m[0907 08-41-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19840, current rewards: -507.06650, mean: -1.63570
[32m[0907 08-41-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19697, current rewards: -607.06650, mean: -1.68630
[32m[0907 08-41-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19580, current rewards: -707.06650, mean: -1.72455
[32m[0907 08-41-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19492, current rewards: -807.06650, mean: -1.75449
[32m[0907 08-41-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19430, current rewards: -907.06650, mean: -1.77856
[32m[0907 08-42-06 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19372, current rewards: -1007.06650, mean: -1.79833
[32m[0907 08-42-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19323, current rewards: -1107.06650, mean: -1.81486
[32m[0907 08-42-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19277, current rewards: -1207.06650, mean: -1.82889
[32m[0907 08-42-34 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19239, current rewards: -1307.06650, mean: -1.84094
[32m[0907 08-42-43 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19210, current rewards: -1407.06650, mean: -1.85140
[32m[0907 08-42-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19148, current rewards: -1507.06650, mean: -1.86058
[32m[0907 08-43-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19064, current rewards: -1607.06650, mean: -1.86868
[32m[0907 08-43-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18992, current rewards: -1707.06650, mean: -1.87590
[32m[0907 08-43-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18924, current rewards: -1807.06650, mean: -1.88236
[32m[0907 08-43-27 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18835, current rewards: -1907.06650, mean: -1.88818
[32m[0907 08-43-36 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18753, current rewards: -2007.06650, mean: -1.89346
[32m[0907 08-43-45 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18680, current rewards: -2107.06650, mean: -1.89826
[32m[0907 08-43-53 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18614, current rewards: -2207.06650, mean: -1.90264
[32m[0907 08-44-02 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18555, current rewards: -2307.06650, mean: -1.90667
[32m[0907 08-44-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18499, current rewards: -2407.06650, mean: -1.91037
[32m[0907 08-44-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18448, current rewards: -2507.06650, mean: -1.91379
[32m[0907 08-44-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18399, current rewards: -2607.06650, mean: -1.91696
[32m[0907 08-44-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18354, current rewards: -2707.06650, mean: -1.91991
[32m[0907 08-44-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18315, current rewards: -2807.06650, mean: -1.92265
[32m[0907 08-44-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18277, current rewards: -2907.06650, mean: -1.92521
[32m[0907 08-45-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18239, current rewards: -3007.06650, mean: -1.92761
[32m[0907 08-45-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18206, current rewards: -3107.06650, mean: -1.92985
[32m[0907 08-45-19 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18175, current rewards: -3207.06650, mean: -1.93197
[32m[0907 08-45-28 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18145, current rewards: -3307.06650, mean: -1.93396
[32m[0907 08-45-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18117, current rewards: -3407.06650, mean: -1.93583
[32m[0907 08-45-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18090, current rewards: -3507.06650, mean: -1.93761
[32m[0907 08-45-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18064, current rewards: -3607.06650, mean: -1.93928
[32m[0907 08-46-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18041, current rewards: -3707.06650, mean: -1.94087
[32m[0907 08-46-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18018, current rewards: -3807.06650, mean: -1.94238
[32m[0907 08-46-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17996, current rewards: -3907.06650, mean: -1.94381
[32m[0907 08-46-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17977, current rewards: -4007.06650, mean: -1.94518
[32m[0907 08-46-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17956, current rewards: -4107.06650, mean: -1.94648
[32m[0907 08-46-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17937, current rewards: -4207.06650, mean: -1.94772
[32m[0907 08-46-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17920, current rewards: -4307.06650, mean: -1.94890
[32m[0907 08-47-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17911, current rewards: -4407.06650, mean: -1.95003
[32m[0907 08-47-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17907, current rewards: -4507.06650, mean: -1.95111
[32m[0907 08-47-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17904, current rewards: -4607.06650, mean: -1.95215
[32m[0907 08-47-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17906, current rewards: -4707.06650, mean: -1.95314
[32m[0907 08-47-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17917, current rewards: -4807.06650, mean: -1.95409
[32m[0907 08-47-46 @Agent.py:117][0m Average action selection time: 0.1792
[32m[0907 08-47-46 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-47-46 @MBExp.py:227][0m Rewards obtained: [-4887.06649620952], Lows: [2403], Highs: [83], Total time: 54021.890936000025
[32m[0907 08-51-59 @MBExp.py:144][0m ####################################################################
[32m[0907 08-51-59 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 08-52-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20051, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-52-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19710, current rewards: -85.00000, mean: -1.41667
[32m[0907 08-52-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.22672, current rewards: -133.83667, mean: -1.21670
[32m[0907 08-52-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.21589, current rewards: -224.34410, mean: -1.40215
[32m[0907 08-52-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.21327, current rewards: -314.74387, mean: -1.49878
[32m[0907 08-52-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.21351, current rewards: -374.36341, mean: -1.43986
[32m[0907 08-53-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20927, current rewards: -474.36341, mean: -1.53020
[32m[0907 08-53-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20620, current rewards: -574.36341, mean: -1.59545
[32m[0907 08-53-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20387, current rewards: -674.36341, mean: -1.64479
[32m[0907 08-53-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20207, current rewards: -774.36341, mean: -1.68340
[32m[0907 08-53-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20067, current rewards: -874.36341, mean: -1.71444
[32m[0907 08-53-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19951, current rewards: -974.36341, mean: -1.73993
[32m[0907 08-54-00 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19847, current rewards: -1074.36341, mean: -1.76125
[32m[0907 08-54-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19761, current rewards: -1174.36341, mean: -1.77934
[32m[0907 08-54-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19690, current rewards: -1274.36341, mean: -1.79488
[32m[0907 08-54-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19627, current rewards: -1374.36341, mean: -1.80837
[32m[0907 08-54-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19531, current rewards: -1474.36341, mean: -1.82020
[32m[0907 08-54-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19428, current rewards: -1574.36341, mean: -1.83066
[32m[0907 08-54-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19339, current rewards: -1674.36341, mean: -1.83996
[32m[0907 08-55-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19261, current rewards: -1774.36341, mean: -1.84830
[32m[0907 08-55-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19168, current rewards: -1874.36341, mean: -1.85581
[32m[0907 08-55-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19072, current rewards: -1974.36341, mean: -1.86261
[32m[0907 08-55-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18986, current rewards: -2074.36341, mean: -1.86880
[32m[0907 08-55-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18908, current rewards: -2174.36341, mean: -1.87445
[32m[0907 08-55-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18835, current rewards: -2274.36341, mean: -1.87964
[32m[0907 08-55-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18767, current rewards: -2374.36341, mean: -1.88442
[32m[0907 08-56-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18703, current rewards: -2474.36341, mean: -1.88883
[32m[0907 08-56-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18643, current rewards: -2574.36341, mean: -1.89291
[32m[0907 08-56-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18589, current rewards: -2674.36341, mean: -1.89671
[32m[0907 08-56-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18540, current rewards: -2774.36341, mean: -1.90025
[32m[0907 08-56-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18495, current rewards: -2874.36341, mean: -1.90355
[32m[0907 08-56-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18452, current rewards: -2974.36341, mean: -1.90664
[32m[0907 08-56-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18411, current rewards: -3074.36341, mean: -1.90954
[32m[0907 08-57-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18374, current rewards: -3174.36341, mean: -1.91227
[32m[0907 08-57-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18341, current rewards: -3274.36341, mean: -1.91483
[32m[0907 08-57-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18308, current rewards: -3374.36341, mean: -1.91725
[32m[0907 08-57-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18277, current rewards: -3474.36341, mean: -1.91954
[32m[0907 08-57-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18247, current rewards: -3574.36341, mean: -1.92170
[32m[0907 08-57-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18219, current rewards: -3674.36341, mean: -1.92375
[32m[0907 08-57-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18190, current rewards: -3774.36341, mean: -1.92570
[32m[0907 08-58-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18166, current rewards: -3874.36341, mean: -1.92754
[32m[0907 08-58-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18143, current rewards: -3974.36341, mean: -1.92930
[32m[0907 08-58-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18120, current rewards: -4074.36341, mean: -1.93098
[32m[0907 08-58-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18097, current rewards: -4174.36341, mean: -1.93258
[32m[0907 08-58-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18079, current rewards: -4274.36341, mean: -1.93410
[32m[0907 08-58-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18078, current rewards: -4374.36341, mean: -1.93556
[32m[0907 08-58-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18040, current rewards: -4474.36341, mean: -1.93695
[32m[0907 08-59-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18002, current rewards: -4574.36341, mean: -1.93829
[32m[0907 08-59-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17966, current rewards: -4674.36341, mean: -1.93957
[32m[0907 08-59-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17943, current rewards: -4774.36341, mean: -1.94080
[32m[0907 08-59-27 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0907 08-59-27 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-59-28 @MBExp.py:227][0m Rewards obtained: [-4854.363412585923], Lows: [2384], Highs: [89], Total time: 54470.944750000024
