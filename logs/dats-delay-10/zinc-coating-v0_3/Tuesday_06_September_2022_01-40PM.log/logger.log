[32m[0906 13-40-33 @logger.py:99][0m Log file set to /app/logs/dats-delay-10/zinc-coating-v0_3/Tuesday_06_September_2022_01-40PM.log
[32m[0906 13-40-33 @MBExp.py:88][0m Starting the experiments
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.00002, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.00002, current rewards: -65.08485, mean: -1.08475
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.00002, current rewards: -114.82719, mean: -1.04388
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.00002, current rewards: -163.04468, mean: -1.01903
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.00002, current rewards: -219.55916, mean: -1.04552
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.00002, current rewards: -268.92926, mean: -1.03434
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.00002, current rewards: -324.19017, mean: -1.04577
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.00002, current rewards: -378.51268, mean: -1.05142
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.00002, current rewards: -434.77524, mean: -1.06043
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.00002, current rewards: -493.22502, mean: -1.07223
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.00002, current rewards: -554.25306, mean: -1.08677
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.00002, current rewards: -613.02057, mean: -1.09468
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.00002, current rewards: -667.89087, mean: -1.09490
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.00002, current rewards: -726.37196, mean: -1.10056
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.00002, current rewards: -781.34443, mean: -1.10049
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.00002, current rewards: -851.26158, mean: -1.12008
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.00002, current rewards: -920.09937, mean: -1.13593
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.00002, current rewards: -1000.20453, mean: -1.16303
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.00002, current rewards: -1087.87865, mean: -1.19547
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.00002, current rewards: -1174.07079, mean: -1.22299
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.00002, current rewards: -1254.73482, mean: -1.24231
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.00002, current rewards: -1345.03613, mean: -1.26890
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.00002, current rewards: -1435.81060, mean: -1.29352
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.00002, current rewards: -1514.10226, mean: -1.30526
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.00002, current rewards: -1569.69182, mean: -1.29727
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.00002, current rewards: -1644.57743, mean: -1.30522
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.00002, current rewards: -1702.28613, mean: -1.29946
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.00002, current rewards: -1763.83859, mean: -1.29694
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.00002, current rewards: -1836.15170, mean: -1.30224
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.00002, current rewards: -1889.77112, mean: -1.29436
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.00002, current rewards: -1948.33015, mean: -1.29028
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.00002, current rewards: -2005.78429, mean: -1.28576
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.00002, current rewards: -2063.02770, mean: -1.28138
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.00002, current rewards: -2128.79745, mean: -1.28241
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.00002, current rewards: -2182.18330, mean: -1.27613
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.00002, current rewards: -2239.41218, mean: -1.27239
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.00002, current rewards: -2282.04394, mean: -1.26080
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.00002, current rewards: -2335.41001, mean: -1.25560
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.00002, current rewards: -2387.72533, mean: -1.25012
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.00002, current rewards: -2428.44503, mean: -1.23900
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.00002, current rewards: -2471.96647, mean: -1.22983
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.00002, current rewards: -2515.21328, mean: -1.22098
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.00002, current rewards: -2554.53029, mean: -1.21068
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.00002, current rewards: -2595.79832, mean: -1.20176
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.00002, current rewards: -2663.05772, mean: -1.20500
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.00002, current rewards: -2721.31796, mean: -1.20412
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.00002, current rewards: -2777.28378, mean: -1.20229
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.00002, current rewards: -2844.99936, mean: -1.20551
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.00002, current rewards: -2917.56277, mean: -1.21061
[32m[0906 13-40-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.00002, current rewards: -2984.23751, mean: -1.21310
[32m[0906 13-40-33 @Agent.py:117][0m Average action selection time: 0.0000
[32m[0906 13-40-33 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-40-35 @MBExp.py:144][0m ####################################################################
[32m[0906 13-40-35 @MBExp.py:145][0m Starting training iteration 1.
[32m[0906 13-40-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18571, current rewards: 0.68979, mean: 0.06898
[32m[0906 13-40-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17271, current rewards: -44.05069, mean: -0.73418
[32m[0906 13-40-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17144, current rewards: -94.05069, mean: -0.85501
[32m[0906 13-41-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17085, current rewards: -144.05069, mean: -0.90032
[32m[0906 13-41-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17082, current rewards: -194.05069, mean: -0.92405
[32m[0906 13-41-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.17106, current rewards: -244.05069, mean: -0.93866
[32m[0906 13-41-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.17263, current rewards: -294.05069, mean: -0.94855
[32m[0906 13-41-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.17539, current rewards: -344.05069, mean: -0.95570
[32m[0906 13-41-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.17722, current rewards: -394.05069, mean: -0.96110
[32m[0906 13-41-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.17863, current rewards: -435.61673, mean: -0.94699
[32m[0906 13-42-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17965, current rewards: -485.61673, mean: -0.95219
[32m[0906 13-42-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18053, current rewards: -535.61673, mean: -0.95646
[32m[0906 13-42-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18121, current rewards: -585.61673, mean: -0.96003
[32m[0906 13-42-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18185, current rewards: -635.61673, mean: -0.96306
[32m[0906 13-42-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18230, current rewards: -685.61673, mean: -0.96566
[32m[0906 13-42-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18278, current rewards: -735.61673, mean: -0.96792
[32m[0906 13-43-04 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18317, current rewards: -785.61673, mean: -0.96990
[32m[0906 13-43-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18351, current rewards: -835.61673, mean: -0.97165
[32m[0906 13-43-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18382, current rewards: -885.61673, mean: -0.97321
[32m[0906 13-43-32 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18409, current rewards: -942.61673, mean: -0.98189
[32m[0906 13-43-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18438, current rewards: -1042.61673, mean: -1.03229
[32m[0906 13-43-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18465, current rewards: -1142.61673, mean: -1.07794
[32m[0906 13-44-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18480, current rewards: -1242.61673, mean: -1.11947
[32m[0906 13-44-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18497, current rewards: -1342.61673, mean: -1.15743
[32m[0906 13-44-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18510, current rewards: -1442.61673, mean: -1.19225
[32m[0906 13-44-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18527, current rewards: -1542.61673, mean: -1.22430
[32m[0906 13-44-39 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18538, current rewards: -1642.61673, mean: -1.25391
[32m[0906 13-44-48 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18548, current rewards: -1742.61673, mean: -1.28134
[32m[0906 13-44-57 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18557, current rewards: -1842.61673, mean: -1.30682
[32m[0906 13-45-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18564, current rewards: -1942.61673, mean: -1.33056
[32m[0906 13-45-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18574, current rewards: -2042.61673, mean: -1.35273
[32m[0906 13-45-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18578, current rewards: -2142.61673, mean: -1.37347
[32m[0906 13-45-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18588, current rewards: -2242.61673, mean: -1.39293
[32m[0906 13-45-44 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18594, current rewards: -2342.61673, mean: -1.41121
[32m[0906 13-45-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18603, current rewards: -2442.61673, mean: -1.42843
[32m[0906 13-46-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18607, current rewards: -2542.61673, mean: -1.44467
[32m[0906 13-46-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18609, current rewards: -2642.61673, mean: -1.46001
[32m[0906 13-46-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18613, current rewards: -2742.61673, mean: -1.47453
[32m[0906 13-46-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18623, current rewards: -2842.61673, mean: -1.48828
[32m[0906 13-46-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18629, current rewards: -2942.61673, mean: -1.50134
[32m[0906 13-46-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18631, current rewards: -3042.61673, mean: -1.51374
[32m[0906 13-47-00 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18632, current rewards: -3142.61673, mean: -1.52554
[32m[0906 13-47-09 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18636, current rewards: -3242.61673, mean: -1.53679
[32m[0906 13-47-19 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18639, current rewards: -3342.61673, mean: -1.54751
[32m[0906 13-47-28 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18638, current rewards: -3442.61673, mean: -1.55775
[32m[0906 13-47-37 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18644, current rewards: -3542.61673, mean: -1.56753
[32m[0906 13-47-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18647, current rewards: -3642.61673, mean: -1.57689
[32m[0906 13-47-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18647, current rewards: -3742.61673, mean: -1.58585
[32m[0906 13-48-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18649, current rewards: -3842.61673, mean: -1.59445
[32m[0906 13-48-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18652, current rewards: -3942.61673, mean: -1.60269
[32m[0906 13-48-22 @Agent.py:117][0m Average action selection time: 0.1865
[32m[0906 13-48-22 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-48-22 @MBExp.py:227][0m Rewards obtained: [-4022.6167266245284], Lows: [1547], Highs: [930], Total time: 467.026105
[32m[0906 13-48-27 @MBExp.py:144][0m ####################################################################
[32m[0906 13-48-27 @MBExp.py:145][0m Starting training iteration 2.
[32m[0906 13-48-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18725, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-48-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18673, current rewards: -5.18834, mean: -0.08647
[32m[0906 13-48-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18637, current rewards: 2.40944, mean: 0.02190
[32m[0906 13-48-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18603, current rewards: 10.00319, mean: 0.06252
[32m[0906 13-49-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18594, current rewards: 17.60093, mean: 0.08381
[32m[0906 13-49-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18572, current rewards: 25.18651, mean: 0.09687
[32m[0906 13-49-24 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18540, current rewards: 32.77465, mean: 0.10572
[32m[0906 13-49-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18546, current rewards: 40.37289, mean: 0.11215
[32m[0906 13-49-43 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18547, current rewards: 47.97265, mean: 0.11701
[32m[0906 13-49-52 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18553, current rewards: 55.56744, mean: 0.12080
[32m[0906 13-50-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18568, current rewards: 54.55765, mean: 0.10698
[32m[0906 13-50-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18567, current rewards: 15.10703, mean: 0.02698
[32m[0906 13-50-20 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18564, current rewards: -3.39139, mean: -0.00556
[32m[0906 13-50-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18556, current rewards: -36.48022, mean: -0.05527
[32m[0906 13-50-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18555, current rewards: -69.68706, mean: -0.09815
[32m[0906 13-50-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18548, current rewards: -91.06565, mean: -0.11982
[32m[0906 13-50-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18546, current rewards: -112.92505, mean: -0.13941
[32m[0906 13-51-07 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18542, current rewards: -152.83027, mean: -0.17771
[32m[0906 13-51-16 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18539, current rewards: -202.97284, mean: -0.22305
[32m[0906 13-51-25 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18535, current rewards: -263.08936, mean: -0.27405
[32m[0906 13-51-34 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18535, current rewards: -313.22347, mean: -0.31012
[32m[0906 13-51-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18530, current rewards: -373.34592, mean: -0.35221
[32m[0906 13-51-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18528, current rewards: -423.56034, mean: -0.38159
[32m[0906 13-52-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18527, current rewards: -508.65080, mean: -0.43849
[32m[0906 13-52-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18530, current rewards: -608.65080, mean: -0.50302
[32m[0906 13-52-21 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18527, current rewards: -708.65080, mean: -0.56242
[32m[0906 13-52-30 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18520, current rewards: -808.65080, mean: -0.61729
[32m[0906 13-52-39 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18518, current rewards: -908.65080, mean: -0.66813
[32m[0906 13-52-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18516, current rewards: -1008.65080, mean: -0.71536
[32m[0906 13-52-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18514, current rewards: -1108.65080, mean: -0.75935
[32m[0906 13-53-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18510, current rewards: -1208.65080, mean: -0.80043
[32m[0906 13-53-16 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18505, current rewards: -1198.78361, mean: -0.76845
[32m[0906 13-53-25 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18502, current rewards: -1182.93693, mean: -0.73474
[32m[0906 13-53-34 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18500, current rewards: -1170.87392, mean: -0.70535
[32m[0906 13-53-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18500, current rewards: -1182.47443, mean: -0.69151
[32m[0906 13-53-53 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18498, current rewards: -1178.66451, mean: -0.66970
[32m[0906 13-54-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18495, current rewards: -1174.73541, mean: -0.64903
[32m[0906 13-54-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18495, current rewards: -1170.81007, mean: -0.62947
[32m[0906 13-54-21 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18498, current rewards: -1159.73535, mean: -0.60719
[32m[0906 13-54-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18495, current rewards: -1151.89978, mean: -0.58770
[32m[0906 13-54-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18495, current rewards: -1144.07397, mean: -0.56919
[32m[0906 13-54-48 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18494, current rewards: -1136.23783, mean: -0.55157
[32m[0906 13-54-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18494, current rewards: -1128.40891, mean: -0.53479
[32m[0906 13-55-07 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18495, current rewards: -1120.58017, mean: -0.51879
[32m[0906 13-55-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18488, current rewards: -1112.75200, mean: -0.50351
[32m[0906 13-55-25 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18492, current rewards: -1156.11449, mean: -0.51156
[32m[0906 13-55-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18493, current rewards: -1244.20483, mean: -0.53862
[32m[0906 13-55-44 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18491, current rewards: -1299.84923, mean: -0.55078
[32m[0906 13-55-53 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18490, current rewards: -1352.66754, mean: -0.56127
[32m[0906 13-56-02 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18492, current rewards: -1406.13885, mean: -0.57160
[32m[0906 13-56-10 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0906 13-56-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 13-56-10 @MBExp.py:227][0m Rewards obtained: [-1422.5658317183381], Lows: [911], Highs: [34], Total time: 930.0076770000001
[32m[0906 13-56-16 @MBExp.py:144][0m ####################################################################
[32m[0906 13-56-16 @MBExp.py:145][0m Starting training iteration 3.
[32m[0906 13-56-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18738, current rewards: -10.00000, mean: -1.00000
[32m[0906 13-56-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18625, current rewards: -7.86717, mean: -0.13112
[32m[0906 13-56-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18575, current rewards: -4.71874, mean: -0.04290
[32m[0906 13-56-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18565, current rewards: -1.57030, mean: -0.00981
[32m[0906 13-56-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18561, current rewards: 1.57812, mean: 0.00751
[32m[0906 13-57-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18549, current rewards: 4.72440, mean: 0.01817
[32m[0906 13-57-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18509, current rewards: 7.87348, mean: 0.02540
[32m[0906 13-57-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18518, current rewards: 11.82077, mean: 0.03284
[32m[0906 13-57-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18535, current rewards: 20.08123, mean: 0.04898
[32m[0906 13-57-42 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18536, current rewards: 28.11540, mean: 0.06112
[32m[0906 13-57-51 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18539, current rewards: 36.13707, mean: 0.07086
[32m[0906 13-58-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18537, current rewards: 22.55155, mean: 0.04027
[32m[0906 13-58-10 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18536, current rewards: 31.43551, mean: 0.05153
[32m[0906 13-58-19 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18541, current rewards: 40.45263, mean: 0.06129
[32m[0906 13-58-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18551, current rewards: 49.46631, mean: 0.06967
[32m[0906 13-58-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18543, current rewards: 58.47449, mean: 0.07694
[32m[0906 13-58-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18536, current rewards: 67.48117, mean: 0.08331
[32m[0906 13-58-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18535, current rewards: 76.49561, mean: 0.08895
[32m[0906 13-59-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18533, current rewards: 85.50511, mean: 0.09396
[32m[0906 13-59-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18534, current rewards: 94.51514, mean: 0.09845
[32m[0906 13-59-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18534, current rewards: 103.52916, mean: 0.10250
[32m[0906 13-59-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18530, current rewards: 104.27534, mean: 0.09837
[32m[0906 13-59-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18528, current rewards: 100.44995, mean: 0.09050
[32m[0906 13-59-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18524, current rewards: 106.03951, mean: 0.09141
[32m[0906 14-00-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18527, current rewards: 109.67068, mean: 0.09064
[32m[0906 14-00-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18528, current rewards: 113.01939, mean: 0.08970
[32m[0906 14-00-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18529, current rewards: 116.36556, mean: 0.08883
[32m[0906 14-00-29 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18532, current rewards: 119.71499, mean: 0.08803
[32m[0906 14-00-38 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18531, current rewards: 123.06171, mean: 0.08728
[32m[0906 14-00-47 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18526, current rewards: 126.41193, mean: 0.08658
[32m[0906 14-00-57 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18527, current rewards: 129.76018, mean: 0.08593
[32m[0906 14-01-06 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18523, current rewards: 133.10861, mean: 0.08533
[32m[0906 14-01-15 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18522, current rewards: 137.67430, mean: 0.08551
[32m[0906 14-01-24 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18521, current rewards: 146.69013, mean: 0.08837
[32m[0906 14-01-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18521, current rewards: 155.26386, mean: 0.09080
[32m[0906 14-01-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18519, current rewards: 147.94103, mean: 0.08406
[32m[0906 14-01-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18515, current rewards: 140.72567, mean: 0.07775
[32m[0906 14-02-01 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18510, current rewards: 128.82102, mean: 0.06926
[32m[0906 14-02-10 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18512, current rewards: 128.71838, mean: 0.06739
[32m[0906 14-02-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18511, current rewards: 113.80802, mean: 0.05807
[32m[0906 14-02-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18513, current rewards: 108.31124, mean: 0.05389
[32m[0906 14-02-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18515, current rewards: 114.49480, mean: 0.05558
[32m[0906 14-02-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18515, current rewards: 118.77286, mean: 0.05629
[32m[0906 14-02-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18514, current rewards: 123.04595, mean: 0.05697
[32m[0906 14-03-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18505, current rewards: 116.52375, mean: 0.05273
[32m[0906 14-03-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18508, current rewards: 120.62493, mean: 0.05337
[32m[0906 14-03-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18510, current rewards: 124.72627, mean: 0.05399
[32m[0906 14-03-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18509, current rewards: 128.82478, mean: 0.05459
[32m[0906 14-03-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18502, current rewards: 132.92145, mean: 0.05515
[32m[0906 14-03-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18504, current rewards: 137.26433, mean: 0.05580
[32m[0906 14-04-00 @Agent.py:117][0m Average action selection time: 0.1850
[32m[0906 14-04-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-04-00 @MBExp.py:227][0m Rewards obtained: [139.8068438536835], Lows: [111], Highs: [32], Total time: 1393.263519
[32m[0906 14-04-08 @MBExp.py:144][0m ####################################################################
[32m[0906 14-04-08 @MBExp.py:145][0m Starting training iteration 4.
[32m[0906 14-04-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18536, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-04-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18600, current rewards: -16.74529, mean: -0.27909
[32m[0906 14-04-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18577, current rewards: 1.76278, mean: 0.01603
[32m[0906 14-04-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18582, current rewards: 20.40683, mean: 0.12754
[32m[0906 14-04-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18583, current rewards: 38.98738, mean: 0.18565
[32m[0906 14-04-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18550, current rewards: 57.56182, mean: 0.22139
[32m[0906 14-05-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18497, current rewards: 76.12237, mean: 0.24556
[32m[0906 14-05-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18510, current rewards: 94.73567, mean: 0.26315
[32m[0906 14-05-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18509, current rewards: 110.26297, mean: 0.26893
[32m[0906 14-05-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18514, current rewards: 125.89553, mean: 0.27369
[32m[0906 14-05-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18513, current rewards: 141.50896, mean: 0.27747
[32m[0906 14-05-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18515, current rewards: 157.22552, mean: 0.28076
[32m[0906 14-06-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18513, current rewards: 172.88764, mean: 0.28342
[32m[0906 14-06-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18512, current rewards: 188.53489, mean: 0.28566
[32m[0906 14-06-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18514, current rewards: 166.46265, mean: 0.23445
[32m[0906 14-06-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18502, current rewards: 135.45076, mean: 0.17822
[32m[0906 14-06-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18505, current rewards: 104.89149, mean: 0.12950
[32m[0906 14-06-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18507, current rewards: 78.28463, mean: 0.09103
[32m[0906 14-06-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18508, current rewards: 52.09412, mean: 0.05725
[32m[0906 14-07-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18503, current rewards: 16.85924, mean: 0.01756
[32m[0906 14-07-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18505, current rewards: -26.58035, mean: -0.02632
[32m[0906 14-07-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18503, current rewards: -59.67704, mean: -0.05630
[32m[0906 14-07-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18499, current rewards: -95.03494, mean: -0.08562
[32m[0906 14-07-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18498, current rewards: -142.37998, mean: -0.12274
[32m[0906 14-07-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18499, current rewards: -184.38787, mean: -0.15239
[32m[0906 14-08-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18499, current rewards: -215.75379, mean: -0.17123
[32m[0906 14-08-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18500, current rewards: -254.42694, mean: -0.19422
[32m[0906 14-08-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18498, current rewards: -300.40614, mean: -0.22089
[32m[0906 14-08-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18495, current rewards: -336.74302, mean: -0.23882
[32m[0906 14-08-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18491, current rewards: -368.10621, mean: -0.25213
[32m[0906 14-08-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18490, current rewards: -411.63930, mean: -0.27261
[32m[0906 14-08-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18493, current rewards: -457.67669, mean: -0.29338
[32m[0906 14-09-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18492, current rewards: -530.67353, mean: -0.32961
[32m[0906 14-09-16 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18490, current rewards: -630.67353, mean: -0.37992
[32m[0906 14-09-25 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18489, current rewards: -730.67353, mean: -0.42729
[32m[0906 14-09-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18488, current rewards: -830.67353, mean: -0.47197
[32m[0906 14-09-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18481, current rewards: -930.67353, mean: -0.51418
[32m[0906 14-09-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18473, current rewards: -1030.67353, mean: -0.55413
[32m[0906 14-10-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18474, current rewards: -1130.67353, mean: -0.59198
[32m[0906 14-10-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18477, current rewards: -1230.67353, mean: -0.62789
[32m[0906 14-10-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18477, current rewards: -1330.67353, mean: -0.66203
[32m[0906 14-10-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18480, current rewards: -1357.46057, mean: -0.65896
[32m[0906 14-10-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18482, current rewards: -1352.21140, mean: -0.64086
[32m[0906 14-10-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18477, current rewards: -1346.96539, mean: -0.62360
[32m[0906 14-10-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18472, current rewards: -1341.72036, mean: -0.60711
[32m[0906 14-11-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18477, current rewards: -1336.47201, mean: -0.59136
[32m[0906 14-11-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18480, current rewards: -1331.22551, mean: -0.57629
[32m[0906 14-11-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18479, current rewards: -1325.97442, mean: -0.56185
[32m[0906 14-11-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18472, current rewards: -1320.71732, mean: -0.54802
[32m[0906 14-11-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18476, current rewards: -1313.51822, mean: -0.53395
[32m[0906 14-11-51 @Agent.py:117][0m Average action selection time: 0.1848
[32m[0906 14-11-51 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-11-51 @MBExp.py:227][0m Rewards obtained: [-1326.7058467003333], Lows: [900], Highs: [20], Total time: 1855.863762
[32m[0906 14-12-02 @MBExp.py:144][0m ####################################################################
[32m[0906 14-12-02 @MBExp.py:145][0m Starting training iteration 5.
[32m[0906 14-12-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18686, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-12-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18645, current rewards: -9.09235, mean: -0.15154
[32m[0906 14-12-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18634, current rewards: -6.67324, mean: -0.06067
[32m[0906 14-12-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18627, current rewards: -4.25401, mean: -0.02659
[32m[0906 14-12-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18600, current rewards: -1.83553, mean: -0.00874
[32m[0906 14-12-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18530, current rewards: 0.58354, mean: 0.00224
[32m[0906 14-12-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18510, current rewards: 3.00213, mean: 0.00968
[32m[0906 14-13-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18533, current rewards: -6.11115, mean: -0.01698
[32m[0906 14-13-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18539, current rewards: -7.26519, mean: -0.01772
[32m[0906 14-13-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18539, current rewards: -11.93627, mean: -0.02595
[32m[0906 14-13-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18538, current rewards: -15.52541, mean: -0.03044
[32m[0906 14-13-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18537, current rewards: -21.28128, mean: -0.03800
[32m[0906 14-13-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18536, current rewards: -24.14638, mean: -0.03958
[32m[0906 14-14-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18534, current rewards: -20.03075, mean: -0.03035
[32m[0906 14-14-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18532, current rewards: -15.91149, mean: -0.02241
[32m[0906 14-14-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18528, current rewards: -11.52653, mean: -0.01517
[32m[0906 14-14-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18526, current rewards: -6.30484, mean: -0.00778
[32m[0906 14-14-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18528, current rewards: -1.68367, mean: -0.00196
[32m[0906 14-14-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18531, current rewards: 2.93521, mean: 0.00323
[32m[0906 14-15-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18524, current rewards: 7.55601, mean: 0.00787
[32m[0906 14-15-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18531, current rewards: 12.17626, mean: 0.01206
[32m[0906 14-15-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18530, current rewards: 16.79496, mean: 0.01584
[32m[0906 14-15-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18527, current rewards: 0.13228, mean: 0.00012
[32m[0906 14-15-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18522, current rewards: 3.26767, mean: 0.00282
[32m[0906 14-15-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18519, current rewards: -9.76173, mean: -0.00807
[32m[0906 14-15-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18520, current rewards: -6.98769, mean: -0.00555
[32m[0906 14-16-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18520, current rewards: -4.21766, mean: -0.00322
[32m[0906 14-16-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18521, current rewards: -1.44849, mean: -0.00107
[32m[0906 14-16-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18521, current rewards: 1.32226, mean: 0.00094
[32m[0906 14-16-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18520, current rewards: 4.09326, mean: 0.00280
[32m[0906 14-16-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18519, current rewards: 6.86362, mean: 0.00455
[32m[0906 14-16-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18521, current rewards: 9.63253, mean: 0.00617
[32m[0906 14-17-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18520, current rewards: 12.76435, mean: 0.00793
[32m[0906 14-17-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18522, current rewards: 16.23003, mean: 0.00978
[32m[0906 14-17-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18524, current rewards: 19.30114, mean: 0.01129
[32m[0906 14-17-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18524, current rewards: 2.66403, mean: 0.00151
[32m[0906 14-17-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18518, current rewards: 8.22718, mean: 0.00455
[32m[0906 14-17-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18507, current rewards: 13.79033, mean: 0.00741
[32m[0906 14-17-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18508, current rewards: 19.35348, mean: 0.01013
[32m[0906 14-18-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18509, current rewards: 24.91663, mean: 0.01271
[32m[0906 14-18-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18512, current rewards: 30.47978, mean: 0.01516
[32m[0906 14-18-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18512, current rewards: 29.89399, mean: 0.01451
[32m[0906 14-18-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18513, current rewards: -20.10601, mean: -0.00953
[32m[0906 14-18-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18505, current rewards: -70.10601, mean: -0.03246
[32m[0906 14-18-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18499, current rewards: -120.10601, mean: -0.05435
[32m[0906 14-19-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18501, current rewards: -170.10601, mean: -0.07527
[32m[0906 14-19-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18504, current rewards: -220.10601, mean: -0.09528
[32m[0906 14-19-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18502, current rewards: -270.10601, mean: -0.11445
[32m[0906 14-19-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18494, current rewards: -320.10601, mean: -0.13282
[32m[0906 14-19-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18495, current rewards: -370.10601, mean: -0.15045
[32m[0906 14-19-45 @Agent.py:117][0m Average action selection time: 0.1850
[32m[0906 14-19-45 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-19-45 @MBExp.py:227][0m Rewards obtained: [-410.10601164937185], Lows: [20], Highs: [516], Total time: 2318.9270189999997
[32m[0906 14-19-57 @MBExp.py:144][0m ####################################################################
[32m[0906 14-19-57 @MBExp.py:145][0m Starting training iteration 6.
[32m[0906 14-19-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18624, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-20-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18628, current rewards: -30.29543, mean: -0.50492
[32m[0906 14-20-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18581, current rewards: -47.46130, mean: -0.43147
[32m[0906 14-20-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18577, current rewards: -71.82375, mean: -0.44890
[32m[0906 14-20-36 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18533, current rewards: -95.07304, mean: -0.45273
[32m[0906 14-20-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18453, current rewards: -112.55572, mean: -0.43291
[32m[0906 14-20-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18445, current rewards: -132.07234, mean: -0.42604
[32m[0906 14-21-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18471, current rewards: -155.56107, mean: -0.43211
[32m[0906 14-21-13 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18480, current rewards: -173.28945, mean: -0.42266
[32m[0906 14-21-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18485, current rewards: -193.05077, mean: -0.41968
[32m[0906 14-21-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18496, current rewards: -217.58971, mean: -0.42665
[32m[0906 14-21-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18498, current rewards: -230.00379, mean: -0.41072
[32m[0906 14-21-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18506, current rewards: -226.13066, mean: -0.37071
[32m[0906 14-22-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18505, current rewards: -222.29873, mean: -0.33682
[32m[0906 14-22-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18510, current rewards: -218.46699, mean: -0.30770
[32m[0906 14-22-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18505, current rewards: -215.04621, mean: -0.28296
[32m[0906 14-22-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18510, current rewards: -211.69638, mean: -0.26135
[32m[0906 14-22-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18509, current rewards: -208.32065, mean: -0.24223
[32m[0906 14-22-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18510, current rewards: -204.94290, mean: -0.22521
[32m[0906 14-22-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18513, current rewards: -201.56524, mean: -0.20996
[32m[0906 14-23-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18515, current rewards: -208.74938, mean: -0.20668
[32m[0906 14-23-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18519, current rewards: -205.59986, mean: -0.19396
[32m[0906 14-23-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18519, current rewards: -202.58055, mean: -0.18251
[32m[0906 14-23-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18521, current rewards: -199.57356, mean: -0.17205
[32m[0906 14-23-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18521, current rewards: -196.53347, mean: -0.16242
[32m[0906 14-23-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18521, current rewards: -193.41437, mean: -0.15350
[32m[0906 14-24-00 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18520, current rewards: -190.29505, mean: -0.14526
[32m[0906 14-24-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18518, current rewards: -187.17591, mean: -0.13763
[32m[0906 14-24-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18517, current rewards: -184.05634, mean: -0.13054
[32m[0906 14-24-28 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18518, current rewards: -180.93706, mean: -0.12393
[32m[0906 14-24-37 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18517, current rewards: -177.81824, mean: -0.11776
[32m[0906 14-24-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18517, current rewards: -174.69839, mean: -0.11199
[32m[0906 14-24-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18517, current rewards: -191.44136, mean: -0.11891
[32m[0906 14-25-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18518, current rewards: -187.26853, mean: -0.11281
[32m[0906 14-25-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18516, current rewards: -183.09569, mean: -0.10707
[32m[0906 14-25-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18514, current rewards: -178.92286, mean: -0.10166
[32m[0906 14-25-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18508, current rewards: -174.75002, mean: -0.09655
[32m[0906 14-25-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18498, current rewards: -170.57719, mean: -0.09171
[32m[0906 14-25-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18499, current rewards: -166.40435, mean: -0.08712
[32m[0906 14-26-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18501, current rewards: -162.23152, mean: -0.08277
[32m[0906 14-26-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18500, current rewards: -177.86676, mean: -0.08849
[32m[0906 14-26-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18499, current rewards: -227.86676, mean: -0.11061
[32m[0906 14-26-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18499, current rewards: -277.86676, mean: -0.13169
[32m[0906 14-26-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18489, current rewards: -327.86676, mean: -0.15179
[32m[0906 14-26-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18485, current rewards: -377.86676, mean: -0.17098
[32m[0906 14-26-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18489, current rewards: -427.86676, mean: -0.18932
[32m[0906 14-27-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18494, current rewards: -477.86676, mean: -0.20687
[32m[0906 14-27-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18494, current rewards: -527.86676, mean: -0.22367
[32m[0906 14-27-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18486, current rewards: -577.86676, mean: -0.23978
[32m[0906 14-27-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18486, current rewards: -627.86676, mean: -0.25523
[32m[0906 14-27-40 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0906 14-27-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-27-40 @MBExp.py:227][0m Rewards obtained: [-667.8667556660594], Lows: [13], Highs: [789], Total time: 2781.8397609999997
[32m[0906 14-27-55 @MBExp.py:144][0m ####################################################################
[32m[0906 14-27-55 @MBExp.py:145][0m Starting training iteration 7.
[32m[0906 14-27-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18816, current rewards: 1.58921, mean: 0.15892
[32m[0906 14-28-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18708, current rewards: 9.92035, mean: 0.16534
[32m[0906 14-28-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18654, current rewards: 18.22047, mean: 0.16564
[32m[0906 14-28-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18606, current rewards: 26.52059, mean: 0.16575
[32m[0906 14-28-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18540, current rewards: 34.82071, mean: 0.16581
[32m[0906 14-28-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18449, current rewards: 43.12083, mean: 0.16585
[32m[0906 14-28-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18429, current rewards: 17.60688, mean: 0.05680
[32m[0906 14-29-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18442, current rewards: -32.39312, mean: -0.08998
[32m[0906 14-29-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18450, current rewards: -82.39312, mean: -0.20096
[32m[0906 14-29-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18458, current rewards: -132.39312, mean: -0.28781
[32m[0906 14-29-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18467, current rewards: -182.39312, mean: -0.35763
[32m[0906 14-29-39 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18468, current rewards: -232.39312, mean: -0.41499
[32m[0906 14-29-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18480, current rewards: -282.39312, mean: -0.46294
[32m[0906 14-29-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18484, current rewards: -332.39312, mean: -0.50363
[32m[0906 14-30-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18487, current rewards: -382.39312, mean: -0.53858
[32m[0906 14-30-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18486, current rewards: -432.39312, mean: -0.56894
[32m[0906 14-30-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18482, current rewards: -482.39312, mean: -0.59555
[32m[0906 14-30-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18479, current rewards: -532.39312, mean: -0.61906
[32m[0906 14-30-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18479, current rewards: -582.39312, mean: -0.63999
[32m[0906 14-30-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18478, current rewards: -632.39312, mean: -0.65874
[32m[0906 14-31-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18481, current rewards: -682.39312, mean: -0.67564
[32m[0906 14-31-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18484, current rewards: -732.39312, mean: -0.69094
[32m[0906 14-31-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18482, current rewards: -782.39312, mean: -0.70486
[32m[0906 14-31-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18480, current rewards: -832.39312, mean: -0.71758
[32m[0906 14-31-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18480, current rewards: -882.39312, mean: -0.72925
[32m[0906 14-31-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18478, current rewards: -932.39312, mean: -0.73999
[32m[0906 14-31-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18484, current rewards: -982.39312, mean: -0.74992
[32m[0906 14-32-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18485, current rewards: -1032.39312, mean: -0.75911
[32m[0906 14-32-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18483, current rewards: -1082.39312, mean: -0.76765
[32m[0906 14-32-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18481, current rewards: -1132.39312, mean: -0.77561
[32m[0906 14-32-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18478, current rewards: -1182.39312, mean: -0.78304
[32m[0906 14-32-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18477, current rewards: -1232.39312, mean: -0.79000
[32m[0906 14-32-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18475, current rewards: -1282.39312, mean: -0.79652
[32m[0906 14-33-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18475, current rewards: -1332.39312, mean: -0.80265
[32m[0906 14-33-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18474, current rewards: -1382.39312, mean: -0.80842
[32m[0906 14-33-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18475, current rewards: -1432.39312, mean: -0.81386
[32m[0906 14-33-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18470, current rewards: -1482.39312, mean: -0.81900
[32m[0906 14-33-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18462, current rewards: -1532.39312, mean: -0.82387
[32m[0906 14-33-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18461, current rewards: -1582.39312, mean: -0.82848
[32m[0906 14-33-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18466, current rewards: -1632.39312, mean: -0.83285
[32m[0906 14-34-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18470, current rewards: -1682.39312, mean: -0.83701
[32m[0906 14-34-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18471, current rewards: -1732.39312, mean: -0.84097
[32m[0906 14-34-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18469, current rewards: -1782.39312, mean: -0.84474
[32m[0906 14-34-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18460, current rewards: -1832.39312, mean: -0.84833
[32m[0906 14-34-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18457, current rewards: -1882.39312, mean: -0.85176
[32m[0906 14-34-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18460, current rewards: -1932.39312, mean: -0.85504
[32m[0906 14-35-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18461, current rewards: -1982.39312, mean: -0.85818
[32m[0906 14-35-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18461, current rewards: -2032.39312, mean: -0.86118
[32m[0906 14-35-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18454, current rewards: -2082.39312, mean: -0.86406
[32m[0906 14-35-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18451, current rewards: -2132.39312, mean: -0.86683
[32m[0906 14-35-37 @Agent.py:117][0m Average action selection time: 0.1845
[32m[0906 14-35-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-35-37 @MBExp.py:227][0m Rewards obtained: [-2172.393115875953], Lows: [0], Highs: [2219], Total time: 3243.8667469999996
[32m[0906 14-35-54 @MBExp.py:144][0m ####################################################################
[32m[0906 14-35-54 @MBExp.py:145][0m Starting training iteration 8.
[32m[0906 14-35-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18764, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-36-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18868, current rewards: -6.43752, mean: -0.10729
[32m[0906 14-36-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18986, current rewards: 0.28716, mean: 0.00261
[32m[0906 14-36-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18882, current rewards: 6.99752, mean: 0.04373
[32m[0906 14-36-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18750, current rewards: 13.71249, mean: 0.06530
[32m[0906 14-36-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18632, current rewards: 20.42633, mean: 0.07856
[32m[0906 14-36-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18596, current rewards: 27.46141, mean: 0.08859
[32m[0906 14-37-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18572, current rewards: 34.17316, mean: 0.09493
[32m[0906 14-37-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18566, current rewards: 40.88119, mean: 0.09971
[32m[0906 14-37-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18563, current rewards: 47.58149, mean: 0.10344
[32m[0906 14-37-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18560, current rewards: 54.29967, mean: 0.10647
[32m[0906 14-37-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18557, current rewards: 39.93933, mean: 0.07132
[32m[0906 14-37-48 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18552, current rewards: 52.18613, mean: 0.08555
[32m[0906 14-37-57 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18549, current rewards: 63.99018, mean: 0.09695
[32m[0906 14-38-06 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18546, current rewards: 74.68598, mean: 0.10519
[32m[0906 14-38-15 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18553, current rewards: 86.16277, mean: 0.11337
[32m[0906 14-38-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18553, current rewards: 72.27019, mean: 0.08922
[32m[0906 14-38-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18547, current rewards: 82.48526, mean: 0.09591
[32m[0906 14-38-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18540, current rewards: 92.70559, mean: 0.10187
[32m[0906 14-38-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18537, current rewards: 102.92145, mean: 0.10721
[32m[0906 14-39-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18536, current rewards: 113.15035, mean: 0.11203
[32m[0906 14-39-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18537, current rewards: 111.46762, mean: 0.10516
[32m[0906 14-39-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18535, current rewards: 120.87626, mean: 0.10890
[32m[0906 14-39-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18536, current rewards: 130.56597, mean: 0.11256
[32m[0906 14-39-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18531, current rewards: 140.25716, mean: 0.11592
[32m[0906 14-39-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18533, current rewards: 149.94901, mean: 0.11901
[32m[0906 14-39-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18535, current rewards: 159.63173, mean: 0.12186
[32m[0906 14-40-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18534, current rewards: 169.32180, mean: 0.12450
[32m[0906 14-40-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18536, current rewards: 178.99380, mean: 0.12695
[32m[0906 14-40-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18538, current rewards: 188.67978, mean: 0.12923
[32m[0906 14-40-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18537, current rewards: 197.80254, mean: 0.13100
[32m[0906 14-40-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18538, current rewards: 202.73622, mean: 0.12996
[32m[0906 14-40-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18536, current rewards: 194.23195, mean: 0.12064
[32m[0906 14-41-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18538, current rewards: 200.57960, mean: 0.12083
[32m[0906 14-41-12 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18536, current rewards: 206.91564, mean: 0.12100
[32m[0906 14-41-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18536, current rewards: 213.26627, mean: 0.12117
[32m[0906 14-41-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18527, current rewards: 219.60884, mean: 0.12133
[32m[0906 14-41-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18515, current rewards: 225.95147, mean: 0.12148
[32m[0906 14-41-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18510, current rewards: 232.02472, mean: 0.12148
[32m[0906 14-41-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18514, current rewards: 238.11377, mean: 0.12149
[32m[0906 14-42-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18516, current rewards: 244.19444, mean: 0.12149
[32m[0906 14-42-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18516, current rewards: 250.27311, mean: 0.12149
[32m[0906 14-42-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18512, current rewards: 256.34705, mean: 0.12149
[32m[0906 14-42-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18503, current rewards: 262.42396, mean: 0.12149
[32m[0906 14-42-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18499, current rewards: 268.50081, mean: 0.12149
[32m[0906 14-42-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18502, current rewards: 274.57580, mean: 0.12149
[32m[0906 14-43-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18504, current rewards: 251.15034, mean: 0.10872
[32m[0906 14-43-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18502, current rewards: 199.44601, mean: 0.08451
[32m[0906 14-43-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18494, current rewards: 218.60306, mean: 0.09071
[32m[0906 14-43-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18487, current rewards: 237.75043, mean: 0.09665
[32m[0906 14-43-37 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0906 14-43-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-43-37 @MBExp.py:227][0m Rewards obtained: [253.07839512203154], Lows: [71], Highs: [32], Total time: 3706.76603
[32m[0906 14-43-56 @MBExp.py:144][0m ####################################################################
[32m[0906 14-43-56 @MBExp.py:145][0m Starting training iteration 9.
[32m[0906 14-43-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18762, current rewards: 1.29217, mean: 0.12922
[32m[0906 14-44-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18652, current rewards: 6.92966, mean: 0.11549
[32m[0906 14-44-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18576, current rewards: 12.74364, mean: 0.11585
[32m[0906 14-44-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18586, current rewards: 18.54773, mean: 0.11592
[32m[0906 14-44-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18514, current rewards: 24.35730, mean: 0.11599
[32m[0906 14-44-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18429, current rewards: 30.16892, mean: 0.11603
[32m[0906 14-44-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18437, current rewards: 40.94046, mean: 0.13207
[32m[0906 14-45-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18468, current rewards: 40.23760, mean: 0.11177
[32m[0906 14-45-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18489, current rewards: 48.61810, mean: 0.11858
[32m[0906 14-45-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18492, current rewards: 56.98157, mean: 0.12387
[32m[0906 14-45-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18501, current rewards: 56.67905, mean: 0.11114
[32m[0906 14-45-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18498, current rewards: 52.20826, mean: 0.09323
[32m[0906 14-45-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18499, current rewards: 62.06628, mean: 0.10175
[32m[0906 14-45-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18502, current rewards: 71.95050, mean: 0.10902
[32m[0906 14-46-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18506, current rewards: 80.52466, mean: 0.11342
[32m[0906 14-46-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18512, current rewards: 86.76933, mean: 0.11417
[32m[0906 14-46-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18517, current rewards: 72.66584, mean: 0.08971
[32m[0906 14-46-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18525, current rewards: 24.00514, mean: 0.02791
[32m[0906 14-46-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18527, current rewards: -55.01377, mean: -0.06045
[32m[0906 14-46-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18527, current rewards: -93.56208, mean: -0.09746
[32m[0906 14-47-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18530, current rewards: -126.28586, mean: -0.12504
[32m[0906 14-47-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18531, current rewards: -166.76090, mean: -0.15732
[32m[0906 14-47-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18533, current rewards: -180.45887, mean: -0.16258
[32m[0906 14-47-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18532, current rewards: -169.98061, mean: -0.14654
[32m[0906 14-47-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18527, current rewards: -163.29574, mean: -0.13496
[32m[0906 14-47-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18526, current rewards: -156.61996, mean: -0.12430
[32m[0906 14-47-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18525, current rewards: -149.94208, mean: -0.11446
[32m[0906 14-48-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18525, current rewards: -143.26218, mean: -0.10534
[32m[0906 14-48-18 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18522, current rewards: -136.58546, mean: -0.09687
[32m[0906 14-48-27 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18520, current rewards: -129.90443, mean: -0.08898
[32m[0906 14-48-36 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18525, current rewards: -124.04082, mean: -0.08215
[32m[0906 14-48-46 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18528, current rewards: -132.69439, mean: -0.08506
[32m[0906 14-48-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18529, current rewards: -124.66911, mean: -0.07743
[32m[0906 14-49-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18527, current rewards: -115.36659, mean: -0.06950
[32m[0906 14-49-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18528, current rewards: -106.04975, mean: -0.06202
[32m[0906 14-49-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18528, current rewards: -96.72074, mean: -0.05495
[32m[0906 14-49-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18519, current rewards: -87.44004, mean: -0.04831
[32m[0906 14-49-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18507, current rewards: -88.50151, mean: -0.04758
[32m[0906 14-49-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18501, current rewards: -99.83044, mean: -0.05227
[32m[0906 14-49-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18503, current rewards: -93.88320, mean: -0.04790
[32m[0906 14-50-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18505, current rewards: -104.86017, mean: -0.05217
[32m[0906 14-50-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18505, current rewards: -116.62365, mean: -0.05661
[32m[0906 14-50-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18496, current rewards: -130.34182, mean: -0.06177
[32m[0906 14-50-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18487, current rewards: -142.03791, mean: -0.06576
[32m[0906 14-50-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18487, current rewards: -155.65234, mean: -0.07043
[32m[0906 14-50-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18489, current rewards: -167.50607, mean: -0.07412
[32m[0906 14-51-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18490, current rewards: -193.61557, mean: -0.08382
[32m[0906 14-51-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18488, current rewards: -183.97300, mean: -0.07795
[32m[0906 14-51-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18480, current rewards: -177.45886, mean: -0.07363
[32m[0906 14-51-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18473, current rewards: -169.67244, mean: -0.06897
[32m[0906 14-51-39 @Agent.py:117][0m Average action selection time: 0.1847
[32m[0906 14-51-39 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-51-39 @MBExp.py:227][0m Rewards obtained: [-163.44368972690717], Lows: [291], Highs: [22], Total time: 4169.305139
[32m[0906 14-52-00 @MBExp.py:144][0m ####################################################################
[32m[0906 14-52-00 @MBExp.py:145][0m Starting training iteration 10.
[32m[0906 14-52-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18710, current rewards: -10.00000, mean: -1.00000
[32m[0906 14-52-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18672, current rewards: -100.13044, mean: -1.66884
[32m[0906 14-52-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18645, current rewards: -189.36542, mean: -1.72150
[32m[0906 14-52-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18593, current rewards: -280.75400, mean: -1.75471
[32m[0906 14-52-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18481, current rewards: -369.98613, mean: -1.76184
[32m[0906 14-52-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18410, current rewards: -461.37644, mean: -1.77452
[32m[0906 14-52-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18446, current rewards: -500.22335, mean: -1.61362
[32m[0906 14-53-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18476, current rewards: -490.62164, mean: -1.36284
[32m[0906 14-53-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18485, current rewards: -481.01965, mean: -1.17322
[32m[0906 14-53-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18503, current rewards: -471.41966, mean: -1.02483
[32m[0906 14-53-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18515, current rewards: -461.81893, mean: -0.90553
[32m[0906 14-53-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18510, current rewards: -452.21772, mean: -0.80753
[32m[0906 14-53-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18509, current rewards: -442.61533, mean: -0.72560
[32m[0906 14-54-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18515, current rewards: -433.00842, mean: -0.65607
[32m[0906 14-54-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18514, current rewards: -461.39089, mean: -0.64985
[32m[0906 14-54-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18520, current rewards: -561.39089, mean: -0.73867
[32m[0906 14-54-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18518, current rewards: -661.39089, mean: -0.81653
[32m[0906 14-54-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18516, current rewards: -761.39089, mean: -0.88534
[32m[0906 14-54-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18519, current rewards: -861.39089, mean: -0.94658
[32m[0906 14-54-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18528, current rewards: -940.33986, mean: -0.97952
[32m[0906 14-55-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18531, current rewards: -1040.33986, mean: -1.03004
[32m[0906 14-55-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18531, current rewards: -1140.33986, mean: -1.07579
[32m[0906 14-55-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18530, current rewards: -1240.33986, mean: -1.11742
[32m[0906 14-55-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18526, current rewards: -1308.50342, mean: -1.12802
[32m[0906 14-55-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18525, current rewards: -1293.70613, mean: -1.06918
[32m[0906 14-55-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18523, current rewards: -1278.79441, mean: -1.01492
[32m[0906 14-56-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18524, current rewards: -1263.90800, mean: -0.96482
[32m[0906 14-56-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18524, current rewards: -1249.02411, mean: -0.91840
[32m[0906 14-56-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18523, current rewards: -1272.75506, mean: -0.90266
[32m[0906 14-56-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18519, current rewards: -1344.43646, mean: -0.92085
[32m[0906 14-56-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18520, current rewards: -1411.75947, mean: -0.93494
[32m[0906 14-56-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18518, current rewards: -1425.33186, mean: -0.91367
[32m[0906 14-56-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18521, current rewards: -1436.14815, mean: -0.89202
[32m[0906 14-57-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18522, current rewards: -1442.43494, mean: -0.86894
[32m[0906 14-57-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18520, current rewards: -1453.21340, mean: -0.84983
[32m[0906 14-57-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18521, current rewards: -1461.73774, mean: -0.83053
[32m[0906 14-57-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18511, current rewards: -1470.29573, mean: -0.81232
[32m[0906 14-57-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18499, current rewards: -1481.04947, mean: -0.79626
[32m[0906 14-57-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18489, current rewards: -1487.37140, mean: -0.77873
[32m[0906 14-58-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18493, current rewards: -1497.88687, mean: -0.76423
[32m[0906 14-58-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18493, current rewards: -1504.07933, mean: -0.74830
[32m[0906 14-58-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18489, current rewards: -1514.74290, mean: -0.73531
[32m[0906 14-58-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18480, current rewards: -1524.63404, mean: -0.72258
[32m[0906 14-58-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18471, current rewards: -1612.94396, mean: -0.74673
[32m[0906 14-58-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18471, current rewards: -1712.94396, mean: -0.77509
[32m[0906 14-58-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18475, current rewards: -1812.94396, mean: -0.80219
[32m[0906 14-59-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18477, current rewards: -1912.94396, mean: -0.82811
[32m[0906 14-59-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18477, current rewards: -2012.94396, mean: -0.85294
[32m[0906 14-59-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18469, current rewards: -2112.94396, mean: -0.87674
[32m[0906 14-59-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18461, current rewards: -2212.94396, mean: -0.89957
[32m[0906 14-59-42 @Agent.py:117][0m Average action selection time: 0.1846
[32m[0906 14-59-42 @Agent.py:118][0m Rollout length: 2510
[32m[0906 14-59-42 @MBExp.py:227][0m Rewards obtained: [-2292.9439608777047], Lows: [1271], Highs: [29], Total time: 4631.443705
[32m[0906 15-00-05 @MBExp.py:144][0m ####################################################################
[32m[0906 15-00-05 @MBExp.py:145][0m Starting training iteration 11.
[32m[0906 15-00-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18675, current rewards: -0.49579, mean: -0.04958
[32m[0906 15-00-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18625, current rewards: 19.41896, mean: 0.32365
[32m[0906 15-00-26 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18576, current rewards: 44.36364, mean: 0.40331
[32m[0906 15-00-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18492, current rewards: 69.36436, mean: 0.43353
[32m[0906 15-00-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18397, current rewards: 94.40168, mean: 0.44953
[32m[0906 15-00-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18327, current rewards: 119.37400, mean: 0.45913
[32m[0906 15-01-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18383, current rewards: 138.57782, mean: 0.44703
[32m[0906 15-01-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18416, current rewards: 162.64418, mean: 0.45179
[32m[0906 15-01-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18451, current rewards: 186.67627, mean: 0.45531
[32m[0906 15-01-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18455, current rewards: 210.79943, mean: 0.45826
[32m[0906 15-01-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18460, current rewards: 234.82784, mean: 0.46045
[32m[0906 15-01-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18472, current rewards: 258.89331, mean: 0.46231
[32m[0906 15-01-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18486, current rewards: 282.94147, mean: 0.46384
[32m[0906 15-02-08 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18489, current rewards: 306.98937, mean: 0.46514
[32m[0906 15-02-17 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18492, current rewards: 257.02827, mean: 0.36201
[32m[0906 15-02-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18496, current rewards: 169.24110, mean: 0.22269
[32m[0906 15-02-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18493, current rewards: 167.44583, mean: 0.20672
[32m[0906 15-02-45 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18495, current rewards: 181.19567, mean: 0.21069
[32m[0906 15-02-54 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18495, current rewards: 194.92086, mean: 0.21420
[32m[0906 15-03-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18492, current rewards: 208.66775, mean: 0.21736
[32m[0906 15-03-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18495, current rewards: 222.42035, mean: 0.22022
[32m[0906 15-03-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18505, current rewards: 236.16684, mean: 0.22280
[32m[0906 15-03-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18500, current rewards: 217.03260, mean: 0.19552
[32m[0906 15-03-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18501, current rewards: 216.83589, mean: 0.18693
[32m[0906 15-03-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18503, current rewards: 225.58377, mean: 0.18643
[32m[0906 15-03-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18502, current rewards: 234.33811, mean: 0.18598
[32m[0906 15-04-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18504, current rewards: 242.26884, mean: 0.18494
[32m[0906 15-04-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18504, current rewards: 252.60285, mean: 0.18574
[32m[0906 15-04-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18503, current rewards: 262.95897, mean: 0.18650
[32m[0906 15-04-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18502, current rewards: 273.30649, mean: 0.18720
[32m[0906 15-04-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18501, current rewards: 275.17348, mean: 0.18223
[32m[0906 15-04-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18501, current rewards: 292.54091, mean: 0.18753
[32m[0906 15-05-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18503, current rewards: 313.50637, mean: 0.19472
[32m[0906 15-05-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18504, current rewards: 334.51647, mean: 0.20152
[32m[0906 15-05-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18503, current rewards: 355.50281, mean: 0.20790
[32m[0906 15-05-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18505, current rewards: 376.36679, mean: 0.21384
[32m[0906 15-05-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18496, current rewards: 369.98568, mean: 0.20441
[32m[0906 15-05-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18484, current rewards: 381.43635, mean: 0.20507
[32m[0906 15-05-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18475, current rewards: 392.87425, mean: 0.20569
[32m[0906 15-06-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18478, current rewards: 400.53147, mean: 0.20435
[32m[0906 15-06-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18478, current rewards: 411.28101, mean: 0.20462
[32m[0906 15-06-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18474, current rewards: 422.04391, mean: 0.20488
[32m[0906 15-06-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18465, current rewards: 432.80592, mean: 0.20512
[32m[0906 15-06-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18456, current rewards: 443.55631, mean: 0.20535
[32m[0906 15-06-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18458, current rewards: 454.32542, mean: 0.20558
[32m[0906 15-07-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18461, current rewards: 465.09255, mean: 0.20579
[32m[0906 15-07-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18462, current rewards: 475.80275, mean: 0.20598
[32m[0906 15-07-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18458, current rewards: 479.07351, mean: 0.20300
[32m[0906 15-07-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18454, current rewards: 405.01395, mean: 0.16806
[32m[0906 15-07-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18448, current rewards: 409.93198, mean: 0.16664
[32m[0906 15-07-47 @Agent.py:117][0m Average action selection time: 0.1844
[32m[0906 15-07-47 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-07-47 @MBExp.py:227][0m Rewards obtained: [416.5236758849059], Lows: [156], Highs: [13], Total time: 5093.236808
[32m[0906 15-08-13 @MBExp.py:144][0m ####################################################################
[32m[0906 15-08-13 @MBExp.py:145][0m Starting training iteration 12.
[32m[0906 15-08-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18535, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-08-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18594, current rewards: -24.50994, mean: -0.40850
[32m[0906 15-08-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18595, current rewards: -19.07680, mean: -0.17343
[32m[0906 15-08-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18473, current rewards: -13.64156, mean: -0.08526
[32m[0906 15-08-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18391, current rewards: -8.21617, mean: -0.03912
[32m[0906 15-09-00 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18331, current rewards: -2.77909, mean: -0.01069
[32m[0906 15-09-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18379, current rewards: 2.07155, mean: 0.00668
[32m[0906 15-09-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18406, current rewards: 7.69757, mean: 0.02138
[32m[0906 15-09-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18428, current rewards: 2.43155, mean: 0.00593
[32m[0906 15-09-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18456, current rewards: 8.44179, mean: 0.01835
[32m[0906 15-09-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18470, current rewards: 14.45273, mean: 0.02834
[32m[0906 15-09-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18475, current rewards: 20.46421, mean: 0.03654
[32m[0906 15-10-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18480, current rewards: 26.47868, mean: 0.04341
[32m[0906 15-10-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18487, current rewards: 32.49102, mean: 0.04923
[32m[0906 15-10-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18486, current rewards: 40.03075, mean: 0.05638
[32m[0906 15-10-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18494, current rewards: 23.73735, mean: 0.03123
[32m[0906 15-10-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18495, current rewards: 32.27527, mean: 0.03985
[32m[0906 15-10-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18492, current rewards: 40.81319, mean: 0.04746
[32m[0906 15-11-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18497, current rewards: 35.30201, mean: 0.03879
[32m[0906 15-11-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18499, current rewards: -14.69799, mean: -0.01531
[32m[0906 15-11-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18502, current rewards: -64.69799, mean: -0.06406
[32m[0906 15-11-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18501, current rewards: -114.69799, mean: -0.10821
[32m[0906 15-11-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18505, current rewards: -164.69799, mean: -0.14838
[32m[0906 15-11-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18509, current rewards: -214.69799, mean: -0.18508
[32m[0906 15-11-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18509, current rewards: -264.69799, mean: -0.21876
[32m[0906 15-12-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18509, current rewards: -314.69799, mean: -0.24976
[32m[0906 15-12-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18509, current rewards: -364.69799, mean: -0.27840
[32m[0906 15-12-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18508, current rewards: -414.69799, mean: -0.30492
[32m[0906 15-12-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18510, current rewards: -464.69799, mean: -0.32957
[32m[0906 15-12-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18508, current rewards: -514.69799, mean: -0.35253
[32m[0906 15-12-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18509, current rewards: -564.69799, mean: -0.37397
[32m[0906 15-13-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18508, current rewards: -614.69799, mean: -0.39404
[32m[0906 15-13-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18505, current rewards: -664.69799, mean: -0.41286
[32m[0906 15-13-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18505, current rewards: -714.69799, mean: -0.43054
[32m[0906 15-13-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18505, current rewards: -764.69799, mean: -0.44719
[32m[0906 15-13-39 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18505, current rewards: -814.69799, mean: -0.46290
[32m[0906 15-13-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18497, current rewards: -864.69799, mean: -0.47773
[32m[0906 15-13-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18487, current rewards: -914.69799, mean: -0.49177
[32m[0906 15-14-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18475, current rewards: -964.69799, mean: -0.50508
[32m[0906 15-14-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18474, current rewards: -1014.69799, mean: -0.51770
[32m[0906 15-14-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18475, current rewards: -1064.69799, mean: -0.52970
[32m[0906 15-14-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18467, current rewards: -1114.69799, mean: -0.54112
[32m[0906 15-14-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18457, current rewards: -1164.69799, mean: -0.55199
[32m[0906 15-14-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18448, current rewards: -1214.69799, mean: -0.56236
[32m[0906 15-15-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18450, current rewards: -1264.69799, mean: -0.57226
[32m[0906 15-15-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18453, current rewards: -1314.69799, mean: -0.58172
[32m[0906 15-15-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18458, current rewards: -1364.69799, mean: -0.59078
[32m[0906 15-15-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18457, current rewards: -1357.42378, mean: -0.57518
[32m[0906 15-15-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18450, current rewards: -1379.14997, mean: -0.57226
[32m[0906 15-15-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18442, current rewards: -1429.14997, mean: -0.58096
[32m[0906 15-15-54 @Agent.py:117][0m Average action selection time: 0.1844
[32m[0906 15-15-54 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-15-54 @MBExp.py:227][0m Rewards obtained: [-1469.1499741576354], Lows: [20], Highs: [1547], Total time: 5554.855073
[32m[0906 15-16-22 @MBExp.py:144][0m ####################################################################
[32m[0906 15-16-22 @MBExp.py:145][0m Starting training iteration 13.
[32m[0906 15-16-24 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18577, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-16-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18630, current rewards: -5.90282, mean: -0.09838
[32m[0906 15-16-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18578, current rewards: -1.29015, mean: -0.01173
[32m[0906 15-16-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18413, current rewards: 3.31803, mean: 0.02074
[32m[0906 15-17-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18325, current rewards: 7.92450, mean: 0.03774
[32m[0906 15-17-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18276, current rewards: 12.53243, mean: 0.04820
[32m[0906 15-17-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18334, current rewards: 17.13790, mean: 0.05528
[32m[0906 15-17-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18377, current rewards: 21.74698, mean: 0.06041
[32m[0906 15-17-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18414, current rewards: 26.34622, mean: 0.06426
[32m[0906 15-17-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18440, current rewards: 30.95804, mean: 0.06730
[32m[0906 15-17-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18451, current rewards: 35.56410, mean: 0.06973
[32m[0906 15-18-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18473, current rewards: 40.17095, mean: 0.07173
[32m[0906 15-18-15 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18477, current rewards: 44.77708, mean: 0.07341
[32m[0906 15-18-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18481, current rewards: 49.38279, mean: 0.07482
[32m[0906 15-18-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18484, current rewards: 53.98758, mean: 0.07604
[32m[0906 15-18-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18488, current rewards: 58.67859, mean: 0.07721
[32m[0906 15-18-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18491, current rewards: 63.29407, mean: 0.07814
[32m[0906 15-19-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18496, current rewards: 69.98703, mean: 0.08138
[32m[0906 15-19-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18499, current rewards: 77.15580, mean: 0.08479
[32m[0906 15-19-20 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18503, current rewards: 82.26113, mean: 0.08569
[32m[0906 15-19-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18503, current rewards: 87.36387, mean: 0.08650
[32m[0906 15-19-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18502, current rewards: 92.47705, mean: 0.08724
[32m[0906 15-19-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18502, current rewards: 97.58657, mean: 0.08792
[32m[0906 15-19-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18501, current rewards: 102.69170, mean: 0.08853
[32m[0906 15-20-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18503, current rewards: 107.80313, mean: 0.08909
[32m[0906 15-20-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18505, current rewards: 112.90585, mean: 0.08961
[32m[0906 15-20-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18502, current rewards: 118.01582, mean: 0.09009
[32m[0906 15-20-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18502, current rewards: 123.11902, mean: 0.09053
[32m[0906 15-20-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18502, current rewards: 128.22777, mean: 0.09094
[32m[0906 15-20-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18500, current rewards: 133.33691, mean: 0.09133
[32m[0906 15-21-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18501, current rewards: 118.80880, mean: 0.07868
[32m[0906 15-21-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18500, current rewards: 126.98534, mean: 0.08140
[32m[0906 15-21-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18498, current rewards: 134.41704, mean: 0.08349
[32m[0906 15-21-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18498, current rewards: 142.16889, mean: 0.08564
[32m[0906 15-21-39 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18497, current rewards: 149.50750, mean: 0.08743
[32m[0906 15-21-48 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18497, current rewards: 156.92661, mean: 0.08916
[32m[0906 15-21-57 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18488, current rewards: 164.35773, mean: 0.09081
[32m[0906 15-22-06 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18478, current rewards: 171.65279, mean: 0.09229
[32m[0906 15-22-15 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18471, current rewards: 156.23779, mean: 0.08180
[32m[0906 15-22-24 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18469, current rewards: 163.70507, mean: 0.08352
[32m[0906 15-22-34 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18469, current rewards: 168.97519, mean: 0.08407
[32m[0906 15-22-43 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18459, current rewards: 174.24618, mean: 0.08459
[32m[0906 15-22-52 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18450, current rewards: 179.51762, mean: 0.08508
[32m[0906 15-23-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18442, current rewards: 184.78951, mean: 0.08555
[32m[0906 15-23-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18445, current rewards: 190.06139, mean: 0.08600
[32m[0906 15-23-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18448, current rewards: 185.27208, mean: 0.08198
[32m[0906 15-23-29 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18452, current rewards: 191.20495, mean: 0.08277
[32m[0906 15-23-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18451, current rewards: 196.69297, mean: 0.08334
[32m[0906 15-23-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18444, current rewards: 202.40707, mean: 0.08399
[32m[0906 15-23-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18437, current rewards: 208.47047, mean: 0.08474
[32m[0906 15-24-03 @Agent.py:117][0m Average action selection time: 0.1843
[32m[0906 15-24-03 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-24-03 @MBExp.py:227][0m Rewards obtained: [213.32540649847834], Lows: [20], Highs: [20], Total time: 6016.337243
[32m[0906 15-24-33 @MBExp.py:144][0m ####################################################################
[32m[0906 15-24-33 @MBExp.py:145][0m Starting training iteration 14.
[32m[0906 15-24-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18660, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-24-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18632, current rewards: -6.78292, mean: -0.11305
[32m[0906 15-24-53 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18528, current rewards: -2.05422, mean: -0.01867
[32m[0906 15-25-02 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18409, current rewards: 2.68019, mean: 0.01675
[32m[0906 15-25-11 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18327, current rewards: 7.41031, mean: 0.03529
[32m[0906 15-25-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18289, current rewards: 12.14082, mean: 0.04670
[32m[0906 15-25-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18346, current rewards: 16.86931, mean: 0.05442
[32m[0906 15-25-39 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18386, current rewards: 21.60001, mean: 0.06000
[32m[0906 15-25-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18401, current rewards: 26.33302, mean: 0.06423
[32m[0906 15-25-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18429, current rewards: 31.05850, mean: 0.06752
[32m[0906 15-26-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18445, current rewards: 35.79389, mean: 0.07018
[32m[0906 15-26-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18455, current rewards: 40.52588, mean: 0.07237
[32m[0906 15-26-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18468, current rewards: 45.25684, mean: 0.07419
[32m[0906 15-26-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18472, current rewards: 49.98818, mean: 0.07574
[32m[0906 15-26-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18475, current rewards: 41.85889, mean: 0.05896
[32m[0906 15-26-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18476, current rewards: 38.38332, mean: 0.05050
[32m[0906 15-27-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18477, current rewards: 42.56383, mean: 0.05255
[32m[0906 15-27-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18478, current rewards: 46.74867, mean: 0.05436
[32m[0906 15-27-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18480, current rewards: 50.92927, mean: 0.05597
[32m[0906 15-27-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18479, current rewards: 55.10893, mean: 0.05741
[32m[0906 15-27-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18481, current rewards: 59.28797, mean: 0.05870
[32m[0906 15-27-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18484, current rewards: 63.46851, mean: 0.05988
[32m[0906 15-27-58 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18486, current rewards: 68.39331, mean: 0.06162
[32m[0906 15-28-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18490, current rewards: 72.79524, mean: 0.06275
[32m[0906 15-28-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18490, current rewards: 77.20589, mean: 0.06381
[32m[0906 15-28-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18494, current rewards: 81.61886, mean: 0.06478
[32m[0906 15-28-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18500, current rewards: 86.03127, mean: 0.06567
[32m[0906 15-28-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18502, current rewards: 80.16441, mean: 0.05894
[32m[0906 15-28-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18497, current rewards: 85.64171, mean: 0.06074
[32m[0906 15-29-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18499, current rewards: 91.13656, mean: 0.06242
[32m[0906 15-29-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18497, current rewards: 96.30824, mean: 0.06378
[32m[0906 15-29-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18496, current rewards: 101.61914, mean: 0.06514
[32m[0906 15-29-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18497, current rewards: 107.08573, mean: 0.06651
[32m[0906 15-29-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18494, current rewards: 112.54840, mean: 0.06780
[32m[0906 15-29-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18496, current rewards: 118.00805, mean: 0.06901
[32m[0906 15-29-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18493, current rewards: 123.47157, mean: 0.07015
[32m[0906 15-30-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18482, current rewards: 128.93368, mean: 0.07123
[32m[0906 15-30-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18470, current rewards: 134.38338, mean: 0.07225
[32m[0906 15-30-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18460, current rewards: 118.64950, mean: 0.06212
[32m[0906 15-30-35 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18459, current rewards: 124.31242, mean: 0.06342
[32m[0906 15-30-44 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18456, current rewards: 129.66066, mean: 0.06451
[32m[0906 15-30-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18448, current rewards: 135.00943, mean: 0.06554
[32m[0906 15-31-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18440, current rewards: 140.35507, mean: 0.06652
[32m[0906 15-31-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18432, current rewards: 145.70335, mean: 0.06746
[32m[0906 15-31-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18434, current rewards: 151.05020, mean: 0.06835
[32m[0906 15-31-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18436, current rewards: 156.39634, mean: 0.06920
[32m[0906 15-31-39 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18436, current rewards: 161.74381, mean: 0.07002
[32m[0906 15-31-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18436, current rewards: 167.09116, mean: 0.07080
[32m[0906 15-31-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18429, current rewards: 172.43831, mean: 0.07155
[32m[0906 15-32-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18422, current rewards: 177.78658, mean: 0.07227
[32m[0906 15-32-14 @Agent.py:117][0m Average action selection time: 0.1842
[32m[0906 15-32-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-32-14 @MBExp.py:227][0m Rewards obtained: [182.06577802582933], Lows: [20], Highs: [21], Total time: 6477.446574
[32m[0906 15-32-46 @MBExp.py:144][0m ####################################################################
[32m[0906 15-32-46 @MBExp.py:145][0m Starting training iteration 15.
[32m[0906 15-32-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18774, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-32-57 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18675, current rewards: -6.74083, mean: -0.11235
[32m[0906 15-33-06 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18442, current rewards: -2.27760, mean: -0.02071
[32m[0906 15-33-15 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18346, current rewards: 2.18225, mean: 0.01364
[32m[0906 15-33-24 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18280, current rewards: 6.63907, mean: 0.03161
[32m[0906 15-33-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18254, current rewards: -9.07621, mean: -0.03491
[32m[0906 15-33-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18324, current rewards: -3.93371, mean: -0.01269
[32m[0906 15-33-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18357, current rewards: 1.20873, mean: 0.00336
[32m[0906 15-34-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18378, current rewards: 6.34884, mean: 0.01548
[32m[0906 15-34-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18395, current rewards: 11.49076, mean: 0.02498
[32m[0906 15-34-20 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18412, current rewards: 16.63486, mean: 0.03262
[32m[0906 15-34-29 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18419, current rewards: 21.77854, mean: 0.03889
[32m[0906 15-34-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18426, current rewards: 26.92183, mean: 0.04413
[32m[0906 15-34-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18441, current rewards: 32.12570, mean: 0.04868
[32m[0906 15-34-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18452, current rewards: 37.27072, mean: 0.05249
[32m[0906 15-35-06 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18461, current rewards: 42.40537, mean: 0.05580
[32m[0906 15-35-15 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18468, current rewards: 27.08493, mean: 0.03344
[32m[0906 15-35-25 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18475, current rewards: 32.96251, mean: 0.03833
[32m[0906 15-35-34 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18475, current rewards: 38.84053, mean: 0.04268
[32m[0906 15-35-43 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18476, current rewards: 44.71800, mean: 0.04658
[32m[0906 15-35-52 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18471, current rewards: 50.59373, mean: 0.05009
[32m[0906 15-36-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18474, current rewards: 55.87353, mean: 0.05271
[32m[0906 15-36-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18473, current rewards: 61.69162, mean: 0.05558
[32m[0906 15-36-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18469, current rewards: 67.51294, mean: 0.05820
[32m[0906 15-36-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18468, current rewards: 73.33244, mean: 0.06061
[32m[0906 15-36-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18469, current rewards: 79.15167, mean: 0.06282
[32m[0906 15-36-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18471, current rewards: 84.97221, mean: 0.06486
[32m[0906 15-36-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18474, current rewards: 90.78994, mean: 0.06676
[32m[0906 15-37-06 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18473, current rewards: 85.44399, mean: 0.06060
[32m[0906 15-37-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18470, current rewards: 93.32589, mean: 0.06392
[32m[0906 15-37-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18469, current rewards: 98.52997, mean: 0.06525
[32m[0906 15-37-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18470, current rewards: 103.73629, mean: 0.06650
[32m[0906 15-37-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18469, current rewards: 108.94158, mean: 0.06767
[32m[0906 15-37-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18469, current rewards: 114.15121, mean: 0.06877
[32m[0906 15-38-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18469, current rewards: 119.35983, mean: 0.06980
[32m[0906 15-38-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18468, current rewards: 124.57084, mean: 0.07078
[32m[0906 15-38-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18456, current rewards: 118.81653, mean: 0.06564
[32m[0906 15-38-29 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18445, current rewards: 124.08478, mean: 0.06671
[32m[0906 15-38-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18435, current rewards: 129.47667, mean: 0.06779
[32m[0906 15-38-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18428, current rewards: 134.84004, mean: 0.06880
[32m[0906 15-38-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18424, current rewards: 140.21086, mean: 0.06976
[32m[0906 15-39-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18417, current rewards: 145.57758, mean: 0.07067
[32m[0906 15-39-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18410, current rewards: 130.00870, mean: 0.06162
[32m[0906 15-39-24 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18404, current rewards: 136.02809, mean: 0.06298
[32m[0906 15-39-33 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18409, current rewards: 142.04170, mean: 0.06427
[32m[0906 15-39-42 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18415, current rewards: 148.27294, mean: 0.06561
[32m[0906 15-39-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18417, current rewards: 154.33546, mean: 0.06681
[32m[0906 15-40-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18416, current rewards: 160.33006, mean: 0.06794
[32m[0906 15-40-10 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18409, current rewards: 166.31507, mean: 0.06901
[32m[0906 15-40-19 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18402, current rewards: 172.30200, mean: 0.07004
[32m[0906 15-40-26 @Agent.py:117][0m Average action selection time: 0.1840
[32m[0906 15-40-26 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-40-26 @MBExp.py:227][0m Rewards obtained: [177.09735034522978], Lows: [30], Highs: [31], Total time: 6938.043237999999
[32m[0906 15-41-00 @MBExp.py:144][0m ####################################################################
[32m[0906 15-41-00 @MBExp.py:145][0m Starting training iteration 16.
[32m[0906 15-41-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18766, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-41-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18746, current rewards: -6.71307, mean: -0.11188
[32m[0906 15-41-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18448, current rewards: -2.00875, mean: -0.01826
[32m[0906 15-41-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18327, current rewards: 2.69686, mean: 0.01686
[32m[0906 15-41-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18277, current rewards: 7.83665, mean: 0.03732
[32m[0906 15-41-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18254, current rewards: 12.55989, mean: 0.04831
[32m[0906 15-41-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18319, current rewards: 17.27878, mean: 0.05574
[32m[0906 15-42-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18359, current rewards: 22.00606, mean: 0.06113
[32m[0906 15-42-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18385, current rewards: 26.73304, mean: 0.06520
[32m[0906 15-42-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18399, current rewards: 31.45862, mean: 0.06839
[32m[0906 15-42-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18414, current rewards: 36.18174, mean: 0.07094
[32m[0906 15-42-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18426, current rewards: 40.91163, mean: 0.07306
[32m[0906 15-42-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18429, current rewards: 45.58392, mean: 0.07473
[32m[0906 15-43-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18437, current rewards: 44.02451, mean: 0.06670
[32m[0906 15-43-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18450, current rewards: 31.87869, mean: 0.04490
[32m[0906 15-43-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18455, current rewards: 36.48241, mean: 0.04800
[32m[0906 15-43-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18458, current rewards: 41.08293, mean: 0.05072
[32m[0906 15-43-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18462, current rewards: 45.68328, mean: 0.05312
[32m[0906 15-43-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18465, current rewards: 50.28142, mean: 0.05525
[32m[0906 15-43-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18472, current rewards: 54.88255, mean: 0.05717
[32m[0906 15-44-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18475, current rewards: 47.53824, mean: 0.04707
[32m[0906 15-44-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18475, current rewards: 51.92192, mean: 0.04898
[32m[0906 15-44-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18478, current rewards: 56.30522, mean: 0.05073
[32m[0906 15-44-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18477, current rewards: 60.69311, mean: 0.05232
[32m[0906 15-44-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18478, current rewards: 65.07437, mean: 0.05378
[32m[0906 15-44-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18480, current rewards: 69.45770, mean: 0.05513
[32m[0906 15-45-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18482, current rewards: 73.84211, mean: 0.05637
[32m[0906 15-45-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18479, current rewards: 78.22512, mean: 0.05752
[32m[0906 15-45-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18482, current rewards: 83.31708, mean: 0.05909
[32m[0906 15-45-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18480, current rewards: 87.79145, mean: 0.06013
[32m[0906 15-45-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18477, current rewards: 92.26545, mean: 0.06110
[32m[0906 15-45-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18477, current rewards: 96.74251, mean: 0.06201
[32m[0906 15-45-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18477, current rewards: 91.27680, mean: 0.05669
[32m[0906 15-46-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18475, current rewards: 95.63299, mean: 0.05761
[32m[0906 15-46-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18474, current rewards: 99.98362, mean: 0.05847
[32m[0906 15-46-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18472, current rewards: 104.33620, mean: 0.05928
[32m[0906 15-46-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18460, current rewards: 108.67834, mean: 0.06004
[32m[0906 15-46-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18449, current rewards: 113.03729, mean: 0.06077
[32m[0906 15-46-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18439, current rewards: 117.41220, mean: 0.06147
[32m[0906 15-47-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18431, current rewards: 121.78396, mean: 0.06213
[32m[0906 15-47-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18422, current rewards: 126.16126, mean: 0.06277
[32m[0906 15-47-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18416, current rewards: 130.53348, mean: 0.06337
[32m[0906 15-47-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18410, current rewards: 134.90774, mean: 0.06394
[32m[0906 15-47-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18404, current rewards: 112.74107, mean: 0.05219
[32m[0906 15-47-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18409, current rewards: 110.79466, mean: 0.05013
[32m[0906 15-47-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18411, current rewards: 116.67672, mean: 0.05163
[32m[0906 15-48-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18412, current rewards: 121.74572, mean: 0.05270
[32m[0906 15-48-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18412, current rewards: 126.81678, mean: 0.05374
[32m[0906 15-48-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18405, current rewards: 131.88913, mean: 0.05473
[32m[0906 15-48-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18398, current rewards: 136.95955, mean: 0.05567
[32m[0906 15-48-40 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 15-48-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-48-40 @MBExp.py:227][0m Rewards obtained: [126.3059516422085], Lows: [41], Highs: [21], Total time: 7398.527123999999
[32m[0906 15-49-16 @MBExp.py:144][0m ####################################################################
[32m[0906 15-49-16 @MBExp.py:145][0m Starting training iteration 17.
[32m[0906 15-49-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18571, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-49-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18520, current rewards: -15.53066, mean: -0.25884
[32m[0906 15-49-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18355, current rewards: -3.82827, mean: -0.03480
[32m[0906 15-49-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18260, current rewards: 14.80599, mean: 0.09254
[32m[0906 15-49-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18230, current rewards: 33.87144, mean: 0.16129
[32m[0906 15-50-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18237, current rewards: 52.91913, mean: 0.20354
[32m[0906 15-50-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18297, current rewards: 71.96567, mean: 0.23215
[32m[0906 15-50-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18322, current rewards: 90.99710, mean: 0.25277
[32m[0906 15-50-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18354, current rewards: 85.95202, mean: 0.20964
[32m[0906 15-50-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18373, current rewards: 92.03383, mean: 0.20007
[32m[0906 15-50-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18392, current rewards: 98.11681, mean: 0.19239
[32m[0906 15-50-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18410, current rewards: 102.94164, mean: 0.18382
[32m[0906 15-51-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18424, current rewards: 107.40448, mean: 0.17607
[32m[0906 15-51-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18435, current rewards: 111.86034, mean: 0.16949
[32m[0906 15-51-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18439, current rewards: 116.31428, mean: 0.16382
[32m[0906 15-51-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18456, current rewards: 99.80845, mean: 0.13133
[32m[0906 15-51-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18468, current rewards: 61.41429, mean: 0.07582
[32m[0906 15-51-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18470, current rewards: 30.64179, mean: 0.03563
[32m[0906 15-52-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18474, current rewards: 2.89476, mean: 0.00318
[32m[0906 15-52-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18474, current rewards: -31.86642, mean: -0.03319
[32m[0906 15-52-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18473, current rewards: -70.59269, mean: -0.06989
[32m[0906 15-52-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18477, current rewards: -109.74798, mean: -0.10354
[32m[0906 15-52-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18477, current rewards: -148.94502, mean: -0.13418
[32m[0906 15-52-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18478, current rewards: -181.79413, mean: -0.15672
[32m[0906 15-53-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18475, current rewards: -212.58931, mean: -0.17569
[32m[0906 15-53-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18476, current rewards: -243.40324, mean: -0.19318
[32m[0906 15-53-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18477, current rewards: -283.48466, mean: -0.21640
[32m[0906 15-53-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18478, current rewards: -322.81357, mean: -0.23736
[32m[0906 15-53-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18480, current rewards: -356.81504, mean: -0.25306
[32m[0906 15-53-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18483, current rewards: -384.44416, mean: -0.26332
[32m[0906 15-53-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18481, current rewards: -414.48021, mean: -0.27449
[32m[0906 15-54-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18481, current rewards: -452.42942, mean: -0.29002
[32m[0906 15-54-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18480, current rewards: -463.18104, mean: -0.28769
[32m[0906 15-54-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18480, current rewards: -457.44704, mean: -0.27557
[32m[0906 15-54-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18477, current rewards: -451.71187, mean: -0.26416
[32m[0906 15-54-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18473, current rewards: -445.98212, mean: -0.25340
[32m[0906 15-54-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18462, current rewards: -438.27896, mean: -0.24214
[32m[0906 15-54-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18450, current rewards: -432.10546, mean: -0.23231
[32m[0906 15-55-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18440, current rewards: -425.93675, mean: -0.22300
[32m[0906 15-55-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18425, current rewards: -419.76625, mean: -0.21417
[32m[0906 15-55-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18416, current rewards: -413.60078, mean: -0.20577
[32m[0906 15-55-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18407, current rewards: -407.42536, mean: -0.19778
[32m[0906 15-55-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18401, current rewards: -401.24999, mean: -0.19017
[32m[0906 15-55-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18397, current rewards: -395.07972, mean: -0.18291
[32m[0906 15-56-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18402, current rewards: -400.89882, mean: -0.18140
[32m[0906 15-56-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18405, current rewards: -396.16038, mean: -0.17529
[32m[0906 15-56-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18408, current rewards: -391.44393, mean: -0.16946
[32m[0906 15-56-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18409, current rewards: -386.72784, mean: -0.16387
[32m[0906 15-56-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18401, current rewards: -382.00906, mean: -0.15851
[32m[0906 15-56-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18394, current rewards: -377.29056, mean: -0.15337
[32m[0906 15-56-56 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 15-56-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 15-56-56 @MBExp.py:227][0m Rewards obtained: [-395.89910207009353], Lows: [357], Highs: [30], Total time: 7858.908493999999
[32m[0906 15-57-34 @MBExp.py:144][0m ####################################################################
[32m[0906 15-57-34 @MBExp.py:145][0m Starting training iteration 18.
[32m[0906 15-57-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18488, current rewards: -10.00000, mean: -1.00000
[32m[0906 15-57-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18319, current rewards: -5.42133, mean: -0.09036
[32m[0906 15-57-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18268, current rewards: -0.55329, mean: -0.00503
[32m[0906 15-58-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18246, current rewards: 4.68870, mean: 0.02930
[32m[0906 15-58-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18198, current rewards: 10.21269, mean: 0.04863
[32m[0906 15-58-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18232, current rewards: 15.74103, mean: 0.06054
[32m[0906 15-58-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18294, current rewards: 21.26321, mean: 0.06859
[32m[0906 15-58-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18325, current rewards: 6.13822, mean: 0.01705
[32m[0906 15-58-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18354, current rewards: 12.08558, mean: 0.02948
[32m[0906 15-58-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18375, current rewards: 17.13640, mean: 0.03725
[32m[0906 15-59-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18391, current rewards: 22.18144, mean: 0.04349
[32m[0906 15-59-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18401, current rewards: 27.27932, mean: 0.04871
[32m[0906 15-59-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18420, current rewards: 32.75841, mean: 0.05370
[32m[0906 15-59-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18427, current rewards: 38.23843, mean: 0.05794
[32m[0906 15-59-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18437, current rewards: 43.71966, mean: 0.06158
[32m[0906 15-59-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18449, current rewards: 49.19718, mean: 0.06473
[32m[0906 16-00-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18454, current rewards: 54.67949, mean: 0.06751
[32m[0906 16-00-13 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18456, current rewards: 60.15751, mean: 0.06995
[32m[0906 16-00-22 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18460, current rewards: 65.63985, mean: 0.07213
[32m[0906 16-00-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18463, current rewards: 72.05780, mean: 0.07506
[32m[0906 16-00-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18461, current rewards: 75.84727, mean: 0.07510
[32m[0906 16-00-50 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18467, current rewards: 79.45191, mean: 0.07495
[32m[0906 16-00-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18468, current rewards: 83.02881, mean: 0.07480
[32m[0906 16-01-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18472, current rewards: 86.60063, mean: 0.07466
[32m[0906 16-01-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18468, current rewards: 79.79141, mean: 0.06594
[32m[0906 16-01-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18471, current rewards: 84.88218, mean: 0.06737
[32m[0906 16-01-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18474, current rewards: 89.98875, mean: 0.06869
[32m[0906 16-01-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18475, current rewards: 95.09445, mean: 0.06992
[32m[0906 16-01-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18477, current rewards: 100.20235, mean: 0.07107
[32m[0906 16-02-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18482, current rewards: 105.31209, mean: 0.07213
[32m[0906 16-02-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18485, current rewards: 113.79014, mean: 0.07536
[32m[0906 16-02-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18486, current rewards: 119.85253, mean: 0.07683
[32m[0906 16-02-32 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18488, current rewards: 124.98671, mean: 0.07763
[32m[0906 16-02-41 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18487, current rewards: 130.11976, mean: 0.07839
[32m[0906 16-02-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18489, current rewards: 135.25864, mean: 0.07910
[32m[0906 16-03-00 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18489, current rewards: 140.39783, mean: 0.07977
[32m[0906 16-03-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18477, current rewards: 145.53220, mean: 0.08040
[32m[0906 16-03-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18465, current rewards: 150.67414, mean: 0.08101
[32m[0906 16-03-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18455, current rewards: 155.81180, mean: 0.08158
[32m[0906 16-03-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18435, current rewards: 160.94904, mean: 0.08212
[32m[0906 16-03-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18425, current rewards: 166.08626, mean: 0.08263
[32m[0906 16-03-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18417, current rewards: 171.22061, mean: 0.08312
[32m[0906 16-04-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18409, current rewards: 176.35686, mean: 0.08358
[32m[0906 16-04-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18407, current rewards: 143.86399, mean: 0.06660
[32m[0906 16-04-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18413, current rewards: 91.19980, mean: 0.04127
[32m[0906 16-04-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18416, current rewards: 50.90264, mean: 0.02252
[32m[0906 16-04-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18419, current rewards: 8.52098, mean: 0.00369
[32m[0906 16-04-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18418, current rewards: -37.82954, mean: -0.01603
[32m[0906 16-04-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18411, current rewards: -76.61149, mean: -0.03179
[32m[0906 16-05-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18404, current rewards: -115.71498, mean: -0.04704
[32m[0906 16-05-14 @Agent.py:117][0m Average action selection time: 0.1840
[32m[0906 16-05-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-05-14 @MBExp.py:227][0m Rewards obtained: [-147.3510568597452], Lows: [195], Highs: [21], Total time: 8319.570241
[32m[0906 16-05-54 @MBExp.py:144][0m ####################################################################
[32m[0906 16-05-54 @MBExp.py:145][0m Starting training iteration 19.
[32m[0906 16-05-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18666, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-06-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18171, current rewards: -0.85936, mean: -0.01432
[32m[0906 16-06-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18192, current rewards: 3.87151, mean: 0.03520
[32m[0906 16-06-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18169, current rewards: 8.91869, mean: 0.05574
[32m[0906 16-06-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18145, current rewards: 13.97428, mean: 0.06654
[32m[0906 16-06-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18195, current rewards: 19.02400, mean: 0.07317
[32m[0906 16-06-51 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18252, current rewards: 24.07269, mean: 0.07765
[32m[0906 16-07-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18297, current rewards: 29.12349, mean: 0.08090
[32m[0906 16-07-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18326, current rewards: 34.17821, mean: 0.08336
[32m[0906 16-07-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18350, current rewards: 39.23166, mean: 0.08529
[32m[0906 16-07-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18373, current rewards: 25.37293, mean: 0.04975
[32m[0906 16-07-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18385, current rewards: 28.72777, mean: 0.05130
[32m[0906 16-07-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18399, current rewards: 34.38569, mean: 0.05637
[32m[0906 16-07-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18412, current rewards: 40.04756, mean: 0.06068
[32m[0906 16-08-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18426, current rewards: 45.70999, mean: 0.06438
[32m[0906 16-08-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18437, current rewards: 40.56873, mean: 0.05338
[32m[0906 16-08-24 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18450, current rewards: 48.06314, mean: 0.05934
[32m[0906 16-08-33 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18456, current rewards: 55.55698, mean: 0.06460
[32m[0906 16-08-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18457, current rewards: 68.77007, mean: 0.07557
[32m[0906 16-08-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18457, current rewards: 76.26582, mean: 0.07944
[32m[0906 16-09-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18461, current rewards: 83.69476, mean: 0.08287
[32m[0906 16-09-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18464, current rewards: 91.13011, mean: 0.08597
[32m[0906 16-09-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18466, current rewards: 98.56200, mean: 0.08879
[32m[0906 16-09-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18468, current rewards: 83.95249, mean: 0.07237
[32m[0906 16-09-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18471, current rewards: 89.36923, mean: 0.07386
[32m[0906 16-09-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18473, current rewards: 94.78903, mean: 0.07523
[32m[0906 16-09-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18477, current rewards: 99.56320, mean: 0.07600
[32m[0906 16-10-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18477, current rewards: 104.16197, mean: 0.07659
[32m[0906 16-10-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18474, current rewards: 109.40539, mean: 0.07759
[32m[0906 16-10-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18478, current rewards: 114.64768, mean: 0.07853
[32m[0906 16-10-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18482, current rewards: 119.88634, mean: 0.07939
[32m[0906 16-10-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18483, current rewards: 125.12737, mean: 0.08021
[32m[0906 16-10-52 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18485, current rewards: 130.36784, mean: 0.08097
[32m[0906 16-11-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18484, current rewards: 135.60531, mean: 0.08169
[32m[0906 16-11-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18487, current rewards: 140.84633, mean: 0.08237
[32m[0906 16-11-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18483, current rewards: 148.61182, mean: 0.08444
[32m[0906 16-11-29 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18470, current rewards: 143.19443, mean: 0.07911
[32m[0906 16-11-38 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18459, current rewards: 149.30155, mean: 0.08027
[32m[0906 16-11-47 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18447, current rewards: 155.40627, mean: 0.08136
[32m[0906 16-11-56 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18424, current rewards: 161.51113, mean: 0.08240
[32m[0906 16-12-05 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18411, current rewards: 167.61542, mean: 0.08339
[32m[0906 16-12-14 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18402, current rewards: 149.90774, mean: 0.07277
[32m[0906 16-12-23 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18395, current rewards: 155.02835, mean: 0.07347
[32m[0906 16-12-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18395, current rewards: 159.75141, mean: 0.07396
[32m[0906 16-12-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18400, current rewards: 166.17890, mean: 0.07519
[32m[0906 16-12-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18404, current rewards: 172.63815, mean: 0.07639
[32m[0906 16-13-00 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18408, current rewards: 179.09961, mean: 0.07753
[32m[0906 16-13-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18407, current rewards: 185.55695, mean: 0.07863
[32m[0906 16-13-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18399, current rewards: 192.02798, mean: 0.07968
[32m[0906 16-13-27 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18393, current rewards: 198.49735, mean: 0.08069
[32m[0906 16-13-34 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0906 16-13-34 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-13-34 @MBExp.py:227][0m Rewards obtained: [203.65868635902493], Lows: [31], Highs: [30], Total time: 8779.930064999999
[32m[0906 16-14-16 @MBExp.py:144][0m ####################################################################
[32m[0906 16-14-16 @MBExp.py:145][0m Starting training iteration 20.
[32m[0906 16-14-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18030, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-14-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18019, current rewards: -5.40392, mean: -0.09007
[32m[0906 16-14-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18069, current rewards: 9.92270, mean: 0.09021
[32m[0906 16-14-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18091, current rewards: 18.38065, mean: 0.11488
[32m[0906 16-14-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18089, current rewards: 26.86293, mean: 0.12792
[32m[0906 16-15-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18150, current rewards: 35.34837, mean: 0.13596
[32m[0906 16-15-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18210, current rewards: 22.20721, mean: 0.07164
[32m[0906 16-15-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18262, current rewards: 29.73824, mean: 0.08261
[32m[0906 16-15-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18298, current rewards: 37.26809, mean: 0.09090
[32m[0906 16-15-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18323, current rewards: 44.79666, mean: 0.09738
[32m[0906 16-15-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18350, current rewards: 55.16677, mean: 0.10817
[32m[0906 16-15-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18360, current rewards: 63.08743, mean: 0.11266
[32m[0906 16-16-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18376, current rewards: 59.35311, mean: 0.09730
[32m[0906 16-16-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18390, current rewards: 65.44586, mean: 0.09916
[32m[0906 16-16-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18396, current rewards: 72.62629, mean: 0.10229
[32m[0906 16-16-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18404, current rewards: 79.82193, mean: 0.10503
[32m[0906 16-16-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18417, current rewards: 87.00629, mean: 0.10742
[32m[0906 16-16-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18424, current rewards: 72.24238, mean: 0.08400
[32m[0906 16-17-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18428, current rewards: 78.70835, mean: 0.08649
[32m[0906 16-17-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18433, current rewards: 85.22879, mean: 0.08878
[32m[0906 16-17-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18436, current rewards: 91.82464, mean: 0.09092
[32m[0906 16-17-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18438, current rewards: 98.42844, mean: 0.09286
[32m[0906 16-17-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18439, current rewards: 105.02655, mean: 0.09462
[32m[0906 16-17-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18441, current rewards: 111.62517, mean: 0.09623
[32m[0906 16-18-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18445, current rewards: 107.25573, mean: 0.08864
[32m[0906 16-18-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18446, current rewards: 113.49475, mean: 0.09008
[32m[0906 16-18-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18450, current rewards: 119.65911, mean: 0.09134
[32m[0906 16-18-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18450, current rewards: 125.71082, mean: 0.09243
[32m[0906 16-18-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18449, current rewards: 131.87206, mean: 0.09353
[32m[0906 16-18-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18455, current rewards: 138.03051, mean: 0.09454
[32m[0906 16-18-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18457, current rewards: 144.19431, mean: 0.09549
[32m[0906 16-19-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18459, current rewards: 150.34844, mean: 0.09638
[32m[0906 16-19-14 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18462, current rewards: 156.50715, mean: 0.09721
[32m[0906 16-19-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18462, current rewards: 162.67183, mean: 0.09800
[32m[0906 16-19-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18462, current rewards: 147.59313, mean: 0.08631
[32m[0906 16-19-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18457, current rewards: 154.39746, mean: 0.08773
[32m[0906 16-19-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18444, current rewards: 161.04768, mean: 0.08898
[32m[0906 16-19-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18433, current rewards: 167.70074, mean: 0.09016
[32m[0906 16-20-08 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18420, current rewards: 174.35060, mean: 0.09128
[32m[0906 16-20-17 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18397, current rewards: 181.00311, mean: 0.09235
[32m[0906 16-20-26 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18383, current rewards: 187.65365, mean: 0.09336
[32m[0906 16-20-35 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18374, current rewards: 194.30755, mean: 0.09432
[32m[0906 16-20-44 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18367, current rewards: 200.96516, mean: 0.09524
[32m[0906 16-20-53 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18370, current rewards: 207.61449, mean: 0.09612
[32m[0906 16-21-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18377, current rewards: 214.26966, mean: 0.09695
[32m[0906 16-21-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18382, current rewards: 219.91149, mean: 0.09731
[32m[0906 16-21-21 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18385, current rewards: 226.58004, mean: 0.09809
[32m[0906 16-21-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18382, current rewards: 233.23991, mean: 0.09883
[32m[0906 16-21-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18375, current rewards: 239.90228, mean: 0.09954
[32m[0906 16-21-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18369, current rewards: 246.56660, mean: 0.10023
[32m[0906 16-21-56 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 16-21-56 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-21-56 @MBExp.py:227][0m Rewards obtained: [251.89959444525542], Lows: [31], Highs: [32], Total time: 9239.710647999998
[32m[0906 16-22-39 @MBExp.py:144][0m ####################################################################
[32m[0906 16-22-39 @MBExp.py:145][0m Starting training iteration 21.
[32m[0906 16-22-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18041, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-22-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18052, current rewards: -5.56400, mean: -0.09273
[32m[0906 16-22-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18083, current rewards: -0.35131, mean: -0.00319
[32m[0906 16-23-08 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18111, current rewards: 4.85763, mean: 0.03036
[32m[0906 16-23-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18102, current rewards: 10.06996, mean: 0.04795
[32m[0906 16-23-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18169, current rewards: 15.27544, mean: 0.05875
[32m[0906 16-23-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18231, current rewards: 20.48719, mean: 0.06609
[32m[0906 16-23-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18266, current rewards: 25.69683, mean: 0.07138
[32m[0906 16-23-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18312, current rewards: 30.90625, mean: 0.07538
[32m[0906 16-24-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18342, current rewards: 14.74782, mean: 0.03206
[32m[0906 16-24-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18358, current rewards: 19.66387, mean: 0.03856
[32m[0906 16-24-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18382, current rewards: 24.57687, mean: 0.04389
[32m[0906 16-24-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18394, current rewards: 29.49190, mean: 0.04835
[32m[0906 16-24-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18409, current rewards: 34.40235, mean: 0.05212
[32m[0906 16-24-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18413, current rewards: 39.31798, mean: 0.05538
[32m[0906 16-25-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18428, current rewards: 44.23450, mean: 0.05820
[32m[0906 16-25-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18442, current rewards: 49.14346, mean: 0.06067
[32m[0906 16-25-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18445, current rewards: 54.19205, mean: 0.06301
[32m[0906 16-25-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18450, current rewards: 59.13393, mean: 0.06498
[32m[0906 16-25-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18452, current rewards: 64.08073, mean: 0.06675
[32m[0906 16-25-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18456, current rewards: 69.02406, mean: 0.06834
[32m[0906 16-25-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18456, current rewards: 73.96635, mean: 0.06978
[32m[0906 16-26-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18457, current rewards: 78.91184, mean: 0.07109
[32m[0906 16-26-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18458, current rewards: 83.85481, mean: 0.07229
[32m[0906 16-26-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18458, current rewards: 88.79918, mean: 0.07339
[32m[0906 16-26-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18459, current rewards: 95.00000, mean: 0.07540
[32m[0906 16-26-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18457, current rewards: 100.51059, mean: 0.07673
[32m[0906 16-26-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18458, current rewards: 91.43119, mean: 0.06723
[32m[0906 16-27-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18461, current rewards: 94.75570, mean: 0.06720
[32m[0906 16-27-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18462, current rewards: 98.06874, mean: 0.06717
[32m[0906 16-27-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18467, current rewards: 101.37613, mean: 0.06714
[32m[0906 16-27-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18466, current rewards: 104.68474, mean: 0.06711
[32m[0906 16-27-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18465, current rewards: 108.32916, mean: 0.06729
[32m[0906 16-27-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18466, current rewards: 114.29466, mean: 0.06885
[32m[0906 16-27-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18468, current rewards: 119.91231, mean: 0.07012
[32m[0906 16-28-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18464, current rewards: 125.53076, mean: 0.07132
[32m[0906 16-28-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18454, current rewards: 131.14329, mean: 0.07245
[32m[0906 16-28-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18445, current rewards: 136.75760, mean: 0.07353
[32m[0906 16-28-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18424, current rewards: 142.36883, mean: 0.07454
[32m[0906 16-28-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18401, current rewards: 147.97979, mean: 0.07550
[32m[0906 16-28-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18384, current rewards: 153.59248, mean: 0.07641
[32m[0906 16-28-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18377, current rewards: 136.99969, mean: 0.06650
[32m[0906 16-29-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18370, current rewards: 140.82364, mean: 0.06674
[32m[0906 16-29-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18372, current rewards: 144.80186, mean: 0.06704
[32m[0906 16-29-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18379, current rewards: 148.77970, mean: 0.06732
[32m[0906 16-29-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18385, current rewards: 152.75731, mean: 0.06759
[32m[0906 16-29-45 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18388, current rewards: 156.73375, mean: 0.06785
[32m[0906 16-29-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18386, current rewards: 160.71141, mean: 0.06810
[32m[0906 16-30-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18380, current rewards: 164.68846, mean: 0.06834
[32m[0906 16-30-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18374, current rewards: 148.31908, mean: 0.06029
[32m[0906 16-30-19 @Agent.py:117][0m Average action selection time: 0.1837
[32m[0906 16-30-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-30-19 @MBExp.py:227][0m Rewards obtained: [155.3277428365126], Lows: [31], Highs: [21], Total time: 9699.622403999998
[32m[0906 16-31-05 @MBExp.py:144][0m ####################################################################
[32m[0906 16-31-05 @MBExp.py:145][0m Starting training iteration 22.
[32m[0906 16-31-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18060, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-31-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18047, current rewards: -3.71205, mean: -0.06187
[32m[0906 16-31-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18112, current rewards: 1.85416, mean: 0.01686
[32m[0906 16-31-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18117, current rewards: 7.41894, mean: 0.04637
[32m[0906 16-31-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18095, current rewards: 12.98939, mean: 0.06185
[32m[0906 16-31-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18181, current rewards: 18.55668, mean: 0.07137
[32m[0906 16-32-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18234, current rewards: 24.12422, mean: 0.07782
[32m[0906 16-32-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18259, current rewards: 29.69254, mean: 0.08248
[32m[0906 16-32-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18284, current rewards: 35.80403, mean: 0.08733
[32m[0906 16-32-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18308, current rewards: 41.34882, mean: 0.08989
[32m[0906 16-32-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18332, current rewards: 25.79553, mean: 0.05058
[32m[0906 16-32-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18351, current rewards: 31.49327, mean: 0.05624
[32m[0906 16-32-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18366, current rewards: 37.05642, mean: 0.06075
[32m[0906 16-33-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18380, current rewards: 42.61957, mean: 0.06458
[32m[0906 16-33-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18387, current rewards: 48.18272, mean: 0.06786
[32m[0906 16-33-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18394, current rewards: 53.74586, mean: 0.07072
[32m[0906 16-33-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18409, current rewards: 58.99197, mean: 0.07283
[32m[0906 16-33-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18413, current rewards: 14.28125, mean: 0.01661
[32m[0906 16-33-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18420, current rewards: -35.71875, mean: -0.03925
[32m[0906 16-34-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18423, current rewards: -85.71875, mean: -0.08929
[32m[0906 16-34-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18425, current rewards: -135.71875, mean: -0.13437
[32m[0906 16-34-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18425, current rewards: -185.71875, mean: -0.17521
[32m[0906 16-34-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18428, current rewards: -235.71875, mean: -0.21236
[32m[0906 16-34-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18431, current rewards: -285.71875, mean: -0.24631
[32m[0906 16-34-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18433, current rewards: -335.71875, mean: -0.27745
[32m[0906 16-34-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18432, current rewards: -385.71875, mean: -0.30613
[32m[0906 16-35-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18435, current rewards: -435.71875, mean: -0.33261
[32m[0906 16-35-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18438, current rewards: -485.71875, mean: -0.35715
[32m[0906 16-35-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18440, current rewards: -535.71875, mean: -0.37994
[32m[0906 16-35-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18447, current rewards: -585.71875, mean: -0.40118
[32m[0906 16-35-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18451, current rewards: -635.71875, mean: -0.42101
[32m[0906 16-35-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18454, current rewards: -685.71875, mean: -0.43956
[32m[0906 16-36-03 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18454, current rewards: -735.71875, mean: -0.45697
[32m[0906 16-36-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18454, current rewards: -785.71875, mean: -0.47332
[32m[0906 16-36-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18455, current rewards: -835.71875, mean: -0.48872
[32m[0906 16-36-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18449, current rewards: -885.71875, mean: -0.50325
[32m[0906 16-36-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18439, current rewards: -935.71875, mean: -0.51697
[32m[0906 16-36-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18429, current rewards: -985.71875, mean: -0.52996
[32m[0906 16-36-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18406, current rewards: -1035.71875, mean: -0.54226
[32m[0906 16-37-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18384, current rewards: -1085.71875, mean: -0.55394
[32m[0906 16-37-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18364, current rewards: -1135.71875, mean: -0.56503
[32m[0906 16-37-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18358, current rewards: -1185.71875, mean: -0.57559
[32m[0906 16-37-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18352, current rewards: -1235.71875, mean: -0.58565
[32m[0906 16-37-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18357, current rewards: -1285.71875, mean: -0.59524
[32m[0906 16-37-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18364, current rewards: -1335.71875, mean: -0.60440
[32m[0906 16-38-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18369, current rewards: -1385.71875, mean: -0.61315
[32m[0906 16-38-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18376, current rewards: -1435.71875, mean: -0.62152
[32m[0906 16-38-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18375, current rewards: -1485.71875, mean: -0.62954
[32m[0906 16-38-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18369, current rewards: -1535.71875, mean: -0.63723
[32m[0906 16-38-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18363, current rewards: -1585.71875, mean: -0.64460
[32m[0906 16-38-45 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 16-38-45 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-38-45 @MBExp.py:227][0m Rewards obtained: [-1625.7187481323401], Lows: [10], Highs: [1695], Total time: 10159.253603999998
[32m[0906 16-39-32 @MBExp.py:144][0m ####################################################################
[32m[0906 16-39-32 @MBExp.py:145][0m Starting training iteration 23.
[32m[0906 16-39-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18035, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-39-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18106, current rewards: -3.22912, mean: -0.05382
[32m[0906 16-39-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18139, current rewards: 2.52123, mean: 0.02292
[32m[0906 16-40-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18122, current rewards: 8.27581, mean: 0.05172
[32m[0906 16-40-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18126, current rewards: -7.06549, mean: -0.03365
[32m[0906 16-40-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18225, current rewards: -0.72921, mean: -0.00280
[32m[0906 16-40-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18283, current rewards: 5.59044, mean: 0.01803
[32m[0906 16-40-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18317, current rewards: 11.90626, mean: 0.03307
[32m[0906 16-40-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18352, current rewards: 17.60540, mean: 0.04294
[32m[0906 16-40-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18365, current rewards: 23.44575, mean: 0.05097
[32m[0906 16-41-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18382, current rewards: 29.26005, mean: 0.05737
[32m[0906 16-41-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18390, current rewards: 35.07302, mean: 0.06263
[32m[0906 16-41-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18405, current rewards: 40.89330, mean: 0.06704
[32m[0906 16-41-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18419, current rewards: 46.71177, mean: 0.07078
[32m[0906 16-41-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18436, current rewards: 32.88143, mean: 0.04631
[32m[0906 16-41-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18447, current rewards: 40.21332, mean: 0.05291
[32m[0906 16-42-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18454, current rewards: 47.55065, mean: 0.05870
[32m[0906 16-42-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18455, current rewards: 54.88795, mean: 0.06382
[32m[0906 16-42-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18455, current rewards: 62.22784, mean: 0.06838
[32m[0906 16-42-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18455, current rewards: 69.56146, mean: 0.07246
[32m[0906 16-42-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18460, current rewards: 76.89810, mean: 0.07614
[32m[0906 16-42-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18460, current rewards: 84.23527, mean: 0.07947
[32m[0906 16-42-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18463, current rewards: 91.56897, mean: 0.08249
[32m[0906 16-43-07 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18463, current rewards: 85.79436, mean: 0.07396
[32m[0906 16-43-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18465, current rewards: 91.39657, mean: 0.07553
[32m[0906 16-43-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18468, current rewards: 97.65829, mean: 0.07751
[32m[0906 16-43-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18468, current rewards: 103.33646, mean: 0.07888
[32m[0906 16-43-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18470, current rewards: 109.01366, mean: 0.08016
[32m[0906 16-43-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18473, current rewards: 114.69138, mean: 0.08134
[32m[0906 16-44-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18476, current rewards: 120.36986, mean: 0.08245
[32m[0906 16-44-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18476, current rewards: 104.93323, mean: 0.06949
[32m[0906 16-44-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18479, current rewards: 110.30621, mean: 0.07071
[32m[0906 16-44-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18479, current rewards: 115.67454, mean: 0.07185
[32m[0906 16-44-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18479, current rewards: 117.71589, mean: 0.07091
[32m[0906 16-44-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18479, current rewards: 114.96227, mean: 0.06723
[32m[0906 16-44-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18471, current rewards: 120.17246, mean: 0.06828
[32m[0906 16-45-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18460, current rewards: 125.38953, mean: 0.06928
[32m[0906 16-45-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18446, current rewards: 130.59906, mean: 0.07021
[32m[0906 16-45-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18422, current rewards: 135.80662, mean: 0.07110
[32m[0906 16-45-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18399, current rewards: 141.01697, mean: 0.07195
[32m[0906 16-45-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18377, current rewards: 146.22533, mean: 0.07275
[32m[0906 16-45-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18370, current rewards: 151.28123, mean: 0.07344
[32m[0906 16-46-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18363, current rewards: 156.43562, mean: 0.07414
[32m[0906 16-46-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18368, current rewards: 161.59286, mean: 0.07481
[32m[0906 16-46-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18372, current rewards: 145.75495, mean: 0.06595
[32m[0906 16-46-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18374, current rewards: 151.02179, mean: 0.06682
[32m[0906 16-46-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18376, current rewards: 156.28603, mean: 0.06766
[32m[0906 16-46-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18376, current rewards: 161.55121, mean: 0.06845
[32m[0906 16-46-56 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18370, current rewards: 166.81662, mean: 0.06922
[32m[0906 16-47-05 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18364, current rewards: 171.66605, mean: 0.06978
[32m[0906 16-47-12 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 16-47-12 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-47-12 @MBExp.py:227][0m Rewards obtained: [175.7436746445503], Lows: [41], Highs: [30], Total time: 10618.911965999998
[32m[0906 16-48-01 @MBExp.py:144][0m ####################################################################
[32m[0906 16-48-01 @MBExp.py:145][0m Starting training iteration 24.
[32m[0906 16-48-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18192, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-48-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18202, current rewards: 0.43714, mean: 0.00729
[32m[0906 16-48-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18156, current rewards: 9.77058, mean: 0.08882
[32m[0906 16-48-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18120, current rewards: 19.10402, mean: 0.11940
[32m[0906 16-48-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18109, current rewards: 28.43746, mean: 0.13542
[32m[0906 16-48-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18206, current rewards: 37.77091, mean: 0.14527
[32m[0906 16-48-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18279, current rewards: 47.10435, mean: 0.15195
[32m[0906 16-49-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18310, current rewards: 56.43779, mean: 0.15677
[32m[0906 16-49-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18337, current rewards: 49.64605, mean: 0.12109
[32m[0906 16-49-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18360, current rewards: -0.35395, mean: -0.00077
[32m[0906 16-49-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18380, current rewards: -50.35395, mean: -0.09873
[32m[0906 16-49-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18398, current rewards: -100.35395, mean: -0.17920
[32m[0906 16-49-54 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18403, current rewards: -150.35395, mean: -0.24648
[32m[0906 16-50-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18414, current rewards: -200.35395, mean: -0.30357
[32m[0906 16-50-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18421, current rewards: -250.35395, mean: -0.35261
[32m[0906 16-50-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18434, current rewards: -300.35395, mean: -0.39520
[32m[0906 16-50-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18439, current rewards: -350.35395, mean: -0.43254
[32m[0906 16-50-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18445, current rewards: -400.35395, mean: -0.46553
[32m[0906 16-50-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18446, current rewards: -450.35395, mean: -0.49489
[32m[0906 16-50-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18451, current rewards: -500.35395, mean: -0.52120
[32m[0906 16-51-08 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18455, current rewards: -550.35395, mean: -0.54490
[32m[0906 16-51-17 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18457, current rewards: -600.35395, mean: -0.56637
[32m[0906 16-51-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18459, current rewards: -650.35395, mean: -0.58590
[32m[0906 16-51-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18460, current rewards: -700.35395, mean: -0.60375
[32m[0906 16-51-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18459, current rewards: -750.35395, mean: -0.62013
[32m[0906 16-51-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18461, current rewards: -800.35395, mean: -0.63520
[32m[0906 16-52-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18462, current rewards: -850.35395, mean: -0.64913
[32m[0906 16-52-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18462, current rewards: -900.35395, mean: -0.66202
[32m[0906 16-52-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18463, current rewards: -950.35395, mean: -0.67401
[32m[0906 16-52-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18462, current rewards: -1000.35395, mean: -0.68517
[32m[0906 16-52-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18460, current rewards: -1050.35395, mean: -0.69560
[32m[0906 16-52-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18460, current rewards: -1100.35395, mean: -0.70536
[32m[0906 16-52-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18461, current rewards: -1150.35395, mean: -0.71451
[32m[0906 16-53-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18460, current rewards: -1200.35395, mean: -0.72310
[32m[0906 16-53-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18460, current rewards: -1250.35395, mean: -0.73120
[32m[0906 16-53-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18452, current rewards: -1300.35395, mean: -0.73884
[32m[0906 16-53-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18440, current rewards: -1350.35395, mean: -0.74605
[32m[0906 16-53-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18423, current rewards: -1400.35395, mean: -0.75288
[32m[0906 16-53-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18399, current rewards: -1450.35395, mean: -0.75935
[32m[0906 16-54-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18377, current rewards: -1500.35395, mean: -0.76549
[32m[0906 16-54-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18355, current rewards: -1550.35395, mean: -0.77132
[32m[0906 16-54-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18346, current rewards: -1600.35395, mean: -0.77687
[32m[0906 16-54-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18342, current rewards: -1650.35395, mean: -0.78216
[32m[0906 16-54-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18346, current rewards: -1700.35395, mean: -0.78720
[32m[0906 16-54-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18350, current rewards: -1750.35395, mean: -0.79202
[32m[0906 16-54-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18356, current rewards: -1800.35395, mean: -0.79662
[32m[0906 16-55-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18361, current rewards: -1850.35395, mean: -0.80102
[32m[0906 16-55-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18361, current rewards: -1900.35395, mean: -0.80523
[32m[0906 16-55-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18355, current rewards: -1950.35395, mean: -0.80928
[32m[0906 16-55-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18350, current rewards: -2000.35395, mean: -0.81315
[32m[0906 16-55-41 @Agent.py:117][0m Average action selection time: 0.1835
[32m[0906 16-55-41 @Agent.py:118][0m Rollout length: 2510
[32m[0906 16-55-41 @MBExp.py:227][0m Rewards obtained: [-2040.3539535905275], Lows: [0], Highs: [2112], Total time: 11078.215931999997
[32m[0906 16-56-32 @MBExp.py:144][0m ####################################################################
[32m[0906 16-56-32 @MBExp.py:145][0m Starting training iteration 25.
[32m[0906 16-56-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18160, current rewards: -10.00000, mean: -1.00000
[32m[0906 16-56-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18146, current rewards: -35.26406, mean: -0.58773
[32m[0906 16-56-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18125, current rewards: -34.09677, mean: -0.30997
[32m[0906 16-57-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18114, current rewards: -30.53131, mean: -0.19082
[32m[0906 16-57-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18128, current rewards: -29.30705, mean: -0.13956
[32m[0906 16-57-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18229, current rewards: -52.89034, mean: -0.20342
[32m[0906 16-57-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18267, current rewards: -109.04117, mean: -0.35175
[32m[0906 16-57-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18304, current rewards: -165.90510, mean: -0.46085
[32m[0906 16-57-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18330, current rewards: -154.11269, mean: -0.37588
[32m[0906 16-57-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18348, current rewards: -146.03923, mean: -0.31748
[32m[0906 16-58-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18363, current rewards: -135.59649, mean: -0.26588
[32m[0906 16-58-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18373, current rewards: -127.43403, mean: -0.22756
[32m[0906 16-58-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18378, current rewards: -116.97033, mean: -0.19175
[32m[0906 16-58-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18384, current rewards: -108.78528, mean: -0.16483
[32m[0906 16-58-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18395, current rewards: -98.29041, mean: -0.13844
[32m[0906 16-58-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18402, current rewards: -90.09940, mean: -0.11855
[32m[0906 16-59-01 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18405, current rewards: -93.73361, mean: -0.11572
[32m[0906 16-59-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18405, current rewards: -120.97400, mean: -0.14067
[32m[0906 16-59-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18403, current rewards: -145.80761, mean: -0.16023
[32m[0906 16-59-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18405, current rewards: -178.88986, mean: -0.18634
[32m[0906 16-59-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18408, current rewards: -232.46820, mean: -0.23017
[32m[0906 16-59-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18412, current rewards: -282.11911, mean: -0.26615
[32m[0906 16-59-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18416, current rewards: -335.94063, mean: -0.30265
[32m[0906 17-00-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18420, current rewards: -387.68956, mean: -0.33422
[32m[0906 17-00-15 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18423, current rewards: -438.96885, mean: -0.36278
[32m[0906 17-00-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18425, current rewards: -490.70696, mean: -0.38945
[32m[0906 17-00-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18426, current rewards: -542.34482, mean: -0.41400
[32m[0906 17-00-43 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18430, current rewards: -596.12759, mean: -0.43833
[32m[0906 17-00-52 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18433, current rewards: -647.72861, mean: -0.45938
[32m[0906 17-01-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18436, current rewards: -709.42973, mean: -0.48591
[32m[0906 17-01-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18435, current rewards: -746.41237, mean: -0.49431
[32m[0906 17-01-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18436, current rewards: -785.41194, mean: -0.50347
[32m[0906 17-01-29 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18440, current rewards: -824.35838, mean: -0.51202
[32m[0906 17-01-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18439, current rewards: -833.88435, mean: -0.50234
[32m[0906 17-01-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18437, current rewards: -861.64611, mean: -0.50389
[32m[0906 17-01-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18430, current rewards: -881.73194, mean: -0.50098
[32m[0906 17-02-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18421, current rewards: -908.75946, mean: -0.50208
[32m[0906 17-02-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18398, current rewards: -938.02979, mean: -0.50432
[32m[0906 17-02-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18375, current rewards: -968.48781, mean: -0.50706
[32m[0906 17-02-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18351, current rewards: -988.58955, mean: -0.50438
[32m[0906 17-02-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18330, current rewards: -1010.82780, mean: -0.50290
[32m[0906 17-02-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18318, current rewards: -1041.61573, mean: -0.50564
[32m[0906 17-02-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18313, current rewards: -1120.49194, mean: -0.53104
[32m[0906 17-03-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18317, current rewards: -1220.49194, mean: -0.56504
[32m[0906 17-03-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18324, current rewards: -1320.49194, mean: -0.59751
[32m[0906 17-03-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18330, current rewards: -1420.49194, mean: -0.62854
[32m[0906 17-03-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18335, current rewards: -1520.49194, mean: -0.65822
[32m[0906 17-03-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18335, current rewards: -1620.49194, mean: -0.68665
[32m[0906 17-03-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18331, current rewards: -1720.49194, mean: -0.71390
[32m[0906 17-04-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18325, current rewards: -1820.49194, mean: -0.74004
[32m[0906 17-04-11 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 17-04-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-04-11 @MBExp.py:227][0m Rewards obtained: [-1819.9368698487979], Lows: [1110], Highs: [36], Total time: 11536.939590999997
[32m[0906 17-05-04 @MBExp.py:144][0m ####################################################################
[32m[0906 17-05-04 @MBExp.py:145][0m Starting training iteration 26.
[32m[0906 17-05-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18154, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-05-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18196, current rewards: -6.32925, mean: -0.10549
[32m[0906 17-05-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18140, current rewards: -1.42499, mean: -0.01295
[32m[0906 17-05-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18131, current rewards: 3.47830, mean: 0.02174
[32m[0906 17-05-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18126, current rewards: 8.38542, mean: 0.03993
[32m[0906 17-05-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18233, current rewards: 13.28898, mean: 0.05111
[32m[0906 17-06-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18289, current rewards: -2.27305, mean: -0.00733
[32m[0906 17-06-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18334, current rewards: 2.60033, mean: 0.00722
[32m[0906 17-06-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18355, current rewards: 7.37592, mean: 0.01799
[32m[0906 17-06-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18377, current rewards: 12.15144, mean: 0.02642
[32m[0906 17-06-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18403, current rewards: 16.92686, mean: 0.03319
[32m[0906 17-06-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18415, current rewards: 21.70252, mean: 0.03875
[32m[0906 17-06-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18423, current rewards: 26.47811, mean: 0.04341
[32m[0906 17-07-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18438, current rewards: 31.25381, mean: 0.04735
[32m[0906 17-07-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18441, current rewards: 36.02927, mean: 0.05075
[32m[0906 17-07-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18447, current rewards: 40.48108, mean: 0.05326
[32m[0906 17-07-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18451, current rewards: 33.00626, mean: 0.04075
[32m[0906 17-07-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18454, current rewards: 36.91580, mean: 0.04293
[32m[0906 17-07-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18454, current rewards: 40.82807, mean: 0.04487
[32m[0906 17-08-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18460, current rewards: 44.74029, mean: 0.04660
[32m[0906 17-08-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18463, current rewards: 48.65271, mean: 0.04817
[32m[0906 17-08-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18464, current rewards: 52.56429, mean: 0.04959
[32m[0906 17-08-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18465, current rewards: 56.46619, mean: 0.05087
[32m[0906 17-08-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18471, current rewards: 60.19402, mean: 0.05189
[32m[0906 17-08-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18473, current rewards: 63.96057, mean: 0.05286
[32m[0906 17-08-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18477, current rewards: 67.74225, mean: 0.05376
[32m[0906 17-09-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18482, current rewards: 71.52987, mean: 0.05460
[32m[0906 17-09-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18484, current rewards: 77.55482, mean: 0.05703
[32m[0906 17-09-25 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18483, current rewards: 82.69301, mean: 0.05865
[32m[0906 17-09-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18483, current rewards: 87.82415, mean: 0.06015
[32m[0906 17-09-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18486, current rewards: 92.96847, mean: 0.06157
[32m[0906 17-09-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18489, current rewards: 97.89233, mean: 0.06275
[32m[0906 17-10-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18491, current rewards: 81.90344, mean: 0.05087
[32m[0906 17-10-12 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18490, current rewards: 86.31165, mean: 0.05199
[32m[0906 17-10-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18492, current rewards: 90.67798, mean: 0.05303
[32m[0906 17-10-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18483, current rewards: 95.04305, mean: 0.05400
[32m[0906 17-10-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18470, current rewards: 99.41011, mean: 0.05492
[32m[0906 17-10-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18444, current rewards: 103.77462, mean: 0.05579
[32m[0906 17-10-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18419, current rewards: 108.14196, mean: 0.05662
[32m[0906 17-11-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18396, current rewards: 112.59186, mean: 0.05744
[32m[0906 17-11-14 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18376, current rewards: 119.44752, mean: 0.05943
[32m[0906 17-11-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18363, current rewards: 123.16220, mean: 0.05979
[32m[0906 17-11-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18356, current rewards: 118.05185, mean: 0.05595
[32m[0906 17-11-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18360, current rewards: 122.68231, mean: 0.05680
[32m[0906 17-11-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18366, current rewards: 127.31462, mean: 0.05761
[32m[0906 17-12-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18369, current rewards: 131.94476, mean: 0.05838
[32m[0906 17-12-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18373, current rewards: 136.57873, mean: 0.05912
[32m[0906 17-12-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18373, current rewards: 141.20766, mean: 0.05983
[32m[0906 17-12-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18367, current rewards: 145.13653, mean: 0.06022
[32m[0906 17-12-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18361, current rewards: 130.34299, mean: 0.05298
[32m[0906 17-12-44 @Agent.py:117][0m Average action selection time: 0.1836
[32m[0906 17-12-44 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-12-44 @MBExp.py:227][0m Rewards obtained: [131.8365463807778], Lows: [30], Highs: [32], Total time: 11996.566437999996
[32m[0906 17-13-40 @MBExp.py:144][0m ####################################################################
[32m[0906 17-13-40 @MBExp.py:145][0m Starting training iteration 27.
[32m[0906 17-13-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18047, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-13-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18107, current rewards: -4.64459, mean: -0.07741
[32m[0906 17-13-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18099, current rewards: 1.56639, mean: 0.01424
[32m[0906 17-14-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18100, current rewards: 7.77525, mean: 0.04860
[32m[0906 17-14-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18135, current rewards: 13.98711, mean: 0.06661
[32m[0906 17-14-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18239, current rewards: 20.20427, mean: 0.07771
[32m[0906 17-14-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18260, current rewards: 26.41859, mean: 0.08522
[32m[0906 17-14-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18291, current rewards: 7.76214, mean: 0.02156
[32m[0906 17-14-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18321, current rewards: 16.63008, mean: 0.04056
[32m[0906 17-15-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18340, current rewards: 25.52614, mean: 0.05549
[32m[0906 17-15-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18353, current rewards: 34.42826, mean: 0.06751
[32m[0906 17-15-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18365, current rewards: 20.21073, mean: 0.03609
[32m[0906 17-15-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18383, current rewards: 27.41084, mean: 0.04494
[32m[0906 17-15-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18394, current rewards: 34.60849, mean: 0.05244
[32m[0906 17-15-50 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18406, current rewards: 41.81164, mean: 0.05889
[32m[0906 17-16-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18410, current rewards: 48.91012, mean: 0.06436
[32m[0906 17-16-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18416, current rewards: 56.24149, mean: 0.06943
[32m[0906 17-16-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18420, current rewards: 63.57894, mean: 0.07393
[32m[0906 17-16-27 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18425, current rewards: 70.92670, mean: 0.07794
[32m[0906 17-16-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18429, current rewards: 78.26731, mean: 0.08153
[32m[0906 17-16-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18430, current rewards: 81.02197, mean: 0.08022
[32m[0906 17-16-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18431, current rewards: 77.93044, mean: 0.07352
[32m[0906 17-17-04 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18437, current rewards: 82.52362, mean: 0.07435
[32m[0906 17-17-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18437, current rewards: 86.93449, mean: 0.07494
[32m[0906 17-17-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18438, current rewards: 91.36443, mean: 0.07551
[32m[0906 17-17-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18443, current rewards: 95.83261, mean: 0.07606
[32m[0906 17-17-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18445, current rewards: 100.30349, mean: 0.07657
[32m[0906 17-17-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18450, current rewards: 104.77067, mean: 0.07704
[32m[0906 17-18-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18451, current rewards: 109.24228, mean: 0.07748
[32m[0906 17-18-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18452, current rewards: 111.62289, mean: 0.07645
[32m[0906 17-18-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18451, current rewards: 97.97397, mean: 0.06488
[32m[0906 17-18-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18450, current rewards: 103.40503, mean: 0.06629
[32m[0906 17-18-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18449, current rewards: 109.09005, mean: 0.06776
[32m[0906 17-18-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18449, current rewards: 114.45404, mean: 0.06895
[32m[0906 17-18-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18449, current rewards: 119.81042, mean: 0.07006
[32m[0906 17-19-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18439, current rewards: 125.16920, mean: 0.07112
[32m[0906 17-19-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18422, current rewards: 130.53205, mean: 0.07212
[32m[0906 17-19-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18397, current rewards: 135.89364, mean: 0.07306
[32m[0906 17-19-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18373, current rewards: 141.25217, mean: 0.07395
[32m[0906 17-19-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18354, current rewards: 142.40089, mean: 0.07265
[32m[0906 17-19-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18333, current rewards: 131.76921, mean: 0.06556
[32m[0906 17-19-57 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18318, current rewards: 138.37023, mean: 0.06717
[32m[0906 17-20-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18311, current rewards: 144.96849, mean: 0.06871
[32m[0906 17-20-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18317, current rewards: 151.56849, mean: 0.07017
[32m[0906 17-20-25 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18322, current rewards: 158.16599, mean: 0.07157
[32m[0906 17-20-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18325, current rewards: 153.92350, mean: 0.06811
[32m[0906 17-20-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18328, current rewards: 160.23883, mean: 0.06937
[32m[0906 17-20-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18327, current rewards: 166.55565, mean: 0.07057
[32m[0906 17-21-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18321, current rewards: 172.01830, mean: 0.07138
[32m[0906 17-21-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18316, current rewards: 178.66373, mean: 0.07263
[32m[0906 17-21-18 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0906 17-21-18 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-21-18 @MBExp.py:227][0m Rewards obtained: [183.9809898631576], Lows: [38], Highs: [43], Total time: 12455.074704999995
[32m[0906 17-22-15 @MBExp.py:144][0m ####################################################################
[32m[0906 17-22-15 @MBExp.py:145][0m Starting training iteration 28.
[32m[0906 17-22-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18019, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-22-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18087, current rewards: -5.02206, mean: -0.08370
[32m[0906 17-22-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18073, current rewards: 1.87648, mean: 0.01706
[32m[0906 17-22-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18084, current rewards: 8.77425, mean: 0.05484
[32m[0906 17-22-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18122, current rewards: 15.67139, mean: 0.07463
[32m[0906 17-23-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18200, current rewards: 22.55919, mean: 0.08677
[32m[0906 17-23-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18241, current rewards: 30.77267, mean: 0.09927
[32m[0906 17-23-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18276, current rewards: 37.71438, mean: 0.10476
[32m[0906 17-23-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18312, current rewards: 44.69756, mean: 0.10902
[32m[0906 17-23-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18333, current rewards: 51.68381, mean: 0.11236
[32m[0906 17-23-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18364, current rewards: 58.66089, mean: 0.11502
[32m[0906 17-23-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18390, current rewards: 37.27742, mean: 0.06657
[32m[0906 17-24-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18400, current rewards: 46.95921, mean: 0.07698
[32m[0906 17-24-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18407, current rewards: 56.60873, mean: 0.08577
[32m[0906 17-24-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18411, current rewards: 67.34411, mean: 0.09485
[32m[0906 17-24-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18416, current rewards: 78.87845, mean: 0.10379
[32m[0906 17-24-45 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18426, current rewards: 79.75791, mean: 0.09847
[32m[0906 17-24-54 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18434, current rewards: 80.63904, mean: 0.09377
[32m[0906 17-25-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18438, current rewards: 87.39453, mean: 0.09604
[32m[0906 17-25-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18441, current rewards: 94.13776, mean: 0.09806
[32m[0906 17-25-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18446, current rewards: 100.88130, mean: 0.09988
[32m[0906 17-25-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18450, current rewards: 107.64614, mean: 0.10155
[32m[0906 17-25-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18455, current rewards: 114.39535, mean: 0.10306
[32m[0906 17-25-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18460, current rewards: 119.50357, mean: 0.10302
[32m[0906 17-25-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18467, current rewards: 125.69603, mean: 0.10388
[32m[0906 17-26-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18468, current rewards: 110.24044, mean: 0.08749
[32m[0906 17-26-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18472, current rewards: 115.86485, mean: 0.08845
[32m[0906 17-26-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18474, current rewards: 121.48980, mean: 0.08933
[32m[0906 17-26-36 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18472, current rewards: 127.11040, mean: 0.09015
[32m[0906 17-26-45 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18473, current rewards: 132.74312, mean: 0.09092
[32m[0906 17-26-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18474, current rewards: 138.36489, mean: 0.09163
[32m[0906 17-27-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18477, current rewards: 145.43557, mean: 0.09323
[32m[0906 17-27-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18480, current rewards: 151.79187, mean: 0.09428
[32m[0906 17-27-23 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18480, current rewards: 158.13530, mean: 0.09526
[32m[0906 17-27-32 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18481, current rewards: 164.49191, mean: 0.09619
[32m[0906 17-27-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18470, current rewards: 170.84832, mean: 0.09707
[32m[0906 17-27-50 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18446, current rewards: 177.19992, mean: 0.09790
[32m[0906 17-27-59 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18423, current rewards: 172.74911, mean: 0.09288
[32m[0906 17-28-07 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18402, current rewards: 180.30543, mean: 0.09440
[32m[0906 17-28-16 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18379, current rewards: 187.45179, mean: 0.09564
[32m[0906 17-28-25 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18358, current rewards: 194.98688, mean: 0.09701
[32m[0906 17-28-34 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18339, current rewards: 202.41489, mean: 0.09826
[32m[0906 17-28-43 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18333, current rewards: 209.84029, mean: 0.09945
[32m[0906 17-28-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18340, current rewards: 217.27627, mean: 0.10059
[32m[0906 17-29-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18345, current rewards: 224.71830, mean: 0.10168
[32m[0906 17-29-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18350, current rewards: 232.14654, mean: 0.10272
[32m[0906 17-29-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18355, current rewards: 239.59044, mean: 0.10372
[32m[0906 17-29-29 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18353, current rewards: 246.95163, mean: 0.10464
[32m[0906 17-29-38 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18349, current rewards: 254.35386, mean: 0.10554
[32m[0906 17-29-47 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18344, current rewards: 240.00647, mean: 0.09756
[32m[0906 17-29-55 @Agent.py:117][0m Average action selection time: 0.1834
[32m[0906 17-29-55 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-29-55 @MBExp.py:227][0m Rewards obtained: [242.6674673587623], Lows: [35], Highs: [33], Total time: 12914.237118999996
[32m[0906 17-30-54 @MBExp.py:144][0m ####################################################################
[32m[0906 17-30-54 @MBExp.py:145][0m Starting training iteration 29.
[32m[0906 17-30-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18006, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-31-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18059, current rewards: -4.39159, mean: -0.07319
[32m[0906 17-31-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18074, current rewards: 0.44655, mean: 0.00406
[32m[0906 17-31-23 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18049, current rewards: 5.28275, mean: 0.03302
[32m[0906 17-31-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18101, current rewards: 10.12046, mean: 0.04819
[32m[0906 17-31-41 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18195, current rewards: -4.69971, mean: -0.01808
[32m[0906 17-31-50 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18248, current rewards: 4.79004, mean: 0.01545
[32m[0906 17-32-00 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18289, current rewards: 14.27602, mean: 0.03966
[32m[0906 17-32-09 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18338, current rewards: 23.77016, mean: 0.05798
[32m[0906 17-32-18 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18366, current rewards: 33.25198, mean: 0.07229
[32m[0906 17-32-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18372, current rewards: 29.44504, mean: 0.05774
[32m[0906 17-32-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18381, current rewards: 34.00879, mean: 0.06073
[32m[0906 17-32-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18397, current rewards: 38.56489, mean: 0.06322
[32m[0906 17-32-55 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18404, current rewards: 43.11840, mean: 0.06533
[32m[0906 17-33-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18406, current rewards: 26.22863, mean: 0.03694
[32m[0906 17-33-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18411, current rewards: 30.62650, mean: 0.04030
[32m[0906 17-33-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18415, current rewards: 35.01774, mean: 0.04323
[32m[0906 17-33-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18416, current rewards: 39.41055, mean: 0.04583
[32m[0906 17-33-42 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18422, current rewards: 43.80578, mean: 0.04814
[32m[0906 17-33-51 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18425, current rewards: 48.20000, mean: 0.05021
[32m[0906 17-34-00 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18426, current rewards: 52.59294, mean: 0.05207
[32m[0906 17-34-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18422, current rewards: 56.98463, mean: 0.05376
[32m[0906 17-34-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18430, current rewards: 61.73008, mean: 0.05561
[32m[0906 17-34-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18435, current rewards: 66.34042, mean: 0.05719
[32m[0906 17-34-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18440, current rewards: 70.95434, mean: 0.05864
[32m[0906 17-34-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18440, current rewards: 75.56791, mean: 0.05997
[32m[0906 17-34-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18445, current rewards: 80.18381, mean: 0.06121
[32m[0906 17-35-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18446, current rewards: 84.79884, mean: 0.06235
[32m[0906 17-35-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18449, current rewards: 89.41540, mean: 0.06342
[32m[0906 17-35-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18447, current rewards: 94.03303, mean: 0.06441
[32m[0906 17-35-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18448, current rewards: 98.92574, mean: 0.06551
[32m[0906 17-35-42 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18447, current rewards: 102.74967, mean: 0.06587
[32m[0906 17-35-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18448, current rewards: 96.99895, mean: 0.06025
[32m[0906 17-36-01 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18450, current rewards: 102.30194, mean: 0.06163
[32m[0906 17-36-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18451, current rewards: 107.60474, mean: 0.06293
[32m[0906 17-36-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18443, current rewards: 112.91460, mean: 0.06416
[32m[0906 17-36-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18418, current rewards: 118.22429, mean: 0.06532
[32m[0906 17-36-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18393, current rewards: 102.47164, mean: 0.05509
[32m[0906 17-36-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18369, current rewards: 107.83531, mean: 0.05646
[32m[0906 17-36-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18347, current rewards: 114.99102, mean: 0.05867
[32m[0906 17-37-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18326, current rewards: 120.24321, mean: 0.05982
[32m[0906 17-37-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18306, current rewards: 125.48992, mean: 0.06092
[32m[0906 17-37-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18299, current rewards: 127.17961, mean: 0.06027
[32m[0906 17-37-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18305, current rewards: 132.79365, mean: 0.06148
[32m[0906 17-37-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18311, current rewards: 137.60046, mean: 0.06226
[32m[0906 17-37-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18317, current rewards: 142.41054, mean: 0.06301
[32m[0906 17-37-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18323, current rewards: 147.21873, mean: 0.06373
[32m[0906 17-38-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18323, current rewards: 151.24268, mean: 0.06409
[32m[0906 17-38-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18318, current rewards: 156.29824, mean: 0.06485
[32m[0906 17-38-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18314, current rewards: 161.36501, mean: 0.06560
[32m[0906 17-38-32 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0906 17-38-32 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-38-32 @MBExp.py:227][0m Rewards obtained: [165.41750041645193], Lows: [32], Highs: [31], Total time: 13372.685015999996
[32m[0906 17-39-34 @MBExp.py:144][0m ####################################################################
[32m[0906 17-39-34 @MBExp.py:145][0m Starting training iteration 30.
[32m[0906 17-39-35 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17953, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-39-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18010, current rewards: -4.62720, mean: -0.07712
[32m[0906 17-39-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18053, current rewards: 0.71851, mean: 0.00653
[32m[0906 17-40-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18059, current rewards: 6.05942, mean: 0.03787
[32m[0906 17-40-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18145, current rewards: 11.40670, mean: 0.05432
[32m[0906 17-40-21 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18237, current rewards: 16.75293, mean: 0.06443
[32m[0906 17-40-30 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18297, current rewards: 21.81218, mean: 0.07036
[32m[0906 17-40-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18356, current rewards: 27.01994, mean: 0.07506
[32m[0906 17-40-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18374, current rewards: 32.23689, mean: 0.07863
[32m[0906 17-40-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18384, current rewards: 37.45064, mean: 0.08141
[32m[0906 17-41-08 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18394, current rewards: 42.66633, mean: 0.08366
[32m[0906 17-41-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18402, current rewards: 47.88044, mean: 0.08550
[32m[0906 17-41-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18400, current rewards: 53.48290, mean: 0.08768
[32m[0906 17-41-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18407, current rewards: 59.46604, mean: 0.09010
[32m[0906 17-41-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18414, current rewards: 66.09661, mean: 0.09309
[32m[0906 17-41-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18416, current rewards: 71.73532, mean: 0.09439
[32m[0906 17-42-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18420, current rewards: 77.36979, mean: 0.09552
[32m[0906 17-42-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18421, current rewards: 82.99659, mean: 0.09651
[32m[0906 17-42-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18419, current rewards: 88.62795, mean: 0.09739
[32m[0906 17-42-31 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18419, current rewards: 94.27291, mean: 0.09820
[32m[0906 17-42-40 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18427, current rewards: 99.91093, mean: 0.09892
[32m[0906 17-42-49 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18429, current rewards: 105.55862, mean: 0.09958
[32m[0906 17-42-59 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18433, current rewards: 111.92242, mean: 0.10083
[32m[0906 17-43-08 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18434, current rewards: 98.57387, mean: 0.08498
[32m[0906 17-43-17 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18434, current rewards: 104.75192, mean: 0.08657
[32m[0906 17-43-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18437, current rewards: 110.93142, mean: 0.08804
[32m[0906 17-43-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18439, current rewards: 117.10686, mean: 0.08939
[32m[0906 17-43-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18437, current rewards: 123.28574, mean: 0.09065
[32m[0906 17-43-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18434, current rewards: 129.46620, mean: 0.09182
[32m[0906 17-44-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18433, current rewards: 135.64282, mean: 0.09291
[32m[0906 17-44-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18433, current rewards: 130.58272, mean: 0.08648
[32m[0906 17-44-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18436, current rewards: 136.32442, mean: 0.08739
[32m[0906 17-44-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18438, current rewards: 142.02733, mean: 0.08822
[32m[0906 17-44-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18437, current rewards: 147.72402, mean: 0.08899
[32m[0906 17-44-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18440, current rewards: 153.42114, mean: 0.08972
[32m[0906 17-44-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18424, current rewards: 159.12583, mean: 0.09041
[32m[0906 17-45-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18398, current rewards: 144.60237, mean: 0.07989
[32m[0906 17-45-16 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18375, current rewards: 152.24067, mean: 0.08185
[32m[0906 17-45-25 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18350, current rewards: 159.56326, mean: 0.08354
[32m[0906 17-45-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18326, current rewards: 166.67598, mean: 0.08504
[32m[0906 17-45-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18304, current rewards: 173.68762, mean: 0.08641
[32m[0906 17-45-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18285, current rewards: 180.69967, mean: 0.08772
[32m[0906 17-46-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18276, current rewards: 187.71173, mean: 0.08896
[32m[0906 17-46-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18285, current rewards: 194.72354, mean: 0.09015
[32m[0906 17-46-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18290, current rewards: 187.91104, mean: 0.08503
[32m[0906 17-46-28 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18295, current rewards: 193.74221, mean: 0.08573
[32m[0906 17-46-37 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18300, current rewards: 199.74921, mean: 0.08647
[32m[0906 17-46-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18302, current rewards: 205.75965, mean: 0.08719
[32m[0906 17-46-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18298, current rewards: 211.61769, mean: 0.08781
[32m[0906 17-47-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18294, current rewards: 217.46838, mean: 0.08840
[32m[0906 17-47-11 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0906 17-47-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-47-12 @MBExp.py:227][0m Rewards obtained: [222.15520078798852], Lows: [20], Highs: [32], Total time: 13830.610912999995
[32m[0906 17-48-15 @MBExp.py:144][0m ####################################################################
[32m[0906 17-48-15 @MBExp.py:145][0m Starting training iteration 31.
[32m[0906 17-48-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18065, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-48-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18038, current rewards: -5.74792, mean: -0.09580
[32m[0906 17-48-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18039, current rewards: -0.01349, mean: -0.00012
[32m[0906 17-48-44 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18065, current rewards: 5.72738, mean: 0.03580
[32m[0906 17-48-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18146, current rewards: 11.45853, mean: 0.05456
[32m[0906 17-49-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18250, current rewards: 17.01457, mean: 0.06544
[32m[0906 17-49-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18287, current rewards: 22.75319, mean: 0.07340
[32m[0906 17-49-21 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18313, current rewards: 28.48863, mean: 0.07914
[32m[0906 17-49-30 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18324, current rewards: 34.21964, mean: 0.08346
[32m[0906 17-49-39 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18347, current rewards: 39.95655, mean: 0.08686
[32m[0906 17-49-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18354, current rewards: 45.68861, mean: 0.08959
[32m[0906 17-49-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18364, current rewards: 51.42441, mean: 0.09183
[32m[0906 17-50-07 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18369, current rewards: 35.77065, mean: 0.05864
[32m[0906 17-50-16 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18379, current rewards: 44.46684, mean: 0.06737
[32m[0906 17-50-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18388, current rewards: 50.70482, mean: 0.07142
[32m[0906 17-50-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18398, current rewards: 56.93511, mean: 0.07491
[32m[0906 17-50-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18400, current rewards: 63.17210, mean: 0.07799
[32m[0906 17-50-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18408, current rewards: 69.40722, mean: 0.08071
[32m[0906 17-51-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18417, current rewards: 75.64441, mean: 0.08313
[32m[0906 17-51-12 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18423, current rewards: 62.75640, mean: 0.06537
[32m[0906 17-51-21 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18428, current rewards: 67.54595, mean: 0.06688
[32m[0906 17-51-30 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18427, current rewards: 73.71760, mean: 0.06954
[32m[0906 17-51-40 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18426, current rewards: 70.48626, mean: 0.06350
[32m[0906 17-51-49 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18428, current rewards: 75.96452, mean: 0.06549
[32m[0906 17-51-58 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18431, current rewards: 81.44589, mean: 0.06731
[32m[0906 17-52-07 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18436, current rewards: 86.93204, mean: 0.06899
[32m[0906 17-52-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18440, current rewards: 92.41464, mean: 0.07055
[32m[0906 17-52-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18443, current rewards: 97.89619, mean: 0.07198
[32m[0906 17-52-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18445, current rewards: 103.37682, mean: 0.07332
[32m[0906 17-52-44 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18448, current rewards: 108.85635, mean: 0.07456
[32m[0906 17-52-54 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18448, current rewards: 117.18053, mean: 0.07760
[32m[0906 17-53-03 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18450, current rewards: 110.15674, mean: 0.07061
[32m[0906 17-53-12 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18450, current rewards: 115.81740, mean: 0.07194
[32m[0906 17-53-21 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18449, current rewards: 121.38393, mean: 0.07312
[32m[0906 17-53-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18450, current rewards: 126.94397, mean: 0.07424
[32m[0906 17-53-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18430, current rewards: 132.50516, mean: 0.07529
[32m[0906 17-53-48 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18404, current rewards: 138.07147, mean: 0.07628
[32m[0906 17-53-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18379, current rewards: 143.63695, mean: 0.07722
[32m[0906 17-54-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18357, current rewards: 149.19532, mean: 0.07811
[32m[0906 17-54-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18334, current rewards: 154.75161, mean: 0.07895
[32m[0906 17-54-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18312, current rewards: 138.87959, mean: 0.06909
[32m[0906 17-54-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18293, current rewards: 144.50280, mean: 0.07015
[32m[0906 17-54-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18281, current rewards: 150.12335, mean: 0.07115
[32m[0906 17-54-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18290, current rewards: 155.74585, mean: 0.07210
[32m[0906 17-55-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18296, current rewards: 161.37715, mean: 0.07302
[32m[0906 17-55-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18303, current rewards: 167.00440, mean: 0.07390
[32m[0906 17-55-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18312, current rewards: 172.83360, mean: 0.07482
[32m[0906 17-55-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18311, current rewards: 178.45238, mean: 0.07562
[32m[0906 17-55-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18305, current rewards: 184.02899, mean: 0.07636
[32m[0906 17-55-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18300, current rewards: 185.38123, mean: 0.07536
[32m[0906 17-55-53 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 17-55-53 @Agent.py:118][0m Rollout length: 2510
[32m[0906 17-55-53 @MBExp.py:227][0m Rewards obtained: [173.21574047905804], Lows: [40], Highs: [29], Total time: 14288.711216999995
[32m[0906 17-56-58 @MBExp.py:144][0m ####################################################################
[32m[0906 17-56-58 @MBExp.py:145][0m Starting training iteration 32.
[32m[0906 17-57-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17956, current rewards: -10.00000, mean: -1.00000
[32m[0906 17-57-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18040, current rewards: -8.26460, mean: -0.13774
[32m[0906 17-57-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18044, current rewards: -4.22553, mean: -0.03841
[32m[0906 17-57-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18083, current rewards: -0.18656, mean: -0.00117
[32m[0906 17-57-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18176, current rewards: 3.87876, mean: 0.01847
[32m[0906 17-57-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18270, current rewards: 10.03841, mean: 0.03861
[32m[0906 17-57-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18321, current rewards: 15.20747, mean: 0.04906
[32m[0906 17-58-04 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18353, current rewards: 20.37771, mean: 0.05660
[32m[0906 17-58-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18380, current rewards: 25.54190, mean: 0.06230
[32m[0906 17-58-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18403, current rewards: 30.70804, mean: 0.06676
[32m[0906 17-58-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18408, current rewards: 25.45686, mean: 0.04992
[32m[0906 17-58-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18418, current rewards: 30.86848, mean: 0.05512
[32m[0906 17-58-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18431, current rewards: 36.28028, mean: 0.05948
[32m[0906 17-59-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18438, current rewards: 40.85015, mean: 0.06189
[32m[0906 17-59-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18446, current rewards: 45.94811, mean: 0.06472
[32m[0906 17-59-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18451, current rewards: 51.04390, mean: 0.06716
[32m[0906 17-59-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18467, current rewards: 56.12964, mean: 0.06930
[32m[0906 17-59-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18470, current rewards: 61.22291, mean: 0.07119
[32m[0906 17-59-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18470, current rewards: 66.31311, mean: 0.07287
[32m[0906 17-59-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18477, current rewards: 71.41516, mean: 0.07439
[32m[0906 18-00-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18478, current rewards: 76.00529, mean: 0.07525
[32m[0906 18-00-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18481, current rewards: 80.94807, mean: 0.07637
[32m[0906 18-00-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18483, current rewards: 85.58472, mean: 0.07710
[32m[0906 18-00-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18487, current rewards: 90.22557, mean: 0.07778
[32m[0906 18-00-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18492, current rewards: 94.86751, mean: 0.07840
[32m[0906 18-00-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18492, current rewards: 99.50915, mean: 0.07898
[32m[0906 18-01-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18493, current rewards: 104.15181, mean: 0.07951
[32m[0906 18-01-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18495, current rewards: 108.79044, mean: 0.07999
[32m[0906 18-01-19 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18495, current rewards: 113.43206, mean: 0.08045
[32m[0906 18-01-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18498, current rewards: 118.03541, mean: 0.08085
[32m[0906 18-01-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18501, current rewards: 122.68204, mean: 0.08125
[32m[0906 18-01-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18504, current rewards: 127.32256, mean: 0.08162
[32m[0906 18-01-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18503, current rewards: 111.18746, mean: 0.06906
[32m[0906 18-02-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18505, current rewards: 116.40985, mean: 0.07013
[32m[0906 18-02-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18506, current rewards: 121.61737, mean: 0.07112
[32m[0906 18-02-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18479, current rewards: 126.82725, mean: 0.07206
[32m[0906 18-02-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18452, current rewards: 132.02294, mean: 0.07294
[32m[0906 18-02-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18427, current rewards: 137.69214, mean: 0.07403
[32m[0906 18-02-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18403, current rewards: 121.84665, mean: 0.06379
[32m[0906 18-02-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18380, current rewards: 126.73982, mean: 0.06466
[32m[0906 18-03-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18360, current rewards: 131.44289, mean: 0.06539
[32m[0906 18-03-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18340, current rewards: 136.14789, mean: 0.06609
[32m[0906 18-03-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18327, current rewards: 140.85204, mean: 0.06675
[32m[0906 18-03-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18334, current rewards: 145.55440, mean: 0.06739
[32m[0906 18-03-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18343, current rewards: 150.25672, mean: 0.06799
[32m[0906 18-03-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18345, current rewards: 155.02672, mean: 0.06860
[32m[0906 18-04-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18348, current rewards: 159.75317, mean: 0.06916
[32m[0906 18-04-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18347, current rewards: 164.41929, mean: 0.06967
[32m[0906 18-04-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18343, current rewards: 169.08715, mean: 0.07016
[32m[0906 18-04-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18337, current rewards: 173.75292, mean: 0.07063
[32m[0906 18-04-37 @Agent.py:117][0m Average action selection time: 0.1833
[32m[0906 18-04-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-04-37 @MBExp.py:227][0m Rewards obtained: [156.83712749870142], Lows: [30], Highs: [22], Total time: 14747.747953999995
[32m[0906 18-05-45 @MBExp.py:144][0m ####################################################################
[32m[0906 18-05-45 @MBExp.py:145][0m Starting training iteration 33.
[32m[0906 18-05-47 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18101, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-05-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18075, current rewards: -6.07943, mean: -0.10132
[32m[0906 18-06-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18067, current rewards: -1.94160, mean: -0.01765
[32m[0906 18-06-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18070, current rewards: 2.19412, mean: 0.01371
[32m[0906 18-06-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18179, current rewards: 6.72750, mean: 0.03204
[32m[0906 18-06-32 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18250, current rewards: 10.88617, mean: 0.04187
[32m[0906 18-06-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18309, current rewards: 15.04278, mean: 0.04853
[32m[0906 18-06-51 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18337, current rewards: -2.67977, mean: -0.00744
[32m[0906 18-07-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18363, current rewards: 2.93891, mean: 0.00717
[32m[0906 18-07-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18380, current rewards: 8.49397, mean: 0.01847
[32m[0906 18-07-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18389, current rewards: 14.04774, mean: 0.02754
[32m[0906 18-07-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18397, current rewards: 19.60167, mean: 0.03500
[32m[0906 18-07-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18403, current rewards: 24.98906, mean: 0.04097
[32m[0906 18-07-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18412, current rewards: 19.13738, mean: 0.02900
[32m[0906 18-07-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18424, current rewards: 26.18826, mean: 0.03688
[32m[0906 18-08-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18425, current rewards: 32.49858, mean: 0.04276
[32m[0906 18-08-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18432, current rewards: 38.80708, mean: 0.04791
[32m[0906 18-08-24 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18437, current rewards: 45.11446, mean: 0.05246
[32m[0906 18-08-33 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18443, current rewards: 51.42567, mean: 0.05651
[32m[0906 18-08-42 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18444, current rewards: 57.73575, mean: 0.06014
[32m[0906 18-08-51 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18444, current rewards: 41.94509, mean: 0.04153
[32m[0906 18-09-00 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18442, current rewards: 48.20300, mean: 0.04547
[32m[0906 18-09-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18448, current rewards: 54.47343, mean: 0.04908
[32m[0906 18-09-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18453, current rewards: 60.74296, mean: 0.05236
[32m[0906 18-09-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18456, current rewards: 67.01081, mean: 0.05538
[32m[0906 18-09-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18458, current rewards: 73.27900, mean: 0.05816
[32m[0906 18-09-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18455, current rewards: 79.54833, mean: 0.06072
[32m[0906 18-09-56 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18456, current rewards: 85.81992, mean: 0.06310
[32m[0906 18-10-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18457, current rewards: 93.41659, mean: 0.06625
[32m[0906 18-10-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18460, current rewards: 99.49090, mean: 0.06814
[32m[0906 18-10-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18460, current rewards: 105.60644, mean: 0.06994
[32m[0906 18-10-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18460, current rewards: 111.71551, mean: 0.07161
[32m[0906 18-10-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18461, current rewards: 117.82676, mean: 0.07318
[32m[0906 18-10-52 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18462, current rewards: 112.42690, mean: 0.06773
[32m[0906 18-11-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18455, current rewards: 118.17702, mean: 0.06911
[32m[0906 18-11-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18428, current rewards: 123.94172, mean: 0.07042
[32m[0906 18-11-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18401, current rewards: 130.09954, mean: 0.07188
[32m[0906 18-11-27 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18377, current rewards: 136.28007, mean: 0.07327
[32m[0906 18-11-36 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18355, current rewards: 121.07013, mean: 0.06339
[32m[0906 18-11-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18333, current rewards: 126.05379, mean: 0.06431
[32m[0906 18-11-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18311, current rewards: 131.04347, mean: 0.06520
[32m[0906 18-12-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18293, current rewards: 136.03095, mean: 0.06603
[32m[0906 18-12-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18282, current rewards: 141.01797, mean: 0.06683
[32m[0906 18-12-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18288, current rewards: 146.00402, mean: 0.06759
[32m[0906 18-12-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18293, current rewards: 150.99239, mean: 0.06832
[32m[0906 18-12-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18298, current rewards: 156.08869, mean: 0.06907
[32m[0906 18-12-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18303, current rewards: 142.20022, mean: 0.06156
[32m[0906 18-12-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18303, current rewards: 146.32050, mean: 0.06200
[32m[0906 18-13-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18298, current rewards: 152.63881, mean: 0.06334
[32m[0906 18-13-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18293, current rewards: 158.96104, mean: 0.06462
[32m[0906 18-13-23 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0906 18-13-23 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-13-23 @MBExp.py:227][0m Rewards obtained: [164.01398683507355], Lows: [42], Highs: [31], Total time: 15205.682062999995
[32m[0906 18-14-32 @MBExp.py:144][0m ####################################################################
[32m[0906 18-14-32 @MBExp.py:145][0m Starting training iteration 34.
[32m[0906 18-14-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17994, current rewards: 1.03638, mean: 0.10364
[32m[0906 18-14-43 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18124, current rewards: 7.61520, mean: 0.12692
[32m[0906 18-14-52 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18071, current rewards: 13.95676, mean: 0.12688
[32m[0906 18-15-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18061, current rewards: 19.14412, mean: 0.11965
[32m[0906 18-15-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18181, current rewards: 25.18513, mean: 0.11993
[32m[0906 18-15-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18257, current rewards: 31.22522, mean: 0.12010
[32m[0906 18-15-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18291, current rewards: 37.27456, mean: 0.12024
[32m[0906 18-15-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18322, current rewards: 43.31259, mean: 0.12031
[32m[0906 18-15-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18348, current rewards: 49.35278, mean: 0.12037
[32m[0906 18-15-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18364, current rewards: 55.39969, mean: 0.12043
[32m[0906 18-16-06 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18383, current rewards: 49.08085, mean: 0.09624
[32m[0906 18-16-15 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18406, current rewards: 53.90168, mean: 0.09625
[32m[0906 18-16-25 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18416, current rewards: 59.30376, mean: 0.09722
[32m[0906 18-16-34 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18419, current rewards: 64.65729, mean: 0.09797
[32m[0906 18-16-43 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18426, current rewards: 70.01094, mean: 0.09861
[32m[0906 18-16-52 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18434, current rewards: 75.35139, mean: 0.09915
[32m[0906 18-17-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18441, current rewards: 80.70110, mean: 0.09963
[32m[0906 18-17-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18451, current rewards: 86.05919, mean: 0.10007
[32m[0906 18-17-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18453, current rewards: 91.40794, mean: 0.10045
[32m[0906 18-17-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18455, current rewards: 75.54685, mean: 0.07869
[32m[0906 18-17-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18454, current rewards: 81.42261, mean: 0.08062
[32m[0906 18-17-48 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18458, current rewards: 87.46541, mean: 0.08251
[32m[0906 18-17-57 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18462, current rewards: 93.50778, mean: 0.08424
[32m[0906 18-18-06 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18465, current rewards: 99.55561, mean: 0.08582
[32m[0906 18-18-16 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18469, current rewards: 105.59883, mean: 0.08727
[32m[0906 18-18-25 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18471, current rewards: 111.63821, mean: 0.08860
[32m[0906 18-18-34 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18470, current rewards: 117.68419, mean: 0.08984
[32m[0906 18-18-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18469, current rewards: 124.93571, mean: 0.09186
[32m[0906 18-18-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18471, current rewards: 134.28012, mean: 0.09523
[32m[0906 18-19-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18471, current rewards: 140.59990, mean: 0.09630
[32m[0906 18-19-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18470, current rewards: 146.91660, mean: 0.09730
[32m[0906 18-19-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18471, current rewards: 152.17362, mean: 0.09755
[32m[0906 18-19-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18473, current rewards: 158.10733, mean: 0.09820
[32m[0906 18-19-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18474, current rewards: 164.03530, mean: 0.09882
[32m[0906 18-19-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18462, current rewards: 169.97179, mean: 0.09940
[32m[0906 18-19-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18436, current rewards: 175.90730, mean: 0.09995
[32m[0906 18-20-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18411, current rewards: 181.83982, mean: 0.10046
[32m[0906 18-20-14 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18387, current rewards: 187.77774, mean: 0.10096
[32m[0906 18-20-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18365, current rewards: 193.70983, mean: 0.10142
[32m[0906 18-20-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18343, current rewards: 199.63864, mean: 0.10186
[32m[0906 18-20-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18323, current rewards: 205.57112, mean: 0.10227
[32m[0906 18-20-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18303, current rewards: 211.50847, mean: 0.10267
[32m[0906 18-20-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18289, current rewards: 217.10610, mean: 0.10289
[32m[0906 18-21-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18297, current rewards: 222.62551, mean: 0.10307
[32m[0906 18-21-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18302, current rewards: 229.21812, mean: 0.10372
[32m[0906 18-21-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18308, current rewards: 235.17772, mean: 0.10406
[32m[0906 18-21-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18314, current rewards: 241.14506, mean: 0.10439
[32m[0906 18-21-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18313, current rewards: 247.10643, mean: 0.10471
[32m[0906 18-21-54 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18308, current rewards: 253.06768, mean: 0.10501
[32m[0906 18-22-03 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18306, current rewards: 259.03315, mean: 0.10530
[32m[0906 18-22-10 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 18-22-10 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-22-10 @MBExp.py:227][0m Rewards obtained: [263.2109947034424], Lows: [10], Highs: [11], Total time: 15663.964498999994
[32m[0906 18-23-22 @MBExp.py:144][0m ####################################################################
[32m[0906 18-23-22 @MBExp.py:145][0m Starting training iteration 35.
[32m[0906 18-23-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18165, current rewards: 0.69587, mean: 0.06959
[32m[0906 18-23-33 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18107, current rewards: 5.85074, mean: 0.09751
[32m[0906 18-23-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18095, current rewards: 10.47637, mean: 0.09524
[32m[0906 18-23-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18097, current rewards: 15.54231, mean: 0.09714
[32m[0906 18-24-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18205, current rewards: 20.61209, mean: 0.09815
[32m[0906 18-24-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18294, current rewards: 25.68352, mean: 0.09878
[32m[0906 18-24-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18343, current rewards: 30.75497, mean: 0.09921
[32m[0906 18-24-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18365, current rewards: 35.82422, mean: 0.09951
[32m[0906 18-24-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18397, current rewards: 40.89259, mean: 0.09974
[32m[0906 18-24-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18408, current rewards: 45.95867, mean: 0.09991
[32m[0906 18-24-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18428, current rewards: 52.70215, mean: 0.10334
[32m[0906 18-25-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18435, current rewards: 39.18675, mean: 0.06998
[32m[0906 18-25-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18444, current rewards: 45.02595, mean: 0.07381
[32m[0906 18-25-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18448, current rewards: 50.86715, mean: 0.07707
[32m[0906 18-25-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18453, current rewards: 56.23999, mean: 0.07921
[32m[0906 18-25-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18455, current rewards: 61.57339, mean: 0.08102
[32m[0906 18-25-51 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18455, current rewards: 66.88765, mean: 0.08258
[32m[0906 18-26-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18459, current rewards: 72.20843, mean: 0.08396
[32m[0906 18-26-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18463, current rewards: 77.52116, mean: 0.08519
[32m[0906 18-26-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18465, current rewards: 76.52516, mean: 0.07971
[32m[0906 18-26-28 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18465, current rewards: 68.10672, mean: 0.06743
[32m[0906 18-26-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18474, current rewards: 73.91964, mean: 0.06974
[32m[0906 18-26-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18480, current rewards: 79.73406, mean: 0.07183
[32m[0906 18-26-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18482, current rewards: 65.19804, mean: 0.05621
[32m[0906 18-27-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18485, current rewards: 71.51938, mean: 0.05911
[32m[0906 18-27-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18486, current rewards: 77.83095, mean: 0.06177
[32m[0906 18-27-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18485, current rewards: 84.14319, mean: 0.06423
[32m[0906 18-27-33 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18483, current rewards: 90.02290, mean: 0.06619
[32m[0906 18-27-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18484, current rewards: 95.55375, mean: 0.06777
[32m[0906 18-27-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18483, current rewards: 101.40910, mean: 0.06946
[32m[0906 18-28-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18483, current rewards: 107.33474, mean: 0.07108
[32m[0906 18-28-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18482, current rewards: 113.25912, mean: 0.07260
[32m[0906 18-28-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18482, current rewards: 108.16854, mean: 0.06719
[32m[0906 18-28-29 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18481, current rewards: 114.39207, mean: 0.06891
[32m[0906 18-28-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18465, current rewards: 120.14617, mean: 0.07026
[32m[0906 18-28-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18440, current rewards: 125.08910, mean: 0.07107
[32m[0906 18-28-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18416, current rewards: 130.67266, mean: 0.07219
[32m[0906 18-29-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18392, current rewards: 136.26380, mean: 0.07326
[32m[0906 18-29-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18369, current rewards: 141.85769, mean: 0.07427
[32m[0906 18-29-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18346, current rewards: 147.43993, mean: 0.07522
[32m[0906 18-29-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18326, current rewards: 131.91046, mean: 0.06563
[32m[0906 18-29-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18307, current rewards: 136.94172, mean: 0.06648
[32m[0906 18-29-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18294, current rewards: 142.00984, mean: 0.06730
[32m[0906 18-29-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18301, current rewards: 146.86613, mean: 0.06799
[32m[0906 18-30-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18306, current rewards: 151.90832, mean: 0.06874
[32m[0906 18-30-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18311, current rewards: 156.90183, mean: 0.06943
[32m[0906 18-30-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18313, current rewards: 161.89825, mean: 0.07009
[32m[0906 18-30-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18313, current rewards: 156.13428, mean: 0.06616
[32m[0906 18-30-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18308, current rewards: 162.14619, mean: 0.06728
[32m[0906 18-30-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18304, current rewards: 168.16427, mean: 0.06836
[32m[0906 18-31-00 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 18-31-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-31-00 @MBExp.py:227][0m Rewards obtained: [172.98014961937793], Lows: [30], Highs: [39], Total time: 16122.207458999994
[32m[0906 18-32-13 @MBExp.py:144][0m ####################################################################
[32m[0906 18-32-13 @MBExp.py:145][0m Starting training iteration 36.
[32m[0906 18-32-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17966, current rewards: 0.76344, mean: 0.07634
[32m[0906 18-32-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18082, current rewards: 5.76448, mean: 0.09607
[32m[0906 18-32-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18092, current rewards: 10.67546, mean: 0.09705
[32m[0906 18-32-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18069, current rewards: 15.76053, mean: 0.09850
[32m[0906 18-32-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18205, current rewards: 20.84564, mean: 0.09926
[32m[0906 18-33-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18317, current rewards: 25.92976, mean: 0.09973
[32m[0906 18-33-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18377, current rewards: 31.01670, mean: 0.10005
[32m[0906 18-33-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18403, current rewards: 36.10326, mean: 0.10029
[32m[0906 18-33-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18420, current rewards: 41.19074, mean: 0.10047
[32m[0906 18-33-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18435, current rewards: 46.28378, mean: 0.10062
[32m[0906 18-33-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18444, current rewards: 55.56126, mean: 0.10894
[32m[0906 18-33-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18450, current rewards: 21.88530, mean: 0.03908
[32m[0906 18-34-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18460, current rewards: -28.11470, mean: -0.04609
[32m[0906 18-34-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18464, current rewards: -78.11470, mean: -0.11836
[32m[0906 18-34-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18465, current rewards: -128.11470, mean: -0.18044
[32m[0906 18-34-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18470, current rewards: -178.11470, mean: -0.23436
[32m[0906 18-34-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18472, current rewards: -228.11470, mean: -0.28162
[32m[0906 18-34-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18475, current rewards: -236.21429, mean: -0.27467
[32m[0906 18-35-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18477, current rewards: -230.72305, mean: -0.25354
[32m[0906 18-35-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18487, current rewards: -225.02732, mean: -0.23440
[32m[0906 18-35-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18486, current rewards: -221.56676, mean: -0.21937
[32m[0906 18-35-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18485, current rewards: -224.94300, mean: -0.21221
[32m[0906 18-35-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18483, current rewards: -219.44103, mean: -0.19769
[32m[0906 18-35-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18483, current rewards: -213.94119, mean: -0.18443
[32m[0906 18-35-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18484, current rewards: -208.44976, mean: -0.17227
[32m[0906 18-36-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18484, current rewards: -202.95006, mean: -0.16107
[32m[0906 18-36-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18481, current rewards: -197.77667, mean: -0.15097
[32m[0906 18-36-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18481, current rewards: -192.32724, mean: -0.14142
[32m[0906 18-36-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18483, current rewards: -186.87683, mean: -0.13254
[32m[0906 18-36-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18481, current rewards: -181.72138, mean: -0.12447
[32m[0906 18-36-53 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18482, current rewards: -176.19103, mean: -0.11668
[32m[0906 18-37-02 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18484, current rewards: -170.48268, mean: -0.10928
[32m[0906 18-37-11 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18487, current rewards: -164.77164, mean: -0.10234
[32m[0906 18-37-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18486, current rewards: -159.06195, mean: -0.09582
[32m[0906 18-37-29 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18467, current rewards: -153.83268, mean: -0.08996
[32m[0906 18-37-38 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18439, current rewards: -148.16231, mean: -0.08418
[32m[0906 18-37-47 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18412, current rewards: -142.54912, mean: -0.07876
[32m[0906 18-37-56 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18387, current rewards: -136.93237, mean: -0.07362
[32m[0906 18-38-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18364, current rewards: -131.32099, mean: -0.06875
[32m[0906 18-38-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18342, current rewards: -125.70589, mean: -0.06414
[32m[0906 18-38-22 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18322, current rewards: -120.09658, mean: -0.05975
[32m[0906 18-38-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18302, current rewards: -114.48375, mean: -0.05557
[32m[0906 18-38-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18290, current rewards: -108.34413, mean: -0.05135
[32m[0906 18-38-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18295, current rewards: -101.96683, mean: -0.04721
[32m[0906 18-38-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18301, current rewards: -96.33767, mean: -0.04359
[32m[0906 18-39-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18306, current rewards: -90.70572, mean: -0.04014
[32m[0906 18-39-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18313, current rewards: -85.74251, mean: -0.03712
[32m[0906 18-39-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18313, current rewards: -80.47149, mean: -0.03410
[32m[0906 18-39-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18309, current rewards: -75.19709, mean: -0.03120
[32m[0906 18-39-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18304, current rewards: -69.92727, mean: -0.02843
[32m[0906 18-39-51 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 18-39-51 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-39-51 @MBExp.py:227][0m Rewards obtained: [-65.7052660390892], Lows: [0], Highs: [308], Total time: 16580.406289999995
[32m[0906 18-41-07 @MBExp.py:144][0m ####################################################################
[32m[0906 18-41-07 @MBExp.py:145][0m Starting training iteration 37.
[32m[0906 18-41-09 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18034, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-41-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18068, current rewards: -11.90203, mean: -0.19837
[32m[0906 18-41-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18090, current rewards: -5.77227, mean: -0.05248
[32m[0906 18-41-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18113, current rewards: 0.28087, mean: 0.00176
[32m[0906 18-41-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18226, current rewards: 6.34864, mean: 0.03023
[32m[0906 18-41-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18287, current rewards: 12.41174, mean: 0.04774
[32m[0906 18-42-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18322, current rewards: 18.47543, mean: 0.05960
[32m[0906 18-42-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18353, current rewards: 24.53353, mean: 0.06815
[32m[0906 18-42-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18375, current rewards: 30.59287, mean: 0.07462
[32m[0906 18-42-32 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18397, current rewards: 36.71273, mean: 0.07981
[32m[0906 18-42-41 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18413, current rewards: 44.90982, mean: 0.08806
[32m[0906 18-42-50 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18425, current rewards: 50.44093, mean: 0.09007
[32m[0906 18-42-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18434, current rewards: 55.44579, mean: 0.09089
[32m[0906 18-43-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18440, current rewards: 60.57726, mean: 0.09178
[32m[0906 18-43-18 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18444, current rewards: 65.70963, mean: 0.09255
[32m[0906 18-43-27 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18449, current rewards: 70.83737, mean: 0.09321
[32m[0906 18-43-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18456, current rewards: 75.96818, mean: 0.09379
[32m[0906 18-43-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18457, current rewards: 81.09543, mean: 0.09430
[32m[0906 18-43-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18463, current rewards: 85.33795, mean: 0.09378
[32m[0906 18-44-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18462, current rewards: 71.21310, mean: 0.07418
[32m[0906 18-44-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18459, current rewards: 75.91879, mean: 0.07517
[32m[0906 18-44-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18464, current rewards: 83.08255, mean: 0.07838
[32m[0906 18-44-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18462, current rewards: 90.24428, mean: 0.08130
[32m[0906 18-44-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18462, current rewards: 97.41323, mean: 0.08398
[32m[0906 18-44-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18464, current rewards: 104.58034, mean: 0.08643
[32m[0906 18-45-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18464, current rewards: 111.74715, mean: 0.08869
[32m[0906 18-45-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18467, current rewards: 118.91454, mean: 0.09077
[32m[0906 18-45-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18472, current rewards: 119.69676, mean: 0.08801
[32m[0906 18-45-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18472, current rewards: 126.64272, mean: 0.08982
[32m[0906 18-45-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18476, current rewards: 132.85935, mean: 0.09100
[32m[0906 18-45-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18474, current rewards: 139.06967, mean: 0.09210
[32m[0906 18-45-55 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18470, current rewards: 145.29081, mean: 0.09314
[32m[0906 18-46-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18467, current rewards: 151.51848, mean: 0.09411
[32m[0906 18-46-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18459, current rewards: 157.73978, mean: 0.09502
[32m[0906 18-46-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18440, current rewards: 163.96087, mean: 0.09588
[32m[0906 18-46-31 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18414, current rewards: 150.79525, mean: 0.08568
[32m[0906 18-46-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18388, current rewards: 156.91403, mean: 0.08669
[32m[0906 18-46-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18366, current rewards: 162.94630, mean: 0.08761
[32m[0906 18-46-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18344, current rewards: 168.98118, mean: 0.08847
[32m[0906 18-47-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18323, current rewards: 175.01459, mean: 0.08929
[32m[0906 18-47-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18302, current rewards: 181.05081, mean: 0.09008
[32m[0906 18-47-24 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18282, current rewards: 187.08963, mean: 0.09082
[32m[0906 18-47-33 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18273, current rewards: 171.79152, mean: 0.08142
[32m[0906 18-47-42 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18279, current rewards: 178.69453, mean: 0.08273
[32m[0906 18-47-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18287, current rewards: 185.69704, mean: 0.08403
[32m[0906 18-48-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18293, current rewards: 191.69665, mean: 0.08482
[32m[0906 18-48-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18297, current rewards: 197.69656, mean: 0.08558
[32m[0906 18-48-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18296, current rewards: 203.69832, mean: 0.08631
[32m[0906 18-48-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18292, current rewards: 209.69697, mean: 0.08701
[32m[0906 18-48-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18289, current rewards: 215.69735, mean: 0.08768
[32m[0906 18-48-45 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0906 18-48-45 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-48-45 @MBExp.py:227][0m Rewards obtained: [220.49814521148565], Lows: [33], Highs: [21], Total time: 17038.245252999994
[32m[0906 18-50-02 @MBExp.py:144][0m ####################################################################
[32m[0906 18-50-02 @MBExp.py:145][0m Starting training iteration 38.
[32m[0906 18-50-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17958, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-50-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18033, current rewards: -6.65988, mean: -0.11100
[32m[0906 18-50-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18047, current rewards: -1.82672, mean: -0.01661
[32m[0906 18-50-31 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18115, current rewards: 2.75238, mean: 0.01720
[32m[0906 18-50-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18244, current rewards: 7.33497, mean: 0.03493
[32m[0906 18-50-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18310, current rewards: 11.91641, mean: 0.04583
[32m[0906 18-50-59 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18353, current rewards: 16.49778, mean: 0.05322
[32m[0906 18-51-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18380, current rewards: 21.07424, mean: 0.05854
[32m[0906 18-51-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18396, current rewards: 25.65257, mean: 0.06257
[32m[0906 18-51-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18419, current rewards: 30.23176, mean: 0.06572
[32m[0906 18-51-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18427, current rewards: 34.62238, mean: 0.06789
[32m[0906 18-51-45 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18437, current rewards: 39.24989, mean: 0.07009
[32m[0906 18-51-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18459, current rewards: 43.87780, mean: 0.07193
[32m[0906 18-52-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18465, current rewards: 48.50542, mean: 0.07349
[32m[0906 18-52-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18469, current rewards: 32.48797, mean: 0.04576
[32m[0906 18-52-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18474, current rewards: 36.91362, mean: 0.04857
[32m[0906 18-52-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18472, current rewards: 41.33289, mean: 0.05103
[32m[0906 18-52-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18472, current rewards: 45.75374, mean: 0.05320
[32m[0906 18-52-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18478, current rewards: 51.37089, mean: 0.05645
[32m[0906 18-53-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18480, current rewards: 55.92164, mean: 0.05825
[32m[0906 18-53-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18479, current rewards: 60.45243, mean: 0.05985
[32m[0906 18-53-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18477, current rewards: 64.98326, mean: 0.06130
[32m[0906 18-53-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18481, current rewards: 69.51352, mean: 0.06262
[32m[0906 18-53-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18481, current rewards: 74.04469, mean: 0.06383
[32m[0906 18-53-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18482, current rewards: 70.20734, mean: 0.05802
[32m[0906 18-53-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18485, current rewards: 62.12610, mean: 0.04931
[32m[0906 18-54-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18490, current rewards: 66.31554, mean: 0.05062
[32m[0906 18-54-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18488, current rewards: 70.68515, mean: 0.05197
[32m[0906 18-54-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18488, current rewards: 75.06385, mean: 0.05324
[32m[0906 18-54-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18488, current rewards: 79.44009, mean: 0.05441
[32m[0906 18-54-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18489, current rewards: 83.81779, mean: 0.05551
[32m[0906 18-54-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18490, current rewards: 88.19169, mean: 0.05653
[32m[0906 18-55-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18491, current rewards: 92.56812, mean: 0.05750
[32m[0906 18-55-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18479, current rewards: 96.94406, mean: 0.05840
[32m[0906 18-55-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18457, current rewards: 82.73492, mean: 0.04838
[32m[0906 18-55-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18430, current rewards: 90.07856, mean: 0.05118
[32m[0906 18-55-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18404, current rewards: 96.84260, mean: 0.05350
[32m[0906 18-55-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18382, current rewards: 103.60664, mean: 0.05570
[32m[0906 18-55-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18358, current rewards: 62.68888, mean: 0.03282
[32m[0906 18-56-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18338, current rewards: 12.68888, mean: 0.00647
[32m[0906 18-56-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18319, current rewards: -37.31112, mean: -0.01856
[32m[0906 18-56-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18297, current rewards: -87.31112, mean: -0.04238
[32m[0906 18-56-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18288, current rewards: -137.31112, mean: -0.06508
[32m[0906 18-56-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18290, current rewards: -187.31112, mean: -0.08672
[32m[0906 18-56-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18297, current rewards: -237.31112, mean: -0.10738
[32m[0906 18-56-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18299, current rewards: -287.31112, mean: -0.12713
[32m[0906 18-57-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18305, current rewards: -337.31112, mean: -0.14602
[32m[0906 18-57-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18304, current rewards: -387.31112, mean: -0.16411
[32m[0906 18-57-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18298, current rewards: -437.31112, mean: -0.18146
[32m[0906 18-57-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18293, current rewards: -487.31112, mean: -0.19809
[32m[0906 18-57-40 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0906 18-57-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 18-57-40 @MBExp.py:227][0m Rewards obtained: [-527.3111164275003], Lows: [30], Highs: [643], Total time: 17496.206648999992
[32m[0906 18-59-00 @MBExp.py:144][0m ####################################################################
[32m[0906 18-59-00 @MBExp.py:145][0m Starting training iteration 39.
[32m[0906 18-59-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18031, current rewards: -10.00000, mean: -1.00000
[32m[0906 18-59-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18076, current rewards: -3.64866, mean: -0.06081
[32m[0906 18-59-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18056, current rewards: 2.71136, mean: 0.02465
[32m[0906 18-59-29 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18100, current rewards: 9.07258, mean: 0.05670
[32m[0906 18-59-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18231, current rewards: 15.42485, mean: 0.07345
[32m[0906 18-59-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18305, current rewards: 21.78602, mean: 0.08379
[32m[0906 18-59-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18353, current rewards: 28.13426, mean: 0.09076
[32m[0906 19-00-06 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18374, current rewards: 34.48746, mean: 0.09580
[32m[0906 19-00-15 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18408, current rewards: 40.83877, mean: 0.09961
[32m[0906 19-00-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18426, current rewards: 48.48703, mean: 0.10541
[32m[0906 19-00-34 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18435, current rewards: 55.26251, mean: 0.10836
[32m[0906 19-00-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18436, current rewards: 40.42240, mean: 0.07218
[32m[0906 19-00-52 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18447, current rewards: 46.79625, mean: 0.07672
[32m[0906 19-01-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18457, current rewards: 53.18995, mean: 0.08059
[32m[0906 19-01-11 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18459, current rewards: 59.58522, mean: 0.08392
[32m[0906 19-01-20 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18464, current rewards: 65.97334, mean: 0.08681
[32m[0906 19-01-29 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18464, current rewards: 72.36766, mean: 0.08934
[32m[0906 19-01-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18466, current rewards: 67.41248, mean: 0.07839
[32m[0906 19-01-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18468, current rewards: 73.03101, mean: 0.08025
[32m[0906 19-01-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18472, current rewards: 78.61947, mean: 0.08190
[32m[0906 19-02-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18472, current rewards: 84.21012, mean: 0.08338
[32m[0906 19-02-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18474, current rewards: 89.79559, mean: 0.08471
[32m[0906 19-02-25 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18479, current rewards: 75.01939, mean: 0.06759
[32m[0906 19-02-34 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18478, current rewards: 83.31951, mean: 0.07183
[32m[0906 19-02-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18481, current rewards: 91.61963, mean: 0.07572
[32m[0906 19-02-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18479, current rewards: 99.84894, mean: 0.07925
[32m[0906 19-03-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18477, current rewards: 106.45718, mean: 0.08127
[32m[0906 19-03-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18476, current rewards: 113.06541, mean: 0.08314
[32m[0906 19-03-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18474, current rewards: 119.67364, mean: 0.08487
[32m[0906 19-03-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18473, current rewards: 126.28187, mean: 0.08649
[32m[0906 19-03-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18473, current rewards: 132.89011, mean: 0.08801
[32m[0906 19-03-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18473, current rewards: 115.72288, mean: 0.07418
[32m[0906 19-03-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18468, current rewards: 65.72288, mean: 0.04082
[32m[0906 19-04-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18453, current rewards: 15.72288, mean: 0.00947
[32m[0906 19-04-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18431, current rewards: -34.27712, mean: -0.02005
[32m[0906 19-04-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18406, current rewards: -84.27712, mean: -0.04788
[32m[0906 19-04-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18381, current rewards: -134.27712, mean: -0.07419
[32m[0906 19-04-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18356, current rewards: -184.27712, mean: -0.09907
[32m[0906 19-04-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18333, current rewards: -234.27712, mean: -0.12266
[32m[0906 19-04-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18311, current rewards: -284.27712, mean: -0.14504
[32m[0906 19-05-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18291, current rewards: -334.27712, mean: -0.16631
[32m[0906 19-05-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18274, current rewards: -384.27712, mean: -0.18654
[32m[0906 19-05-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18267, current rewards: -434.27712, mean: -0.20582
[32m[0906 19-05-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18266, current rewards: -484.27712, mean: -0.22420
[32m[0906 19-05-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18273, current rewards: -534.27712, mean: -0.24175
[32m[0906 19-05-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18279, current rewards: -584.27712, mean: -0.25853
[32m[0906 19-06-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18286, current rewards: -634.27712, mean: -0.27458
[32m[0906 19-06-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18285, current rewards: -684.27712, mean: -0.28995
[32m[0906 19-06-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18282, current rewards: -734.27712, mean: -0.30468
[32m[0906 19-06-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18278, current rewards: -784.27712, mean: -0.31881
[32m[0906 19-06-37 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 19-06-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-06-37 @MBExp.py:227][0m Rewards obtained: [-824.2771176084286], Lows: [20], Highs: [981], Total time: 17953.791986999993
[32m[0906 19-07-59 @MBExp.py:144][0m ####################################################################
[32m[0906 19-07-59 @MBExp.py:145][0m Starting training iteration 40.
[32m[0906 19-08-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17998, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-08-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18128, current rewards: -4.10325, mean: -0.06839
[32m[0906 19-08-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18100, current rewards: 1.83226, mean: 0.01666
[32m[0906 19-08-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18147, current rewards: 7.76326, mean: 0.04852
[32m[0906 19-08-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18276, current rewards: 13.69828, mean: 0.06523
[32m[0906 19-08-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18324, current rewards: 19.63805, mean: 0.07553
[32m[0906 19-08-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18364, current rewards: 25.57613, mean: 0.08250
[32m[0906 19-09-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18390, current rewards: 31.51201, mean: 0.08753
[32m[0906 19-09-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18400, current rewards: 37.44501, mean: 0.09133
[32m[0906 19-09-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18414, current rewards: 21.60152, mean: 0.04696
[32m[0906 19-09-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18424, current rewards: 27.13206, mean: 0.05320
[32m[0906 19-09-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18435, current rewards: 32.66802, mean: 0.05834
[32m[0906 19-09-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18446, current rewards: 38.20105, mean: 0.06262
[32m[0906 19-10-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18446, current rewards: 43.73993, mean: 0.06627
[32m[0906 19-10-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18453, current rewards: 49.27523, mean: 0.06940
[32m[0906 19-10-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18457, current rewards: 40.03258, mean: 0.05267
[32m[0906 19-10-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18463, current rewards: 39.71748, mean: 0.04903
[32m[0906 19-10-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18467, current rewards: 47.19348, mean: 0.05488
[32m[0906 19-10-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18475, current rewards: 52.76191, mean: 0.05798
[32m[0906 19-10-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18477, current rewards: 58.32491, mean: 0.06076
[32m[0906 19-11-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18478, current rewards: 63.88367, mean: 0.06325
[32m[0906 19-11-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18480, current rewards: 69.44385, mean: 0.06551
[32m[0906 19-11-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18480, current rewards: 75.00455, mean: 0.06757
[32m[0906 19-11-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18479, current rewards: 80.56450, mean: 0.06945
[32m[0906 19-11-43 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18483, current rewards: 86.12389, mean: 0.07118
[32m[0906 19-11-52 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18483, current rewards: 79.93115, mean: 0.06344
[32m[0906 19-12-01 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18484, current rewards: 84.56409, mean: 0.06455
[32m[0906 19-12-10 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18482, current rewards: 89.88710, mean: 0.06609
[32m[0906 19-12-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18485, current rewards: 95.20983, mean: 0.06752
[32m[0906 19-12-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18485, current rewards: 100.53011, mean: 0.06886
[32m[0906 19-12-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18485, current rewards: 105.84428, mean: 0.07010
[32m[0906 19-12-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18484, current rewards: 111.15044, mean: 0.07125
[32m[0906 19-12-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18479, current rewards: 116.47012, mean: 0.07234
[32m[0906 19-13-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18468, current rewards: 101.09986, mean: 0.06090
[32m[0906 19-13-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18445, current rewards: 112.54325, mean: 0.06581
[32m[0906 19-13-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18418, current rewards: 120.19884, mean: 0.06829
[32m[0906 19-13-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18394, current rewards: 127.65903, mean: 0.07053
[32m[0906 19-13-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18370, current rewards: 135.11922, mean: 0.07264
[32m[0906 19-13-50 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18348, current rewards: 142.57941, mean: 0.07465
[32m[0906 19-13-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18328, current rewards: 150.03960, mean: 0.07655
[32m[0906 19-14-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18309, current rewards: 102.33801, mean: 0.05091
[32m[0906 19-14-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18290, current rewards: 52.33801, mean: 0.02541
[32m[0906 19-14-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18286, current rewards: 2.33801, mean: 0.00111
[32m[0906 19-14-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18284, current rewards: -47.66199, mean: -0.02207
[32m[0906 19-14-44 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18293, current rewards: -97.66199, mean: -0.04419
[32m[0906 19-14-53 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18301, current rewards: -147.66199, mean: -0.06534
[32m[0906 19-15-02 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18308, current rewards: -197.66199, mean: -0.08557
[32m[0906 19-15-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18308, current rewards: -247.66199, mean: -0.10494
[32m[0906 19-15-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18305, current rewards: -297.66199, mean: -0.12351
[32m[0906 19-15-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18300, current rewards: -347.66199, mean: -0.14133
[32m[0906 19-15-37 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 19-15-37 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-15-37 @MBExp.py:227][0m Rewards obtained: [-387.66198789250063], Lows: [30], Highs: [558], Total time: 18411.912791999992
[32m[0906 19-17-00 @MBExp.py:144][0m ####################################################################
[32m[0906 19-17-00 @MBExp.py:145][0m Starting training iteration 41.
[32m[0906 19-17-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18306, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-17-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18131, current rewards: -3.35514, mean: -0.05592
[32m[0906 19-17-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18104, current rewards: 2.29304, mean: 0.02085
[32m[0906 19-17-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18177, current rewards: 7.94061, mean: 0.04963
[32m[0906 19-17-39 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18276, current rewards: 13.58592, mean: 0.06469
[32m[0906 19-17-48 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18339, current rewards: 8.26683, mean: 0.03180
[32m[0906 19-17-57 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18366, current rewards: 14.96477, mean: 0.04827
[32m[0906 19-18-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18390, current rewards: 21.68340, mean: 0.06023
[32m[0906 19-18-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18401, current rewards: 28.39629, mean: 0.06926
[32m[0906 19-18-25 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18416, current rewards: 34.81410, mean: 0.07568
[32m[0906 19-18-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18426, current rewards: 41.54000, mean: 0.08145
[32m[0906 19-18-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18434, current rewards: 29.05522, mean: 0.05188
[32m[0906 19-18-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18439, current rewards: 32.66561, mean: 0.05355
[32m[0906 19-19-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18447, current rewards: 37.97172, mean: 0.05753
[32m[0906 19-19-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18451, current rewards: 43.27935, mean: 0.06096
[32m[0906 19-19-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18447, current rewards: 48.58647, mean: 0.06393
[32m[0906 19-19-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18451, current rewards: 53.89488, mean: 0.06654
[32m[0906 19-19-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18453, current rewards: 58.56246, mean: 0.06810
[32m[0906 19-19-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18452, current rewards: 63.76461, mean: 0.07007
[32m[0906 19-19-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18453, current rewards: 69.03801, mean: 0.07191
[32m[0906 19-20-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18455, current rewards: 74.31006, mean: 0.07357
[32m[0906 19-20-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18455, current rewards: 79.57472, mean: 0.07507
[32m[0906 19-20-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18453, current rewards: 84.84347, mean: 0.07644
[32m[0906 19-20-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18452, current rewards: 90.11512, mean: 0.07769
[32m[0906 19-20-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18454, current rewards: 74.62347, mean: 0.06167
[32m[0906 19-20-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18455, current rewards: 80.54634, mean: 0.06393
[32m[0906 19-21-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18459, current rewards: 86.35403, mean: 0.06592
[32m[0906 19-21-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18464, current rewards: 92.00649, mean: 0.06765
[32m[0906 19-21-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18467, current rewards: 97.65864, mean: 0.06926
[32m[0906 19-21-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18467, current rewards: 103.31347, mean: 0.07076
[32m[0906 19-21-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18468, current rewards: 96.85463, mean: 0.06414
[32m[0906 19-21-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18468, current rewards: 102.44082, mean: 0.06567
[32m[0906 19-21-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18459, current rewards: 108.02223, mean: 0.06709
[32m[0906 19-22-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18446, current rewards: 113.60362, mean: 0.06844
[32m[0906 19-22-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18420, current rewards: 119.85685, mean: 0.07009
[32m[0906 19-22-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18393, current rewards: 125.48715, mean: 0.07130
[32m[0906 19-22-33 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18369, current rewards: 131.11985, mean: 0.07244
[32m[0906 19-22-42 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18344, current rewards: 136.75101, mean: 0.07352
[32m[0906 19-22-51 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18322, current rewards: 121.17488, mean: 0.06344
[32m[0906 19-23-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18301, current rewards: 126.61380, mean: 0.06460
[32m[0906 19-23-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18282, current rewards: 132.26675, mean: 0.06580
[32m[0906 19-23-17 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18266, current rewards: 137.92556, mean: 0.06695
[32m[0906 19-23-26 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18262, current rewards: 143.44118, mean: 0.06798
[32m[0906 19-23-35 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18260, current rewards: 149.05106, mean: 0.06901
[32m[0906 19-23-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18268, current rewards: 154.65700, mean: 0.06998
[32m[0906 19-23-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18274, current rewards: 160.27210, mean: 0.07092
[32m[0906 19-24-03 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18278, current rewards: 159.20484, mean: 0.06892
[32m[0906 19-24-12 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18277, current rewards: 158.48911, mean: 0.06716
[32m[0906 19-24-21 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18272, current rewards: 164.10899, mean: 0.06810
[32m[0906 19-24-30 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18268, current rewards: 169.71511, mean: 0.06899
[32m[0906 19-24-38 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 19-24-38 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-24-38 @MBExp.py:227][0m Rewards obtained: [173.98423477602609], Lows: [31], Highs: [41], Total time: 18869.24041999999
[32m[0906 19-26-03 @MBExp.py:144][0m ####################################################################
[32m[0906 19-26-03 @MBExp.py:145][0m Starting training iteration 42.
[32m[0906 19-26-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18089, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-26-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18070, current rewards: -5.50422, mean: -0.09174
[32m[0906 19-26-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18059, current rewards: -0.77117, mean: -0.00701
[32m[0906 19-26-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18149, current rewards: 3.96717, mean: 0.02479
[32m[0906 19-26-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18234, current rewards: 8.70909, mean: 0.04147
[32m[0906 19-26-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18277, current rewards: 13.45168, mean: 0.05174
[32m[0906 19-27-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18329, current rewards: 18.19208, mean: 0.05868
[32m[0906 19-27-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18363, current rewards: 22.92899, mean: 0.06369
[32m[0906 19-27-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18381, current rewards: 27.95316, mean: 0.06818
[32m[0906 19-27-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18397, current rewards: 33.98771, mean: 0.07389
[32m[0906 19-27-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18413, current rewards: 38.83950, mean: 0.07616
[32m[0906 19-27-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18423, current rewards: 43.68931, mean: 0.07802
[32m[0906 19-27-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18438, current rewards: 48.54083, mean: 0.07958
[32m[0906 19-28-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18445, current rewards: 53.39254, mean: 0.08090
[32m[0906 19-28-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18450, current rewards: 37.27336, mean: 0.05250
[32m[0906 19-28-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18454, current rewards: 42.68722, mean: 0.05617
[32m[0906 19-28-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18454, current rewards: 48.03141, mean: 0.05930
[32m[0906 19-28-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18458, current rewards: 53.06863, mean: 0.06171
[32m[0906 19-28-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18459, current rewards: 58.37327, mean: 0.06415
[32m[0906 19-29-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18460, current rewards: 63.68019, mean: 0.06633
[32m[0906 19-29-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18466, current rewards: 58.08407, mean: 0.05751
[32m[0906 19-29-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18465, current rewards: 63.35963, mean: 0.05977
[32m[0906 19-29-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18466, current rewards: 68.18170, mean: 0.06142
[32m[0906 19-29-38 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18474, current rewards: 73.00732, mean: 0.06294
[32m[0906 19-29-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18473, current rewards: 77.83306, mean: 0.06432
[32m[0906 19-29-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18474, current rewards: 82.47491, mean: 0.06546
[32m[0906 19-30-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18473, current rewards: 87.36581, mean: 0.06669
[32m[0906 19-30-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18473, current rewards: 92.27132, mean: 0.06785
[32m[0906 19-30-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18476, current rewards: 97.17618, mean: 0.06892
[32m[0906 19-30-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18479, current rewards: 102.07915, mean: 0.06992
[32m[0906 19-30-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18476, current rewards: 106.98245, mean: 0.07085
[32m[0906 19-30-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18473, current rewards: 111.88221, mean: 0.07172
[32m[0906 19-31-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18461, current rewards: 96.08665, mean: 0.05968
[32m[0906 19-31-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18449, current rewards: 78.87938, mean: 0.04752
[32m[0906 19-31-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18423, current rewards: 83.55439, mean: 0.04886
[32m[0906 19-31-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18397, current rewards: 88.18437, mean: 0.05010
[32m[0906 19-31-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18372, current rewards: 92.81167, mean: 0.05128
[32m[0906 19-31-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18352, current rewards: 97.44346, mean: 0.05239
[32m[0906 19-31-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18330, current rewards: 102.07507, mean: 0.05344
[32m[0906 19-32-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18309, current rewards: 106.69952, mean: 0.05444
[32m[0906 19-32-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18290, current rewards: 111.32623, mean: 0.05539
[32m[0906 19-32-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18275, current rewards: 115.90805, mean: 0.05627
[32m[0906 19-32-29 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18270, current rewards: 120.51345, mean: 0.05712
[32m[0906 19-32-38 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18265, current rewards: 125.11710, mean: 0.05792
[32m[0906 19-32-47 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18270, current rewards: 129.72265, mean: 0.05870
[32m[0906 19-32-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18276, current rewards: 113.63490, mean: 0.05028
[32m[0906 19-33-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18283, current rewards: 118.55969, mean: 0.05132
[32m[0906 19-33-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18282, current rewards: 123.49674, mean: 0.05233
[32m[0906 19-33-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18279, current rewards: 128.43717, mean: 0.05329
[32m[0906 19-33-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18275, current rewards: 133.75117, mean: 0.05437
[32m[0906 19-33-41 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 19-33-41 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-33-41 @MBExp.py:227][0m Rewards obtained: [138.66579098211304], Lows: [42], Highs: [21], Total time: 19326.74226399999
[32m[0906 19-35-08 @MBExp.py:144][0m ####################################################################
[32m[0906 19-35-08 @MBExp.py:145][0m Starting training iteration 43.
[32m[0906 19-35-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17918, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-35-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18047, current rewards: -24.54474, mean: -0.40908
[32m[0906 19-35-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18073, current rewards: -18.28924, mean: -0.16627
[32m[0906 19-35-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18176, current rewards: -12.03661, mean: -0.07523
[32m[0906 19-35-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18300, current rewards: -5.78394, mean: -0.02754
[32m[0906 19-35-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18364, current rewards: 0.46460, mean: 0.00179
[32m[0906 19-36-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18391, current rewards: -16.31650, mean: -0.05263
[32m[0906 19-36-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18421, current rewards: -10.38246, mean: -0.02884
[32m[0906 19-36-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18426, current rewards: -5.51446, mean: -0.01345
[32m[0906 19-36-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18431, current rewards: -3.09982, mean: -0.00674
[32m[0906 19-36-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18439, current rewards: -11.16811, mean: -0.02190
[32m[0906 19-36-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18447, current rewards: -61.16811, mean: -0.10923
[32m[0906 19-37-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18452, current rewards: -111.16811, mean: -0.18224
[32m[0906 19-37-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18465, current rewards: -161.16811, mean: -0.24419
[32m[0906 19-37-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18469, current rewards: -211.16811, mean: -0.29742
[32m[0906 19-37-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18471, current rewards: -261.16811, mean: -0.34364
[32m[0906 19-37-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18472, current rewards: -311.16811, mean: -0.38416
[32m[0906 19-37-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18477, current rewards: -361.16811, mean: -0.41996
[32m[0906 19-37-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18488, current rewards: -411.16811, mean: -0.45183
[32m[0906 19-38-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18495, current rewards: -461.16811, mean: -0.48038
[32m[0906 19-38-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18493, current rewards: -511.16811, mean: -0.50611
[32m[0906 19-38-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18495, current rewards: -561.16811, mean: -0.52940
[32m[0906 19-38-34 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18495, current rewards: -611.16811, mean: -0.55060
[32m[0906 19-38-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18497, current rewards: -661.16811, mean: -0.56997
[32m[0906 19-38-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18497, current rewards: -711.16811, mean: -0.58774
[32m[0906 19-39-02 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18499, current rewards: -761.16811, mean: -0.60410
[32m[0906 19-39-11 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18502, current rewards: -811.16811, mean: -0.61921
[32m[0906 19-39-20 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18502, current rewards: -861.16811, mean: -0.63321
[32m[0906 19-39-29 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18501, current rewards: -911.16811, mean: -0.64622
[32m[0906 19-39-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18502, current rewards: -961.16811, mean: -0.65833
[32m[0906 19-39-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18502, current rewards: -1011.16811, mean: -0.66965
[32m[0906 19-39-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18495, current rewards: -1061.16811, mean: -0.68024
[32m[0906 19-40-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18488, current rewards: -1111.16811, mean: -0.69017
[32m[0906 19-40-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18476, current rewards: -1161.16811, mean: -0.69950
[32m[0906 19-40-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18448, current rewards: -1211.16811, mean: -0.70829
[32m[0906 19-40-33 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18422, current rewards: -1261.16811, mean: -0.71657
[32m[0906 19-40-42 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18397, current rewards: -1311.16811, mean: -0.72440
[32m[0906 19-40-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18375, current rewards: -1361.16811, mean: -0.73181
[32m[0906 19-40-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18352, current rewards: -1411.16811, mean: -0.73883
[32m[0906 19-41-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18331, current rewards: -1461.16811, mean: -0.74549
[32m[0906 19-41-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18310, current rewards: -1511.16811, mean: -0.75182
[32m[0906 19-41-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18296, current rewards: -1561.16811, mean: -0.75785
[32m[0906 19-41-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18291, current rewards: -1611.16811, mean: -0.76359
[32m[0906 19-41-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18286, current rewards: -1661.16811, mean: -0.76906
[32m[0906 19-41-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18291, current rewards: -1711.16811, mean: -0.77428
[32m[0906 19-42-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18298, current rewards: -1761.16811, mean: -0.77928
[32m[0906 19-42-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18305, current rewards: -1811.16811, mean: -0.78406
[32m[0906 19-42-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18305, current rewards: -1861.16811, mean: -0.78863
[32m[0906 19-42-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18300, current rewards: -1911.16811, mean: -0.79302
[32m[0906 19-42-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18295, current rewards: -1961.16811, mean: -0.79722
[32m[0906 19-42-46 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0906 19-42-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-42-46 @MBExp.py:227][0m Rewards obtained: [-2001.168108909902], Lows: [22], Highs: [2011], Total time: 19784.75190599999
[32m[0906 19-44-16 @MBExp.py:144][0m ####################################################################
[32m[0906 19-44-16 @MBExp.py:145][0m Starting training iteration 44.
[32m[0906 19-44-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18180, current rewards: 0.62621, mean: 0.06262
[32m[0906 19-44-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18166, current rewards: 5.71040, mean: 0.09517
[32m[0906 19-44-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18118, current rewards: 11.26780, mean: 0.10243
[32m[0906 19-44-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18236, current rewards: 16.82444, mean: 0.10515
[32m[0906 19-44-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18297, current rewards: 22.37854, mean: 0.10656
[32m[0906 19-45-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18349, current rewards: 27.93336, mean: 0.10744
[32m[0906 19-45-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18379, current rewards: 33.48849, mean: 0.10803
[32m[0906 19-45-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18407, current rewards: 39.04902, mean: 0.10847
[32m[0906 19-45-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18420, current rewards: 44.17469, mean: 0.10774
[32m[0906 19-45-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18430, current rewards: 49.66644, mean: 0.10797
[32m[0906 19-45-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18445, current rewards: 55.15704, mean: 0.10815
[32m[0906 19-45-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18454, current rewards: 60.64828, mean: 0.10830
[32m[0906 19-46-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18458, current rewards: 66.14299, mean: 0.10843
[32m[0906 19-46-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18473, current rewards: 71.63054, mean: 0.10853
[32m[0906 19-46-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18485, current rewards: 77.12582, mean: 0.10863
[32m[0906 19-46-36 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18490, current rewards: 61.97080, mean: 0.08154
[32m[0906 19-46-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18491, current rewards: 47.84602, mean: 0.05907
[32m[0906 19-46-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18487, current rewards: 56.61005, mean: 0.06583
[32m[0906 19-47-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18493, current rewards: 65.50204, mean: 0.07198
[32m[0906 19-47-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18490, current rewards: 74.37089, mean: 0.07747
[32m[0906 19-47-23 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18492, current rewards: 83.24731, mean: 0.08242
[32m[0906 19-47-32 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18491, current rewards: 92.12972, mean: 0.08691
[32m[0906 19-47-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18492, current rewards: 101.03907, mean: 0.09103
[32m[0906 19-47-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18492, current rewards: 109.90607, mean: 0.09475
[32m[0906 19-48-00 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18492, current rewards: 118.59033, mean: 0.09801
[32m[0906 19-48-09 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18492, current rewards: 103.40930, mean: 0.08207
[32m[0906 19-48-18 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18488, current rewards: 109.60366, mean: 0.08367
[32m[0906 19-48-27 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18494, current rewards: 115.71499, mean: 0.08508
[32m[0906 19-48-37 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18496, current rewards: 121.82419, mean: 0.08640
[32m[0906 19-48-46 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18495, current rewards: 127.93378, mean: 0.08763
[32m[0906 19-48-55 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18494, current rewards: 134.04276, mean: 0.08877
[32m[0906 19-49-04 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18480, current rewards: 140.15058, mean: 0.08984
[32m[0906 19-49-13 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18467, current rewards: 146.54250, mean: 0.09102
[32m[0906 19-49-22 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18454, current rewards: 152.86406, mean: 0.09209
[32m[0906 19-49-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18427, current rewards: 158.88849, mean: 0.09292
[32m[0906 19-49-40 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18403, current rewards: 165.29465, mean: 0.09392
[32m[0906 19-49-49 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18379, current rewards: 171.63433, mean: 0.09483
[32m[0906 19-49-57 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18356, current rewards: 177.98093, mean: 0.09569
[32m[0906 19-50-06 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18335, current rewards: 184.32353, mean: 0.09650
[32m[0906 19-50-15 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18314, current rewards: 190.67167, mean: 0.09728
[32m[0906 19-50-24 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18294, current rewards: 196.99089, mean: 0.09801
[32m[0906 19-50-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18284, current rewards: 203.14495, mean: 0.09861
[32m[0906 19-50-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18281, current rewards: 198.98450, mean: 0.09431
[32m[0906 19-50-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18277, current rewards: 193.63375, mean: 0.08965
[32m[0906 19-51-00 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18281, current rewards: 198.91966, mean: 0.09001
[32m[0906 19-51-10 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18291, current rewards: 204.20857, mean: 0.09036
[32m[0906 19-51-19 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18297, current rewards: 209.49813, mean: 0.09069
[32m[0906 19-51-28 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18295, current rewards: 214.78503, mean: 0.09101
[32m[0906 19-51-37 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18291, current rewards: 220.07224, mean: 0.09132
[32m[0906 19-51-46 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18287, current rewards: 225.36531, mean: 0.09161
[32m[0906 19-51-53 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 19-51-53 @Agent.py:118][0m Rollout length: 2510
[32m[0906 19-51-53 @MBExp.py:227][0m Rewards obtained: [229.59441698667106], Lows: [35], Highs: [12], Total time: 20242.55984699999
[32m[0906 19-53-25 @MBExp.py:144][0m ####################################################################
[32m[0906 19-53-25 @MBExp.py:145][0m Starting training iteration 45.
[32m[0906 19-53-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18214, current rewards: -10.00000, mean: -1.00000
[32m[0906 19-53-36 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18092, current rewards: -5.91033, mean: -0.09851
[32m[0906 19-53-45 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18095, current rewards: -0.59102, mean: -0.00537
[32m[0906 19-53-54 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18255, current rewards: 4.72972, mean: 0.02956
[32m[0906 19-54-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18337, current rewards: 10.04766, mean: 0.04785
[32m[0906 19-54-13 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18376, current rewards: 15.36514, mean: 0.05910
[32m[0906 19-54-22 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18401, current rewards: 20.68311, mean: 0.06672
[32m[0906 19-54-31 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18431, current rewards: 25.38558, mean: 0.07052
[32m[0906 19-54-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18462, current rewards: 21.18600, mean: 0.05167
[32m[0906 19-54-50 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18484, current rewards: 26.26303, mean: 0.05709
[32m[0906 19-54-59 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18493, current rewards: 31.33198, mean: 0.06144
[32m[0906 19-55-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18500, current rewards: 36.40580, mean: 0.06501
[32m[0906 19-55-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18501, current rewards: 41.47156, mean: 0.06799
[32m[0906 19-55-27 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18505, current rewards: 46.55290, mean: 0.07053
[32m[0906 19-55-36 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18505, current rewards: 51.62313, mean: 0.07271
[32m[0906 19-55-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18510, current rewards: 56.98230, mean: 0.07498
[32m[0906 19-55-55 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18510, current rewards: 62.04335, mean: 0.07660
[32m[0906 19-56-04 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18514, current rewards: 67.12589, mean: 0.07805
[32m[0906 19-56-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18514, current rewards: 59.59102, mean: 0.06548
[32m[0906 19-56-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18511, current rewards: 55.12994, mean: 0.05743
[32m[0906 19-56-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18508, current rewards: 60.61328, mean: 0.06001
[32m[0906 19-56-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18511, current rewards: 66.09656, mean: 0.06236
[32m[0906 19-56-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18517, current rewards: 71.58178, mean: 0.06449
[32m[0906 19-57-00 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18514, current rewards: 78.70353, mean: 0.06785
[32m[0906 19-57-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18515, current rewards: 86.93219, mean: 0.07184
[32m[0906 19-57-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18514, current rewards: 36.93219, mean: 0.02931
[32m[0906 19-57-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18517, current rewards: -13.06781, mean: -0.00998
[32m[0906 19-57-37 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18517, current rewards: -63.06781, mean: -0.04637
[32m[0906 19-57-46 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18517, current rewards: -113.06781, mean: -0.08019
[32m[0906 19-57-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18519, current rewards: -163.06781, mean: -0.11169
[32m[0906 19-58-05 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18514, current rewards: -213.06781, mean: -0.14110
[32m[0906 19-58-14 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18501, current rewards: -263.06781, mean: -0.16863
[32m[0906 19-58-23 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18488, current rewards: -313.06781, mean: -0.19445
[32m[0906 19-58-32 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18472, current rewards: -363.06781, mean: -0.21872
[32m[0906 19-58-41 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18444, current rewards: -413.06781, mean: -0.24156
[32m[0906 19-58-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18420, current rewards: -463.06781, mean: -0.26311
[32m[0906 19-58-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18398, current rewards: -513.06781, mean: -0.28346
[32m[0906 19-59-07 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18376, current rewards: -563.06781, mean: -0.30272
[32m[0906 19-59-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18353, current rewards: -613.06781, mean: -0.32098
[32m[0906 19-59-25 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18333, current rewards: -663.06781, mean: -0.33830
[32m[0906 19-59-33 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18313, current rewards: -713.06781, mean: -0.35476
[32m[0906 19-59-42 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18302, current rewards: -763.06781, mean: -0.37042
[32m[0906 19-59-51 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18298, current rewards: -813.06781, mean: -0.38534
[32m[0906 20-00-01 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18294, current rewards: -863.06781, mean: -0.39957
[32m[0906 20-00-10 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18298, current rewards: -913.06781, mean: -0.41315
[32m[0906 20-00-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18306, current rewards: -963.06781, mean: -0.42614
[32m[0906 20-00-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18311, current rewards: -1013.06781, mean: -0.43856
[32m[0906 20-00-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18310, current rewards: -1063.06781, mean: -0.45045
[32m[0906 20-00-47 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18306, current rewards: -1113.06781, mean: -0.46185
[32m[0906 20-00-56 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18302, current rewards: -1163.06781, mean: -0.47279
[32m[0906 20-01-03 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0906 20-01-03 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-01-03 @MBExp.py:227][0m Rewards obtained: [-1203.0678123398782], Lows: [11], Highs: [1312], Total time: 20700.82230899999
[32m[0906 20-02-37 @MBExp.py:144][0m ####################################################################
[32m[0906 20-02-37 @MBExp.py:145][0m Starting training iteration 46.
[32m[0906 20-02-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18305, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-02-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18141, current rewards: -5.19365, mean: -0.08656
[32m[0906 20-02-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18122, current rewards: 0.85302, mean: 0.00775
[32m[0906 20-03-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18319, current rewards: 6.88054, mean: 0.04300
[32m[0906 20-03-15 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18417, current rewards: 12.91532, mean: 0.06150
[32m[0906 20-03-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18450, current rewards: 18.94007, mean: 0.07285
[32m[0906 20-03-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18469, current rewards: 24.97050, mean: 0.08055
[32m[0906 20-03-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18479, current rewards: 33.19732, mean: 0.09221
[32m[0906 20-03-53 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18483, current rewards: 38.87375, mean: 0.09481
[32m[0906 20-04-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18479, current rewards: 44.58109, mean: 0.09692
[32m[0906 20-04-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18487, current rewards: 50.28970, mean: 0.09861
[32m[0906 20-04-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18494, current rewards: 55.99562, mean: 0.09999
[32m[0906 20-04-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18490, current rewards: 61.71030, mean: 0.10116
[32m[0906 20-04-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18493, current rewards: 67.42190, mean: 0.10215
[32m[0906 20-04-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18499, current rewards: 61.99951, mean: 0.08732
[32m[0906 20-04-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18499, current rewards: 68.50369, mean: 0.09014
[32m[0906 20-05-07 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18505, current rewards: 74.80011, mean: 0.09235
[32m[0906 20-05-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18518, current rewards: 81.03104, mean: 0.09422
[32m[0906 20-05-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18520, current rewards: 87.26678, mean: 0.09590
[32m[0906 20-05-35 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18524, current rewards: 93.49874, mean: 0.09739
[32m[0906 20-05-44 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18522, current rewards: 99.73191, mean: 0.09874
[32m[0906 20-05-53 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18523, current rewards: 105.96701, mean: 0.09997
[32m[0906 20-06-03 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18523, current rewards: 112.19860, mean: 0.10108
[32m[0906 20-06-12 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18522, current rewards: 96.75707, mean: 0.08341
[32m[0906 20-06-21 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18522, current rewards: 102.48543, mean: 0.08470
[32m[0906 20-06-30 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18520, current rewards: 108.26993, mean: 0.08593
[32m[0906 20-06-40 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18517, current rewards: 114.04817, mean: 0.08706
[32m[0906 20-06-49 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18512, current rewards: 119.83509, mean: 0.08811
[32m[0906 20-06-58 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18512, current rewards: 125.61699, mean: 0.08909
[32m[0906 20-07-07 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18510, current rewards: 131.40350, mean: 0.09000
[32m[0906 20-07-16 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18501, current rewards: 137.18852, mean: 0.09085
[32m[0906 20-07-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18492, current rewards: 142.93086, mean: 0.09162
[32m[0906 20-07-35 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18477, current rewards: 148.54659, mean: 0.09226
[32m[0906 20-07-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18458, current rewards: 133.10543, mean: 0.08018
[32m[0906 20-07-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18431, current rewards: 138.73910, mean: 0.08113
[32m[0906 20-08-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18404, current rewards: 144.37687, mean: 0.08203
[32m[0906 20-08-10 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18381, current rewards: 150.01352, mean: 0.08288
[32m[0906 20-08-19 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18357, current rewards: 155.64944, mean: 0.08368
[32m[0906 20-08-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18335, current rewards: 159.17085, mean: 0.08334
[32m[0906 20-08-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18314, current rewards: 146.35241, mean: 0.07467
[32m[0906 20-08-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18295, current rewards: 151.29504, mean: 0.07527
[32m[0906 20-08-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18287, current rewards: 156.68175, mean: 0.07606
[32m[0906 20-09-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18285, current rewards: 162.07271, mean: 0.07681
[32m[0906 20-09-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18280, current rewards: 167.46510, mean: 0.07753
[32m[0906 20-09-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18283, current rewards: 172.85418, mean: 0.07821
[32m[0906 20-09-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18291, current rewards: 178.24694, mean: 0.07887
[32m[0906 20-09-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18297, current rewards: 172.74523, mean: 0.07478
[32m[0906 20-09-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18297, current rewards: 178.42261, mean: 0.07560
[32m[0906 20-09-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18292, current rewards: 185.92430, mean: 0.07715
[32m[0906 20-10-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18288, current rewards: 191.45263, mean: 0.07783
[32m[0906 20-10-14 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 20-10-14 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-10-14 @MBExp.py:227][0m Rewards obtained: [195.87741259113454], Lows: [30], Highs: [30], Total time: 21158.65619899999
[32m[0906 20-11-50 @MBExp.py:144][0m ####################################################################
[32m[0906 20-11-50 @MBExp.py:145][0m Starting training iteration 47.
[32m[0906 20-11-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18057, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-12-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18026, current rewards: -6.00623, mean: -0.10010
[32m[0906 20-12-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18044, current rewards: -0.59422, mean: -0.00540
[32m[0906 20-12-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18217, current rewards: 4.82844, mean: 0.03018
[32m[0906 20-12-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18323, current rewards: 10.24868, mean: 0.04880
[32m[0906 20-12-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18363, current rewards: 15.66512, mean: 0.06025
[32m[0906 20-12-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18382, current rewards: 20.94593, mean: 0.06757
[32m[0906 20-12-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18402, current rewards: 25.96333, mean: 0.07212
[32m[0906 20-13-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18412, current rewards: 31.27994, mean: 0.07629
[32m[0906 20-13-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18424, current rewards: 36.58929, mean: 0.07954
[32m[0906 20-13-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18429, current rewards: 41.89661, mean: 0.08215
[32m[0906 20-13-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18440, current rewards: 47.20002, mean: 0.08429
[32m[0906 20-13-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18455, current rewards: 31.41364, mean: 0.05150
[32m[0906 20-13-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18461, current rewards: 36.44728, mean: 0.05522
[32m[0906 20-14-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18470, current rewards: 41.64157, mean: 0.05865
[32m[0906 20-14-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18475, current rewards: 47.67477, mean: 0.06273
[32m[0906 20-14-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18482, current rewards: 52.95264, mean: 0.06537
[32m[0906 20-14-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18489, current rewards: 58.23215, mean: 0.06771
[32m[0906 20-14-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18491, current rewards: 63.50610, mean: 0.06979
[32m[0906 20-14-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18491, current rewards: 57.72682, mean: 0.06013
[32m[0906 20-14-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18495, current rewards: 63.00674, mean: 0.06238
[32m[0906 20-15-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18494, current rewards: 68.33963, mean: 0.06447
[32m[0906 20-15-16 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18495, current rewards: 73.67254, mean: 0.06637
[32m[0906 20-15-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18495, current rewards: 80.18958, mean: 0.06913
[32m[0906 20-15-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18498, current rewards: 65.50627, mean: 0.05414
[32m[0906 20-15-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18506, current rewards: 74.08015, mean: 0.05879
[32m[0906 20-15-53 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18509, current rewards: 81.34593, mean: 0.06210
[32m[0906 20-16-02 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18507, current rewards: 88.61213, mean: 0.06516
[32m[0906 20-16-11 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18506, current rewards: 84.42550, mean: 0.05988
[32m[0906 20-16-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18503, current rewards: 87.43244, mean: 0.05989
[32m[0906 20-16-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18488, current rewards: 92.93064, mean: 0.06154
[32m[0906 20-16-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18475, current rewards: 98.25648, mean: 0.06298
[32m[0906 20-16-48 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18462, current rewards: 103.72950, mean: 0.06443
[32m[0906 20-16-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18438, current rewards: 109.20144, mean: 0.06578
[32m[0906 20-17-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18411, current rewards: 114.67849, mean: 0.06706
[32m[0906 20-17-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18386, current rewards: 120.15810, mean: 0.06827
[32m[0906 20-17-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18363, current rewards: 114.33490, mean: 0.06317
[32m[0906 20-17-32 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18341, current rewards: 119.32379, mean: 0.06415
[32m[0906 20-17-40 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18318, current rewards: 124.31761, mean: 0.06509
[32m[0906 20-17-49 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18302, current rewards: 128.75244, mean: 0.06569
[32m[0906 20-17-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18283, current rewards: 133.53803, mean: 0.06644
[32m[0906 20-18-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18278, current rewards: 138.45391, mean: 0.06721
[32m[0906 20-18-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18273, current rewards: 143.36794, mean: 0.06795
[32m[0906 20-18-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18269, current rewards: 148.28210, mean: 0.06865
[32m[0906 20-18-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18271, current rewards: 153.20019, mean: 0.06932
[32m[0906 20-18-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18279, current rewards: 158.11578, mean: 0.06996
[32m[0906 20-18-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18286, current rewards: 163.03359, mean: 0.07058
[32m[0906 20-19-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18287, current rewards: 167.94820, mean: 0.07116
[32m[0906 20-19-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18283, current rewards: 172.76582, mean: 0.07169
[32m[0906 20-19-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18278, current rewards: 177.66406, mean: 0.07222
[32m[0906 20-19-28 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0906 20-19-28 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-19-28 @MBExp.py:227][0m Rewards obtained: [181.58524864613918], Lows: [20], Highs: [43], Total time: 21616.28150399999
[32m[0906 20-21-05 @MBExp.py:144][0m ####################################################################
[32m[0906 20-21-05 @MBExp.py:145][0m Starting training iteration 48.
[32m[0906 20-21-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17994, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-21-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18066, current rewards: -5.78000, mean: -0.09633
[32m[0906 20-21-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18061, current rewards: -0.23841, mean: -0.00217
[32m[0906 20-21-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18251, current rewards: 5.28815, mean: 0.03305
[32m[0906 20-21-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18362, current rewards: 10.82031, mean: 0.05153
[32m[0906 20-21-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18381, current rewards: 16.34784, mean: 0.06288
[32m[0906 20-22-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18439, current rewards: 22.79583, mean: 0.07353
[32m[0906 20-22-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18457, current rewards: 29.71556, mean: 0.08254
[32m[0906 20-22-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18465, current rewards: 35.23789, mean: 0.08595
[32m[0906 20-22-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18468, current rewards: 40.75636, mean: 0.08860
[32m[0906 20-22-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18473, current rewards: 46.27450, mean: 0.09073
[32m[0906 20-22-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18484, current rewards: 29.67695, mean: 0.05299
[32m[0906 20-22-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18485, current rewards: 35.72221, mean: 0.05856
[32m[0906 20-23-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18487, current rewards: 41.76748, mean: 0.06328
[32m[0906 20-23-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18486, current rewards: 47.81275, mean: 0.06734
[32m[0906 20-23-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18484, current rewards: 33.86463, mean: 0.04456
[32m[0906 20-23-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18479, current rewards: -16.13537, mean: -0.01992
[32m[0906 20-23-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18478, current rewards: -66.13537, mean: -0.07690
[32m[0906 20-23-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18474, current rewards: -116.13537, mean: -0.12762
[32m[0906 20-24-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18477, current rewards: -166.13537, mean: -0.17306
[32m[0906 20-24-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18481, current rewards: -216.13537, mean: -0.21400
[32m[0906 20-24-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18483, current rewards: -266.13537, mean: -0.25107
[32m[0906 20-24-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18484, current rewards: -316.13537, mean: -0.28481
[32m[0906 20-24-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18484, current rewards: -366.13537, mean: -0.31563
[32m[0906 20-24-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18486, current rewards: -416.13537, mean: -0.34391
[32m[0906 20-24-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18484, current rewards: -466.13537, mean: -0.36995
[32m[0906 20-25-07 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18486, current rewards: -516.13537, mean: -0.39400
[32m[0906 20-25-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18483, current rewards: -566.13537, mean: -0.41628
[32m[0906 20-25-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18481, current rewards: -616.13537, mean: -0.43698
[32m[0906 20-25-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18472, current rewards: -666.13537, mean: -0.45626
[32m[0906 20-25-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18461, current rewards: -716.13537, mean: -0.47426
[32m[0906 20-25-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18449, current rewards: -766.13537, mean: -0.49111
[32m[0906 20-26-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18437, current rewards: -816.13537, mean: -0.50692
[32m[0906 20-26-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18413, current rewards: -866.13537, mean: -0.52177
[32m[0906 20-26-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18389, current rewards: -916.13537, mean: -0.53575
[32m[0906 20-26-29 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18365, current rewards: -966.13537, mean: -0.54894
[32m[0906 20-26-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18342, current rewards: -1016.13537, mean: -0.56140
[32m[0906 20-26-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18319, current rewards: -1066.13537, mean: -0.57319
[32m[0906 20-26-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18299, current rewards: -1116.13537, mean: -0.58436
[32m[0906 20-27-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18281, current rewards: -1166.13537, mean: -0.59497
[32m[0906 20-27-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18265, current rewards: -1216.13537, mean: -0.60504
[32m[0906 20-27-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18260, current rewards: -1266.13537, mean: -0.61463
[32m[0906 20-27-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18254, current rewards: -1316.13537, mean: -0.62376
[32m[0906 20-27-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18250, current rewards: -1366.13537, mean: -0.63247
[32m[0906 20-27-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18252, current rewards: -1416.13537, mean: -0.64079
[32m[0906 20-27-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18260, current rewards: -1466.13537, mean: -0.64873
[32m[0906 20-28-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18266, current rewards: -1516.13537, mean: -0.65634
[32m[0906 20-28-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18269, current rewards: -1566.13537, mean: -0.66362
[32m[0906 20-28-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18266, current rewards: -1616.13537, mean: -0.67060
[32m[0906 20-28-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18262, current rewards: -1666.13537, mean: -0.67729
[32m[0906 20-28-42 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0906 20-28-42 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-28-42 @MBExp.py:227][0m Rewards obtained: [-1706.1353700453833], Lows: [11], Highs: [1768], Total time: 22073.458293999993
[32m[0906 20-30-22 @MBExp.py:144][0m ####################################################################
[32m[0906 20-30-22 @MBExp.py:145][0m Starting training iteration 49.
[32m[0906 20-30-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18084, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-30-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18174, current rewards: -3.44187, mean: -0.05736
[32m[0906 20-30-42 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18169, current rewards: 2.04417, mean: 0.01858
[32m[0906 20-30-51 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18297, current rewards: 7.53027, mean: 0.04706
[32m[0906 20-31-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18363, current rewards: 13.01754, mean: 0.06199
[32m[0906 20-31-10 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18415, current rewards: 18.50341, mean: 0.07117
[32m[0906 20-31-19 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18446, current rewards: 23.99178, mean: 0.07739
[32m[0906 20-31-28 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18458, current rewards: 30.68451, mean: 0.08523
[32m[0906 20-31-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18470, current rewards: 36.27893, mean: 0.08849
[32m[0906 20-31-47 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18475, current rewards: 30.82107, mean: 0.06700
[32m[0906 20-31-56 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18477, current rewards: 36.59550, mean: 0.07176
[32m[0906 20-32-05 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18480, current rewards: 42.36630, mean: 0.07565
[32m[0906 20-32-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18485, current rewards: 48.14051, mean: 0.07892
[32m[0906 20-32-24 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18482, current rewards: 53.91703, mean: 0.08169
[32m[0906 20-32-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18491, current rewards: 59.69073, mean: 0.08407
[32m[0906 20-32-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18499, current rewards: 65.08900, mean: 0.08564
[32m[0906 20-32-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18507, current rewards: 70.78350, mean: 0.08739
[32m[0906 20-33-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18508, current rewards: 76.47342, mean: 0.08892
[32m[0906 20-33-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18508, current rewards: 70.90667, mean: 0.07792
[32m[0906 20-33-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18509, current rewards: 76.75814, mean: 0.07996
[32m[0906 20-33-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18508, current rewards: 82.61205, mean: 0.08179
[32m[0906 20-33-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18508, current rewards: 88.45779, mean: 0.08345
[32m[0906 20-33-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18507, current rewards: 94.31193, mean: 0.08497
[32m[0906 20-33-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18506, current rewards: 99.32565, mean: 0.08563
[32m[0906 20-34-06 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18505, current rewards: 105.19409, mean: 0.08694
[32m[0906 20-34-15 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18504, current rewards: 111.01877, mean: 0.08811
[32m[0906 20-34-24 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18503, current rewards: 116.84558, mean: 0.08920
[32m[0906 20-34-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18502, current rewards: 122.66981, mean: 0.09020
[32m[0906 20-34-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18504, current rewards: 128.50234, mean: 0.09114
[32m[0906 20-34-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18489, current rewards: 134.33283, mean: 0.09201
[32m[0906 20-35-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18474, current rewards: 140.16092, mean: 0.09282
[32m[0906 20-35-10 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18462, current rewards: 146.18433, mean: 0.09371
[32m[0906 20-35-19 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18449, current rewards: 133.11482, mean: 0.08268
[32m[0906 20-35-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18421, current rewards: 139.00835, mean: 0.08374
[32m[0906 20-35-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18395, current rewards: 145.26353, mean: 0.08495
[32m[0906 20-35-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18370, current rewards: 151.53314, mean: 0.08610
[32m[0906 20-35-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18346, current rewards: 157.78581, mean: 0.08717
[32m[0906 20-36-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18325, current rewards: 164.04906, mean: 0.08820
[32m[0906 20-36-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18304, current rewards: 170.30799, mean: 0.08917
[32m[0906 20-36-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18285, current rewards: 176.57367, mean: 0.09009
[32m[0906 20-36-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18270, current rewards: 182.27170, mean: 0.09068
[32m[0906 20-36-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18267, current rewards: 188.60349, mean: 0.09156
[32m[0906 20-36-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18263, current rewards: 183.67504, mean: 0.08705
[32m[0906 20-36-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18259, current rewards: 189.28658, mean: 0.08763
[32m[0906 20-37-06 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18260, current rewards: 194.88485, mean: 0.08818
[32m[0906 20-37-15 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18269, current rewards: 200.47660, mean: 0.08871
[32m[0906 20-37-24 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18275, current rewards: 206.07474, mean: 0.08921
[32m[0906 20-37-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18276, current rewards: 211.66475, mean: 0.08969
[32m[0906 20-37-43 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18272, current rewards: 219.24798, mean: 0.09097
[32m[0906 20-37-52 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18269, current rewards: 225.09901, mean: 0.09150
[32m[0906 20-37-59 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0906 20-37-59 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-37-59 @MBExp.py:227][0m Rewards obtained: [229.77301210670132], Lows: [10], Highs: [40], Total time: 22530.829782999994
[32m[0906 20-39-40 @MBExp.py:144][0m ####################################################################
[32m[0906 20-39-40 @MBExp.py:145][0m Starting training iteration 50.
[32m[0906 20-39-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18020, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-39-51 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18066, current rewards: -6.33430, mean: -0.10557
[32m[0906 20-40-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18095, current rewards: -0.63244, mean: -0.00575
[32m[0906 20-40-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18297, current rewards: 5.06999, mean: 0.03169
[32m[0906 20-40-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18355, current rewards: 10.76642, mean: 0.05127
[32m[0906 20-40-28 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18393, current rewards: 16.46470, mean: 0.06333
[32m[0906 20-40-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18412, current rewards: 22.16309, mean: 0.07149
[32m[0906 20-40-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18434, current rewards: 28.25738, mean: 0.07849
[32m[0906 20-40-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18470, current rewards: 33.96789, mean: 0.08285
[32m[0906 20-41-05 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18482, current rewards: 39.66672, mean: 0.08623
[32m[0906 20-41-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18486, current rewards: 45.36970, mean: 0.08896
[32m[0906 20-41-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18491, current rewards: 51.06876, mean: 0.09119
[32m[0906 20-41-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18491, current rewards: 56.76942, mean: 0.09306
[32m[0906 20-41-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18493, current rewards: 62.46757, mean: 0.09465
[32m[0906 20-41-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18501, current rewards: 68.16924, mean: 0.09601
[32m[0906 20-42-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18499, current rewards: 53.42653, mean: 0.07030
[32m[0906 20-42-12 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18694, current rewards: 59.32902, mean: 0.07325
[32m[0906 20-42-21 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18696, current rewards: 65.06321, mean: 0.07565
[32m[0906 20-42-31 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18681, current rewards: 70.79763, mean: 0.07780
[32m[0906 20-42-40 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18677, current rewards: 76.53219, mean: 0.07972
[32m[0906 20-42-49 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18668, current rewards: 82.26404, mean: 0.08145
[32m[0906 20-42-58 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18660, current rewards: 87.99807, mean: 0.08302
[32m[0906 20-43-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18654, current rewards: 93.72910, mean: 0.08444
[32m[0906 20-43-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18647, current rewards: 99.23473, mean: 0.08555
[32m[0906 20-43-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18641, current rewards: 104.17527, mean: 0.08610
[32m[0906 20-43-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18636, current rewards: 109.82339, mean: 0.08716
[32m[0906 20-43-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18638, current rewards: 105.95866, mean: 0.08088
[32m[0906 20-43-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18631, current rewards: 111.25286, mean: 0.08180
[32m[0906 20-44-03 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18619, current rewards: 116.48880, mean: 0.08262
[32m[0906 20-44-12 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18599, current rewards: 121.71730, mean: 0.08337
[32m[0906 20-44-21 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18582, current rewards: 126.95409, mean: 0.08408
[32m[0906 20-44-30 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18564, current rewards: 132.19203, mean: 0.08474
[32m[0906 20-44-39 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18543, current rewards: 139.28724, mean: 0.08651
[32m[0906 20-44-48 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18511, current rewards: 149.23178, mean: 0.08990
[32m[0906 20-44-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18481, current rewards: 154.58358, mean: 0.09040
[32m[0906 20-45-06 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18454, current rewards: 159.93081, mean: 0.09087
[32m[0906 20-45-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18428, current rewards: 165.27497, mean: 0.09131
[32m[0906 20-45-23 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18403, current rewards: 170.62108, mean: 0.09173
[32m[0906 20-45-32 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18379, current rewards: 175.96632, mean: 0.09213
[32m[0906 20-45-41 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18355, current rewards: 181.31354, mean: 0.09251
[32m[0906 20-45-50 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18343, current rewards: 186.41694, mean: 0.09274
[32m[0906 20-45-59 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18337, current rewards: 191.67037, mean: 0.09304
[32m[0906 20-46-08 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18331, current rewards: 196.95887, mean: 0.09335
[32m[0906 20-46-17 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18325, current rewards: 181.72205, mean: 0.08413
[32m[0906 20-46-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18322, current rewards: 187.29809, mean: 0.08475
[32m[0906 20-46-35 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18330, current rewards: 192.86934, mean: 0.08534
[32m[0906 20-46-44 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18334, current rewards: 198.44674, mean: 0.08591
[32m[0906 20-46-54 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18334, current rewards: 204.01403, mean: 0.08645
[32m[0906 20-47-03 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18330, current rewards: 209.60191, mean: 0.08697
[32m[0906 20-47-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18325, current rewards: 215.24341, mean: 0.08750
[32m[0906 20-47-19 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0906 20-47-19 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-47-19 @MBExp.py:227][0m Rewards obtained: [219.70849899248762], Lows: [20], Highs: [21], Total time: 22989.614286999993
[32m[0906 20-49-02 @MBExp.py:144][0m ####################################################################
[32m[0906 20-49-02 @MBExp.py:145][0m Starting training iteration 51.
[32m[0906 20-49-04 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18070, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-49-13 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18098, current rewards: -5.84740, mean: -0.09746
[32m[0906 20-49-22 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18129, current rewards: -0.17694, mean: -0.00161
[32m[0906 20-49-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18311, current rewards: 5.49053, mean: 0.03432
[32m[0906 20-49-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18370, current rewards: 11.15495, mean: 0.05312
[32m[0906 20-49-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18402, current rewards: 16.82954, mean: 0.06473
[32m[0906 20-50-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18442, current rewards: 22.50179, mean: 0.07259
[32m[0906 20-50-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18457, current rewards: 21.72106, mean: 0.06034
[32m[0906 20-50-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18461, current rewards: 12.39745, mean: 0.03024
[32m[0906 20-50-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18455, current rewards: 17.97825, mean: 0.03908
[32m[0906 20-50-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18470, current rewards: 23.55945, mean: 0.04619
[32m[0906 20-50-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18475, current rewards: 29.14102, mean: 0.05204
[32m[0906 20-50-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18474, current rewards: 34.72120, mean: 0.05692
[32m[0906 20-51-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18473, current rewards: 40.30158, mean: 0.06106
[32m[0906 20-51-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18465, current rewards: 33.51269, mean: 0.04720
[32m[0906 20-51-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18465, current rewards: 39.01650, mean: 0.05134
[32m[0906 20-51-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18470, current rewards: 44.58231, mean: 0.05504
[32m[0906 20-51-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18468, current rewards: 50.14008, mean: 0.05830
[32m[0906 20-51-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18466, current rewards: 55.69815, mean: 0.06121
[32m[0906 20-52-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18473, current rewards: 61.25678, mean: 0.06381
[32m[0906 20-52-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18478, current rewards: 66.81724, mean: 0.06616
[32m[0906 20-52-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18480, current rewards: 72.37694, mean: 0.06828
[32m[0906 20-52-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18476, current rewards: 78.61142, mean: 0.07082
[32m[0906 20-52-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18475, current rewards: 84.51189, mean: 0.07286
[32m[0906 20-52-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18471, current rewards: 91.09821, mean: 0.07529
[32m[0906 20-52-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18470, current rewards: 97.74183, mean: 0.07757
[32m[0906 20-53-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18466, current rewards: 104.37212, mean: 0.07967
[32m[0906 20-53-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18467, current rewards: 111.00297, mean: 0.08162
[32m[0906 20-53-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18455, current rewards: 117.63945, mean: 0.08343
[32m[0906 20-53-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18440, current rewards: 124.26453, mean: 0.08511
[32m[0906 20-53-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18427, current rewards: 130.89894, mean: 0.08669
[32m[0906 20-53-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18413, current rewards: 139.15058, mean: 0.08920
[32m[0906 20-53-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18392, current rewards: 147.30404, mean: 0.09149
[32m[0906 20-54-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18367, current rewards: 154.25622, mean: 0.09293
[32m[0906 20-54-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18341, current rewards: 161.21061, mean: 0.09428
[32m[0906 20-54-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18316, current rewards: 146.32216, mean: 0.08314
[32m[0906 20-54-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18294, current rewards: 151.95975, mean: 0.08396
[32m[0906 20-54-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18272, current rewards: 157.60678, mean: 0.08473
[32m[0906 20-54-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18252, current rewards: 163.24861, mean: 0.08547
[32m[0906 20-55-00 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18233, current rewards: 147.77280, mean: 0.07539
[32m[0906 20-55-09 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18223, current rewards: 153.95829, mean: 0.07660
[32m[0906 20-55-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18218, current rewards: 160.18222, mean: 0.07776
[32m[0906 20-55-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18213, current rewards: 166.41564, mean: 0.07887
[32m[0906 20-55-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18208, current rewards: 172.64694, mean: 0.07993
[32m[0906 20-55-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18208, current rewards: 178.88426, mean: 0.08094
[32m[0906 20-55-55 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18218, current rewards: 185.12787, mean: 0.08191
[32m[0906 20-56-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18227, current rewards: 179.49073, mean: 0.07770
[32m[0906 20-56-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18232, current rewards: 185.04739, mean: 0.07841
[32m[0906 20-56-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18230, current rewards: 189.74797, mean: 0.07873
[32m[0906 20-56-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18228, current rewards: 195.32861, mean: 0.07940
[32m[0906 20-56-39 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 20-56-39 @Agent.py:118][0m Rollout length: 2510
[32m[0906 20-56-39 @MBExp.py:227][0m Rewards obtained: [199.80919798111992], Lows: [30], Highs: [32], Total time: 23445.969287999993
[32m[0906 20-58-24 @MBExp.py:144][0m ####################################################################
[32m[0906 20-58-24 @MBExp.py:145][0m Starting training iteration 52.
[32m[0906 20-58-26 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18066, current rewards: -10.00000, mean: -1.00000
[32m[0906 20-58-35 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18033, current rewards: -5.57695, mean: -0.09295
[32m[0906 20-58-44 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18127, current rewards: 0.10596, mean: 0.00096
[32m[0906 20-58-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18280, current rewards: 5.79066, mean: 0.03619
[32m[0906 20-59-03 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18331, current rewards: 11.47595, mean: 0.05465
[32m[0906 20-59-12 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18352, current rewards: 17.15890, mean: 0.06600
[32m[0906 20-59-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18382, current rewards: 6.77997, mean: 0.02187
[32m[0906 20-59-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18397, current rewards: 14.26830, mean: 0.03963
[32m[0906 20-59-40 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18407, current rewards: 21.77833, mean: 0.05312
[32m[0906 20-59-49 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18416, current rewards: 29.29175, mean: 0.06368
[32m[0906 20-59-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18429, current rewards: 36.80219, mean: 0.07216
[32m[0906 21-00-08 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18447, current rewards: 44.32645, mean: 0.07915
[32m[0906 21-00-17 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18450, current rewards: 51.85201, mean: 0.08500
[32m[0906 21-00-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18470, current rewards: 59.37541, mean: 0.08996
[32m[0906 21-00-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18471, current rewards: 66.89507, mean: 0.09422
[32m[0906 21-00-45 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18472, current rewards: 80.93561, mean: 0.10649
[32m[0906 21-00-54 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18475, current rewards: 89.13724, mean: 0.11005
[32m[0906 21-01-03 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18479, current rewards: 97.33564, mean: 0.11318
[32m[0906 21-01-12 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18479, current rewards: 105.53810, mean: 0.11598
[32m[0906 21-01-22 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18477, current rewards: 86.19929, mean: 0.08979
[32m[0906 21-01-31 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18478, current rewards: 92.94324, mean: 0.09202
[32m[0906 21-01-40 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18477, current rewards: 99.62110, mean: 0.09398
[32m[0906 21-01-49 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18476, current rewards: 106.29873, mean: 0.09576
[32m[0906 21-01-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18476, current rewards: 112.17739, mean: 0.09670
[32m[0906 21-02-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18478, current rewards: 107.00816, mean: 0.08844
[32m[0906 21-02-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18479, current rewards: 113.51170, mean: 0.09009
[32m[0906 21-02-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18478, current rewards: 119.50247, mean: 0.09122
[32m[0906 21-02-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18477, current rewards: 125.48142, mean: 0.09227
[32m[0906 21-02-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18462, current rewards: 131.46784, mean: 0.09324
[32m[0906 21-02-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18447, current rewards: 137.45378, mean: 0.09415
[32m[0906 21-03-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18434, current rewards: 143.44684, mean: 0.09500
[32m[0906 21-03-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18421, current rewards: 131.35204, mean: 0.08420
[32m[0906 21-03-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18400, current rewards: 139.99090, mean: 0.08695
[32m[0906 21-03-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18373, current rewards: 146.95481, mean: 0.08853
[32m[0906 21-03-38 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18349, current rewards: 153.93340, mean: 0.09002
[32m[0906 21-03-47 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18325, current rewards: 160.90378, mean: 0.09142
[32m[0906 21-03-56 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18303, current rewards: 167.87368, mean: 0.09275
[32m[0906 21-04-05 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18282, current rewards: 162.00511, mean: 0.08710
[32m[0906 21-04-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18263, current rewards: 161.12005, mean: 0.08436
[32m[0906 21-04-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18242, current rewards: 167.35256, mean: 0.08538
[32m[0906 21-04-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18238, current rewards: 172.53625, mean: 0.08584
[32m[0906 21-04-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18236, current rewards: 178.57260, mean: 0.08669
[32m[0906 21-04-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18233, current rewards: 184.61228, mean: 0.08749
[32m[0906 21-04-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18228, current rewards: 190.65182, mean: 0.08826
[32m[0906 21-05-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18228, current rewards: 196.69070, mean: 0.08900
[32m[0906 21-05-17 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18236, current rewards: 202.72769, mean: 0.08970
[32m[0906 21-05-26 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18242, current rewards: 208.76390, mean: 0.09037
[32m[0906 21-05-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18244, current rewards: 214.80014, mean: 0.09102
[32m[0906 21-05-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18241, current rewards: 220.69142, mean: 0.09157
[32m[0906 21-05-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18236, current rewards: 226.69934, mean: 0.09215
[32m[0906 21-06-01 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0906 21-06-01 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-06-01 @MBExp.py:227][0m Rewards obtained: [231.50151700295814], Lows: [31], Highs: [41], Total time: 23902.476638999993
[32m[0906 21-07-48 @MBExp.py:144][0m ####################################################################
[32m[0906 21-07-48 @MBExp.py:145][0m Starting training iteration 53.
[32m[0906 21-07-50 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18091, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-07-59 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18057, current rewards: -3.43244, mean: -0.05721
[32m[0906 21-08-08 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18188, current rewards: 2.27142, mean: 0.02065
[32m[0906 21-08-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18317, current rewards: 7.97082, mean: 0.04982
[32m[0906 21-08-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18351, current rewards: 13.67483, mean: 0.06512
[32m[0906 21-08-36 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18364, current rewards: 19.37853, mean: 0.07453
[32m[0906 21-08-45 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18394, current rewards: 25.08668, mean: 0.08092
[32m[0906 21-08-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18431, current rewards: 30.39891, mean: 0.08444
[32m[0906 21-09-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18436, current rewards: 36.02586, mean: 0.08787
[32m[0906 21-09-13 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18442, current rewards: 21.66405, mean: 0.04710
[32m[0906 21-09-22 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18448, current rewards: 28.33786, mean: 0.05556
[32m[0906 21-09-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18459, current rewards: 35.01012, mean: 0.06252
[32m[0906 21-09-41 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18463, current rewards: 30.53705, mean: 0.05006
[32m[0906 21-09-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18469, current rewards: 36.77330, mean: 0.05572
[32m[0906 21-09-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18464, current rewards: 42.49643, mean: 0.05985
[32m[0906 21-10-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18469, current rewards: 47.57762, mean: 0.06260
[32m[0906 21-10-18 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18470, current rewards: 53.16112, mean: 0.06563
[32m[0906 21-10-27 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18474, current rewards: 58.73853, mean: 0.06830
[32m[0906 21-10-36 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18475, current rewards: 64.31787, mean: 0.07068
[32m[0906 21-10-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18473, current rewards: 69.89791, mean: 0.07281
[32m[0906 21-10-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18476, current rewards: 75.47516, mean: 0.07473
[32m[0906 21-11-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18480, current rewards: 81.04668, mean: 0.07646
[32m[0906 21-11-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18480, current rewards: 86.62170, mean: 0.07804
[32m[0906 21-11-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18478, current rewards: 92.73001, mean: 0.07994
[32m[0906 21-11-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18478, current rewards: 98.36625, mean: 0.08129
[32m[0906 21-11-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18476, current rewards: 103.34752, mean: 0.08202
[32m[0906 21-11-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18475, current rewards: 108.08416, mean: 0.08251
[32m[0906 21-11-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18463, current rewards: 112.81963, mean: 0.08296
[32m[0906 21-12-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18448, current rewards: 117.55587, mean: 0.08337
[32m[0906 21-12-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18433, current rewards: 122.29415, mean: 0.08376
[32m[0906 21-12-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18420, current rewards: 127.02929, mean: 0.08413
[32m[0906 21-12-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18409, current rewards: 131.42508, mean: 0.08425
[32m[0906 21-12-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18383, current rewards: 135.64715, mean: 0.08425
[32m[0906 21-12-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18356, current rewards: 139.91623, mean: 0.08429
[32m[0906 21-13-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18333, current rewards: 123.50664, mean: 0.07223
[32m[0906 21-13-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18309, current rewards: 129.19118, mean: 0.07340
[32m[0906 21-13-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18286, current rewards: 134.86541, mean: 0.07451
[32m[0906 21-13-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18264, current rewards: 140.53399, mean: 0.07556
[32m[0906 21-13-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18244, current rewards: 146.20775, mean: 0.07655
[32m[0906 21-13-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18224, current rewards: 151.87865, mean: 0.07749
[32m[0906 21-13-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18217, current rewards: 162.91410, mean: 0.08105
[32m[0906 21-14-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18212, current rewards: 169.21634, mean: 0.08214
[32m[0906 21-14-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18208, current rewards: 175.51674, mean: 0.08318
[32m[0906 21-14-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18206, current rewards: 181.81654, mean: 0.08417
[32m[0906 21-14-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18205, current rewards: 188.11874, mean: 0.08512
[32m[0906 21-14-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18214, current rewards: 194.41876, mean: 0.08603
[32m[0906 21-14-49 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18221, current rewards: 189.45847, mean: 0.08202
[32m[0906 21-14-58 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18222, current rewards: 194.05841, mean: 0.08223
[32m[0906 21-15-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18222, current rewards: 199.27816, mean: 0.08269
[32m[0906 21-15-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18219, current rewards: 204.69781, mean: 0.08321
[32m[0906 21-15-24 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 21-15-24 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-15-24 @MBExp.py:227][0m Rewards obtained: [209.0339692574432], Lows: [20], Highs: [33], Total time: 24358.633234999994
[32m[0906 21-17-13 @MBExp.py:144][0m ####################################################################
[32m[0906 21-17-13 @MBExp.py:145][0m Starting training iteration 54.
[32m[0906 21-17-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19359, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-17-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18286, current rewards: -5.09533, mean: -0.08492
[32m[0906 21-17-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18285, current rewards: 0.23264, mean: 0.00211
[32m[0906 21-17-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18369, current rewards: 5.55714, mean: 0.03473
[32m[0906 21-17-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18380, current rewards: 10.87732, mean: 0.05180
[32m[0906 21-18-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18409, current rewards: 16.19535, mean: 0.06229
[32m[0906 21-18-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18443, current rewards: 21.41010, mean: 0.06906
[32m[0906 21-18-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18452, current rewards: 26.73008, mean: 0.07425
[32m[0906 21-18-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18451, current rewards: 32.03848, mean: 0.07814
[32m[0906 21-18-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18450, current rewards: 16.18437, mean: 0.03518
[32m[0906 21-18-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18456, current rewards: 21.47220, mean: 0.04210
[32m[0906 21-18-57 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18467, current rewards: 26.75372, mean: 0.04777
[32m[0906 21-19-06 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18466, current rewards: 32.03670, mean: 0.05252
[32m[0906 21-19-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18477, current rewards: 37.32298, mean: 0.05655
[32m[0906 21-19-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18486, current rewards: 42.41622, mean: 0.05974
[32m[0906 21-19-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18485, current rewards: 47.50098, mean: 0.06250
[32m[0906 21-19-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18483, current rewards: 52.67955, mean: 0.06504
[32m[0906 21-19-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18482, current rewards: 57.85850, mean: 0.06728
[32m[0906 21-20-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18480, current rewards: 63.03830, mean: 0.06927
[32m[0906 21-20-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18478, current rewards: 68.21462, mean: 0.07106
[32m[0906 21-20-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18476, current rewards: 73.39270, mean: 0.07267
[32m[0906 21-20-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18475, current rewards: 78.56445, mean: 0.07412
[32m[0906 21-20-39 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18476, current rewards: 83.78532, mean: 0.07548
[32m[0906 21-20-48 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18473, current rewards: 85.77091, mean: 0.07394
[32m[0906 21-20-57 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18478, current rewards: 91.30009, mean: 0.07545
[32m[0906 21-21-06 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18477, current rewards: 96.83196, mean: 0.07685
[32m[0906 21-21-16 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18476, current rewards: 102.36579, mean: 0.07814
[32m[0906 21-21-25 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18465, current rewards: 107.89650, mean: 0.07934
[32m[0906 21-21-34 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18451, current rewards: 113.42921, mean: 0.08045
[32m[0906 21-21-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18436, current rewards: 118.95840, mean: 0.08148
[32m[0906 21-21-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18423, current rewards: 124.49064, mean: 0.08244
[32m[0906 21-22-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18410, current rewards: 108.35395, mean: 0.06946
[32m[0906 21-22-10 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18383, current rewards: 113.59883, mean: 0.07056
[32m[0906 21-22-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18356, current rewards: 118.86873, mean: 0.07161
[32m[0906 21-22-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18330, current rewards: 124.14178, mean: 0.07260
[32m[0906 21-22-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18306, current rewards: 129.41237, mean: 0.07353
[32m[0906 21-22-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18283, current rewards: 134.68337, mean: 0.07441
[32m[0906 21-22-53 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18263, current rewards: 139.95708, mean: 0.07525
[32m[0906 21-23-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18243, current rewards: 145.22752, mean: 0.07604
[32m[0906 21-23-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18225, current rewards: 153.09297, mean: 0.07811
[32m[0906 21-23-20 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18222, current rewards: 163.26380, mean: 0.08123
[32m[0906 21-23-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18221, current rewards: 172.05246, mean: 0.08352
[32m[0906 21-23-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18218, current rewards: 180.84113, mean: 0.08571
[32m[0906 21-23-47 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18214, current rewards: 189.62979, mean: 0.08779
[32m[0906 21-23-56 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18214, current rewards: 180.78185, mean: 0.08180
[32m[0906 21-24-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18221, current rewards: 130.78185, mean: 0.05787
[32m[0906 21-24-15 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18227, current rewards: 80.78185, mean: 0.03497
[32m[0906 21-24-24 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18230, current rewards: 30.78185, mean: 0.01304
[32m[0906 21-24-33 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18227, current rewards: -19.21815, mean: -0.00797
[32m[0906 21-24-42 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18223, current rewards: -69.21815, mean: -0.02814
[32m[0906 21-24-49 @Agent.py:117][0m Average action selection time: 0.1822
[32m[0906 21-24-49 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-24-49 @MBExp.py:227][0m Rewards obtained: [-109.21814916438419], Lows: [20], Highs: [319], Total time: 24814.874894999994
[32m[0906 21-26-41 @MBExp.py:144][0m ####################################################################
[32m[0906 21-26-41 @MBExp.py:145][0m Starting training iteration 55.
[32m[0906 21-26-43 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17953, current rewards: 0.99632, mean: 0.09963
[32m[0906 21-26-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18016, current rewards: 5.40151, mean: 0.09003
[32m[0906 21-27-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18158, current rewards: 11.44677, mean: 0.10406
[32m[0906 21-27-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18302, current rewards: 17.49204, mean: 0.10933
[32m[0906 21-27-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18365, current rewards: 23.53731, mean: 0.11208
[32m[0906 21-27-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18394, current rewards: 29.58257, mean: 0.11378
[32m[0906 21-27-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18417, current rewards: 35.62784, mean: 0.11493
[32m[0906 21-27-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18445, current rewards: 41.67310, mean: 0.11576
[32m[0906 21-27-57 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18456, current rewards: 47.71837, mean: 0.11639
[32m[0906 21-28-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18460, current rewards: 41.43367, mean: 0.09007
[32m[0906 21-28-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18460, current rewards: -8.56633, mean: -0.01680
[32m[0906 21-28-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18466, current rewards: -58.56633, mean: -0.10458
[32m[0906 21-28-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18465, current rewards: -108.56633, mean: -0.17798
[32m[0906 21-28-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18468, current rewards: -158.56633, mean: -0.24025
[32m[0906 21-28-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18472, current rewards: -208.56633, mean: -0.29376
[32m[0906 21-29-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18467, current rewards: -258.56633, mean: -0.34022
[32m[0906 21-29-11 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18468, current rewards: -308.56633, mean: -0.38095
[32m[0906 21-29-20 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18471, current rewards: -358.56633, mean: -0.41694
[32m[0906 21-29-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18472, current rewards: -408.56633, mean: -0.44897
[32m[0906 21-29-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18473, current rewards: -458.56633, mean: -0.47767
[32m[0906 21-29-48 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18481, current rewards: -508.56633, mean: -0.50353
[32m[0906 21-29-57 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18484, current rewards: -558.56633, mean: -0.52695
[32m[0906 21-30-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18484, current rewards: -608.56633, mean: -0.54826
[32m[0906 21-30-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18485, current rewards: -658.56633, mean: -0.56773
[32m[0906 21-30-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18484, current rewards: -708.56633, mean: -0.58559
[32m[0906 21-30-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18481, current rewards: -758.56633, mean: -0.60204
[32m[0906 21-30-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18475, current rewards: -808.56633, mean: -0.61723
[32m[0906 21-30-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18459, current rewards: -858.56633, mean: -0.63130
[32m[0906 21-31-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18444, current rewards: -908.56633, mean: -0.64437
[32m[0906 21-31-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18430, current rewards: -958.56633, mean: -0.65655
[32m[0906 21-31-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18418, current rewards: -1008.56633, mean: -0.66792
[32m[0906 21-31-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18400, current rewards: -1058.56633, mean: -0.67857
[32m[0906 21-31-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18372, current rewards: -1108.56633, mean: -0.68855
[32m[0906 21-31-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18345, current rewards: -1158.56633, mean: -0.69793
[32m[0906 21-31-54 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18321, current rewards: -1208.56633, mean: -0.70676
[32m[0906 21-32-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18297, current rewards: -1258.56633, mean: -0.71509
[32m[0906 21-32-12 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18273, current rewards: -1308.56633, mean: -0.72296
[32m[0906 21-32-21 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18252, current rewards: -1358.56633, mean: -0.73041
[32m[0906 21-32-29 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18231, current rewards: -1408.56633, mean: -0.73747
[32m[0906 21-32-38 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18215, current rewards: -1458.56633, mean: -0.74417
[32m[0906 21-32-47 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18211, current rewards: -1508.56633, mean: -0.75053
[32m[0906 21-32-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18207, current rewards: -1558.56633, mean: -0.75659
[32m[0906 21-33-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18203, current rewards: -1608.56633, mean: -0.76235
[32m[0906 21-33-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18199, current rewards: -1658.56633, mean: -0.76785
[32m[0906 21-33-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18198, current rewards: -1708.56633, mean: -0.77311
[32m[0906 21-33-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18208, current rewards: -1758.56633, mean: -0.77813
[32m[0906 21-33-42 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18215, current rewards: -1808.56633, mean: -0.78293
[32m[0906 21-33-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18218, current rewards: -1858.56633, mean: -0.78753
[32m[0906 21-34-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18216, current rewards: -1908.56633, mean: -0.79194
[32m[0906 21-34-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18215, current rewards: -1958.56633, mean: -0.79617
[32m[0906 21-34-17 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0906 21-34-17 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-34-17 @MBExp.py:227][0m Rewards obtained: [-1998.5663257447407], Lows: [1], Highs: [2051], Total time: 25270.921460999994
[32m[0906 21-36-10 @MBExp.py:144][0m ####################################################################
[32m[0906 21-36-10 @MBExp.py:145][0m Starting training iteration 56.
[32m[0906 21-36-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17983, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-36-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18041, current rewards: -10.99836, mean: -0.18331
[32m[0906 21-36-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18185, current rewards: -5.27713, mean: -0.04797
[32m[0906 21-36-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18313, current rewards: 0.43195, mean: 0.00270
[32m[0906 21-36-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18342, current rewards: 6.15233, mean: 0.02930
[32m[0906 21-36-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18373, current rewards: 11.86339, mean: 0.04563
[32m[0906 21-37-07 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18399, current rewards: 19.67932, mean: 0.06348
[32m[0906 21-37-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18403, current rewards: 4.08717, mean: 0.01135
[32m[0906 21-37-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18416, current rewards: 9.75141, mean: 0.02378
[32m[0906 21-37-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18415, current rewards: 15.40986, mean: 0.03350
[32m[0906 21-37-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18423, current rewards: 21.07527, mean: 0.04132
[32m[0906 21-37-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18428, current rewards: 26.74208, mean: 0.04775
[32m[0906 21-38-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18428, current rewards: 32.40401, mean: 0.05312
[32m[0906 21-38-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18437, current rewards: 38.06924, mean: 0.05768
[32m[0906 21-38-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18442, current rewards: 42.90816, mean: 0.06043
[32m[0906 21-38-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18443, current rewards: 48.84333, mean: 0.06427
[32m[0906 21-38-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18451, current rewards: 54.96118, mean: 0.06785
[32m[0906 21-38-49 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18454, current rewards: 61.07215, mean: 0.07101
[32m[0906 21-38-58 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18458, current rewards: 67.18629, mean: 0.07383
[32m[0906 21-39-07 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18464, current rewards: 51.14508, mean: 0.05328
[32m[0906 21-39-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18465, current rewards: 56.37753, mean: 0.05582
[32m[0906 21-39-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18464, current rewards: 61.60820, mean: 0.05812
[32m[0906 21-39-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18466, current rewards: 66.83382, mean: 0.06021
[32m[0906 21-39-44 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18465, current rewards: 72.62977, mean: 0.06261
[32m[0906 21-39-54 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18466, current rewards: 77.92749, mean: 0.06440
[32m[0906 21-40-03 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18468, current rewards: 83.21551, mean: 0.06604
[32m[0906 21-40-12 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18454, current rewards: 67.72291, mean: 0.05170
[32m[0906 21-40-21 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18445, current rewards: 73.03650, mean: 0.05370
[32m[0906 21-40-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18429, current rewards: 78.35251, mean: 0.05557
[32m[0906 21-40-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18415, current rewards: 83.67217, mean: 0.05731
[32m[0906 21-40-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18401, current rewards: 88.98909, mean: 0.05893
[32m[0906 21-40-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18380, current rewards: 97.34719, mean: 0.06240
[32m[0906 21-41-06 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18352, current rewards: 102.91768, mean: 0.06392
[32m[0906 21-41-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18326, current rewards: 108.48817, mean: 0.06535
[32m[0906 21-41-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18300, current rewards: 102.84212, mean: 0.06014
[32m[0906 21-41-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18276, current rewards: 107.95303, mean: 0.06134
[32m[0906 21-41-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18252, current rewards: 113.05783, mean: 0.06246
[32m[0906 21-41-49 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18231, current rewards: 118.15862, mean: 0.06353
[32m[0906 21-41-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18209, current rewards: 123.26505, mean: 0.06454
[32m[0906 21-42-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18200, current rewards: 129.59884, mean: 0.06612
[32m[0906 21-42-16 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18196, current rewards: 134.88626, mean: 0.06711
[32m[0906 21-42-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18194, current rewards: 128.32368, mean: 0.06229
[32m[0906 21-42-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18191, current rewards: 133.85600, mean: 0.06344
[32m[0906 21-42-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18188, current rewards: 139.35787, mean: 0.06452
[32m[0906 21-42-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18189, current rewards: 144.85986, mean: 0.06555
[32m[0906 21-43-02 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18196, current rewards: 150.35519, mean: 0.06653
[32m[0906 21-43-11 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18203, current rewards: 134.67974, mean: 0.05830
[32m[0906 21-43-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18208, current rewards: 140.01014, mean: 0.05933
[32m[0906 21-43-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18210, current rewards: 145.23795, mean: 0.06026
[32m[0906 21-43-38 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18206, current rewards: 151.01038, mean: 0.06139
[32m[0906 21-43-46 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0906 21-43-46 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-43-46 @MBExp.py:227][0m Rewards obtained: [155.6292835791862], Lows: [40], Highs: [37], Total time: 25726.743118999995
[32m[0906 21-45-41 @MBExp.py:144][0m ####################################################################
[32m[0906 21-45-41 @MBExp.py:145][0m Starting training iteration 57.
[32m[0906 21-45-42 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18005, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-45-52 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18028, current rewards: -22.43850, mean: -0.37397
[32m[0906 21-46-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18191, current rewards: -17.22897, mean: -0.15663
[32m[0906 21-46-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18318, current rewards: -12.01591, mean: -0.07510
[32m[0906 21-46-19 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18354, current rewards: -6.80471, mean: -0.03240
[32m[0906 21-46-29 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18396, current rewards: -1.59098, mean: -0.00612
[32m[0906 21-46-38 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18420, current rewards: 3.32124, mean: 0.01071
[32m[0906 21-46-47 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18430, current rewards: -12.81686, mean: -0.03560
[32m[0906 21-46-56 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18436, current rewards: -8.77679, mean: -0.02141
[32m[0906 21-47-06 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18443, current rewards: -4.67182, mean: -0.01016
[32m[0906 21-47-15 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18447, current rewards: -0.52107, mean: -0.00102
[32m[0906 21-47-24 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18446, current rewards: 3.63944, mean: 0.00650
[32m[0906 21-47-33 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18449, current rewards: 7.80627, mean: 0.01280
[32m[0906 21-47-43 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18447, current rewards: 11.95823, mean: 0.01812
[32m[0906 21-47-52 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18446, current rewards: 16.11543, mean: 0.02270
[32m[0906 21-48-01 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18445, current rewards: 20.66063, mean: 0.02719
[32m[0906 21-48-10 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18448, current rewards: 25.03832, mean: 0.03091
[32m[0906 21-48-19 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18444, current rewards: 18.88091, mean: 0.02195
[32m[0906 21-48-29 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18442, current rewards: 25.00882, mean: 0.02748
[32m[0906 21-48-38 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18444, current rewards: 31.12612, mean: 0.03242
[32m[0906 21-48-47 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18445, current rewards: 37.29673, mean: 0.03693
[32m[0906 21-48-56 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18443, current rewards: 20.01422, mean: 0.01888
[32m[0906 21-49-06 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18445, current rewards: 26.34457, mean: 0.02373
[32m[0906 21-49-15 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18446, current rewards: 32.57684, mean: 0.02808
[32m[0906 21-49-24 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18448, current rewards: 38.81058, mean: 0.03207
[32m[0906 21-49-33 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18438, current rewards: 45.04445, mean: 0.03575
[32m[0906 21-49-42 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18422, current rewards: 51.27812, mean: 0.03914
[32m[0906 21-49-51 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18405, current rewards: 57.51161, mean: 0.04229
[32m[0906 21-50-00 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18391, current rewards: 52.49829, mean: 0.03723
[32m[0906 21-50-09 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18379, current rewards: 31.70906, mean: 0.02172
[32m[0906 21-50-18 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18369, current rewards: 4.50375, mean: 0.00298
[32m[0906 21-50-27 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18342, current rewards: -16.10902, mean: -0.01033
[32m[0906 21-50-36 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18312, current rewards: -30.30696, mean: -0.01882
[32m[0906 21-50-45 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18289, current rewards: -44.19822, mean: -0.02663
[32m[0906 21-50-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18266, current rewards: -77.08542, mean: -0.04508
[32m[0906 21-51-02 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18243, current rewards: -73.72638, mean: -0.04189
[32m[0906 21-51-11 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18220, current rewards: -70.38482, mean: -0.03889
[32m[0906 21-51-20 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18199, current rewards: -67.04104, mean: -0.03604
[32m[0906 21-51-28 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18181, current rewards: -63.69979, mean: -0.03335
[32m[0906 21-51-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18172, current rewards: -60.43359, mean: -0.03083
[32m[0906 21-51-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18170, current rewards: -57.04651, mean: -0.02838
[32m[0906 21-51-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18166, current rewards: -57.79679, mean: -0.02806
[32m[0906 21-52-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18162, current rewards: -68.61943, mean: -0.03252
[32m[0906 21-52-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18159, current rewards: -62.38083, mean: -0.02888
[32m[0906 21-52-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18160, current rewards: -56.14197, mean: -0.02540
[32m[0906 21-52-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18169, current rewards: -62.62323, mean: -0.02771
[32m[0906 21-52-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18176, current rewards: -59.20551, mean: -0.02563
[32m[0906 21-52-50 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18185, current rewards: -55.87756, mean: -0.02368
[32m[0906 21-53-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18190, current rewards: -52.41429, mean: -0.02175
[32m[0906 21-53-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18186, current rewards: -48.95341, mean: -0.01990
[32m[0906 21-53-16 @Agent.py:117][0m Average action selection time: 0.1818
[32m[0906 21-53-16 @Agent.py:118][0m Rollout length: 2510
[32m[0906 21-53-16 @MBExp.py:227][0m Rewards obtained: [-46.18179080240337], Lows: [129], Highs: [45], Total time: 26182.065351999994
[32m[0906 21-55-13 @MBExp.py:144][0m ####################################################################
[32m[0906 21-55-13 @MBExp.py:145][0m Starting training iteration 58.
[32m[0906 21-55-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18127, current rewards: -10.00000, mean: -1.00000
[32m[0906 21-55-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18059, current rewards: -5.11009, mean: -0.08517
[32m[0906 21-55-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18234, current rewards: 0.50309, mean: 0.00457
[32m[0906 21-55-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18348, current rewards: 6.12316, mean: 0.03827
[32m[0906 21-55-51 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18401, current rewards: 11.73781, mean: 0.05589
[32m[0906 21-56-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18397, current rewards: 17.61106, mean: 0.06773
[32m[0906 21-56-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18397, current rewards: 23.24621, mean: 0.07499
[32m[0906 21-56-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18392, current rewards: 28.87299, mean: 0.08020
[32m[0906 21-56-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18394, current rewards: 34.49921, mean: 0.08414
[32m[0906 21-56-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18407, current rewards: 40.12163, mean: 0.08722
[32m[0906 21-56-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18413, current rewards: 45.74235, mean: 0.08969
[32m[0906 21-56-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18417, current rewards: 51.36186, mean: 0.09172
[32m[0906 21-57-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18429, current rewards: 56.98001, mean: 0.09341
[32m[0906 21-57-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18450, current rewards: 38.91270, mean: 0.05896
[32m[0906 21-57-24 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18449, current rewards: 43.90264, mean: 0.06183
[32m[0906 21-57-33 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18444, current rewards: 48.76935, mean: 0.06417
[32m[0906 21-57-42 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18443, current rewards: 53.63700, mean: 0.06622
[32m[0906 21-57-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18444, current rewards: 58.50340, mean: 0.06803
[32m[0906 21-58-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18445, current rewards: 63.36760, mean: 0.06963
[32m[0906 21-58-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18448, current rewards: 68.23400, mean: 0.07108
[32m[0906 21-58-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18448, current rewards: 73.09649, mean: 0.07237
[32m[0906 21-58-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18450, current rewards: 77.96192, mean: 0.07355
[32m[0906 21-58-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18451, current rewards: 82.82626, mean: 0.07462
[32m[0906 21-58-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18452, current rewards: 87.69237, mean: 0.07560
[32m[0906 21-58-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18453, current rewards: 92.55780, mean: 0.07649
[32m[0906 21-59-05 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18441, current rewards: 97.42196, mean: 0.07732
[32m[0906 21-59-15 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18431, current rewards: 102.28857, mean: 0.07808
[32m[0906 21-59-24 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18415, current rewards: 95.10309, mean: 0.06993
[32m[0906 21-59-33 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18409, current rewards: 99.35356, mean: 0.07046
[32m[0906 21-59-42 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18398, current rewards: 104.69203, mean: 0.07171
[32m[0906 21-59-51 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18386, current rewards: 110.03283, mean: 0.07287
[32m[0906 21-59-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18353, current rewards: 115.38094, mean: 0.07396
[32m[0906 22-00-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18326, current rewards: 120.72687, mean: 0.07499
[32m[0906 22-00-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18298, current rewards: 126.07050, mean: 0.07595
[32m[0906 22-00-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18273, current rewards: 131.41356, mean: 0.07685
[32m[0906 22-00-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18249, current rewards: 136.76084, mean: 0.07771
[32m[0906 22-00-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18228, current rewards: 142.10438, mean: 0.07851
[32m[0906 22-00-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18207, current rewards: 138.87702, mean: 0.07467
[32m[0906 22-01-01 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18188, current rewards: 142.12537, mean: 0.07441
[32m[0906 22-01-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18184, current rewards: 147.76040, mean: 0.07539
[32m[0906 22-01-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18184, current rewards: 153.38014, mean: 0.07631
[32m[0906 22-01-28 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18180, current rewards: 159.00996, mean: 0.07719
[32m[0906 22-01-37 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18178, current rewards: 164.63688, mean: 0.07803
[32m[0906 22-01-46 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18174, current rewards: 170.26513, mean: 0.07883
[32m[0906 22-01-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18175, current rewards: 175.89586, mean: 0.07959
[32m[0906 22-02-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18182, current rewards: 181.51096, mean: 0.08031
[32m[0906 22-02-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18188, current rewards: 186.46328, mean: 0.08072
[32m[0906 22-02-23 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18198, current rewards: 161.86587, mean: 0.06859
[32m[0906 22-02-32 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18203, current rewards: 167.41150, mean: 0.06947
[32m[0906 22-02-41 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18200, current rewards: 172.96347, mean: 0.07031
[32m[0906 22-02-48 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0906 22-02-48 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-02-48 @MBExp.py:227][0m Rewards obtained: [177.40450717980286], Lows: [21], Highs: [41], Total time: 26637.745579999995
[32m[0906 22-04-47 @MBExp.py:144][0m ####################################################################
[32m[0906 22-04-47 @MBExp.py:145][0m Starting training iteration 59.
[32m[0906 22-04-49 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17992, current rewards: 0.67653, mean: 0.06765
[32m[0906 22-04-58 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18051, current rewards: -13.53348, mean: -0.22556
[32m[0906 22-05-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18198, current rewards: -48.96783, mean: -0.44516
[32m[0906 22-05-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18315, current rewards: -86.16711, mean: -0.53854
[32m[0906 22-05-26 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18383, current rewards: -122.30752, mean: -0.58242
[32m[0906 22-05-35 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18410, current rewards: -142.88640, mean: -0.54956
[32m[0906 22-05-44 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18416, current rewards: -161.90392, mean: -0.52227
[32m[0906 22-05-54 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18418, current rewards: -145.12863, mean: -0.40314
[32m[0906 22-06-03 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18434, current rewards: -127.37241, mean: -0.31066
[32m[0906 22-06-12 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18438, current rewards: -109.67611, mean: -0.23843
[32m[0906 22-06-21 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18442, current rewards: -91.86945, mean: -0.18014
[32m[0906 22-06-31 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18451, current rewards: -74.00389, mean: -0.13215
[32m[0906 22-06-40 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18450, current rewards: -56.37711, mean: -0.09242
[32m[0906 22-06-49 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18448, current rewards: -48.71477, mean: -0.07381
[32m[0906 22-06-58 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18451, current rewards: -43.19221, mean: -0.06083
[32m[0906 22-07-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18453, current rewards: -37.65631, mean: -0.04955
[32m[0906 22-07-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18453, current rewards: -32.13031, mean: -0.03967
[32m[0906 22-07-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18454, current rewards: -26.59761, mean: -0.03093
[32m[0906 22-07-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18457, current rewards: -32.01179, mean: -0.03518
[32m[0906 22-07-45 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18461, current rewards: -77.44965, mean: -0.08068
[32m[0906 22-07-54 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18466, current rewards: -84.39112, mean: -0.08356
[32m[0906 22-08-03 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18467, current rewards: -72.90587, mean: -0.06878
[32m[0906 22-08-12 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18466, current rewards: -66.65623, mean: -0.06005
[32m[0906 22-08-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18470, current rewards: -77.32732, mean: -0.06666
[32m[0906 22-08-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18466, current rewards: -84.86041, mean: -0.07013
[32m[0906 22-08-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18448, current rewards: -96.65820, mean: -0.07671
[32m[0906 22-08-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18432, current rewards: -106.22549, mean: -0.08109
[32m[0906 22-08-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18416, current rewards: -115.96224, mean: -0.08527
[32m[0906 22-09-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18404, current rewards: -127.86696, mean: -0.09069
[32m[0906 22-09-16 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18388, current rewards: -135.39947, mean: -0.09274
[32m[0906 22-09-25 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18372, current rewards: -149.58357, mean: -0.09906
[32m[0906 22-09-34 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18343, current rewards: -182.43620, mean: -0.11695
[32m[0906 22-09-43 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18321, current rewards: -199.67156, mean: -0.12402
[32m[0906 22-09-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18296, current rewards: -234.40619, mean: -0.14121
[32m[0906 22-10-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18271, current rewards: -257.98955, mean: -0.15087
[32m[0906 22-10-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18248, current rewards: -285.65226, mean: -0.16230
[32m[0906 22-10-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18225, current rewards: -315.86551, mean: -0.17451
[32m[0906 22-10-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18205, current rewards: -337.26759, mean: -0.18133
[32m[0906 22-10-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18187, current rewards: -374.07817, mean: -0.19585
[32m[0906 22-10-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18183, current rewards: -389.58432, mean: -0.19877
[32m[0906 22-10-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18178, current rewards: -427.16071, mean: -0.21252
[32m[0906 22-11-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18176, current rewards: -442.36393, mean: -0.21474
[32m[0906 22-11-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18172, current rewards: -479.38547, mean: -0.22720
[32m[0906 22-11-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18168, current rewards: -498.39258, mean: -0.23074
[32m[0906 22-11-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18168, current rewards: -506.41412, mean: -0.22915
[32m[0906 22-11-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18177, current rewards: -497.83545, mean: -0.22028
[32m[0906 22-11-48 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18186, current rewards: -491.90893, mean: -0.21295
[32m[0906 22-11-57 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18192, current rewards: -486.02978, mean: -0.20594
[32m[0906 22-12-06 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18198, current rewards: -480.14439, mean: -0.19923
[32m[0906 22-12-15 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18195, current rewards: -474.26809, mean: -0.19279
[32m[0906 22-12-23 @Agent.py:117][0m Average action selection time: 0.1819
[32m[0906 22-12-23 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-12-23 @MBExp.py:227][0m Rewards obtained: [-469.5655325220431], Lows: [432], Highs: [30], Total time: 27093.292445999996
[32m[0906 22-14-23 @MBExp.py:144][0m ####################################################################
[32m[0906 22-14-23 @MBExp.py:145][0m Starting training iteration 60.
[32m[0906 22-14-25 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17988, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-14-34 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17978, current rewards: -4.00615, mean: -0.06677
[32m[0906 22-14-43 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18191, current rewards: 1.01724, mean: 0.00925
[32m[0906 22-14-53 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18297, current rewards: 6.02661, mean: 0.03767
[32m[0906 22-15-02 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18312, current rewards: 10.56253, mean: 0.05030
[32m[0906 22-15-11 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18357, current rewards: 15.44568, mean: 0.05941
[32m[0906 22-15-21 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18379, current rewards: 20.32953, mean: 0.06558
[32m[0906 22-15-30 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18395, current rewards: 25.21407, mean: 0.07004
[32m[0906 22-15-39 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18396, current rewards: 30.10056, mean: 0.07342
[32m[0906 22-15-48 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18402, current rewards: 34.98574, mean: 0.07606
[32m[0906 22-15-58 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18426, current rewards: 39.86796, mean: 0.07817
[32m[0906 22-16-07 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18431, current rewards: 44.75585, mean: 0.07992
[32m[0906 22-16-16 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18432, current rewards: 49.30405, mean: 0.08083
[32m[0906 22-16-25 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18433, current rewards: 54.10576, mean: 0.08198
[32m[0906 22-16-35 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18433, current rewards: 38.69394, mean: 0.05450
[32m[0906 22-16-44 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18431, current rewards: 45.66174, mean: 0.06008
[32m[0906 22-16-53 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18431, current rewards: 50.97362, mean: 0.06293
[32m[0906 22-17-02 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18437, current rewards: 56.28406, mean: 0.06545
[32m[0906 22-17-11 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18433, current rewards: 61.58791, mean: 0.06768
[32m[0906 22-17-21 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18433, current rewards: 66.89308, mean: 0.06968
[32m[0906 22-17-30 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18432, current rewards: 74.03950, mean: 0.07331
[32m[0906 22-17-39 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18430, current rewards: 79.11016, mean: 0.07463
[32m[0906 22-17-48 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18426, current rewards: 84.17195, mean: 0.07583
[32m[0906 22-17-57 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18427, current rewards: 89.23428, mean: 0.07693
[32m[0906 22-18-07 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18421, current rewards: 86.25491, mean: 0.07129
[32m[0906 22-18-16 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18404, current rewards: 91.20453, mean: 0.07238
[32m[0906 22-18-25 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18387, current rewards: 96.21297, mean: 0.07345
[32m[0906 22-18-34 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18372, current rewards: 101.22418, mean: 0.07443
[32m[0906 22-18-43 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18359, current rewards: 106.23339, mean: 0.07534
[32m[0906 22-18-52 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18347, current rewards: 111.24786, mean: 0.07620
[32m[0906 22-19-01 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18326, current rewards: 95.41954, mean: 0.06319
[32m[0906 22-19-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18298, current rewards: 100.56522, mean: 0.06446
[32m[0906 22-19-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18272, current rewards: 105.70318, mean: 0.06565
[32m[0906 22-19-27 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18247, current rewards: 110.84476, mean: 0.06677
[32m[0906 22-19-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18225, current rewards: 115.98245, mean: 0.06783
[32m[0906 22-19-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18204, current rewards: 121.12149, mean: 0.06882
[32m[0906 22-19-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18182, current rewards: 125.78777, mean: 0.06950
[32m[0906 22-20-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18164, current rewards: 131.04242, mean: 0.07045
[32m[0906 22-20-11 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18153, current rewards: 136.21346, mean: 0.07132
[32m[0906 22-20-20 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18149, current rewards: 141.38010, mean: 0.07213
[32m[0906 22-20-29 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18145, current rewards: 146.54278, mean: 0.07291
[32m[0906 22-20-38 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18141, current rewards: 132.22722, mean: 0.06419
[32m[0906 22-20-47 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18137, current rewards: 123.93904, mean: 0.05874
[32m[0906 22-20-56 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18134, current rewards: 128.07006, mean: 0.05929
[32m[0906 22-21-05 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18134, current rewards: 132.34614, mean: 0.05989
[32m[0906 22-21-14 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18142, current rewards: 137.29775, mean: 0.06075
[32m[0906 22-21-23 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18150, current rewards: 141.63026, mean: 0.06131
[32m[0906 22-21-33 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18157, current rewards: 145.94780, mean: 0.06184
[32m[0906 22-21-42 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18162, current rewards: 150.26348, mean: 0.06235
[32m[0906 22-21-51 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18160, current rewards: 154.35607, mean: 0.06275
[32m[0906 22-21-58 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 22-21-58 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-21-58 @MBExp.py:227][0m Rewards obtained: [158.8861321576328], Lows: [31], Highs: [31], Total time: 27547.996270999996
[32m[0906 22-24-01 @MBExp.py:144][0m ####################################################################
[32m[0906 22-24-01 @MBExp.py:145][0m Starting training iteration 61.
[32m[0906 22-24-03 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17994, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-24-12 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17996, current rewards: -18.26850, mean: -0.30447
[32m[0906 22-24-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18256, current rewards: -12.59842, mean: -0.11453
[32m[0906 22-24-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18355, current rewards: -1.86299, mean: -0.01164
[32m[0906 22-24-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18393, current rewards: 3.89992, mean: 0.01857
[32m[0906 22-24-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18409, current rewards: 9.60509, mean: 0.03694
[32m[0906 22-24-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18413, current rewards: 15.31033, mean: 0.04939
[32m[0906 22-25-07 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18418, current rewards: 21.01394, mean: 0.05837
[32m[0906 22-25-16 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18420, current rewards: 26.71858, mean: 0.06517
[32m[0906 22-25-26 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18420, current rewards: 19.73981, mean: 0.04291
[32m[0906 22-25-35 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18422, current rewards: 25.34759, mean: 0.04970
[32m[0906 22-25-44 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18427, current rewards: 30.97507, mean: 0.05531
[32m[0906 22-25-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18429, current rewards: 36.60294, mean: 0.06000
[32m[0906 22-26-03 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18426, current rewards: 42.22672, mean: 0.06398
[32m[0906 22-26-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18423, current rewards: 47.84845, mean: 0.06739
[32m[0906 22-26-21 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18426, current rewards: 53.46819, mean: 0.07035
[32m[0906 22-26-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18430, current rewards: 59.09627, mean: 0.07296
[32m[0906 22-26-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18428, current rewards: 64.72290, mean: 0.07526
[32m[0906 22-26-49 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18428, current rewards: 70.34281, mean: 0.07730
[32m[0906 22-26-58 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18425, current rewards: 74.61462, mean: 0.07772
[32m[0906 22-27-07 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18421, current rewards: 70.22837, mean: 0.06953
[32m[0906 22-27-16 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18421, current rewards: 76.00328, mean: 0.07170
[32m[0906 22-27-26 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18423, current rewards: 81.77284, mean: 0.07367
[32m[0906 22-27-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18417, current rewards: 87.54839, mean: 0.07547
[32m[0906 22-27-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18401, current rewards: 93.32198, mean: 0.07713
[32m[0906 22-27-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18385, current rewards: 99.09289, mean: 0.07865
[32m[0906 22-28-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18373, current rewards: 104.86718, mean: 0.08005
[32m[0906 22-28-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18359, current rewards: 110.30110, mean: 0.08110
[32m[0906 22-28-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18347, current rewards: 116.05785, mean: 0.08231
[32m[0906 22-28-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18339, current rewards: 121.79591, mean: 0.08342
[32m[0906 22-28-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18317, current rewards: 127.67085, mean: 0.08455
[32m[0906 22-28-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18290, current rewards: 133.43898, mean: 0.08554
[32m[0906 22-28-55 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18265, current rewards: 139.21307, mean: 0.08647
[32m[0906 22-29-04 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18240, current rewards: 144.97917, mean: 0.08734
[32m[0906 22-29-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18217, current rewards: 150.74892, mean: 0.08816
[32m[0906 22-29-21 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18195, current rewards: 156.51976, mean: 0.08893
[32m[0906 22-29-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18174, current rewards: 162.78364, mean: 0.08994
[32m[0906 22-29-39 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18153, current rewards: 168.56978, mean: 0.09063
[32m[0906 22-29-48 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18143, current rewards: 152.89290, mean: 0.08005
[32m[0906 22-29-57 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18140, current rewards: 158.11194, mean: 0.08067
[32m[0906 22-30-06 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18137, current rewards: 163.32955, mean: 0.08126
[32m[0906 22-30-15 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18134, current rewards: 168.54630, mean: 0.08182
[32m[0906 22-30-24 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18129, current rewards: 173.76413, mean: 0.08235
[32m[0906 22-30-33 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18127, current rewards: 178.98226, mean: 0.08286
[32m[0906 22-30-42 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18129, current rewards: 183.64359, mean: 0.08310
[32m[0906 22-30-51 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18138, current rewards: 188.77108, mean: 0.08353
[32m[0906 22-31-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18147, current rewards: 193.90261, mean: 0.08394
[32m[0906 22-31-10 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18154, current rewards: 199.03239, mean: 0.08434
[32m[0906 22-31-19 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18161, current rewards: 204.16237, mean: 0.08471
[32m[0906 22-31-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18159, current rewards: 209.28887, mean: 0.08508
[32m[0906 22-31-35 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 22-31-35 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-31-35 @MBExp.py:227][0m Rewards obtained: [213.3904501181694], Lows: [11], Highs: [41], Total time: 28002.643999999997
[32m[0906 22-33-40 @MBExp.py:144][0m ####################################################################
[32m[0906 22-33-40 @MBExp.py:145][0m Starting training iteration 62.
[32m[0906 22-33-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17908, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-33-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17984, current rewards: -27.67640, mean: -0.46127
[32m[0906 22-34-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18125, current rewards: -20.06936, mean: -0.18245
[32m[0906 22-34-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18245, current rewards: -14.70542, mean: -0.09191
[32m[0906 22-34-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18313, current rewards: -9.35006, mean: -0.04452
[32m[0906 22-34-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18327, current rewards: -3.98907, mean: -0.01534
[32m[0906 22-34-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18349, current rewards: 1.37081, mean: 0.00442
[32m[0906 22-34-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18381, current rewards: 6.72642, mean: 0.01868
[32m[0906 22-34-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18400, current rewards: -17.69044, mean: -0.04315
[32m[0906 22-35-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18410, current rewards: -12.43771, mean: -0.02704
[32m[0906 22-35-14 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18425, current rewards: -7.15794, mean: -0.01404
[32m[0906 22-35-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18425, current rewards: -1.75553, mean: -0.00313
[32m[0906 22-35-32 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18428, current rewards: 3.51751, mean: 0.00577
[32m[0906 22-35-41 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18423, current rewards: 8.78936, mean: 0.01332
[32m[0906 22-35-51 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18426, current rewards: 14.06422, mean: 0.01981
[32m[0906 22-36-00 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18428, current rewards: 19.33667, mean: 0.02544
[32m[0906 22-36-09 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18431, current rewards: 24.60871, mean: 0.03038
[32m[0906 22-36-18 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18435, current rewards: 22.13954, mean: 0.02574
[32m[0906 22-36-28 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18440, current rewards: 22.51834, mean: 0.02475
[32m[0906 22-36-37 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18439, current rewards: 29.01923, mean: 0.03023
[32m[0906 22-36-46 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18439, current rewards: 34.48602, mean: 0.03414
[32m[0906 22-36-55 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18450, current rewards: 39.95688, mean: 0.03770
[32m[0906 22-37-05 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18450, current rewards: 45.42089, mean: 0.04092
[32m[0906 22-37-14 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18438, current rewards: 50.88712, mean: 0.04387
[32m[0906 22-37-23 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18418, current rewards: 34.93708, mean: 0.02887
[32m[0906 22-37-32 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18402, current rewards: 40.20831, mean: 0.03191
[32m[0906 22-37-41 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18388, current rewards: 45.48262, mean: 0.03472
[32m[0906 22-37-50 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18375, current rewards: 50.14223, mean: 0.03687
[32m[0906 22-37-59 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18362, current rewards: 55.49096, mean: 0.03936
[32m[0906 22-38-08 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18351, current rewards: 60.83654, mean: 0.04167
[32m[0906 22-38-17 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18333, current rewards: 66.18189, mean: 0.04383
[32m[0906 22-38-26 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18303, current rewards: 71.53139, mean: 0.04585
[32m[0906 22-38-34 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18278, current rewards: 76.87280, mean: 0.04775
[32m[0906 22-38-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18251, current rewards: 82.22294, mean: 0.04953
[32m[0906 22-38-52 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18229, current rewards: 67.55040, mean: 0.03950
[32m[0906 22-39-01 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18210, current rewards: 74.06582, mean: 0.04208
[32m[0906 22-39-09 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18189, current rewards: 79.85476, mean: 0.04412
[32m[0906 22-39-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18169, current rewards: 85.64423, mean: 0.04605
[32m[0906 22-39-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18163, current rewards: 91.43131, mean: 0.04787
[32m[0906 22-39-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18159, current rewards: 97.22065, mean: 0.04960
[32m[0906 22-39-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18157, current rewards: 103.00783, mean: 0.05125
[32m[0906 22-39-54 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18153, current rewards: 108.79509, mean: 0.05281
[32m[0906 22-40-03 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18151, current rewards: 114.58256, mean: 0.05430
[32m[0906 22-40-12 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18147, current rewards: 109.79448, mean: 0.05083
[32m[0906 22-40-21 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18144, current rewards: 115.67693, mean: 0.05234
[32m[0906 22-40-30 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18149, current rewards: 121.33815, mean: 0.05369
[32m[0906 22-40-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18156, current rewards: 127.00622, mean: 0.05498
[32m[0906 22-40-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18162, current rewards: 132.66911, mean: 0.05622
[32m[0906 22-40-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18170, current rewards: 138.32817, mean: 0.05740
[32m[0906 22-41-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18172, current rewards: 143.99292, mean: 0.05853
[32m[0906 22-41-15 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0906 22-41-15 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-41-15 @MBExp.py:227][0m Rewards obtained: [148.52235570209004], Lows: [49], Highs: [32], Total time: 28457.660637999998
[32m[0906 22-43-21 @MBExp.py:144][0m ####################################################################
[32m[0906 22-43-21 @MBExp.py:145][0m Starting training iteration 63.
[32m[0906 22-43-23 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17976, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-43-32 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17983, current rewards: -5.54275, mean: -0.09238
[32m[0906 22-43-41 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18152, current rewards: 0.68371, mean: 0.00622
[32m[0906 22-43-50 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18279, current rewards: 5.95436, mean: 0.03721
[32m[0906 22-44-00 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18327, current rewards: 11.22550, mean: 0.05345
[32m[0906 22-44-09 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18336, current rewards: 16.49116, mean: 0.06343
[32m[0906 22-44-18 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18351, current rewards: 21.75725, mean: 0.07018
[32m[0906 22-44-27 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18364, current rewards: 27.02793, mean: 0.07508
[32m[0906 22-44-37 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18398, current rewards: 8.63222, mean: 0.02105
[32m[0906 22-44-46 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18406, current rewards: 17.42088, mean: 0.03787
[32m[0906 22-44-55 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18411, current rewards: 13.41267, mean: 0.02630
[32m[0906 22-45-04 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18415, current rewards: -36.58733, mean: -0.06533
[32m[0906 22-45-14 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18422, current rewards: -86.58733, mean: -0.14195
[32m[0906 22-45-23 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18432, current rewards: -131.02811, mean: -0.19853
[32m[0906 22-45-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18559, current rewards: -137.94044, mean: -0.19428
[32m[0906 22-45-42 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18552, current rewards: -132.51579, mean: -0.17436
[32m[0906 22-45-52 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18551, current rewards: -127.09258, mean: -0.15690
[32m[0906 22-46-01 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18541, current rewards: -121.67217, mean: -0.14148
[32m[0906 22-46-10 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18534, current rewards: -126.25918, mean: -0.13875
[32m[0906 22-46-19 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18530, current rewards: -121.07136, mean: -0.12612
[32m[0906 22-46-29 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18526, current rewards: -116.28445, mean: -0.11513
[32m[0906 22-46-38 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18522, current rewards: -111.49809, mean: -0.10519
[32m[0906 22-46-47 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18514, current rewards: -106.70636, mean: -0.09613
[32m[0906 22-46-56 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18493, current rewards: -101.92748, mean: -0.08787
[32m[0906 22-47-05 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18473, current rewards: -97.14255, mean: -0.08028
[32m[0906 22-47-14 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18451, current rewards: -91.30791, mean: -0.07247
[32m[0906 22-47-23 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18438, current rewards: -82.15476, mean: -0.06271
[32m[0906 22-47-32 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18425, current rewards: -74.97708, mean: -0.05513
[32m[0906 22-47-41 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18411, current rewards: -69.85057, mean: -0.04954
[32m[0906 22-47-50 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18397, current rewards: -64.71382, mean: -0.04432
[32m[0906 22-47-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18369, current rewards: -59.58270, mean: -0.03946
[32m[0906 22-48-08 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18340, current rewards: -58.65978, mean: -0.03760
[32m[0906 22-48-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18311, current rewards: -69.31138, mean: -0.04305
[32m[0906 22-48-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18285, current rewards: -63.29570, mean: -0.03813
[32m[0906 22-48-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18260, current rewards: -57.27809, mean: -0.03350
[32m[0906 22-48-43 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18237, current rewards: -51.71316, mean: -0.02938
[32m[0906 22-48-51 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18214, current rewards: -45.83176, mean: -0.02532
[32m[0906 22-49-00 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18197, current rewards: -39.95249, mean: -0.02148
[32m[0906 22-49-09 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18192, current rewards: -41.89717, mean: -0.02194
[32m[0906 22-49-18 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18187, current rewards: -40.36898, mean: -0.02060
[32m[0906 22-49-27 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18184, current rewards: -35.11418, mean: -0.01747
[32m[0906 22-49-36 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18181, current rewards: -29.86000, mean: -0.01450
[32m[0906 22-49-45 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18176, current rewards: -24.61202, mean: -0.01166
[32m[0906 22-49-54 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18173, current rewards: -19.71204, mean: -0.00913
[32m[0906 22-50-03 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18168, current rewards: -14.52961, mean: -0.00657
[32m[0906 22-50-12 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18176, current rewards: -9.31886, mean: -0.00412
[32m[0906 22-50-22 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18185, current rewards: -4.10540, mean: -0.00178
[32m[0906 22-50-31 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18192, current rewards: 1.10277, mean: 0.00047
[32m[0906 22-50-40 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18197, current rewards: 6.31737, mean: 0.00262
[32m[0906 22-50-49 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18195, current rewards: 11.53026, mean: 0.00469
[32m[0906 22-50-57 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0906 22-50-57 @Agent.py:118][0m Rollout length: 2510
[32m[0906 22-50-57 @MBExp.py:227][0m Rewards obtained: [-7.535705992940073], Lows: [35], Highs: [192], Total time: 28913.352206999996
[32m[0906 22-53-05 @MBExp.py:144][0m ####################################################################
[32m[0906 22-53-05 @MBExp.py:145][0m Starting training iteration 64.
[32m[0906 22-53-07 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17982, current rewards: -10.00000, mean: -1.00000
[32m[0906 22-53-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18003, current rewards: -4.74272, mean: -0.07905
[32m[0906 22-53-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18238, current rewards: 0.43055, mean: 0.00391
[32m[0906 22-53-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18360, current rewards: 5.60075, mean: 0.03500
[32m[0906 22-53-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18436, current rewards: 10.77133, mean: 0.05129
[32m[0906 22-53-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18452, current rewards: -0.88606, mean: -0.00341
[32m[0906 22-54-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18460, current rewards: 0.15660, mean: 0.00051
[32m[0906 22-54-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18463, current rewards: 5.26281, mean: 0.01462
[32m[0906 22-54-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18465, current rewards: 10.36525, mean: 0.02528
[32m[0906 22-54-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18468, current rewards: 15.46979, mean: 0.03363
[32m[0906 22-54-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18468, current rewards: 21.16965, mean: 0.04151
[32m[0906 22-54-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18463, current rewards: 23.62446, mean: 0.04219
[32m[0906 22-54-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18468, current rewards: 28.92122, mean: 0.04741
[32m[0906 22-55-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18469, current rewards: 34.21532, mean: 0.05184
[32m[0906 22-55-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18471, current rewards: 39.50995, mean: 0.05565
[32m[0906 22-55-26 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18470, current rewards: 44.80459, mean: 0.05895
[32m[0906 22-55-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18464, current rewards: 24.49098, mean: 0.03024
[32m[0906 22-55-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18467, current rewards: 32.35052, mean: 0.03762
[32m[0906 22-55-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18470, current rewards: 39.30004, mean: 0.04319
[32m[0906 22-56-03 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18467, current rewards: 46.06408, mean: 0.04798
[32m[0906 22-56-12 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18462, current rewards: 52.82812, mean: 0.05231
[32m[0906 22-56-21 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18459, current rewards: 59.59216, mean: 0.05622
[32m[0906 22-56-30 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18445, current rewards: 53.86811, mean: 0.04853
[32m[0906 22-56-39 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18425, current rewards: 3.86811, mean: 0.00333
[32m[0906 22-56-48 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18406, current rewards: -46.13189, mean: -0.03813
[32m[0906 22-56-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18391, current rewards: -96.13189, mean: -0.07630
[32m[0906 22-57-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18377, current rewards: -146.13189, mean: -0.11155
[32m[0906 22-57-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18363, current rewards: -196.13189, mean: -0.14421
[32m[0906 22-57-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18351, current rewards: -246.13189, mean: -0.17456
[32m[0906 22-57-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18340, current rewards: -296.13189, mean: -0.20283
[32m[0906 22-57-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18310, current rewards: -346.13189, mean: -0.22923
[32m[0906 22-57-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18285, current rewards: -396.13189, mean: -0.25393
[32m[0906 22-58-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18260, current rewards: -446.13189, mean: -0.27710
[32m[0906 22-58-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18237, current rewards: -496.13189, mean: -0.29887
[32m[0906 22-58-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18213, current rewards: -546.13189, mean: -0.31938
[32m[0906 22-58-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18189, current rewards: -596.13189, mean: -0.33871
[32m[0906 22-58-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18168, current rewards: -646.13189, mean: -0.35698
[32m[0906 22-58-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18155, current rewards: -686.23960, mean: -0.36895
[32m[0906 22-58-52 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18151, current rewards: -681.28239, mean: -0.35669
[32m[0906 22-59-01 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18147, current rewards: -676.32518, mean: -0.34506
[32m[0906 22-59-10 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18144, current rewards: -671.36797, mean: -0.33401
[32m[0906 22-59-19 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18140, current rewards: -666.41076, mean: -0.32350
[32m[0906 22-59-28 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18138, current rewards: -681.78149, mean: -0.32312
[32m[0906 22-59-37 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18134, current rewards: -731.78149, mean: -0.33879
[32m[0906 22-59-46 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18130, current rewards: -781.78149, mean: -0.35375
[32m[0906 22-59-56 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18142, current rewards: -831.78149, mean: -0.36804
[32m[0906 23-00-05 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18152, current rewards: -881.78149, mean: -0.38172
[32m[0906 23-00-14 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18156, current rewards: -931.78149, mean: -0.39482
[32m[0906 23-00-23 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18161, current rewards: -981.78149, mean: -0.40738
[32m[0906 23-00-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18159, current rewards: -1031.78149, mean: -0.41942
[32m[0906 23-00-40 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0906 23-00-40 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-00-40 @MBExp.py:227][0m Rewards obtained: [-1071.7814917168098], Lows: [23], Highs: [1172], Total time: 29368.048268999995
[32m[0906 23-02-50 @MBExp.py:144][0m ####################################################################
[32m[0906 23-02-50 @MBExp.py:145][0m Starting training iteration 65.
[32m[0906 23-02-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17839, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-03-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17986, current rewards: -107.85853, mean: -1.79764
[32m[0906 23-03-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18226, current rewards: -207.85853, mean: -1.88962
[32m[0906 23-03-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18340, current rewards: -307.85853, mean: -1.92412
[32m[0906 23-03-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18367, current rewards: -407.85853, mean: -1.94218
[32m[0906 23-03-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18398, current rewards: -507.85853, mean: -1.95330
[32m[0906 23-03-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18398, current rewards: -607.85853, mean: -1.96083
[32m[0906 23-03-56 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18403, current rewards: -707.85853, mean: -1.96627
[32m[0906 23-04-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18425, current rewards: -807.85853, mean: -1.97039
[32m[0906 23-04-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18440, current rewards: -907.85853, mean: -1.97361
[32m[0906 23-04-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18446, current rewards: -1007.85853, mean: -1.97619
[32m[0906 23-04-34 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18448, current rewards: -1107.85853, mean: -1.97832
[32m[0906 23-04-43 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18449, current rewards: -1207.85853, mean: -1.98010
[32m[0906 23-04-52 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18451, current rewards: -1307.85853, mean: -1.98160
[32m[0906 23-05-01 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18451, current rewards: -1407.85853, mean: -1.98290
[32m[0906 23-05-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18453, current rewards: -1507.85853, mean: -1.98402
[32m[0906 23-05-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18457, current rewards: -1607.85853, mean: -1.98501
[32m[0906 23-05-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18455, current rewards: -1707.85853, mean: -1.98588
[32m[0906 23-05-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18453, current rewards: -1807.85853, mean: -1.98666
[32m[0906 23-05-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18459, current rewards: -1907.85853, mean: -1.98735
[32m[0906 23-05-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18458, current rewards: -2007.85853, mean: -1.98798
[32m[0906 23-06-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18455, current rewards: -2107.85853, mean: -1.98855
[32m[0906 23-06-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18442, current rewards: -2207.85853, mean: -1.98906
[32m[0906 23-06-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18425, current rewards: -2307.85853, mean: -1.98953
[32m[0906 23-06-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18407, current rewards: -2407.85853, mean: -1.98997
[32m[0906 23-06-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18391, current rewards: -2507.85853, mean: -1.99036
[32m[0906 23-06-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18376, current rewards: -2607.85853, mean: -1.99073
[32m[0906 23-07-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18360, current rewards: -2707.85853, mean: -1.99107
[32m[0906 23-07-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18347, current rewards: -2807.85853, mean: -1.99139
[32m[0906 23-07-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18326, current rewards: -2907.85853, mean: -1.99168
[32m[0906 23-07-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18298, current rewards: -3007.85853, mean: -1.99196
[32m[0906 23-07-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18269, current rewards: -3107.85853, mean: -1.99222
[32m[0906 23-07-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18243, current rewards: -3207.85853, mean: -1.99246
[32m[0906 23-07-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18219, current rewards: -3307.85853, mean: -1.99269
[32m[0906 23-08-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18195, current rewards: -3407.85853, mean: -1.99290
[32m[0906 23-08-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18172, current rewards: -3507.85853, mean: -1.99310
[32m[0906 23-08-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18154, current rewards: -3607.85853, mean: -1.99329
[32m[0906 23-08-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18148, current rewards: -3707.85853, mean: -1.99347
[32m[0906 23-08-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18143, current rewards: -3807.85853, mean: -1.99364
[32m[0906 23-08-46 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18139, current rewards: -3907.85853, mean: -1.99381
[32m[0906 23-08-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18135, current rewards: -4007.85853, mean: -1.99396
[32m[0906 23-09-04 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18131, current rewards: -4107.85853, mean: -1.99411
[32m[0906 23-09-13 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18127, current rewards: -4207.85853, mean: -1.99425
[32m[0906 23-09-22 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18124, current rewards: -4307.85853, mean: -1.99438
[32m[0906 23-09-31 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18122, current rewards: -4407.85853, mean: -1.99451
[32m[0906 23-09-40 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18132, current rewards: -4507.85853, mean: -1.99463
[32m[0906 23-09-50 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18140, current rewards: -4607.85853, mean: -1.99474
[32m[0906 23-09-59 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18148, current rewards: -4707.85853, mean: -1.99486
[32m[0906 23-10-08 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18156, current rewards: -4807.85853, mean: -1.99496
[32m[0906 23-10-17 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18155, current rewards: -4907.85853, mean: -1.99506
[32m[0906 23-10-25 @Agent.py:117][0m Average action selection time: 0.1815
[32m[0906 23-10-25 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-10-25 @MBExp.py:227][0m Rewards obtained: [-4987.858527623176], Lows: [2489], Highs: [10], Total time: 29822.665246999997
[32m[0906 23-12-37 @MBExp.py:144][0m ####################################################################
[32m[0906 23-12-37 @MBExp.py:145][0m Starting training iteration 66.
[32m[0906 23-12-39 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19098, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-12-48 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18180, current rewards: -53.06176, mean: -0.88436
[32m[0906 23-12-57 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18348, current rewards: -47.65414, mean: -0.43322
[32m[0906 23-13-06 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18391, current rewards: -42.30278, mean: -0.26439
[32m[0906 23-13-16 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18410, current rewards: -36.96244, mean: -0.17601
[32m[0906 23-13-25 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18429, current rewards: -31.62119, mean: -0.12162
[32m[0906 23-13-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18424, current rewards: -26.27781, mean: -0.08477
[32m[0906 23-13-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18425, current rewards: -20.94165, mean: -0.05817
[32m[0906 23-13-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18434, current rewards: -15.59644, mean: -0.03804
[32m[0906 23-14-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18438, current rewards: -15.81123, mean: -0.03437
[32m[0906 23-14-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18441, current rewards: -19.39176, mean: -0.03802
[32m[0906 23-14-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18444, current rewards: -13.83031, mean: -0.02470
[32m[0906 23-14-29 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18441, current rewards: -8.27282, mean: -0.01356
[32m[0906 23-14-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18453, current rewards: -2.71348, mean: -0.00411
[32m[0906 23-14-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18453, current rewards: 2.84634, mean: 0.00401
[32m[0906 23-14-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18449, current rewards: 8.39859, mean: 0.01105
[32m[0906 23-15-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18445, current rewards: 13.95477, mean: 0.01723
[32m[0906 23-15-16 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18447, current rewards: 19.51302, mean: 0.02269
[32m[0906 23-15-25 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18445, current rewards: 25.68064, mean: 0.02822
[32m[0906 23-15-34 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18444, current rewards: 31.22559, mean: 0.03253
[32m[0906 23-15-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18440, current rewards: 36.76824, mean: 0.03640
[32m[0906 23-15-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18422, current rewards: 42.31548, mean: 0.03992
[32m[0906 23-16-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18401, current rewards: 47.86768, mean: 0.04312
[32m[0906 23-16-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18387, current rewards: 53.41397, mean: 0.04605
[32m[0906 23-16-19 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18372, current rewards: 44.18498, mean: 0.03652
[32m[0906 23-16-28 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18357, current rewards: 41.03928, mean: 0.03257
[32m[0906 23-16-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18345, current rewards: 46.03906, mean: 0.03514
[32m[0906 23-16-47 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18339, current rewards: 51.48283, mean: 0.03786
[32m[0906 23-16-56 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18327, current rewards: 56.92825, mean: 0.04037
[32m[0906 23-17-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18312, current rewards: 62.37357, mean: 0.04272
[32m[0906 23-17-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18285, current rewards: 67.81890, mean: 0.04491
[32m[0906 23-17-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18259, current rewards: 73.25988, mean: 0.04696
[32m[0906 23-17-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18234, current rewards: 78.70560, mean: 0.04889
[32m[0906 23-17-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18209, current rewards: 84.15225, mean: 0.05069
[32m[0906 23-17-48 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18186, current rewards: 91.75854, mean: 0.05366
[32m[0906 23-17-57 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18166, current rewards: 86.11221, mean: 0.04893
[32m[0906 23-18-06 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18146, current rewards: 91.36621, mean: 0.05048
[32m[0906 23-18-15 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18142, current rewards: 96.78494, mean: 0.05203
[32m[0906 23-18-24 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18139, current rewards: 102.20608, mean: 0.05351
[32m[0906 23-18-33 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18136, current rewards: 107.62923, mean: 0.05491
[32m[0906 23-18-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18132, current rewards: 113.04572, mean: 0.05624
[32m[0906 23-18-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18133, current rewards: 118.46992, mean: 0.05751
[32m[0906 23-19-00 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18130, current rewards: 124.05263, mean: 0.05879
[32m[0906 23-19-09 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18127, current rewards: 129.50708, mean: 0.05996
[32m[0906 23-19-18 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18123, current rewards: 134.93874, mean: 0.06106
[32m[0906 23-19-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18129, current rewards: 140.26365, mean: 0.06206
[32m[0906 23-19-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18138, current rewards: 138.35947, mean: 0.05990
[32m[0906 23-19-46 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18144, current rewards: 143.82399, mean: 0.06094
[32m[0906 23-19-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18152, current rewards: 149.29316, mean: 0.06195
[32m[0906 23-20-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18151, current rewards: 154.75716, mean: 0.06291
[32m[0906 23-20-11 @Agent.py:117][0m Average action selection time: 0.1815
[32m[0906 23-20-11 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-20-11 @MBExp.py:227][0m Rewards obtained: [159.12699171171036], Lows: [40], Highs: [30], Total time: 30277.149875999996
[32m[0906 23-22-26 @MBExp.py:144][0m ####################################################################
[32m[0906 23-22-26 @MBExp.py:145][0m Starting training iteration 67.
[32m[0906 23-22-27 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17972, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-22-37 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18377, current rewards: -25.40088, mean: -0.42335
[32m[0906 23-22-46 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18278, current rewards: -20.02076, mean: -0.18201
[32m[0906 23-22-55 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18381, current rewards: -14.64269, mean: -0.09152
[32m[0906 23-23-04 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18472, current rewards: -9.26073, mean: -0.04410
[32m[0906 23-23-14 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18490, current rewards: -36.94132, mean: -0.14208
[32m[0906 23-23-23 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18483, current rewards: -62.66007, mean: -0.20213
[32m[0906 23-23-32 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18487, current rewards: -84.09917, mean: -0.23361
[32m[0906 23-23-41 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18473, current rewards: -107.70968, mean: -0.26271
[32m[0906 23-23-51 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18477, current rewards: -131.43867, mean: -0.28574
[32m[0906 23-24-00 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18476, current rewards: -152.99073, mean: -0.29998
[32m[0906 23-24-09 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18476, current rewards: -178.77257, mean: -0.31924
[32m[0906 23-24-19 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18493, current rewards: -200.30083, mean: -0.32836
[32m[0906 23-24-28 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18493, current rewards: -215.57326, mean: -0.32663
[32m[0906 23-24-37 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18492, current rewards: -209.92975, mean: -0.29568
[32m[0906 23-24-46 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18493, current rewards: -204.28222, mean: -0.26879
[32m[0906 23-24-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18484, current rewards: -198.64210, mean: -0.24524
[32m[0906 23-25-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18488, current rewards: -191.59657, mean: -0.22279
[32m[0906 23-25-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18489, current rewards: -185.41889, mean: -0.20376
[32m[0906 23-25-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18486, current rewards: -211.82427, mean: -0.22065
[32m[0906 23-25-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18477, current rewards: -261.82427, mean: -0.25923
[32m[0906 23-25-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18454, current rewards: -311.82427, mean: -0.29417
[32m[0906 23-25-51 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18432, current rewards: -361.82427, mean: -0.32597
[32m[0906 23-25-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18411, current rewards: -411.82427, mean: -0.35502
[32m[0906 23-26-09 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18395, current rewards: -461.82427, mean: -0.38167
[32m[0906 23-26-18 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18380, current rewards: -511.82427, mean: -0.40621
[32m[0906 23-26-27 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18366, current rewards: -561.82427, mean: -0.42887
[32m[0906 23-26-36 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18351, current rewards: -611.82427, mean: -0.44987
[32m[0906 23-26-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18340, current rewards: -661.82427, mean: -0.46938
[32m[0906 23-26-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18317, current rewards: -711.82427, mean: -0.48755
[32m[0906 23-27-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18288, current rewards: -761.82427, mean: -0.50452
[32m[0906 23-27-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18261, current rewards: -811.82427, mean: -0.52040
[32m[0906 23-27-20 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18236, current rewards: -861.82427, mean: -0.53529
[32m[0906 23-27-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18211, current rewards: -911.82427, mean: -0.54929
[32m[0906 23-27-37 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18188, current rewards: -961.82427, mean: -0.56247
[32m[0906 23-27-46 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18166, current rewards: -1011.82427, mean: -0.57490
[32m[0906 23-27-55 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18153, current rewards: -1061.82427, mean: -0.58664
[32m[0906 23-28-04 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18148, current rewards: -1111.82427, mean: -0.59775
[32m[0906 23-28-13 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18144, current rewards: -1161.82427, mean: -0.60828
[32m[0906 23-28-22 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18141, current rewards: -1211.82427, mean: -0.61828
[32m[0906 23-28-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18137, current rewards: -1261.82427, mean: -0.62777
[32m[0906 23-28-40 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18135, current rewards: -1311.82427, mean: -0.63681
[32m[0906 23-28-49 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18131, current rewards: -1361.82427, mean: -0.64541
[32m[0906 23-28-58 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18130, current rewards: -1411.82427, mean: -0.65362
[32m[0906 23-29-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18129, current rewards: -1461.82427, mean: -0.66146
[32m[0906 23-29-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18136, current rewards: -1511.82427, mean: -0.66895
[32m[0906 23-29-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18146, current rewards: -1561.82427, mean: -0.67611
[32m[0906 23-29-35 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18152, current rewards: -1611.82427, mean: -0.68298
[32m[0906 23-29-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18158, current rewards: -1661.82427, mean: -0.68955
[32m[0906 23-29-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18158, current rewards: -1711.82427, mean: -0.69586
[32m[0906 23-30-00 @Agent.py:117][0m Average action selection time: 0.1815
[32m[0906 23-30-00 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-30-00 @MBExp.py:227][0m Rewards obtained: [-1751.8242654182927], Lows: [128], Highs: [1589], Total time: 30731.809581999994
[32m[0906 23-32-17 @MBExp.py:144][0m ####################################################################
[32m[0906 23-32-17 @MBExp.py:145][0m Starting training iteration 68.
[32m[0906 23-32-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17967, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-32-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17988, current rewards: -69.85774, mean: -1.16430
[32m[0906 23-32-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18054, current rewards: -112.29265, mean: -1.02084
[32m[0906 23-32-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18202, current rewards: -163.55306, mean: -1.02221
[32m[0906 23-32-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18244, current rewards: -205.72921, mean: -0.97966
[32m[0906 23-33-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18270, current rewards: -252.83725, mean: -0.97245
[32m[0906 23-33-13 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18304, current rewards: -307.04904, mean: -0.99048
[32m[0906 23-33-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18324, current rewards: -339.24796, mean: -0.94236
[32m[0906 23-33-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18363, current rewards: -398.61517, mean: -0.97223
[32m[0906 23-33-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18383, current rewards: -446.38258, mean: -0.97040
[32m[0906 23-33-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18392, current rewards: -493.00027, mean: -0.96667
[32m[0906 23-34-00 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18390, current rewards: -491.33461, mean: -0.87738
[32m[0906 23-34-09 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18396, current rewards: -486.11398, mean: -0.79691
[32m[0906 23-34-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18401, current rewards: -480.88811, mean: -0.72862
[32m[0906 23-34-27 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18401, current rewards: -475.65445, mean: -0.66994
[32m[0906 23-34-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18398, current rewards: -491.55436, mean: -0.64678
[32m[0906 23-34-46 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18396, current rewards: -535.34944, mean: -0.66093
[32m[0906 23-34-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18394, current rewards: -537.96301, mean: -0.62554
[32m[0906 23-35-04 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18400, current rewards: -532.10997, mean: -0.58474
[32m[0906 23-35-13 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18400, current rewards: -526.26695, mean: -0.54819
[32m[0906 23-35-22 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18384, current rewards: -541.40567, mean: -0.53605
[32m[0906 23-35-31 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18369, current rewards: -531.89129, mean: -0.50178
[32m[0906 23-35-41 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18356, current rewards: -522.28242, mean: -0.47052
[32m[0906 23-35-50 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18339, current rewards: -512.66192, mean: -0.44195
[32m[0906 23-35-59 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18326, current rewards: -503.04389, mean: -0.41574
[32m[0906 23-36-08 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18313, current rewards: -494.31867, mean: -0.39232
[32m[0906 23-36-17 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18300, current rewards: -484.51849, mean: -0.36986
[32m[0906 23-36-26 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18288, current rewards: -499.42927, mean: -0.36723
[32m[0906 23-36-35 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18276, current rewards: -495.65943, mean: -0.35153
[32m[0906 23-36-43 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18248, current rewards: -489.64839, mean: -0.33538
[32m[0906 23-36-52 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18221, current rewards: -483.63553, mean: -0.32029
[32m[0906 23-37-01 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18194, current rewards: -477.62518, mean: -0.30617
[32m[0906 23-37-09 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18172, current rewards: -471.61647, mean: -0.29293
[32m[0906 23-37-18 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18151, current rewards: -460.61241, mean: -0.27748
[32m[0906 23-37-27 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18147, current rewards: -465.76468, mean: -0.27238
[32m[0906 23-37-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18127, current rewards: -460.07970, mean: -0.26141
[32m[0906 23-37-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18122, current rewards: -453.41548, mean: -0.25051
[32m[0906 23-37-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18119, current rewards: -446.73803, mean: -0.24018
[32m[0906 23-38-03 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18117, current rewards: -441.20480, mean: -0.23100
[32m[0906 23-38-12 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18115, current rewards: -448.80726, mean: -0.22898
[32m[0906 23-38-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18112, current rewards: -443.56905, mean: -0.22068
[32m[0906 23-38-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18108, current rewards: -439.09303, mean: -0.21315
[32m[0906 23-38-39 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18105, current rewards: -433.98524, mean: -0.20568
[32m[0906 23-38-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18102, current rewards: -428.85074, mean: -0.19854
[32m[0906 23-38-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18100, current rewards: -423.71186, mean: -0.19172
[32m[0906 23-39-06 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18108, current rewards: -435.39781, mean: -0.19265
[32m[0906 23-39-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18118, current rewards: -433.35149, mean: -0.18760
[32m[0906 23-39-25 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18124, current rewards: -427.36238, mean: -0.18109
[32m[0906 23-39-34 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18132, current rewards: -421.36866, mean: -0.17484
[32m[0906 23-39-43 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18135, current rewards: -415.36617, mean: -0.16885
[32m[0906 23-39-50 @Agent.py:117][0m Average action selection time: 0.1813
[32m[0906 23-39-50 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-39-51 @MBExp.py:227][0m Rewards obtained: [-402.35029697321016], Lows: [340], Highs: [35], Total time: 31185.958862999993
[32m[0906 23-42-09 @MBExp.py:144][0m ####################################################################
[32m[0906 23-42-09 @MBExp.py:145][0m Starting training iteration 69.
[32m[0906 23-42-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18005, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-42-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18039, current rewards: -5.11124, mean: -0.08519
[32m[0906 23-42-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18121, current rewards: 0.41844, mean: 0.00380
[32m[0906 23-42-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18248, current rewards: 5.93990, mean: 0.03712
[32m[0906 23-42-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18340, current rewards: -1.75090, mean: -0.00834
[32m[0906 23-42-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18358, current rewards: 3.76893, mean: 0.01450
[32m[0906 23-43-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18377, current rewards: 9.26615, mean: 0.02989
[32m[0906 23-43-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18391, current rewards: 14.76512, mean: 0.04101
[32m[0906 23-43-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18407, current rewards: 19.67927, mean: 0.04800
[32m[0906 23-43-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18416, current rewards: 24.91557, mean: 0.05416
[32m[0906 23-43-43 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18424, current rewards: 30.27021, mean: 0.05935
[32m[0906 23-43-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18428, current rewards: 35.62494, mean: 0.06362
[32m[0906 23-44-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18440, current rewards: 40.98214, mean: 0.06718
[32m[0906 23-44-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18462, current rewards: 22.92462, mean: 0.03473
[32m[0906 23-44-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18464, current rewards: 29.34676, mean: 0.04133
[32m[0906 23-44-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18460, current rewards: 36.21998, mean: 0.04766
[32m[0906 23-44-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18455, current rewards: 43.08787, mean: 0.05319
[32m[0906 23-44-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18452, current rewards: 49.52537, mean: 0.05759
[32m[0906 23-44-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18452, current rewards: 32.15887, mean: 0.03534
[32m[0906 23-45-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18443, current rewards: 23.80739, mean: 0.02480
[32m[0906 23-45-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18423, current rewards: 16.73646, mean: 0.01657
[32m[0906 23-45-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18403, current rewards: -6.66112, mean: -0.00628
[32m[0906 23-45-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18389, current rewards: -32.46875, mean: -0.02925
[32m[0906 23-45-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18371, current rewards: -45.93069, mean: -0.03960
[32m[0906 23-45-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18354, current rewards: -73.64579, mean: -0.06086
[32m[0906 23-46-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18343, current rewards: -67.88756, mean: -0.05388
[32m[0906 23-46-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18335, current rewards: -62.31985, mean: -0.04757
[32m[0906 23-46-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18322, current rewards: -56.75067, mean: -0.04173
[32m[0906 23-46-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18308, current rewards: -51.18591, mean: -0.03630
[32m[0906 23-46-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18278, current rewards: -45.61769, mean: -0.03124
[32m[0906 23-46-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18252, current rewards: -40.05428, mean: -0.02653
[32m[0906 23-46-53 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18224, current rewards: -34.48434, mean: -0.02211
[32m[0906 23-47-02 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18199, current rewards: -35.25309, mean: -0.02190
[32m[0906 23-47-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18176, current rewards: -52.58525, mean: -0.03168
[32m[0906 23-47-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18155, current rewards: -47.39925, mean: -0.02772
[32m[0906 23-47-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18135, current rewards: -42.21643, mean: -0.02399
[32m[0906 23-47-37 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18131, current rewards: -37.03247, mean: -0.02046
[32m[0906 23-47-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18129, current rewards: -31.84687, mean: -0.01712
[32m[0906 23-47-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18126, current rewards: -26.66064, mean: -0.01396
[32m[0906 23-48-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18124, current rewards: -21.47713, mean: -0.01096
[32m[0906 23-48-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18122, current rewards: -16.29439, mean: -0.00811
[32m[0906 23-48-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18119, current rewards: -10.70295, mean: -0.00520
[32m[0906 23-48-31 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18117, current rewards: -5.38558, mean: -0.00255
[32m[0906 23-48-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18114, current rewards: -2.17828, mean: -0.00101
[32m[0906 23-48-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18112, current rewards: -11.76345, mean: -0.00532
[32m[0906 23-48-59 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18121, current rewards: -42.63293, mean: -0.01886
[32m[0906 23-49-08 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18126, current rewards: -64.97394, mean: -0.02813
[32m[0906 23-49-17 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18133, current rewards: -70.99338, mean: -0.03008
[32m[0906 23-49-26 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18138, current rewards: -80.11096, mean: -0.03324
[32m[0906 23-49-35 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18141, current rewards: -108.61421, mean: -0.04415
[32m[0906 23-49-43 @Agent.py:117][0m Average action selection time: 0.1814
[32m[0906 23-49-43 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-49-43 @MBExp.py:227][0m Rewards obtained: [-112.15612239256434], Lows: [207], Highs: [38], Total time: 31640.23135099999
[32m[0906 23-52-03 @MBExp.py:144][0m ####################################################################
[32m[0906 23-52-03 @MBExp.py:145][0m Starting training iteration 70.
[32m[0906 23-52-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17906, current rewards: -10.00000, mean: -1.00000
[32m[0906 23-52-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18001, current rewards: -7.08708, mean: -0.11812
[32m[0906 23-52-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18043, current rewards: -1.78232, mean: -0.01620
[32m[0906 23-52-32 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18209, current rewards: 3.52171, mean: 0.02201
[32m[0906 23-52-41 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18285, current rewards: 8.81222, mean: 0.04196
[32m[0906 23-52-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18309, current rewards: 14.11010, mean: 0.05427
[32m[0906 23-53-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18318, current rewards: 19.40821, mean: 0.06261
[32m[0906 23-53-09 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18336, current rewards: 24.70863, mean: 0.06864
[32m[0906 23-53-18 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18350, current rewards: 30.85538, mean: 0.07526
[32m[0906 23-53-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18363, current rewards: 36.39058, mean: 0.07911
[32m[0906 23-53-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18370, current rewards: 41.92736, mean: 0.08221
[32m[0906 23-53-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18370, current rewards: 47.46832, mean: 0.08476
[32m[0906 23-53-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18382, current rewards: 53.00821, mean: 0.08690
[32m[0906 23-54-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18396, current rewards: 58.53958, mean: 0.08870
[32m[0906 23-54-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18404, current rewards: 49.58350, mean: 0.06984
[32m[0906 23-54-23 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18405, current rewards: 56.46977, mean: 0.07430
[32m[0906 23-54-32 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18412, current rewards: 63.04282, mean: 0.07783
[32m[0906 23-54-41 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18414, current rewards: 69.95972, mean: 0.08135
[32m[0906 23-54-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18417, current rewards: 76.89073, mean: 0.08450
[32m[0906 23-55-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18399, current rewards: 83.82037, mean: 0.08731
[32m[0906 23-55-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18379, current rewards: 90.73522, mean: 0.08984
[32m[0906 23-55-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18359, current rewards: 97.66720, mean: 0.09214
[32m[0906 23-55-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18342, current rewards: 104.60498, mean: 0.09424
[32m[0906 23-55-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18324, current rewards: 111.51533, mean: 0.09613
[32m[0906 23-55-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18310, current rewards: 118.10698, mean: 0.09761
[32m[0906 23-55-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18296, current rewards: 124.99503, mean: 0.09920
[32m[0906 23-56-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18294, current rewards: 107.55459, mean: 0.08210
[32m[0906 23-56-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18282, current rewards: 113.33875, mean: 0.08334
[32m[0906 23-56-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18271, current rewards: 119.08763, mean: 0.08446
[32m[0906 23-56-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18245, current rewards: 124.84377, mean: 0.08551
[32m[0906 23-56-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18221, current rewards: 130.59668, mean: 0.08649
[32m[0906 23-56-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18194, current rewards: 136.34829, mean: 0.08740
[32m[0906 23-56-56 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18169, current rewards: 142.40146, mean: 0.08845
[32m[0906 23-57-05 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18145, current rewards: 148.10873, mean: 0.08922
[32m[0906 23-57-13 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18124, current rewards: 153.80818, mean: 0.08995
[32m[0906 23-57-22 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18107, current rewards: 159.51551, mean: 0.09063
[32m[0906 23-57-31 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18102, current rewards: 165.22037, mean: 0.09128
[32m[0906 23-57-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18097, current rewards: 156.12011, mean: 0.08394
[32m[0906 23-57-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18096, current rewards: 155.21289, mean: 0.08126
[32m[0906 23-57-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18094, current rewards: 160.43149, mean: 0.08185
[32m[0906 23-58-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18091, current rewards: 167.76153, mean: 0.08346
[32m[0906 23-58-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18090, current rewards: 176.66909, mean: 0.08576
[32m[0906 23-58-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18086, current rewards: 183.76564, mean: 0.08709
[32m[0906 23-58-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18084, current rewards: 190.86219, mean: 0.08836
[32m[0906 23-58-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18084, current rewards: 197.95874, mean: 0.08957
[32m[0906 23-58-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18085, current rewards: 205.05529, mean: 0.09073
[32m[0906 23-59-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18094, current rewards: 176.75198, mean: 0.07652
[32m[0906 23-59-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18102, current rewards: 126.75198, mean: 0.05371
[32m[0906 23-59-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18110, current rewards: 76.75198, mean: 0.03185
[32m[0906 23-59-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18114, current rewards: 26.75198, mean: 0.01087
[32m[0906 23-59-36 @Agent.py:117][0m Average action selection time: 0.1811
[32m[0906 23-59-36 @Agent.py:118][0m Rollout length: 2510
[32m[0906 23-59-36 @MBExp.py:227][0m Rewards obtained: [-13.248017606567657], Lows: [25], Highs: [242], Total time: 32093.81186699999
[32m[0907 00-01-58 @MBExp.py:144][0m ####################################################################
[32m[0907 00-01-58 @MBExp.py:145][0m Starting training iteration 71.
[32m[0907 00-02-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17929, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-02-09 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17969, current rewards: -11.35725, mean: -0.18929
[32m[0907 00-02-18 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17995, current rewards: -5.12514, mean: -0.04659
[32m[0907 00-02-27 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18179, current rewards: 1.09821, mean: 0.00686
[32m[0907 00-02-37 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18264, current rewards: 7.32353, mean: 0.03487
[32m[0907 00-02-46 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18327, current rewards: 13.54978, mean: 0.05211
[32m[0907 00-02-55 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18375, current rewards: 18.88334, mean: 0.06091
[32m[0907 00-03-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18388, current rewards: 24.39780, mean: 0.06777
[32m[0907 00-03-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18387, current rewards: 29.90652, mean: 0.07294
[32m[0907 00-03-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18393, current rewards: 35.48726, mean: 0.07715
[32m[0907 00-03-32 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18398, current rewards: 41.05943, mean: 0.08051
[32m[0907 00-03-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18394, current rewards: 46.62974, mean: 0.08327
[32m[0907 00-03-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18400, current rewards: 52.20411, mean: 0.08558
[32m[0907 00-04-00 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18423, current rewards: 32.21975, mean: 0.04882
[32m[0907 00-04-09 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18427, current rewards: 40.97457, mean: 0.05771
[32m[0907 00-04-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18423, current rewards: 49.61245, mean: 0.06528
[32m[0907 00-04-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18424, current rewards: 57.06290, mean: 0.07045
[32m[0907 00-04-37 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18426, current rewards: 66.16579, mean: 0.07694
[32m[0907 00-04-46 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18419, current rewards: 75.28069, mean: 0.08273
[32m[0907 00-04-55 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18402, current rewards: 84.39991, mean: 0.08792
[32m[0907 00-05-04 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18385, current rewards: 93.50844, mean: 0.09258
[32m[0907 00-05-13 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18367, current rewards: 102.60644, mean: 0.09680
[32m[0907 00-05-22 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18349, current rewards: 111.30652, mean: 0.10028
[32m[0907 00-05-31 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18333, current rewards: 116.05529, mean: 0.10005
[32m[0907 00-05-40 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18318, current rewards: 121.10167, mean: 0.10008
[32m[0907 00-05-49 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18304, current rewards: 126.40893, mean: 0.10032
[32m[0907 00-05-58 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18293, current rewards: 131.71691, mean: 0.10055
[32m[0907 00-06-07 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18282, current rewards: 137.02886, mean: 0.10076
[32m[0907 00-06-16 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18271, current rewards: 142.33209, mean: 0.10094
[32m[0907 00-06-25 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18247, current rewards: 147.63852, mean: 0.10112
[32m[0907 00-06-34 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18221, current rewards: 152.94493, mean: 0.10129
[32m[0907 00-06-43 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18195, current rewards: 158.25116, mean: 0.10144
[32m[0907 00-06-51 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18171, current rewards: 165.66371, mean: 0.10290
[32m[0907 00-07-00 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18149, current rewards: 170.84711, mean: 0.10292
[32m[0907 00-07-09 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18132, current rewards: 156.42756, mean: 0.09148
[32m[0907 00-07-18 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18116, current rewards: 161.07562, mean: 0.09152
[32m[0907 00-07-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18113, current rewards: 166.40906, mean: 0.09194
[32m[0907 00-07-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18109, current rewards: 171.73997, mean: 0.09233
[32m[0907 00-07-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18107, current rewards: 177.07425, mean: 0.09271
[32m[0907 00-07-54 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18103, current rewards: 160.74279, mean: 0.08201
[32m[0907 00-08-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18101, current rewards: 165.01888, mean: 0.08210
[32m[0907 00-08-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18098, current rewards: 169.50974, mean: 0.08229
[32m[0907 00-08-21 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18097, current rewards: 174.10807, mean: 0.08252
[32m[0907 00-08-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18094, current rewards: 178.70480, mean: 0.08273
[32m[0907 00-08-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18093, current rewards: 183.30304, mean: 0.08294
[32m[0907 00-08-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18091, current rewards: 187.89721, mean: 0.08314
[32m[0907 00-08-57 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18100, current rewards: 192.49629, mean: 0.08333
[32m[0907 00-09-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18109, current rewards: 172.44939, mean: 0.07307
[32m[0907 00-09-16 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18119, current rewards: 177.50928, mean: 0.07366
[32m[0907 00-09-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18122, current rewards: 184.57736, mean: 0.07503
[32m[0907 00-09-32 @Agent.py:117][0m Average action selection time: 0.1812
[32m[0907 00-09-32 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-09-32 @MBExp.py:227][0m Rewards obtained: [188.72884002735688], Lows: [32], Highs: [36], Total time: 32547.58462799999
[32m[0907 00-11-56 @MBExp.py:144][0m ####################################################################
[32m[0907 00-11-56 @MBExp.py:145][0m Starting training iteration 72.
[32m[0907 00-11-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17999, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-12-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18195, current rewards: -7.04286, mean: -0.11738
[32m[0907 00-12-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18130, current rewards: -1.27393, mean: -0.01158
[32m[0907 00-12-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18256, current rewards: 4.49177, mean: 0.02807
[32m[0907 00-12-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18325, current rewards: 10.25673, mean: 0.04884
[32m[0907 00-12-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18367, current rewards: 16.01956, mean: 0.06161
[32m[0907 00-12-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18393, current rewards: 21.78134, mean: 0.07026
[32m[0907 00-13-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18405, current rewards: 26.76971, mean: 0.07436
[32m[0907 00-13-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18697, current rewards: 7.60713, mean: 0.01855
[32m[0907 00-13-22 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18828, current rewards: -9.48056, mean: -0.02061
[32m[0907 00-13-31 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18795, current rewards: -3.62516, mean: -0.00711
[32m[0907 00-13-41 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18753, current rewards: 2.16693, mean: 0.00387
[32m[0907 00-13-50 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18724, current rewards: 7.95739, mean: 0.01304
[32m[0907 00-13-59 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18705, current rewards: 13.74623, mean: 0.02083
[32m[0907 00-14-08 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18679, current rewards: 19.54641, mean: 0.02753
[32m[0907 00-14-18 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18665, current rewards: 25.22819, mean: 0.03319
[32m[0907 00-14-27 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18650, current rewards: 31.04603, mean: 0.03833
[32m[0907 00-14-36 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18635, current rewards: 36.83517, mean: 0.04283
[32m[0907 00-14-45 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18622, current rewards: 42.62268, mean: 0.04684
[32m[0907 00-14-54 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18593, current rewards: 48.41468, mean: 0.05043
[32m[0907 00-15-03 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18563, current rewards: 54.19793, mean: 0.05366
[32m[0907 00-15-12 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18536, current rewards: 59.97980, mean: 0.05658
[32m[0907 00-15-21 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18514, current rewards: 63.64562, mean: 0.05734
[32m[0907 00-15-30 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18497, current rewards: 50.64261, mean: 0.04366
[32m[0907 00-15-39 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18476, current rewards: 56.78548, mean: 0.04693
[32m[0907 00-15-48 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18456, current rewards: 62.56159, mean: 0.04965
[32m[0907 00-15-57 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18438, current rewards: 68.33434, mean: 0.05216
[32m[0907 00-16-06 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18422, current rewards: 74.10143, mean: 0.05449
[32m[0907 00-16-15 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18403, current rewards: 79.87440, mean: 0.05665
[32m[0907 00-16-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18368, current rewards: 85.63753, mean: 0.05866
[32m[0907 00-16-33 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18337, current rewards: 80.16776, mean: 0.05309
[32m[0907 00-16-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18307, current rewards: 86.86070, mean: 0.05568
[32m[0907 00-16-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18279, current rewards: 93.72197, mean: 0.05821
[32m[0907 00-16-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18251, current rewards: 99.66045, mean: 0.06004
[32m[0907 00-17-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18226, current rewards: 105.61367, mean: 0.06176
[32m[0907 00-17-16 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18203, current rewards: 111.54828, mean: 0.06338
[32m[0907 00-17-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18196, current rewards: 117.48687, mean: 0.06491
[32m[0907 00-17-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18195, current rewards: 123.43418, mean: 0.06636
[32m[0907 00-17-43 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18189, current rewards: 129.36999, mean: 0.06773
[32m[0907 00-17-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18183, current rewards: 114.02150, mean: 0.05817
[32m[0907 00-18-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18177, current rewards: 120.31662, mean: 0.05986
[32m[0907 00-18-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18172, current rewards: 126.05451, mean: 0.06119
[32m[0907 00-18-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18166, current rewards: 131.79442, mean: 0.06246
[32m[0907 00-18-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18163, current rewards: 137.53702, mean: 0.06367
[32m[0907 00-18-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18158, current rewards: 143.27560, mean: 0.06483
[32m[0907 00-18-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18156, current rewards: 149.01449, mean: 0.06594
[32m[0907 00-18-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18162, current rewards: 154.75379, mean: 0.06699
[32m[0907 00-19-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18169, current rewards: 160.48963, mean: 0.06800
[32m[0907 00-19-14 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18174, current rewards: 166.84443, mean: 0.06923
[32m[0907 00-19-23 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18174, current rewards: 150.05332, mean: 0.06100
[32m[0907 00-19-30 @Agent.py:117][0m Average action selection time: 0.1817
[32m[0907 00-19-30 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-19-31 @MBExp.py:227][0m Rewards obtained: [154.71316372599256], Lows: [52], Highs: [35], Total time: 33002.68131299999
[32m[0907 00-21-56 @MBExp.py:144][0m ####################################################################
[32m[0907 00-21-56 @MBExp.py:145][0m Starting training iteration 73.
[32m[0907 00-21-58 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17825, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-22-07 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17973, current rewards: -5.20990, mean: -0.08683
[32m[0907 00-22-16 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18055, current rewards: -0.30564, mean: -0.00278
[32m[0907 00-22-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18203, current rewards: 4.59876, mean: 0.02874
[32m[0907 00-22-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18279, current rewards: 9.50647, mean: 0.04527
[32m[0907 00-22-44 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18313, current rewards: 14.40837, mean: 0.05542
[32m[0907 00-22-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18323, current rewards: 18.62034, mean: 0.06007
[32m[0907 00-23-03 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18340, current rewards: 23.64138, mean: 0.06567
[32m[0907 00-23-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18349, current rewards: 28.72599, mean: 0.07006
[32m[0907 00-23-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18365, current rewards: 33.81348, mean: 0.07351
[32m[0907 00-23-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18386, current rewards: 26.29242, mean: 0.05155
[32m[0907 00-23-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18407, current rewards: 24.44892, mean: 0.04366
[32m[0907 00-23-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18419, current rewards: 31.37981, mean: 0.05144
[32m[0907 00-23-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18417, current rewards: 38.30778, mean: 0.05804
[32m[0907 00-24-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18416, current rewards: 45.23150, mean: 0.06371
[32m[0907 00-24-17 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18416, current rewards: 51.97824, mean: 0.06839
[32m[0907 00-24-26 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18412, current rewards: 58.82230, mean: 0.07262
[32m[0907 00-24-35 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18405, current rewards: 65.65686, mean: 0.07635
[32m[0907 00-24-44 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18403, current rewards: 72.49783, mean: 0.07967
[32m[0907 00-24-53 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18383, current rewards: 79.33676, mean: 0.08264
[32m[0907 00-25-02 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18365, current rewards: 86.17308, mean: 0.08532
[32m[0907 00-25-11 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18346, current rewards: 93.00880, mean: 0.08774
[32m[0907 00-25-20 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18329, current rewards: 99.84366, mean: 0.08995
[32m[0907 00-25-29 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18317, current rewards: 108.77799, mean: 0.09377
[32m[0907 00-25-38 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18305, current rewards: 116.30851, mean: 0.09612
[32m[0907 00-25-47 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18291, current rewards: 123.83306, mean: 0.09828
[32m[0907 00-25-56 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18285, current rewards: 131.36030, mean: 0.10028
[32m[0907 00-26-05 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18274, current rewards: 138.88615, mean: 0.10212
[32m[0907 00-26-14 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18272, current rewards: 105.99991, mean: 0.07518
[32m[0907 00-26-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18275, current rewards: 39.87007, mean: 0.02731
[32m[0907 00-26-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18255, current rewards: -23.31076, mean: -0.01544
[32m[0907 00-26-41 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18229, current rewards: -98.08433, mean: -0.06287
[32m[0907 00-26-50 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18212, current rewards: -171.65970, mean: -0.10662
[32m[0907 00-26-59 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18201, current rewards: -239.29407, mean: -0.14415
[32m[0907 00-27-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18194, current rewards: -301.77398, mean: -0.17648
[32m[0907 00-27-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18197, current rewards: -382.39940, mean: -0.21727
[32m[0907 00-27-26 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18190, current rewards: -387.96296, mean: -0.21434
[32m[0907 00-27-35 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18184, current rewards: -392.89862, mean: -0.21124
[32m[0907 00-27-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18179, current rewards: -395.77080, mean: -0.20721
[32m[0907 00-27-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18175, current rewards: -400.81781, mean: -0.20450
[32m[0907 00-28-02 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18174, current rewards: -403.66681, mean: -0.20083
[32m[0907 00-28-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18169, current rewards: -408.65190, mean: -0.19837
[32m[0907 00-28-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18164, current rewards: -411.48492, mean: -0.19502
[32m[0907 00-28-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18159, current rewards: -416.46788, mean: -0.19281
[32m[0907 00-28-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18153, current rewards: -419.30113, mean: -0.18973
[32m[0907 00-28-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18149, current rewards: -424.29293, mean: -0.18774
[32m[0907 00-28-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18146, current rewards: -427.11971, mean: -0.18490
[32m[0907 00-29-05 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18152, current rewards: -428.93881, mean: -0.18175
[32m[0907 00-29-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18165, current rewards: -434.57040, mean: -0.18032
[32m[0907 00-29-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18165, current rewards: -429.64824, mean: -0.17465
[32m[0907 00-29-31 @Agent.py:117][0m Average action selection time: 0.1816
[32m[0907 00-29-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-29-31 @MBExp.py:227][0m Rewards obtained: [-425.70753244914766], Lows: [343], Highs: [30], Total time: 33457.547494999984
[32m[0907 00-31-59 @MBExp.py:144][0m ####################################################################
[32m[0907 00-31-59 @MBExp.py:145][0m Starting training iteration 74.
[32m[0907 00-32-01 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17954, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-32-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18177, current rewards: -30.70414, mean: -0.51174
[32m[0907 00-32-19 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18296, current rewards: -25.22067, mean: -0.22928
[32m[0907 00-32-28 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18331, current rewards: -19.73945, mean: -0.12337
[32m[0907 00-32-38 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18366, current rewards: -14.25256, mean: -0.06787
[32m[0907 00-32-47 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18377, current rewards: -8.76282, mean: -0.03370
[32m[0907 00-32-56 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18385, current rewards: -2.94215, mean: -0.00949
[32m[0907 00-33-05 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18399, current rewards: 2.54719, mean: 0.00708
[32m[0907 00-33-14 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18410, current rewards: 8.04197, mean: 0.01961
[32m[0907 00-33-24 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18416, current rewards: 13.53289, mean: 0.02942
[32m[0907 00-33-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18419, current rewards: 19.02794, mean: 0.03731
[32m[0907 00-33-42 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18418, current rewards: 5.06097, mean: 0.00904
[32m[0907 00-33-51 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18428, current rewards: 8.92813, mean: 0.01464
[32m[0907 00-34-01 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18429, current rewards: 12.79306, mean: 0.01938
[32m[0907 00-34-10 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18431, current rewards: 16.31193, mean: 0.02297
[32m[0907 00-34-19 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18443, current rewards: 20.00300, mean: 0.02632
[32m[0907 00-34-28 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18441, current rewards: 3.56964, mean: 0.00441
[32m[0907 00-34-38 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18441, current rewards: 8.80564, mean: 0.01024
[32m[0907 00-34-47 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18434, current rewards: 14.13326, mean: 0.01553
[32m[0907 00-34-56 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18410, current rewards: 19.45980, mean: 0.02027
[32m[0907 00-35-05 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18389, current rewards: 24.78632, mean: 0.02454
[32m[0907 00-35-14 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18371, current rewards: 30.11097, mean: 0.02841
[32m[0907 00-35-23 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18354, current rewards: 35.00650, mean: 0.03154
[32m[0907 00-35-32 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18339, current rewards: 40.28810, mean: 0.03473
[32m[0907 00-35-41 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18326, current rewards: 45.57240, mean: 0.03766
[32m[0907 00-35-50 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18314, current rewards: 50.85802, mean: 0.04036
[32m[0907 00-35-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18304, current rewards: 56.14090, mean: 0.04286
[32m[0907 00-36-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18293, current rewards: 61.42403, mean: 0.04516
[32m[0907 00-36-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18284, current rewards: 56.75776, mean: 0.04025
[32m[0907 00-36-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18291, current rewards: 2.60438, mean: 0.00178
[32m[0907 00-36-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18286, current rewards: -16.30448, mean: -0.01080
[32m[0907 00-36-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18260, current rewards: -11.15868, mean: -0.00715
[32m[0907 00-36-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18234, current rewards: -5.97012, mean: -0.00371
[32m[0907 00-37-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18209, current rewards: -0.79197, mean: -0.00048
[32m[0907 00-37-10 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18188, current rewards: 4.39533, mean: 0.00257
[32m[0907 00-37-19 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18167, current rewards: 9.57971, mean: 0.00544
[32m[0907 00-37-28 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18158, current rewards: 14.76734, mean: 0.00816
[32m[0907 00-37-37 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18154, current rewards: 22.67004, mean: 0.01219
[32m[0907 00-37-46 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18150, current rewards: 28.89991, mean: 0.01513
[32m[0907 00-37-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18146, current rewards: 34.85839, mean: 0.01778
[32m[0907 00-38-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18145, current rewards: 40.85012, mean: 0.02032
[32m[0907 00-38-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18141, current rewards: 46.84769, mean: 0.02274
[32m[0907 00-38-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18138, current rewards: 52.84742, mean: 0.02505
[32m[0907 00-38-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18137, current rewards: 58.84213, mean: 0.02724
[32m[0907 00-38-40 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18134, current rewards: 62.46748, mean: 0.02827
[32m[0907 00-38-49 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18131, current rewards: 67.04339, mean: 0.02967
[32m[0907 00-38-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18128, current rewards: 71.77908, mean: 0.03107
[32m[0907 00-39-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18137, current rewards: 76.59653, mean: 0.03246
[32m[0907 00-39-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18145, current rewards: 81.19459, mean: 0.03369
[32m[0907 00-39-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18152, current rewards: 85.79420, mean: 0.03488
[32m[0907 00-39-33 @Agent.py:117][0m Average action selection time: 0.1815
[32m[0907 00-39-33 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-39-33 @MBExp.py:227][0m Rewards obtained: [89.47380241472312], Lows: [66], Highs: [34], Total time: 33912.09303099998
[32m[0907 00-42-03 @MBExp.py:144][0m ####################################################################
[32m[0907 00-42-03 @MBExp.py:145][0m Starting training iteration 75.
[32m[0907 00-42-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18045, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-42-14 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18042, current rewards: -109.00000, mean: -1.81667
[32m[0907 00-42-23 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18199, current rewards: -209.00000, mean: -1.90000
[32m[0907 00-42-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18313, current rewards: -309.00000, mean: -1.93125
[32m[0907 00-42-42 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18372, current rewards: -409.00000, mean: -1.94762
[32m[0907 00-42-51 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18420, current rewards: -509.00000, mean: -1.95769
[32m[0907 00-43-01 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18427, current rewards: -609.00000, mean: -1.96452
[32m[0907 00-43-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18425, current rewards: -709.00000, mean: -1.96944
[32m[0907 00-43-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18426, current rewards: -809.00000, mean: -1.97317
[32m[0907 00-43-28 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18423, current rewards: -909.00000, mean: -1.97609
[32m[0907 00-43-37 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18425, current rewards: -1009.00000, mean: -1.97843
[32m[0907 00-43-47 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18423, current rewards: -1109.00000, mean: -1.98036
[32m[0907 00-43-56 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18423, current rewards: -1209.00000, mean: -1.98197
[32m[0907 00-44-05 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18421, current rewards: -1309.00000, mean: -1.98333
[32m[0907 00-44-14 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18422, current rewards: -1409.00000, mean: -1.98451
[32m[0907 00-44-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18429, current rewards: -1509.00000, mean: -1.98553
[32m[0907 00-44-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18431, current rewards: -1609.00000, mean: -1.98642
[32m[0907 00-44-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18437, current rewards: -1709.00000, mean: -1.98721
[32m[0907 00-44-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18439, current rewards: -1809.00000, mean: -1.98791
[32m[0907 00-45-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18440, current rewards: -1909.00000, mean: -1.98854
[32m[0907 00-45-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18438, current rewards: -2009.00000, mean: -1.98911
[32m[0907 00-45-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18422, current rewards: -2109.00000, mean: -1.98962
[32m[0907 00-45-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18403, current rewards: -2209.00000, mean: -1.99009
[32m[0907 00-45-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18386, current rewards: -2309.00000, mean: -1.99052
[32m[0907 00-45-46 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18369, current rewards: -2409.00000, mean: -1.99091
[32m[0907 00-45-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18355, current rewards: -2509.00000, mean: -1.99127
[32m[0907 00-46-04 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18340, current rewards: -2609.00000, mean: -1.99160
[32m[0907 00-46-13 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18327, current rewards: -2709.00000, mean: -1.99191
[32m[0907 00-46-22 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18317, current rewards: -2809.00000, mean: -1.99220
[32m[0907 00-46-31 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18298, current rewards: -2909.00000, mean: -1.99247
[32m[0907 00-46-40 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18267, current rewards: -3009.00000, mean: -1.99272
[32m[0907 00-46-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18241, current rewards: -3109.00000, mean: -1.99295
[32m[0907 00-46-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18219, current rewards: -3209.00000, mean: -1.99317
[32m[0907 00-47-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18193, current rewards: -3309.00000, mean: -1.99337
[32m[0907 00-47-14 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18171, current rewards: -3409.00000, mean: -1.99357
[32m[0907 00-47-23 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18149, current rewards: -3509.00000, mean: -1.99375
[32m[0907 00-47-32 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18129, current rewards: -3609.00000, mean: -1.99392
[32m[0907 00-47-41 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18110, current rewards: -3709.00000, mean: -1.99409
[32m[0907 00-47-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18092, current rewards: -3809.00000, mean: -1.99424
[32m[0907 00-47-58 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18090, current rewards: -3909.00000, mean: -1.99439
[32m[0907 00-48-07 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18087, current rewards: -4009.00000, mean: -1.99453
[32m[0907 00-48-16 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18084, current rewards: -4109.00000, mean: -1.99466
[32m[0907 00-48-25 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18082, current rewards: -4209.00000, mean: -1.99479
[32m[0907 00-48-34 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18079, current rewards: -4309.00000, mean: -1.99491
[32m[0907 00-48-43 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18077, current rewards: -4409.00000, mean: -1.99502
[32m[0907 00-48-52 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18076, current rewards: -4509.00000, mean: -1.99513
[32m[0907 00-49-01 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18076, current rewards: -4609.00000, mean: -1.99524
[32m[0907 00-49-11 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18082, current rewards: -4709.00000, mean: -1.99534
[32m[0907 00-49-20 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18092, current rewards: -4809.00000, mean: -1.99544
[32m[0907 00-49-29 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18100, current rewards: -4909.00000, mean: -1.99553
[32m[0907 00-49-36 @Agent.py:117][0m Average action selection time: 0.1810
[32m[0907 00-49-36 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-49-37 @MBExp.py:227][0m Rewards obtained: [-4989], Lows: [2489], Highs: [11], Total time: 34365.36520999998
[32m[0907 00-52-08 @MBExp.py:144][0m ####################################################################
[32m[0907 00-52-08 @MBExp.py:145][0m Starting training iteration 76.
[32m[0907 00-52-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19274, current rewards: -10.00000, mean: -1.00000
[32m[0907 00-52-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18220, current rewards: -7.49732, mean: -0.12496
[32m[0907 00-52-28 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18296, current rewards: 1.44142, mean: 0.01310
[32m[0907 00-52-37 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18360, current rewards: 10.37264, mean: 0.06483
[32m[0907 00-52-47 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18388, current rewards: 18.69888, mean: 0.08904
[32m[0907 00-52-56 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18416, current rewards: 27.70904, mean: 0.10657
[32m[0907 00-53-05 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18429, current rewards: 36.70178, mean: 0.11839
[32m[0907 00-53-15 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18450, current rewards: 45.68524, mean: 0.12690
[32m[0907 00-53-24 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18440, current rewards: 54.66715, mean: 0.13333
[32m[0907 00-53-33 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18442, current rewards: 63.64947, mean: 0.13837
[32m[0907 00-53-42 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18427, current rewards: 72.63543, mean: 0.14242
[32m[0907 00-53-51 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18426, current rewards: 81.62479, mean: 0.14576
[32m[0907 00-54-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18420, current rewards: 91.13977, mean: 0.14941
[32m[0907 00-54-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18421, current rewards: 100.11146, mean: 0.15168
[32m[0907 00-54-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18414, current rewards: 109.08056, mean: 0.15363
[32m[0907 00-54-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18413, current rewards: 118.05585, mean: 0.15534
[32m[0907 00-54-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18412, current rewards: 127.01420, mean: 0.15681
[32m[0907 00-54-47 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18409, current rewards: 135.97194, mean: 0.15811
[32m[0907 00-54-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18404, current rewards: 148.42985, mean: 0.16311
[32m[0907 00-55-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18402, current rewards: 154.44263, mean: 0.16088
[32m[0907 00-55-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18400, current rewards: 162.52920, mean: 0.16092
[32m[0907 00-55-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18385, current rewards: 168.89083, mean: 0.15933
[32m[0907 00-55-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18367, current rewards: 175.10262, mean: 0.15775
[32m[0907 00-55-41 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18349, current rewards: 181.30549, mean: 0.15630
[32m[0907 00-55-50 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18332, current rewards: 187.51257, mean: 0.15497
[32m[0907 00-55-59 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18319, current rewards: 193.72134, mean: 0.15375
[32m[0907 00-56-08 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18306, current rewards: 199.92377, mean: 0.15261
[32m[0907 00-56-17 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18294, current rewards: 206.12189, mean: 0.15156
[32m[0907 00-56-26 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18282, current rewards: 212.09200, mean: 0.15042
[32m[0907 00-56-35 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18255, current rewards: 217.70280, mean: 0.14911
[32m[0907 00-56-44 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18225, current rewards: 223.32924, mean: 0.14790
[32m[0907 00-56-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18199, current rewards: 228.96407, mean: 0.14677
[32m[0907 00-57-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18173, current rewards: 234.59816, mean: 0.14571
[32m[0907 00-57-10 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18150, current rewards: 219.24950, mean: 0.13208
[32m[0907 00-57-18 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18129, current rewards: 227.42575, mean: 0.13300
[32m[0907 00-57-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18110, current rewards: 232.94094, mean: 0.13235
[32m[0907 00-57-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18090, current rewards: 238.46204, mean: 0.13175
[32m[0907 00-57-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18071, current rewards: 243.78979, mean: 0.13107
[32m[0907 00-57-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18058, current rewards: 249.36117, mean: 0.13056
[32m[0907 00-58-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18056, current rewards: 254.93246, mean: 0.13007
[32m[0907 00-58-11 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18053, current rewards: 260.51053, mean: 0.12961
[32m[0907 00-58-20 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18051, current rewards: 266.07929, mean: 0.12916
[32m[0907 00-58-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18060, current rewards: 259.34427, mean: 0.12291
[32m[0907 00-58-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18058, current rewards: 248.79581, mean: 0.11518
[32m[0907 00-58-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18055, current rewards: 240.31283, mean: 0.10874
[32m[0907 00-58-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18060, current rewards: 231.49212, mean: 0.10243
[32m[0907 00-59-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18070, current rewards: 222.82328, mean: 0.09646
[32m[0907 00-59-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18084, current rewards: 217.02900, mean: 0.09196
[32m[0907 00-59-25 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18107, current rewards: 211.50883, mean: 0.08776
[32m[0907 00-59-34 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18121, current rewards: 207.82803, mean: 0.08448
[32m[0907 00-59-42 @Agent.py:117][0m Average action selection time: 0.1812
[32m[0907 00-59-42 @Agent.py:118][0m Rollout length: 2510
[32m[0907 00-59-42 @MBExp.py:227][0m Rewards obtained: [203.14847837144836], Lows: [12], Highs: [113], Total time: 34819.24424099998
[32m[0907 01-02-16 @MBExp.py:144][0m ####################################################################
[32m[0907 01-02-16 @MBExp.py:145][0m Starting training iteration 77.
[32m[0907 01-02-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17905, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-02-27 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18054, current rewards: -4.53765, mean: -0.07563
[32m[0907 01-02-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18010, current rewards: 22.23713, mean: 0.20216
[32m[0907 01-02-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18044, current rewards: 54.47990, mean: 0.34050
[32m[0907 01-02-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18148, current rewards: 82.00491, mean: 0.39050
[32m[0907 01-03-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18210, current rewards: 119.82005, mean: 0.46085
[32m[0907 01-03-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18253, current rewards: 162.34247, mean: 0.52369
[32m[0907 01-03-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18278, current rewards: 206.59066, mean: 0.57386
[32m[0907 01-03-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18372, current rewards: 199.91548, mean: 0.48760
[32m[0907 01-03-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18399, current rewards: 209.17448, mean: 0.45473
[32m[0907 01-03-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18405, current rewards: 218.40499, mean: 0.42825
[32m[0907 01-03-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18403, current rewards: 226.72403, mean: 0.40486
[32m[0907 01-04-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18406, current rewards: 238.39856, mean: 0.39082
[32m[0907 01-04-18 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18473, current rewards: 208.76602, mean: 0.31631
[32m[0907 01-04-28 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18542, current rewards: 176.18353, mean: 0.24815
[32m[0907 01-04-37 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18568, current rewards: 136.20522, mean: 0.17922
[32m[0907 01-04-47 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18588, current rewards: 85.17281, mean: 0.10515
[32m[0907 01-04-56 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18596, current rewards: 40.29762, mean: 0.04686
[32m[0907 01-05-05 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18612, current rewards: -19.76328, mean: -0.02172
[32m[0907 01-05-15 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18625, current rewards: -84.86385, mean: -0.08840
[32m[0907 01-05-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18620, current rewards: -114.39098, mean: -0.11326
[32m[0907 01-05-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18595, current rewards: -168.85854, mean: -0.15930
[32m[0907 01-05-43 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18608, current rewards: -228.12194, mean: -0.20552
[32m[0907 01-05-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18601, current rewards: -285.45110, mean: -0.24608
[32m[0907 01-06-01 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18594, current rewards: -357.55786, mean: -0.29550
[32m[0907 01-06-10 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18579, current rewards: -408.17851, mean: -0.32395
[32m[0907 01-06-19 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18574, current rewards: -461.12969, mean: -0.35201
[32m[0907 01-06-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18688, current rewards: -526.96497, mean: -0.38747
[32m[0907 01-06-40 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18689, current rewards: -571.14582, mean: -0.40507
[32m[0907 01-06-49 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18689, current rewards: -630.55696, mean: -0.43189
[32m[0907 01-06-59 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18717, current rewards: -690.23853, mean: -0.45711
[32m[0907 01-07-09 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18750, current rewards: -743.20218, mean: -0.47641
[32m[0907 01-07-18 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18762, current rewards: -791.20578, mean: -0.49143
[32m[0907 01-07-28 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18767, current rewards: -841.14832, mean: -0.50672
[32m[0907 01-07-36 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18726, current rewards: -882.47669, mean: -0.51607
[32m[0907 01-07-45 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18690, current rewards: -920.95531, mean: -0.52327
[32m[0907 01-07-54 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18658, current rewards: -955.56121, mean: -0.52793
[32m[0907 01-08-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18639, current rewards: -970.37345, mean: -0.52171
[32m[0907 01-08-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18626, current rewards: -1008.10968, mean: -0.52781
[32m[0907 01-08-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18609, current rewards: -1022.96998, mean: -0.52192
[32m[0907 01-08-30 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18594, current rewards: -1060.19185, mean: -0.52746
[32m[0907 01-08-39 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18579, current rewards: -1074.64293, mean: -0.52167
[32m[0907 01-08-48 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18567, current rewards: -1112.81492, mean: -0.52740
[32m[0907 01-08-57 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18555, current rewards: -1126.43785, mean: -0.52150
[32m[0907 01-09-07 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18569, current rewards: -1149.60837, mean: -0.52018
[32m[0907 01-09-16 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18563, current rewards: -1125.89017, mean: -0.49818
[32m[0907 01-09-25 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18561, current rewards: -1098.21521, mean: -0.47542
[32m[0907 01-09-34 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18559, current rewards: -1070.69588, mean: -0.45368
[32m[0907 01-09-44 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18555, current rewards: -1042.92758, mean: -0.43275
[32m[0907 01-09-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18544, current rewards: -1015.32592, mean: -0.41273
[32m[0907 01-10-00 @Agent.py:117][0m Average action selection time: 0.1854
[32m[0907 01-10-00 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-10-00 @MBExp.py:227][0m Rewards obtained: [-993.313114086687], Lows: [700], Highs: [167], Total time: 35283.493477999975
[32m[0907 01-12-36 @MBExp.py:144][0m ####################################################################
[32m[0907 01-12-36 @MBExp.py:145][0m Starting training iteration 78.
[32m[0907 01-12-38 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.26929, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-12-49 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21629, current rewards: -60.29251, mean: -1.00488
[32m[0907 01-12-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.21487, current rewards: -109.67596, mean: -0.99705
[32m[0907 01-13-10 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.21699, current rewards: -178.56577, mean: -1.11604
[32m[0907 01-13-20 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.21345, current rewards: -228.95749, mean: -1.09027
[32m[0907 01-13-31 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.21211, current rewards: -289.24493, mean: -1.11248
[32m[0907 01-13-41 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.21156, current rewards: -346.20081, mean: -1.11678
[32m[0907 01-13-50 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20780, current rewards: -349.26947, mean: -0.97019
[32m[0907 01-14-00 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20487, current rewards: -344.86702, mean: -0.84114
[32m[0907 01-14-09 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20281, current rewards: -339.10980, mean: -0.73720
[32m[0907 01-14-18 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20100, current rewards: -334.64263, mean: -0.65616
[32m[0907 01-14-27 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19949, current rewards: -329.17999, mean: -0.58782
[32m[0907 01-14-37 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19821, current rewards: -325.01222, mean: -0.53281
[32m[0907 01-14-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19709, current rewards: -319.65335, mean: -0.48432
[32m[0907 01-14-55 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19621, current rewards: -316.00579, mean: -0.44508
[32m[0907 01-15-04 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19542, current rewards: -312.87450, mean: -0.41168
[32m[0907 01-15-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19472, current rewards: -303.36088, mean: -0.37452
[32m[0907 01-15-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19390, current rewards: -293.47268, mean: -0.34125
[32m[0907 01-15-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19317, current rewards: -283.57610, mean: -0.31162
[32m[0907 01-15-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19252, current rewards: -274.03023, mean: -0.28545
[32m[0907 01-15-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19188, current rewards: -264.12856, mean: -0.26151
[32m[0907 01-15-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19129, current rewards: -254.31054, mean: -0.23992
[32m[0907 01-16-08 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19076, current rewards: -270.86858, mean: -0.24403
[32m[0907 01-16-17 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19033, current rewards: -259.54087, mean: -0.22374
[32m[0907 01-16-26 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18988, current rewards: -248.19982, mean: -0.20512
[32m[0907 01-16-35 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18947, current rewards: -236.87115, mean: -0.18799
[32m[0907 01-16-44 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18910, current rewards: -255.78790, mean: -0.19526
[32m[0907 01-16-53 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18893, current rewards: -284.68707, mean: -0.20933
[32m[0907 01-17-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18861, current rewards: -281.98520, mean: -0.19999
[32m[0907 01-17-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18839, current rewards: -275.73779, mean: -0.18886
[32m[0907 01-17-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18795, current rewards: -285.00374, mean: -0.18874
[32m[0907 01-17-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18753, current rewards: -295.87540, mean: -0.18966
[32m[0907 01-17-37 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18711, current rewards: -292.54849, mean: -0.18171
[32m[0907 01-17-46 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18675, current rewards: -320.55765, mean: -0.19311
[32m[0907 01-17-55 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18638, current rewards: -350.80109, mean: -0.20515
[32m[0907 01-18-04 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18618, current rewards: -366.14645, mean: -0.20804
[32m[0907 01-18-13 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18607, current rewards: -383.47042, mean: -0.21186
[32m[0907 01-18-22 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18593, current rewards: -410.01959, mean: -0.22044
[32m[0907 01-18-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18575, current rewards: -430.83581, mean: -0.22557
[32m[0907 01-18-40 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18559, current rewards: -457.58879, mean: -0.23346
[32m[0907 01-18-49 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18542, current rewards: -505.03966, mean: -0.25126
[32m[0907 01-18-58 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18529, current rewards: -518.14043, mean: -0.25152
[32m[0907 01-19-07 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18521, current rewards: -539.72976, mean: -0.25580
[32m[0907 01-19-16 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18518, current rewards: -539.07434, mean: -0.24957
[32m[0907 01-19-26 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18549, current rewards: -561.74342, mean: -0.25418
[32m[0907 01-19-36 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18579, current rewards: -592.08905, mean: -0.26199
[32m[0907 01-19-46 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18596, current rewards: -607.01332, mean: -0.26278
[32m[0907 01-19-55 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18591, current rewards: -623.59566, mean: -0.26424
[32m[0907 01-20-04 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18587, current rewards: -649.75668, mean: -0.26961
[32m[0907 01-20-13 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18574, current rewards: -679.03078, mean: -0.27603
[32m[0907 01-20-20 @Agent.py:117][0m Average action selection time: 0.1856
[32m[0907 01-20-20 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-20-20 @MBExp.py:227][0m Rewards obtained: [-671.0786758884423], Lows: [494], Highs: [105], Total time: 35748.393903999975
[32m[0907 01-22-58 @MBExp.py:144][0m ####################################################################
[32m[0907 01-22-58 @MBExp.py:145][0m Starting training iteration 79.
[32m[0907 01-23-00 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.22714, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-23-10 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19747, current rewards: -74.65368, mean: -1.24423
[32m[0907 01-23-20 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19764, current rewards: -145.70525, mean: -1.32459
[32m[0907 01-23-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19724, current rewards: -212.77576, mean: -1.32985
[32m[0907 01-23-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19743, current rewards: -287.55462, mean: -1.36931
[32m[0907 01-23-50 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19877, current rewards: -359.06893, mean: -1.38103
[32m[0907 01-24-00 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19911, current rewards: -427.55655, mean: -1.37921
[32m[0907 01-24-10 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19855, current rewards: -500.42160, mean: -1.39006
[32m[0907 01-24-19 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19694, current rewards: -571.12626, mean: -1.39299
[32m[0907 01-24-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19702, current rewards: -639.53613, mean: -1.39030
[32m[0907 01-24-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19724, current rewards: -720.54304, mean: -1.41283
[32m[0907 01-24-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19828, current rewards: -805.36948, mean: -1.43816
[32m[0907 01-24-59 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19781, current rewards: -895.60779, mean: -1.46821
[32m[0907 01-25-09 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19791, current rewards: -970.09963, mean: -1.46985
[32m[0907 01-25-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19890, current rewards: -1058.96169, mean: -1.49150
[32m[0907 01-25-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19913, current rewards: -1154.27462, mean: -1.51878
[32m[0907 01-25-40 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19961, current rewards: -1234.97952, mean: -1.52467
[32m[0907 01-25-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19992, current rewards: -1323.64720, mean: -1.53912
[32m[0907 01-26-00 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19985, current rewards: -1410.36192, mean: -1.54985
[32m[0907 01-26-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19957, current rewards: -1490.22084, mean: -1.55231
[32m[0907 01-26-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19929, current rewards: -1564.44362, mean: -1.54895
[32m[0907 01-26-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19848, current rewards: -1653.89730, mean: -1.56028
[32m[0907 01-26-38 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19764, current rewards: -1753.89730, mean: -1.58009
[32m[0907 01-26-47 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19688, current rewards: -1853.89730, mean: -1.59819
[32m[0907 01-26-56 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19594, current rewards: -1953.89730, mean: -1.61479
[32m[0907 01-27-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19505, current rewards: -2053.89730, mean: -1.63008
[32m[0907 01-27-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19423, current rewards: -2153.89730, mean: -1.64420
[32m[0907 01-27-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19348, current rewards: -2253.89730, mean: -1.65728
[32m[0907 01-27-30 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19278, current rewards: -2353.89730, mean: -1.66943
[32m[0907 01-27-39 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19213, current rewards: -2453.89730, mean: -1.68075
[32m[0907 01-27-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19156, current rewards: -2553.89730, mean: -1.69132
[32m[0907 01-27-57 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19102, current rewards: -2653.89730, mean: -1.70122
[32m[0907 01-28-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19052, current rewards: -2753.89730, mean: -1.71050
[32m[0907 01-28-14 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19005, current rewards: -2853.89730, mean: -1.71922
[32m[0907 01-28-23 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18973, current rewards: -2953.89730, mean: -1.72743
[32m[0907 01-28-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18947, current rewards: -3053.89730, mean: -1.73517
[32m[0907 01-28-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18923, current rewards: -3153.89730, mean: -1.74248
[32m[0907 01-28-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18903, current rewards: -3253.89730, mean: -1.74941
[32m[0907 01-28-59 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18881, current rewards: -3353.89730, mean: -1.75597
[32m[0907 01-29-08 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18860, current rewards: -3453.89730, mean: -1.76219
[32m[0907 01-29-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18839, current rewards: -3553.89730, mean: -1.76811
[32m[0907 01-29-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18820, current rewards: -3653.89730, mean: -1.77374
[32m[0907 01-29-36 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18808, current rewards: -3753.89730, mean: -1.77910
[32m[0907 01-29-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18804, current rewards: -3853.89730, mean: -1.78421
[32m[0907 01-29-54 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18799, current rewards: -3953.89730, mean: -1.78909
[32m[0907 01-30-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18794, current rewards: -4053.89730, mean: -1.79376
[32m[0907 01-30-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18780, current rewards: -4153.89730, mean: -1.79822
[32m[0907 01-30-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18766, current rewards: -4253.89730, mean: -1.80250
[32m[0907 01-30-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18752, current rewards: -4353.89730, mean: -1.80660
[32m[0907 01-30-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18732, current rewards: -4453.89730, mean: -1.81053
[32m[0907 01-30-47 @Agent.py:117][0m Average action selection time: 0.1871
[32m[0907 01-30-47 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-30-47 @MBExp.py:227][0m Rewards obtained: [-4533.897301604304], Lows: [2286], Highs: [16], Total time: 36217.011228999974
[32m[0907 01-33-27 @MBExp.py:144][0m ####################################################################
[32m[0907 01-33-27 @MBExp.py:145][0m Starting training iteration 80.
[32m[0907 01-33-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18521, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-33-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18479, current rewards: -26.54522, mean: -0.44242
[32m[0907 01-33-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18467, current rewards: -21.35507, mean: -0.19414
[32m[0907 01-33-56 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18452, current rewards: -16.70799, mean: -0.10442
[32m[0907 01-34-05 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18459, current rewards: -11.60168, mean: -0.05525
[32m[0907 01-34-15 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18442, current rewards: -6.48835, mean: -0.02496
[32m[0907 01-34-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18945, current rewards: -62.03350, mean: -0.20011
[32m[0907 01-34-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19559, current rewards: -110.86719, mean: -0.30796
[32m[0907 01-34-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19978, current rewards: -159.12438, mean: -0.38811
[32m[0907 01-35-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20335, current rewards: -202.99814, mean: -0.44130
[32m[0907 01-35-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20473, current rewards: -241.23978, mean: -0.47302
[32m[0907 01-35-23 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20778, current rewards: -286.93038, mean: -0.51238
[32m[0907 01-35-34 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20953, current rewards: -327.52368, mean: -0.53692
[32m[0907 01-35-46 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.21113, current rewards: -352.05590, mean: -0.53342
[32m[0907 01-35-57 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.21200, current rewards: -408.57919, mean: -0.57546
[32m[0907 01-36-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.21166, current rewards: -436.25027, mean: -0.57401
[32m[0907 01-36-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.20967, current rewards: -444.35175, mean: -0.54858
[32m[0907 01-36-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.20789, current rewards: -439.57966, mean: -0.51114
[32m[0907 01-36-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.20634, current rewards: -434.80136, mean: -0.47780
[32m[0907 01-36-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.20497, current rewards: -430.31051, mean: -0.44824
[32m[0907 01-36-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.20370, current rewards: -425.52399, mean: -0.42131
[32m[0907 01-37-01 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.20238, current rewards: -420.72067, mean: -0.39691
[32m[0907 01-37-10 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.20114, current rewards: -415.92464, mean: -0.37471
[32m[0907 01-37-19 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.20000, current rewards: -411.11545, mean: -0.35441
[32m[0907 01-37-28 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19892, current rewards: -406.31588, mean: -0.33580
[32m[0907 01-37-36 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19793, current rewards: -401.51572, mean: -0.31866
[32m[0907 01-37-45 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19705, current rewards: -396.71524, mean: -0.30284
[32m[0907 01-37-54 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19620, current rewards: -390.44891, mean: -0.28709
[32m[0907 01-38-02 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19541, current rewards: -436.46167, mean: -0.30955
[32m[0907 01-38-11 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19476, current rewards: -460.54305, mean: -0.31544
[32m[0907 01-38-20 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19409, current rewards: -454.11138, mean: -0.30074
[32m[0907 01-38-29 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19348, current rewards: -447.95849, mean: -0.28715
[32m[0907 01-38-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19316, current rewards: -471.85573, mean: -0.29308
[32m[0907 01-38-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19303, current rewards: -498.78596, mean: -0.30047
[32m[0907 01-38-57 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19312, current rewards: -528.31489, mean: -0.30896
[32m[0907 01-39-07 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19333, current rewards: -555.93445, mean: -0.31587
[32m[0907 01-39-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19309, current rewards: -557.52226, mean: -0.30802
[32m[0907 01-39-25 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.19274, current rewards: -548.10740, mean: -0.29468
[32m[0907 01-39-34 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19238, current rewards: -539.06062, mean: -0.28223
[32m[0907 01-39-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.19208, current rewards: -578.31030, mean: -0.29506
[32m[0907 01-39-53 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.19190, current rewards: -616.43850, mean: -0.30669
[32m[0907 01-40-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19171, current rewards: -666.54537, mean: -0.32357
[32m[0907 01-40-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19155, current rewards: -712.47119, mean: -0.33766
[32m[0907 01-40-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19134, current rewards: -749.38833, mean: -0.34694
[32m[0907 01-40-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19109, current rewards: -785.87008, mean: -0.35560
[32m[0907 01-40-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19085, current rewards: -846.39713, mean: -0.37451
[32m[0907 01-40-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19061, current rewards: -891.81721, mean: -0.38607
[32m[0907 01-40-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19026, current rewards: -944.41914, mean: -0.40018
[32m[0907 01-41-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18994, current rewards: -1000.31632, mean: -0.41507
[32m[0907 01-41-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18961, current rewards: -1045.56875, mean: -0.42503
[32m[0907 01-41-21 @Agent.py:117][0m Average action selection time: 0.1894
[32m[0907 01-41-21 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-41-21 @MBExp.py:227][0m Rewards obtained: [-1089.0780516697396], Lows: [690], Highs: [30], Total time: 36691.30805899997
[32m[0907 01-44-04 @MBExp.py:144][0m ####################################################################
[32m[0907 01-44-04 @MBExp.py:145][0m Starting training iteration 81.
[32m[0907 01-44-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20805, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-44-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20527, current rewards: -18.00332, mean: -0.30006
[32m[0907 01-44-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19676, current rewards: -19.26929, mean: -0.17518
[32m[0907 01-44-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19317, current rewards: -14.11641, mean: -0.08823
[32m[0907 01-44-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19100, current rewards: -8.95708, mean: -0.04265
[32m[0907 01-44-53 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18979, current rewards: -3.79443, mean: -0.01459
[32m[0907 01-45-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18908, current rewards: 1.36669, mean: 0.00441
[32m[0907 01-45-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18858, current rewards: 6.52194, mean: 0.01812
[32m[0907 01-45-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18810, current rewards: 11.68551, mean: 0.02850
[32m[0907 01-45-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18826, current rewards: -4.56806, mean: -0.00993
[32m[0907 01-45-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18794, current rewards: -2.60291, mean: -0.00510
[32m[0907 01-45-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18765, current rewards: 2.45635, mean: 0.00439
[32m[0907 01-45-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18734, current rewards: 7.51806, mean: 0.01232
[32m[0907 01-46-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18693, current rewards: 1.56718, mean: 0.00237
[32m[0907 01-46-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18641, current rewards: 5.62553, mean: 0.00792
[32m[0907 01-46-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18599, current rewards: 12.17946, mean: 0.01603
[32m[0907 01-46-34 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18558, current rewards: 18.73578, mean: 0.02313
[32m[0907 01-46-43 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18524, current rewards: 25.28701, mean: 0.02940
[32m[0907 01-46-52 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18495, current rewards: 33.11753, mean: 0.03639
[32m[0907 01-47-01 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18468, current rewards: 39.70745, mean: 0.04136
[32m[0907 01-47-10 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18439, current rewards: 45.59475, mean: 0.04514
[32m[0907 01-47-19 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18390, current rewards: 50.09623, mean: 0.04726
[32m[0907 01-47-28 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18345, current rewards: 56.15102, mean: 0.05059
[32m[0907 01-47-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18308, current rewards: 62.19260, mean: 0.05361
[32m[0907 01-47-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18273, current rewards: 68.28860, mean: 0.05644
[32m[0907 01-47-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18239, current rewards: 13.96743, mean: 0.01109
[32m[0907 01-48-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18236, current rewards: -47.18217, mean: -0.03602
[32m[0907 01-48-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18217, current rewards: -104.07590, mean: -0.07653
[32m[0907 01-48-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18225, current rewards: -160.14136, mean: -0.11358
[32m[0907 01-48-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18204, current rewards: -225.76625, mean: -0.15463
[32m[0907 01-48-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18241, current rewards: -286.83421, mean: -0.18996
[32m[0907 01-48-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18244, current rewards: -347.89599, mean: -0.22301
[32m[0907 01-48-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18260, current rewards: -377.24958, mean: -0.23432
[32m[0907 01-49-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18302, current rewards: -415.08395, mean: -0.25005
[32m[0907 01-49-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18320, current rewards: -457.19494, mean: -0.26737
[32m[0907 01-49-27 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18319, current rewards: -506.55536, mean: -0.28782
[32m[0907 01-49-36 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18345, current rewards: -550.25743, mean: -0.30401
[32m[0907 01-49-46 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18382, current rewards: -603.51869, mean: -0.32447
[32m[0907 01-49-55 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18388, current rewards: -642.01201, mean: -0.33613
[32m[0907 01-50-05 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18434, current rewards: -685.11316, mean: -0.34955
[32m[0907 01-50-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18458, current rewards: -743.72247, mean: -0.37001
[32m[0907 01-50-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18538, current rewards: -791.24170, mean: -0.38410
[32m[0907 01-50-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18538, current rewards: -876.57483, mean: -0.41544
[32m[0907 01-50-45 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18541, current rewards: -948.92448, mean: -0.43932
[32m[0907 01-50-55 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18566, current rewards: -1015.43494, mean: -0.45947
[32m[0907 01-51-04 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18573, current rewards: -1083.02275, mean: -0.47921
[32m[0907 01-51-13 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18566, current rewards: -1149.19539, mean: -0.49749
[32m[0907 01-51-22 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18557, current rewards: -1220.97516, mean: -0.51736
[32m[0907 01-51-31 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18532, current rewards: -1213.82139, mean: -0.50366
[32m[0907 01-51-40 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18510, current rewards: -1207.24138, mean: -0.49075
[32m[0907 01-51-47 @Agent.py:117][0m Average action selection time: 0.1849
[32m[0907 01-51-47 @Agent.py:118][0m Rollout length: 2510
[32m[0907 01-51-47 @MBExp.py:227][0m Rewards obtained: [-1201.9786981570685], Lows: [696], Highs: [64], Total time: 37154.402801999975
[32m[0907 01-54-32 @MBExp.py:144][0m ####################################################################
[32m[0907 01-54-32 @MBExp.py:145][0m Starting training iteration 82.
[32m[0907 01-54-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.23344, current rewards: -10.00000, mean: -1.00000
[32m[0907 01-54-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21838, current rewards: -49.04499, mean: -0.81742
[32m[0907 01-54-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20956, current rewards: -50.83993, mean: -0.46218
[32m[0907 01-55-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20178, current rewards: -45.10400, mean: -0.28190
[32m[0907 01-55-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19763, current rewards: -39.38659, mean: -0.18756
[32m[0907 01-55-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19502, current rewards: -33.66710, mean: -0.12949
[32m[0907 01-55-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19351, current rewards: -27.94814, mean: -0.09016
[32m[0907 01-55-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19220, current rewards: -22.23105, mean: -0.06175
[32m[0907 01-55-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19123, current rewards: -16.51209, mean: -0.04027
[32m[0907 01-56-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19053, current rewards: -9.16701, mean: -0.01993
[32m[0907 01-56-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18999, current rewards: -0.64972, mean: -0.00127
[32m[0907 01-56-18 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18925, current rewards: 5.50869, mean: 0.00984
[32m[0907 01-56-27 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18849, current rewards: 11.66496, mean: 0.01912
[32m[0907 01-56-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18782, current rewards: 0.83691, mean: 0.00127
[32m[0907 01-56-45 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18727, current rewards: 3.61205, mean: 0.00509
[32m[0907 01-56-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18676, current rewards: 12.40072, mean: 0.01632
[32m[0907 01-57-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18633, current rewards: 21.18938, mean: 0.02616
[32m[0907 01-57-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18591, current rewards: 29.97805, mean: 0.03486
[32m[0907 01-57-21 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18554, current rewards: 35.88806, mean: 0.03944
[32m[0907 01-57-30 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18492, current rewards: 40.19974, mean: 0.04187
[32m[0907 01-57-39 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18442, current rewards: 44.51142, mean: 0.04407
[32m[0907 01-57-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18393, current rewards: 48.82310, mean: 0.04606
[32m[0907 01-57-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18348, current rewards: 53.13479, mean: 0.04787
[32m[0907 01-58-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18309, current rewards: 10.73842, mean: 0.00926
[32m[0907 01-58-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18277, current rewards: -39.26158, mean: -0.03245
[32m[0907 01-58-22 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18244, current rewards: -89.26158, mean: -0.07084
[32m[0907 01-58-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18212, current rewards: -139.26158, mean: -0.10631
[32m[0907 01-58-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18184, current rewards: -189.26158, mean: -0.13916
[32m[0907 01-58-48 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18156, current rewards: -239.26158, mean: -0.16969
[32m[0907 01-58-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18131, current rewards: -289.26158, mean: -0.19812
[32m[0907 01-59-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18105, current rewards: -339.26158, mean: -0.22468
[32m[0907 01-59-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18101, current rewards: -389.26158, mean: -0.24953
[32m[0907 01-59-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18098, current rewards: -439.26158, mean: -0.27283
[32m[0907 01-59-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18093, current rewards: -489.26158, mean: -0.29474
[32m[0907 01-59-42 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18089, current rewards: -539.26158, mean: -0.31536
[32m[0907 01-59-51 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18087, current rewards: -589.26158, mean: -0.33481
[32m[0907 02-00-00 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18085, current rewards: -639.26158, mean: -0.35318
[32m[0907 02-00-09 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18083, current rewards: -689.26158, mean: -0.37057
[32m[0907 02-00-18 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18096, current rewards: -739.26158, mean: -0.38705
[32m[0907 02-00-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18106, current rewards: -789.26158, mean: -0.40268
[32m[0907 02-00-37 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18116, current rewards: -839.26158, mean: -0.41754
[32m[0907 02-00-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18124, current rewards: -889.26158, mean: -0.43168
[32m[0907 02-00-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18130, current rewards: -939.26158, mean: -0.44515
[32m[0907 02-01-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18129, current rewards: -989.26158, mean: -0.45799
[32m[0907 02-01-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18127, current rewards: -1039.26158, mean: -0.47025
[32m[0907 02-01-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18115, current rewards: -1089.26158, mean: -0.48197
[32m[0907 02-01-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18100, current rewards: -1139.26158, mean: -0.49319
[32m[0907 02-01-39 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18085, current rewards: -1189.26158, mean: -0.50392
[32m[0907 02-01-48 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18071, current rewards: -1239.26158, mean: -0.51422
[32m[0907 02-01-57 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18059, current rewards: -1289.26158, mean: -0.52409
[32m[0907 02-02-04 @Agent.py:117][0m Average action selection time: 0.1805
[32m[0907 02-02-04 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-02-04 @MBExp.py:227][0m Rewards obtained: [-1329.2615775903319], Lows: [36], Highs: [1395], Total time: 37606.46052599997
[32m[0907 02-04-52 @MBExp.py:144][0m ####################################################################
[32m[0907 02-04-52 @MBExp.py:145][0m Starting training iteration 83.
[32m[0907 02-04-54 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18461, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-05-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18521, current rewards: -51.61052, mean: -0.86018
[32m[0907 02-05-12 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18495, current rewards: -37.19884, mean: -0.33817
[32m[0907 02-05-21 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18474, current rewards: -23.19263, mean: -0.14495
[32m[0907 02-05-31 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18475, current rewards: -9.22877, mean: -0.04395
[32m[0907 02-05-40 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18473, current rewards: 4.78279, mean: 0.01840
[32m[0907 02-05-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18466, current rewards: 18.71673, mean: 0.06038
[32m[0907 02-05-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18447, current rewards: 32.73717, mean: 0.09094
[32m[0907 02-06-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18444, current rewards: 46.66917, mean: 0.11383
[32m[0907 02-06-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18436, current rewards: 59.58725, mean: 0.12954
[32m[0907 02-06-26 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18433, current rewards: 73.70163, mean: 0.14451
[32m[0907 02-06-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18414, current rewards: 87.60586, mean: 0.15644
[32m[0907 02-06-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18378, current rewards: 77.64392, mean: 0.12729
[32m[0907 02-06-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18348, current rewards: 84.91954, mean: 0.12867
[32m[0907 02-07-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18325, current rewards: 92.09706, mean: 0.12971
[32m[0907 02-07-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18306, current rewards: 99.27466, mean: 0.13062
[32m[0907 02-07-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18287, current rewards: 106.45005, mean: 0.13142
[32m[0907 02-07-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18269, current rewards: 113.56699, mean: 0.13205
[32m[0907 02-07-38 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18239, current rewards: 120.38119, mean: 0.13229
[32m[0907 02-07-47 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18197, current rewards: 127.48625, mean: 0.13280
[32m[0907 02-07-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18159, current rewards: 134.59886, mean: 0.13327
[32m[0907 02-08-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18124, current rewards: 113.21862, mean: 0.10681
[32m[0907 02-08-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18093, current rewards: 123.16490, mean: 0.11096
[32m[0907 02-08-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18065, current rewards: 134.66162, mean: 0.11609
[32m[0907 02-08-30 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18037, current rewards: 146.15070, mean: 0.12079
[32m[0907 02-08-39 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18015, current rewards: 157.62937, mean: 0.12510
[32m[0907 02-08-48 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17991, current rewards: 123.43468, mean: 0.09422
[32m[0907 02-08-57 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17971, current rewards: 136.36415, mean: 0.10027
[32m[0907 02-09-05 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17952, current rewards: 148.39951, mean: 0.10525
[32m[0907 02-09-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17934, current rewards: 160.44422, mean: 0.10989
[32m[0907 02-09-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17920, current rewards: 172.48590, mean: 0.11423
[32m[0907 02-09-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17921, current rewards: 184.53195, mean: 0.11829
[32m[0907 02-09-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17923, current rewards: 196.58547, mean: 0.12210
[32m[0907 02-09-50 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17924, current rewards: 208.63006, mean: 0.12568
[32m[0907 02-09-59 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17926, current rewards: 198.66807, mean: 0.11618
[32m[0907 02-10-08 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17929, current rewards: 204.57920, mean: 0.11624
[32m[0907 02-10-17 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17930, current rewards: 210.43287, mean: 0.11626
[32m[0907 02-10-26 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17931, current rewards: 216.28497, mean: 0.11628
[32m[0907 02-10-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17943, current rewards: 222.13819, mean: 0.11630
[32m[0907 02-10-44 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17962, current rewards: 227.98898, mean: 0.11632
[32m[0907 02-10-54 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17974, current rewards: 233.84258, mean: 0.11634
[32m[0907 02-11-03 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17986, current rewards: 239.69498, mean: 0.11636
[32m[0907 02-11-12 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17995, current rewards: 245.55088, mean: 0.11637
[32m[0907 02-11-21 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.17998, current rewards: 251.40053, mean: 0.11639
[32m[0907 02-11-30 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.17997, current rewards: 257.25700, mean: 0.11641
[32m[0907 02-11-39 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17985, current rewards: 263.10745, mean: 0.11642
[32m[0907 02-11-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17970, current rewards: 268.96661, mean: 0.11644
[32m[0907 02-11-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17959, current rewards: 274.81829, mean: 0.11645
[32m[0907 02-12-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17947, current rewards: 282.73577, mean: 0.11732
[32m[0907 02-12-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17937, current rewards: 288.84537, mean: 0.11742
[32m[0907 02-12-21 @Agent.py:117][0m Average action selection time: 0.1793
[32m[0907 02-12-21 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-12-21 @MBExp.py:227][0m Rewards obtained: [293.2891488756969], Lows: [74], Highs: [20], Total time: 38055.511914999974
[32m[0907 02-15-10 @MBExp.py:144][0m ####################################################################
[32m[0907 02-15-10 @MBExp.py:145][0m Starting training iteration 84.
[32m[0907 02-15-12 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19124, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-15-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18657, current rewards: -50.11086, mean: -0.83518
[32m[0907 02-15-31 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18632, current rewards: -71.52321, mean: -0.65021
[32m[0907 02-15-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18565, current rewards: -93.39857, mean: -0.58374
[32m[0907 02-15-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18525, current rewards: -93.49844, mean: -0.44523
[32m[0907 02-15-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18516, current rewards: -86.70996, mean: -0.33350
[32m[0907 02-16-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18498, current rewards: -79.87240, mean: -0.25765
[32m[0907 02-16-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18494, current rewards: -73.01913, mean: -0.20283
[32m[0907 02-16-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18479, current rewards: -87.67595, mean: -0.21384
[32m[0907 02-16-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18483, current rewards: -82.00437, mean: -0.17827
[32m[0907 02-16-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18471, current rewards: -76.30642, mean: -0.14962
[32m[0907 02-16-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18429, current rewards: -70.61245, mean: -0.12609
[32m[0907 02-17-03 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18407, current rewards: -64.91651, mean: -0.10642
[32m[0907 02-17-12 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18375, current rewards: -59.22294, mean: -0.08973
[32m[0907 02-17-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18347, current rewards: -53.52783, mean: -0.07539
[32m[0907 02-17-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18325, current rewards: -47.82981, mean: -0.06293
[32m[0907 02-17-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18302, current rewards: -41.97444, mean: -0.05182
[32m[0907 02-17-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18281, current rewards: -56.95924, mean: -0.06623
[32m[0907 02-17-56 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18247, current rewards: -49.15055, mean: -0.05401
[32m[0907 02-18-05 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18202, current rewards: -43.28386, mean: -0.04509
[32m[0907 02-18-14 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18163, current rewards: -37.41819, mean: -0.03705
[32m[0907 02-18-23 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18127, current rewards: -31.55225, mean: -0.02977
[32m[0907 02-18-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18094, current rewards: -25.68623, mean: -0.02314
[32m[0907 02-18-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18066, current rewards: -19.81994, mean: -0.01709
[32m[0907 02-18-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18038, current rewards: -26.29932, mean: -0.02173
[32m[0907 02-18-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18013, current rewards: -20.22607, mean: -0.01605
[32m[0907 02-19-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17994, current rewards: -14.59939, mean: -0.01114
[32m[0907 02-19-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17974, current rewards: -8.97429, mean: -0.00660
[32m[0907 02-19-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17953, current rewards: -3.34983, mean: -0.00238
[32m[0907 02-19-32 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17934, current rewards: 2.27407, mean: 0.00156
[32m[0907 02-19-41 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17917, current rewards: 7.89712, mean: 0.00523
[32m[0907 02-19-50 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17917, current rewards: 13.52145, mean: 0.00867
[32m[0907 02-19-59 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17918, current rewards: 19.14303, mean: 0.01189
[32m[0907 02-20-08 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17920, current rewards: 24.04589, mean: 0.01449
[32m[0907 02-20-17 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17920, current rewards: 21.23389, mean: 0.01242
[32m[0907 02-20-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.17928, current rewards: 18.46070, mean: 0.01049
[32m[0907 02-20-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.17928, current rewards: 25.96073, mean: 0.01434
[32m[0907 02-20-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.17931, current rewards: 33.45406, mean: 0.01799
[32m[0907 02-20-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.17944, current rewards: 40.95198, mean: 0.02144
[32m[0907 02-21-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.17958, current rewards: 48.44966, mean: 0.02472
[32m[0907 02-21-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.17971, current rewards: 55.94917, mean: 0.02784
[32m[0907 02-21-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.17984, current rewards: 63.21969, mean: 0.03069
[32m[0907 02-21-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.17995, current rewards: 67.24677, mean: 0.03187
[32m[0907 02-21-40 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18006, current rewards: 38.94005, mean: 0.01803
[32m[0907 02-21-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18008, current rewards: 44.59662, mean: 0.02018
[32m[0907 02-21-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.17996, current rewards: 50.25578, mean: 0.02224
[32m[0907 02-22-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.17984, current rewards: 55.92916, mean: 0.02421
[32m[0907 02-22-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.17971, current rewards: 61.59480, mean: 0.02610
[32m[0907 02-22-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.17960, current rewards: 67.26324, mean: 0.02791
[32m[0907 02-22-32 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.17949, current rewards: 72.98023, mean: 0.02967
[32m[0907 02-22-39 @Agent.py:117][0m Average action selection time: 0.1794
[32m[0907 02-22-39 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-22-39 @MBExp.py:227][0m Rewards obtained: [77.51578707144523], Lows: [92], Highs: [39], Total time: 38504.841526999975
[32m[0907 02-25-31 @MBExp.py:144][0m ####################################################################
[32m[0907 02-25-31 @MBExp.py:145][0m Starting training iteration 85.
[32m[0907 02-25-33 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18569, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-25-42 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18552, current rewards: -21.80047, mean: -0.36334
[32m[0907 02-25-51 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18494, current rewards: -16.88079, mean: -0.15346
[32m[0907 02-26-01 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18550, current rewards: -12.25683, mean: -0.07661
[32m[0907 02-26-10 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18595, current rewards: -7.32471, mean: -0.03488
[32m[0907 02-26-20 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18625, current rewards: -2.57142, mean: -0.00989
[32m[0907 02-26-29 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18661, current rewards: 2.19771, mean: 0.00709
[32m[0907 02-26-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18682, current rewards: 7.31393, mean: 0.02032
[32m[0907 02-26-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18695, current rewards: 11.86565, mean: 0.02894
[32m[0907 02-26-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18710, current rewards: 16.69975, mean: 0.03630
[32m[0907 02-27-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18716, current rewards: 21.31993, mean: 0.04180
[32m[0907 02-27-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18793, current rewards: -7.27567, mean: -0.01299
[32m[0907 02-27-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18838, current rewards: -8.41539, mean: -0.01380
[32m[0907 02-27-36 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18877, current rewards: -8.02382, mean: -0.01216
[32m[0907 02-27-46 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18927, current rewards: -6.43643, mean: -0.00907
[32m[0907 02-27-55 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18922, current rewards: -12.38127, mean: -0.01629
[32m[0907 02-28-05 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18933, current rewards: -22.42087, mean: -0.02768
[32m[0907 02-28-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19020, current rewards: -29.55568, mean: -0.03437
[32m[0907 02-28-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19010, current rewards: -37.10413, mean: -0.04077
[32m[0907 02-28-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18952, current rewards: -46.33696, mean: -0.04827
[32m[0907 02-28-43 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18928, current rewards: -53.98789, mean: -0.05345
[32m[0907 02-28-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18907, current rewards: -60.56034, mean: -0.05713
[32m[0907 02-29-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18924, current rewards: -102.99117, mean: -0.09278
[32m[0907 02-29-11 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18907, current rewards: -123.00957, mean: -0.10604
[32m[0907 02-29-20 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18860, current rewards: -139.54293, mean: -0.11532
[32m[0907 02-29-29 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18823, current rewards: -140.93791, mean: -0.11186
[32m[0907 02-29-37 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18782, current rewards: -170.62581, mean: -0.13025
[32m[0907 02-29-46 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18744, current rewards: -193.91132, mean: -0.14258
[32m[0907 02-29-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18712, current rewards: -217.07860, mean: -0.15396
[32m[0907 02-30-05 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18703, current rewards: -215.05771, mean: -0.14730
[32m[0907 02-30-14 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18681, current rewards: -219.45061, mean: -0.14533
[32m[0907 02-30-23 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18682, current rewards: -232.79574, mean: -0.14923
[32m[0907 02-30-33 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18732, current rewards: -266.36724, mean: -0.16545
[32m[0907 02-30-43 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18752, current rewards: -322.06654, mean: -0.19402
[32m[0907 02-30-53 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18771, current rewards: -346.72099, mean: -0.20276
[32m[0907 02-31-03 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18845, current rewards: -375.62140, mean: -0.21342
[32m[0907 02-31-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18903, current rewards: -402.95721, mean: -0.22263
[32m[0907 02-31-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18952, current rewards: -433.33014, mean: -0.23297
[32m[0907 02-31-35 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.19011, current rewards: -459.78810, mean: -0.24073
[32m[0907 02-31-45 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.19056, current rewards: -481.95079, mean: -0.24589
[32m[0907 02-31-55 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.19091, current rewards: -508.82799, mean: -0.25315
[32m[0907 02-32-05 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19118, current rewards: -536.06153, mean: -0.26022
[32m[0907 02-32-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19161, current rewards: -577.17575, mean: -0.27354
[32m[0907 02-32-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19139, current rewards: -584.24237, mean: -0.27048
[32m[0907 02-32-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.19155, current rewards: -582.93196, mean: -0.26377
[32m[0907 02-32-45 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.19164, current rewards: -578.44461, mean: -0.25595
[32m[0907 02-32-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19170, current rewards: -570.05221, mean: -0.24678
[32m[0907 02-33-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19165, current rewards: -567.44530, mean: -0.24044
[32m[0907 02-33-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19148, current rewards: -570.76022, mean: -0.23683
[32m[0907 02-33-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19125, current rewards: -570.08103, mean: -0.23174
[32m[0907 02-33-29 @Agent.py:117][0m Average action selection time: 0.1910
[32m[0907 02-33-29 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-33-30 @MBExp.py:227][0m Rewards obtained: [-565.8852474088008], Lows: [157], Highs: [469], Total time: 38983.230113999976
[32m[0907 02-36-27 @MBExp.py:144][0m ####################################################################
[32m[0907 02-36-27 @MBExp.py:145][0m Starting training iteration 86.
[32m[0907 02-36-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20238, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-36-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19462, current rewards: -10.88781, mean: -0.18146
[32m[0907 02-36-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19577, current rewards: -7.12086, mean: -0.06474
[32m[0907 02-36-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19542, current rewards: -3.70502, mean: -0.02316
[32m[0907 02-37-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19645, current rewards: -2.69999, mean: -0.01286
[32m[0907 02-37-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19491, current rewards: -8.85476, mean: -0.03406
[32m[0907 02-37-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19440, current rewards: -6.33524, mean: -0.02044
[32m[0907 02-37-38 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19568, current rewards: -5.02054, mean: -0.01395
[32m[0907 02-37-47 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19476, current rewards: -4.40076, mean: -0.01073
[32m[0907 02-37-57 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19434, current rewards: 0.56429, mean: 0.00123
[32m[0907 02-38-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19484, current rewards: 5.17410, mean: 0.01015
[32m[0907 02-38-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19448, current rewards: 9.98576, mean: 0.01783
[32m[0907 02-38-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19464, current rewards: 14.63922, mean: 0.02400
[32m[0907 02-38-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19381, current rewards: -2.13537, mean: -0.00324
[32m[0907 02-38-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19309, current rewards: 3.90990, mean: 0.00551
[32m[0907 02-38-54 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19247, current rewards: -2.19188, mean: -0.00288
[32m[0907 02-39-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19171, current rewards: -52.19188, mean: -0.06443
[32m[0907 02-39-12 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19088, current rewards: -102.19188, mean: -0.11883
[32m[0907 02-39-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19015, current rewards: -152.19188, mean: -0.16724
[32m[0907 02-39-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18947, current rewards: -202.19188, mean: -0.21062
[32m[0907 02-39-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18885, current rewards: -252.19188, mean: -0.24969
[32m[0907 02-39-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18830, current rewards: -302.19188, mean: -0.28509
[32m[0907 02-39-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18782, current rewards: -352.19188, mean: -0.31729
[32m[0907 02-40-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18738, current rewards: -402.19188, mean: -0.34672
[32m[0907 02-40-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18695, current rewards: -400.04900, mean: -0.33062
[32m[0907 02-40-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18656, current rewards: -417.00893, mean: -0.33096
[32m[0907 02-40-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18622, current rewards: -467.00893, mean: -0.35650
[32m[0907 02-40-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18589, current rewards: -517.00893, mean: -0.38015
[32m[0907 02-40-49 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18569, current rewards: -567.00893, mean: -0.40213
[32m[0907 02-40-58 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18561, current rewards: -617.00893, mean: -0.42261
[32m[0907 02-41-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18555, current rewards: -667.00893, mean: -0.44173
[32m[0907 02-41-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18549, current rewards: -717.00893, mean: -0.45962
[32m[0907 02-41-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18543, current rewards: -767.00893, mean: -0.47640
[32m[0907 02-41-35 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18537, current rewards: -817.00893, mean: -0.49217
[32m[0907 02-41-44 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18532, current rewards: -867.00893, mean: -0.50702
[32m[0907 02-41-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18525, current rewards: -917.00893, mean: -0.52103
[32m[0907 02-42-03 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18525, current rewards: -967.00893, mean: -0.53426
[32m[0907 02-42-12 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18532, current rewards: -1017.00893, mean: -0.54678
[32m[0907 02-42-22 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18541, current rewards: -1067.00893, mean: -0.55864
[32m[0907 02-42-31 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18545, current rewards: -1117.00893, mean: -0.56990
[32m[0907 02-42-41 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18550, current rewards: -1167.00893, mean: -0.58060
[32m[0907 02-42-50 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18557, current rewards: -1217.00893, mean: -0.59078
[32m[0907 02-42-59 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18544, current rewards: -1267.00893, mean: -0.60048
[32m[0907 02-43-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18525, current rewards: -1317.00893, mean: -0.60973
[32m[0907 02-43-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18508, current rewards: -1367.00893, mean: -0.61856
[32m[0907 02-43-26 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18492, current rewards: -1417.00893, mean: -0.62700
[32m[0907 02-43-35 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18476, current rewards: -1467.00893, mean: -0.63507
[32m[0907 02-43-43 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18462, current rewards: -1517.00893, mean: -0.64280
[32m[0907 02-43-52 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18448, current rewards: -1567.00893, mean: -0.65021
[32m[0907 02-44-01 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18434, current rewards: -1617.00893, mean: -0.65732
[32m[0907 02-44-08 @Agent.py:117][0m Average action selection time: 0.1842
[32m[0907 02-44-08 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-44-09 @MBExp.py:227][0m Rewards obtained: [-1657.0089286085886], Lows: [12], Highs: [1705], Total time: 39444.62478299998
[32m[0907 02-47-09 @MBExp.py:144][0m ####################################################################
[32m[0907 02-47-09 @MBExp.py:145][0m Starting training iteration 87.
[32m[0907 02-47-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18795, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-47-20 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19308, current rewards: -13.35960, mean: -0.22266
[32m[0907 02-47-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19037, current rewards: -17.19937, mean: -0.15636
[32m[0907 02-47-39 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18952, current rewards: -9.01992, mean: -0.05637
[32m[0907 02-47-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18917, current rewards: -0.80307, mean: -0.00382
[32m[0907 02-47-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18991, current rewards: -44.19281, mean: -0.16997
[32m[0907 02-48-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19067, current rewards: -92.75531, mean: -0.29921
[32m[0907 02-48-18 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19141, current rewards: -152.35984, mean: -0.42322
[32m[0907 02-48-27 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19045, current rewards: -195.57159, mean: -0.47700
[32m[0907 02-48-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19095, current rewards: -258.87649, mean: -0.56277
[32m[0907 02-48-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19080, current rewards: -317.15165, mean: -0.62187
[32m[0907 02-48-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19096, current rewards: -360.24747, mean: -0.64330
[32m[0907 02-49-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19086, current rewards: -421.12561, mean: -0.69037
[32m[0907 02-49-15 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19102, current rewards: -481.64343, mean: -0.72976
[32m[0907 02-49-25 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19145, current rewards: -541.92006, mean: -0.76327
[32m[0907 02-49-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19110, current rewards: -599.46665, mean: -0.78877
[32m[0907 02-49-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19102, current rewards: -659.35286, mean: -0.81402
[32m[0907 02-49-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19061, current rewards: -669.02298, mean: -0.77793
[32m[0907 02-50-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19177, current rewards: -672.89854, mean: -0.73945
[32m[0907 02-50-14 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19228, current rewards: -701.20304, mean: -0.73042
[32m[0907 02-50-24 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19282, current rewards: -713.12552, mean: -0.70606
[32m[0907 02-50-33 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19232, current rewards: -740.76806, mean: -0.69884
[32m[0907 02-50-42 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19182, current rewards: -771.66980, mean: -0.69520
[32m[0907 02-50-52 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19210, current rewards: -788.47687, mean: -0.67972
[32m[0907 02-51-03 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19339, current rewards: -797.77900, mean: -0.65932
[32m[0907 02-51-12 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19276, current rewards: -847.77900, mean: -0.67284
[32m[0907 02-51-21 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19222, current rewards: -897.77900, mean: -0.68533
[32m[0907 02-51-30 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19190, current rewards: -947.77900, mean: -0.69690
[32m[0907 02-51-39 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19160, current rewards: -997.77900, mean: -0.70764
[32m[0907 02-51-48 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19131, current rewards: -1047.77900, mean: -0.71766
[32m[0907 02-51-58 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19105, current rewards: -1097.77900, mean: -0.72701
[32m[0907 02-52-07 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19081, current rewards: -1147.77900, mean: -0.73576
[32m[0907 02-52-16 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19059, current rewards: -1197.77900, mean: -0.74396
[32m[0907 02-52-25 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19036, current rewards: -1247.77900, mean: -0.75167
[32m[0907 02-52-34 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19017, current rewards: -1297.77900, mean: -0.75894
[32m[0907 02-52-44 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19000, current rewards: -1317.69629, mean: -0.74869
[32m[0907 02-52-53 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18997, current rewards: -1310.23986, mean: -0.72389
[32m[0907 02-53-02 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18994, current rewards: -1302.76346, mean: -0.70041
[32m[0907 02-53-12 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18989, current rewards: -1295.24626, mean: -0.67814
[32m[0907 02-53-21 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18984, current rewards: -1287.72383, mean: -0.65700
[32m[0907 02-53-31 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18989, current rewards: -1339.58892, mean: -0.66646
[32m[0907 02-53-41 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.19006, current rewards: -1386.09544, mean: -0.67286
[32m[0907 02-53-50 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.19010, current rewards: -1435.60748, mean: -0.68038
[32m[0907 02-54-00 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.19007, current rewards: -1489.99557, mean: -0.68981
[32m[0907 02-54-09 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18993, current rewards: -1546.63325, mean: -0.69983
[32m[0907 02-54-19 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18993, current rewards: -1603.81513, mean: -0.70965
[32m[0907 02-54-28 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18996, current rewards: -1649.93132, mean: -0.71426
[32m[0907 02-54-37 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18975, current rewards: -1711.47494, mean: -0.72520
[32m[0907 02-54-46 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18949, current rewards: -1720.38365, mean: -0.71385
[32m[0907 02-54-55 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18925, current rewards: -1716.58440, mean: -0.69780
[32m[0907 02-55-02 @Agent.py:117][0m Average action selection time: 0.1891
[32m[0907 02-55-02 @Agent.py:118][0m Rollout length: 2510
[32m[0907 02-55-02 @MBExp.py:227][0m Rewards obtained: [-1713.545004580141], Lows: [632], Highs: [643], Total time: 39918.10991499998
[32m[0907 02-58-03 @MBExp.py:144][0m ####################################################################
[32m[0907 02-58-03 @MBExp.py:145][0m Starting training iteration 88.
[32m[0907 02-58-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.21322, current rewards: -10.00000, mean: -1.00000
[32m[0907 02-58-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19311, current rewards: -4.68643, mean: -0.07811
[32m[0907 02-58-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19089, current rewards: 0.79349, mean: 0.00721
[32m[0907 02-58-33 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18999, current rewards: 6.27382, mean: 0.03921
[32m[0907 02-58-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18949, current rewards: 11.74987, mean: 0.05595
[32m[0907 02-58-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18936, current rewards: 17.23096, mean: 0.06627
[32m[0907 02-59-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18868, current rewards: 22.70743, mean: 0.07325
[32m[0907 02-59-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18790, current rewards: 7.38042, mean: 0.02050
[32m[0907 02-59-20 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18730, current rewards: 12.46257, mean: 0.03040
[32m[0907 02-59-29 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18686, current rewards: 17.36622, mean: 0.03775
[32m[0907 02-59-38 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18655, current rewards: 22.26908, mean: 0.04366
[32m[0907 02-59-48 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18650, current rewards: 22.77946, mean: 0.04068
[32m[0907 02-59-57 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18623, current rewards: 12.85383, mean: 0.02107
[32m[0907 03-00-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18601, current rewards: 13.26693, mean: 0.02010
[32m[0907 03-00-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18584, current rewards: 16.80903, mean: 0.02367
[32m[0907 03-00-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18552, current rewards: 20.35294, mean: 0.02678
[32m[0907 03-00-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18504, current rewards: 23.89629, mean: 0.02950
[32m[0907 03-00-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18457, current rewards: 27.43912, mean: 0.03191
[32m[0907 03-00-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18419, current rewards: 30.98340, mean: 0.03405
[32m[0907 03-01-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18383, current rewards: 34.52694, mean: 0.03597
[32m[0907 03-01-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18353, current rewards: 38.07028, mean: 0.03769
[32m[0907 03-01-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18338, current rewards: 41.74479, mean: 0.03938
[32m[0907 03-01-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18311, current rewards: 46.53414, mean: 0.04192
[32m[0907 03-01-35 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18286, current rewards: 50.72832, mean: 0.04373
[32m[0907 03-01-44 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18265, current rewards: 55.60930, mean: 0.04596
[32m[0907 03-01-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18244, current rewards: 60.49487, mean: 0.04801
[32m[0907 03-02-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18225, current rewards: 65.37998, mean: 0.04991
[32m[0907 03-02-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18227, current rewards: 70.26017, mean: 0.05166
[32m[0907 03-02-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18232, current rewards: 75.14434, mean: 0.05329
[32m[0907 03-02-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18236, current rewards: 80.02550, mean: 0.05481
[32m[0907 03-02-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18238, current rewards: 64.06605, mean: 0.04243
[32m[0907 03-02-48 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18239, current rewards: 69.01894, mean: 0.04424
[32m[0907 03-02-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18242, current rewards: 73.81307, mean: 0.04585
[32m[0907 03-03-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18244, current rewards: 78.60759, mean: 0.04735
[32m[0907 03-03-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18246, current rewards: 83.40014, mean: 0.04877
[32m[0907 03-03-25 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18247, current rewards: 88.19508, mean: 0.05011
[32m[0907 03-03-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18261, current rewards: 92.98946, mean: 0.05138
[32m[0907 03-03-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18277, current rewards: 97.78317, mean: 0.05257
[32m[0907 03-03-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18290, current rewards: 102.57759, mean: 0.05371
[32m[0907 03-04-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18302, current rewards: 107.12172, mean: 0.05465
[32m[0907 03-04-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18314, current rewards: 111.89729, mean: 0.05567
[32m[0907 03-04-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18320, current rewards: 116.67472, mean: 0.05664
[32m[0907 03-04-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18319, current rewards: 121.45111, mean: 0.05756
[32m[0907 03-04-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18319, current rewards: 126.22762, mean: 0.05844
[32m[0907 03-04-48 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18318, current rewards: 131.00447, mean: 0.05928
[32m[0907 03-04-58 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18318, current rewards: 135.78200, mean: 0.06008
[32m[0907 03-05-07 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18311, current rewards: 140.55670, mean: 0.06085
[32m[0907 03-05-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18298, current rewards: 147.18764, mean: 0.06237
[32m[0907 03-05-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18287, current rewards: 145.57589, mean: 0.06040
[32m[0907 03-05-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18276, current rewards: 106.13980, mean: 0.04315
[32m[0907 03-05-40 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0907 03-05-40 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-05-41 @MBExp.py:227][0m Rewards obtained: [76.66155891394843], Lows: [21], Highs: [109], Total time: 40375.62142999998
[32m[0907 03-08-44 @MBExp.py:144][0m ####################################################################
[32m[0907 03-08-44 @MBExp.py:145][0m Starting training iteration 89.
[32m[0907 03-08-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18802, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-08-55 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18824, current rewards: -69.62930, mean: -1.16049
[32m[0907 03-09-05 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18832, current rewards: -128.80997, mean: -1.17100
[32m[0907 03-09-14 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18793, current rewards: -165.09582, mean: -1.03185
[32m[0907 03-09-23 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18790, current rewards: -241.82643, mean: -1.15155
[32m[0907 03-09-33 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18794, current rewards: -313.62527, mean: -1.20625
[32m[0907 03-09-42 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18792, current rewards: -385.73403, mean: -1.24430
[32m[0907 03-09-52 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18763, current rewards: -452.72988, mean: -1.25758
[32m[0907 03-10-01 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18709, current rewards: -529.71329, mean: -1.29198
[32m[0907 03-10-10 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18670, current rewards: -598.92692, mean: -1.30202
[32m[0907 03-10-19 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18636, current rewards: -664.30223, mean: -1.30255
[32m[0907 03-10-28 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18640, current rewards: -724.19462, mean: -1.29320
[32m[0907 03-10-38 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18616, current rewards: -817.17332, mean: -1.33963
[32m[0907 03-10-47 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18594, current rewards: -917.17332, mean: -1.38966
[32m[0907 03-10-56 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18579, current rewards: -1017.17332, mean: -1.43264
[32m[0907 03-11-05 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18553, current rewards: -1117.17332, mean: -1.46996
[32m[0907 03-11-14 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18508, current rewards: -1217.17332, mean: -1.50268
[32m[0907 03-11-23 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18464, current rewards: -1317.17332, mean: -1.53160
[32m[0907 03-11-32 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18427, current rewards: -1417.17332, mean: -1.55733
[32m[0907 03-11-41 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18391, current rewards: -1517.17332, mean: -1.58039
[32m[0907 03-11-50 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18361, current rewards: -1617.17332, mean: -1.60116
[32m[0907 03-11-59 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18333, current rewards: -1717.17332, mean: -1.61997
[32m[0907 03-12-07 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18309, current rewards: -1817.17332, mean: -1.63709
[32m[0907 03-12-16 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18285, current rewards: -1917.17332, mean: -1.65274
[32m[0907 03-12-25 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18260, current rewards: -2017.17332, mean: -1.66709
[32m[0907 03-12-34 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18240, current rewards: -2117.17332, mean: -1.68030
[32m[0907 03-12-43 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18223, current rewards: -2217.17332, mean: -1.69250
[32m[0907 03-12-52 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18206, current rewards: -2317.17332, mean: -1.70380
[32m[0907 03-13-01 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18196, current rewards: -2417.17332, mean: -1.71431
[32m[0907 03-13-10 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18202, current rewards: -2517.17332, mean: -1.72409
[32m[0907 03-13-19 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18209, current rewards: -2617.17332, mean: -1.73323
[32m[0907 03-13-28 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18212, current rewards: -2717.17332, mean: -1.74178
[32m[0907 03-13-38 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18214, current rewards: -2817.17332, mean: -1.74980
[32m[0907 03-13-47 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18217, current rewards: -2917.17332, mean: -1.75733
[32m[0907 03-13-56 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18222, current rewards: -3017.17332, mean: -1.76443
[32m[0907 03-14-05 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18224, current rewards: -3117.17332, mean: -1.77112
[32m[0907 03-14-14 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18234, current rewards: -3217.17332, mean: -1.77744
[32m[0907 03-14-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18254, current rewards: -3317.17332, mean: -1.78343
[32m[0907 03-14-33 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18269, current rewards: -3417.17332, mean: -1.78910
[32m[0907 03-14-43 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18284, current rewards: -3517.17332, mean: -1.79448
[32m[0907 03-14-52 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18298, current rewards: -3617.17332, mean: -1.79959
[32m[0907 03-15-02 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18306, current rewards: -3717.17332, mean: -1.80445
[32m[0907 03-15-11 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18306, current rewards: -3817.17332, mean: -1.80909
[32m[0907 03-15-20 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18307, current rewards: -3917.17332, mean: -1.81351
[32m[0907 03-15-29 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18306, current rewards: -4017.17332, mean: -1.81773
[32m[0907 03-15-38 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18308, current rewards: -4117.17332, mean: -1.82176
[32m[0907 03-15-47 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: -4217.17332, mean: -1.82562
[32m[0907 03-15-56 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18292, current rewards: -4317.17332, mean: -1.82931
[32m[0907 03-16-05 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18281, current rewards: -4417.17332, mean: -1.83285
[32m[0907 03-16-14 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18271, current rewards: -4517.17332, mean: -1.83625
[32m[0907 03-16-21 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0907 03-16-21 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-16-21 @MBExp.py:227][0m Rewards obtained: [-4597.1733239602145], Lows: [2322], Highs: [11], Total time: 40833.023182999976
[32m[0907 03-19-26 @MBExp.py:144][0m ####################################################################
[32m[0907 03-19-26 @MBExp.py:145][0m Starting training iteration 90.
[32m[0907 03-19-28 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20016, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-19-38 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19151, current rewards: -80.57869, mean: -1.34298
[32m[0907 03-19-47 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19088, current rewards: -145.46752, mean: -1.32243
[32m[0907 03-19-57 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19053, current rewards: -216.89693, mean: -1.35561
[32m[0907 03-20-06 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19037, current rewards: -288.40622, mean: -1.37336
[32m[0907 03-20-16 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19004, current rewards: -352.03731, mean: -1.35399
[32m[0907 03-20-25 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18978, current rewards: -412.83920, mean: -1.33174
[32m[0907 03-20-34 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18919, current rewards: -467.19415, mean: -1.29776
[32m[0907 03-20-44 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18903, current rewards: -535.08485, mean: -1.30509
[32m[0907 03-20-53 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18872, current rewards: -595.98276, mean: -1.29561
[32m[0907 03-21-02 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18863, current rewards: -648.47868, mean: -1.27153
[32m[0907 03-21-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18910, current rewards: -728.43714, mean: -1.30078
[32m[0907 03-21-23 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19095, current rewards: -784.63021, mean: -1.28628
[32m[0907 03-21-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19188, current rewards: -853.57414, mean: -1.29329
[32m[0907 03-21-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19354, current rewards: -932.04926, mean: -1.31275
[32m[0907 03-21-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19365, current rewards: -1022.86931, mean: -1.34588
[32m[0907 03-22-03 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19405, current rewards: -1102.44957, mean: -1.36105
[32m[0907 03-22-14 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19447, current rewards: -1164.12721, mean: -1.35364
[32m[0907 03-22-23 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19432, current rewards: -1238.01651, mean: -1.36046
[32m[0907 03-22-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19420, current rewards: -1305.36927, mean: -1.35976
[32m[0907 03-22-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19395, current rewards: -1384.74536, mean: -1.37104
[32m[0907 03-22-52 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19386, current rewards: -1458.65989, mean: -1.37609
[32m[0907 03-23-01 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19312, current rewards: -1489.65652, mean: -1.34203
[32m[0907 03-23-10 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19244, current rewards: -1539.65652, mean: -1.32729
[32m[0907 03-23-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19182, current rewards: -1589.65652, mean: -1.31377
[32m[0907 03-23-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19125, current rewards: -1639.65652, mean: -1.30131
[32m[0907 03-23-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19072, current rewards: -1689.65652, mean: -1.28981
[32m[0907 03-23-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19041, current rewards: -1739.65652, mean: -1.27916
[32m[0907 03-23-55 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19015, current rewards: -1789.65652, mean: -1.26926
[32m[0907 03-24-04 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18993, current rewards: -1839.65652, mean: -1.26004
[32m[0907 03-24-13 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18971, current rewards: -1889.65652, mean: -1.25143
[32m[0907 03-24-22 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18950, current rewards: -1939.65652, mean: -1.24337
[32m[0907 03-24-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18932, current rewards: -1989.65652, mean: -1.23581
[32m[0907 03-24-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18914, current rewards: -2039.65652, mean: -1.22871
[32m[0907 03-24-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18897, current rewards: -2089.65652, mean: -1.22202
[32m[0907 03-24-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18890, current rewards: -2139.65652, mean: -1.21571
[32m[0907 03-25-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18891, current rewards: -2189.65652, mean: -1.20975
[32m[0907 03-25-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18892, current rewards: -2239.65652, mean: -1.20412
[32m[0907 03-25-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18890, current rewards: -2289.65652, mean: -1.19877
[32m[0907 03-25-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18888, current rewards: -2342.60498, mean: -1.19521
[32m[0907 03-25-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18898, current rewards: -2416.42216, mean: -1.20220
[32m[0907 03-25-56 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18916, current rewards: -2472.11434, mean: -1.20006
[32m[0907 03-26-06 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18911, current rewards: -2536.42727, mean: -1.20210
[32m[0907 03-26-15 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18908, current rewards: -2607.89386, mean: -1.20736
[32m[0907 03-26-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18906, current rewards: -2676.43216, mean: -1.21106
[32m[0907 03-26-34 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18923, current rewards: -2756.84841, mean: -1.21984
[32m[0907 03-26-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18910, current rewards: -2835.07350, mean: -1.22730
[32m[0907 03-26-53 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18908, current rewards: -2895.41021, mean: -1.22687
[32m[0907 03-27-02 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18893, current rewards: -2952.43105, mean: -1.22508
[32m[0907 03-27-12 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18896, current rewards: -3027.79580, mean: -1.23081
[32m[0907 03-27-19 @Agent.py:117][0m Average action selection time: 0.1890
[32m[0907 03-27-19 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-27-19 @MBExp.py:227][0m Rewards obtained: [-3092.1255355120993], Lows: [1146], Highs: [898], Total time: 41306.38017999998
[32m[0907 03-30-27 @MBExp.py:144][0m ####################################################################
[32m[0907 03-30-27 @MBExp.py:145][0m Starting training iteration 91.
[32m[0907 03-30-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18748, current rewards: 1.20711, mean: 0.12071
[32m[0907 03-30-39 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18896, current rewards: -58.89262, mean: -0.98154
[32m[0907 03-30-48 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18923, current rewards: -137.06197, mean: -1.24602
[32m[0907 03-30-58 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19023, current rewards: -201.52321, mean: -1.25952
[32m[0907 03-31-07 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19098, current rewards: -276.51202, mean: -1.31672
[32m[0907 03-31-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19186, current rewards: -349.27731, mean: -1.34337
[32m[0907 03-31-26 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19087, current rewards: -424.63841, mean: -1.36980
[32m[0907 03-31-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18983, current rewards: -494.75298, mean: -1.37431
[32m[0907 03-31-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18908, current rewards: -585.75298, mean: -1.42867
[32m[0907 03-31-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18843, current rewards: -685.75298, mean: -1.49077
[32m[0907 03-32-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18792, current rewards: -785.75298, mean: -1.54069
[32m[0907 03-32-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18748, current rewards: -885.75298, mean: -1.58170
[32m[0907 03-32-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18721, current rewards: -985.75298, mean: -1.61599
[32m[0907 03-32-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18666, current rewards: -1085.75298, mean: -1.64508
[32m[0907 03-32-39 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18606, current rewards: -1185.75298, mean: -1.67007
[32m[0907 03-32-48 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18548, current rewards: -1285.75298, mean: -1.69178
[32m[0907 03-32-57 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18498, current rewards: -1385.75298, mean: -1.71081
[32m[0907 03-33-06 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18452, current rewards: -1485.75298, mean: -1.72762
[32m[0907 03-33-15 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18413, current rewards: -1585.75298, mean: -1.74259
[32m[0907 03-33-24 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18377, current rewards: -1685.75298, mean: -1.75599
[32m[0907 03-33-33 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18344, current rewards: -1785.75298, mean: -1.76807
[32m[0907 03-33-42 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18314, current rewards: -1885.75298, mean: -1.77901
[32m[0907 03-33-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18290, current rewards: -1985.75298, mean: -1.78897
[32m[0907 03-33-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18268, current rewards: -2085.75298, mean: -1.79806
[32m[0907 03-34-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18246, current rewards: -2185.75298, mean: -1.80641
[32m[0907 03-34-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18226, current rewards: -2285.75298, mean: -1.81409
[32m[0907 03-34-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18224, current rewards: -2385.75298, mean: -1.82119
[32m[0907 03-34-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18227, current rewards: -2485.75298, mean: -1.82776
[32m[0907 03-34-45 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18232, current rewards: -2585.75298, mean: -1.83387
[32m[0907 03-34-54 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18235, current rewards: -2685.75298, mean: -1.83956
[32m[0907 03-35-03 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18237, current rewards: -2785.75298, mean: -1.84487
[32m[0907 03-35-12 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18240, current rewards: -2885.75298, mean: -1.84984
[32m[0907 03-35-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18246, current rewards: -2985.75298, mean: -1.85450
[32m[0907 03-35-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18248, current rewards: -3085.75298, mean: -1.85889
[32m[0907 03-35-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18255, current rewards: -3185.75298, mean: -1.86301
[32m[0907 03-35-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18272, current rewards: -3285.75298, mean: -1.86691
[32m[0907 03-35-59 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18286, current rewards: -3385.75298, mean: -1.87058
[32m[0907 03-36-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18301, current rewards: -3485.75298, mean: -1.87406
[32m[0907 03-36-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18315, current rewards: -3585.75298, mean: -1.87736
[32m[0907 03-36-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18329, current rewards: -3685.75298, mean: -1.88049
[32m[0907 03-36-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18333, current rewards: -3785.75298, mean: -1.88346
[32m[0907 03-36-45 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18334, current rewards: -3885.75298, mean: -1.88629
[32m[0907 03-36-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18334, current rewards: -3985.75298, mean: -1.88898
[32m[0907 03-37-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18334, current rewards: -4085.75298, mean: -1.89155
[32m[0907 03-37-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18334, current rewards: -4185.75298, mean: -1.89401
[32m[0907 03-37-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18333, current rewards: -4285.75298, mean: -1.89635
[32m[0907 03-37-31 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18333, current rewards: -4385.75298, mean: -1.89859
[32m[0907 03-37-40 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18319, current rewards: -4485.75298, mean: -1.90074
[32m[0907 03-37-49 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18307, current rewards: -4585.75298, mean: -1.90280
[32m[0907 03-37-58 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18296, current rewards: -4685.75298, mean: -1.90478
[32m[0907 03-38-05 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 03-38-05 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-38-05 @MBExp.py:227][0m Rewards obtained: [-4765.752979428763], Lows: [2390], Highs: [10], Total time: 41764.40408999998
[32m[0907 03-41-14 @MBExp.py:144][0m ####################################################################
[32m[0907 03-41-14 @MBExp.py:145][0m Starting training iteration 92.
[32m[0907 03-41-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20214, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-41-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19090, current rewards: -96.30377, mean: -1.60506
[32m[0907 03-41-35 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19044, current rewards: -190.05923, mean: -1.72781
[32m[0907 03-41-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19024, current rewards: -283.85168, mean: -1.77407
[32m[0907 03-41-54 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18972, current rewards: -377.51981, mean: -1.79771
[32m[0907 03-42-03 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18854, current rewards: -469.05194, mean: -1.80405
[32m[0907 03-42-12 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18778, current rewards: -562.58758, mean: -1.81480
[32m[0907 03-42-22 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18718, current rewards: -654.15149, mean: -1.81709
[32m[0907 03-42-31 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18672, current rewards: -732.52603, mean: -1.78665
[32m[0907 03-42-40 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18639, current rewards: -824.22321, mean: -1.79179
[32m[0907 03-42-49 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18613, current rewards: -915.83697, mean: -1.79576
[32m[0907 03-42-58 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18591, current rewards: -1013.77835, mean: -1.81032
[32m[0907 03-43-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18576, current rewards: -1113.77835, mean: -1.82587
[32m[0907 03-43-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18555, current rewards: -1213.77835, mean: -1.83906
[32m[0907 03-43-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18537, current rewards: -1313.77835, mean: -1.85039
[32m[0907 03-43-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18487, current rewards: -1413.77835, mean: -1.86023
[32m[0907 03-43-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18448, current rewards: -1513.77835, mean: -1.86886
[32m[0907 03-43-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18408, current rewards: -1613.77835, mean: -1.87649
[32m[0907 03-44-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18372, current rewards: -1713.77835, mean: -1.88327
[32m[0907 03-44-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18341, current rewards: -1813.77835, mean: -1.88935
[32m[0907 03-44-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18314, current rewards: -1913.77835, mean: -1.89483
[32m[0907 03-44-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18286, current rewards: -2013.77835, mean: -1.89979
[32m[0907 03-44-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18263, current rewards: -2113.77835, mean: -1.90430
[32m[0907 03-44-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18241, current rewards: -2213.77835, mean: -1.90843
[32m[0907 03-44-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18221, current rewards: -2313.77835, mean: -1.91221
[32m[0907 03-45-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18204, current rewards: -2413.77835, mean: -1.91570
[32m[0907 03-45-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18205, current rewards: -2513.77835, mean: -1.91891
[32m[0907 03-45-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18208, current rewards: -2613.77835, mean: -1.92190
[32m[0907 03-45-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18213, current rewards: -2713.77835, mean: -1.92467
[32m[0907 03-45-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18217, current rewards: -2813.77835, mean: -1.92725
[32m[0907 03-45-50 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18221, current rewards: -2913.77835, mean: -1.92965
[32m[0907 03-45-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18225, current rewards: -3013.77835, mean: -1.93191
[32m[0907 03-46-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18228, current rewards: -3113.77835, mean: -1.93402
[32m[0907 03-46-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18231, current rewards: -3213.77835, mean: -1.93601
[32m[0907 03-46-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18235, current rewards: -3313.77835, mean: -1.93788
[32m[0907 03-46-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18237, current rewards: -3413.77835, mean: -1.93965
[32m[0907 03-46-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18247, current rewards: -3513.77835, mean: -1.94131
[32m[0907 03-46-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18263, current rewards: -3613.77835, mean: -1.94289
[32m[0907 03-47-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18277, current rewards: -3713.77835, mean: -1.94439
[32m[0907 03-47-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18290, current rewards: -3813.77835, mean: -1.94581
[32m[0907 03-47-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18305, current rewards: -3913.77835, mean: -1.94715
[32m[0907 03-47-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18316, current rewards: -4013.77835, mean: -1.94844
[32m[0907 03-47-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18316, current rewards: -4113.77835, mean: -1.94966
[32m[0907 03-47-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18316, current rewards: -4213.77835, mean: -1.95082
[32m[0907 03-47-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18317, current rewards: -4313.77835, mean: -1.95194
[32m[0907 03-48-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18319, current rewards: -4413.77835, mean: -1.95300
[32m[0907 03-48-18 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18319, current rewards: -4513.77835, mean: -1.95402
[32m[0907 03-48-27 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18308, current rewards: -4613.77835, mean: -1.95499
[32m[0907 03-48-36 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18297, current rewards: -4713.77835, mean: -1.95592
[32m[0907 03-48-45 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18285, current rewards: -4813.77835, mean: -1.95682
[32m[0907 03-48-52 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0907 03-48-52 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-48-52 @MBExp.py:227][0m Rewards obtained: [-4893.778354931811], Lows: [2443], Highs: [13], Total time: 42222.14261599998
[32m[0907 03-52-03 @MBExp.py:144][0m ####################################################################
[32m[0907 03-52-03 @MBExp.py:145][0m Starting training iteration 93.
[32m[0907 03-52-05 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18856, current rewards: -10.00000, mean: -1.00000
[32m[0907 03-52-15 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19199, current rewards: -75.35267, mean: -1.25588
[32m[0907 03-52-24 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19057, current rewards: -161.71149, mean: -1.47010
[32m[0907 03-52-34 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19126, current rewards: -224.67531, mean: -1.40422
[32m[0907 03-52-43 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18936, current rewards: -300.48474, mean: -1.43088
[32m[0907 03-52-52 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18912, current rewards: -354.62036, mean: -1.36392
[32m[0907 03-53-02 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18918, current rewards: -431.46054, mean: -1.39181
[32m[0907 03-53-11 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18892, current rewards: -513.12375, mean: -1.42534
[32m[0907 03-53-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18882, current rewards: -570.01292, mean: -1.39028
[32m[0907 03-53-30 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18849, current rewards: -634.68337, mean: -1.37975
[32m[0907 03-53-39 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18798, current rewards: -708.41973, mean: -1.38906
[32m[0907 03-53-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18827, current rewards: -765.87731, mean: -1.36764
[32m[0907 03-53-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18782, current rewards: -857.52441, mean: -1.40578
[32m[0907 03-54-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18786, current rewards: -873.93703, mean: -1.32415
[32m[0907 03-54-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18743, current rewards: -875.69567, mean: -1.23337
[32m[0907 03-54-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18693, current rewards: -883.19781, mean: -1.16210
[32m[0907 03-54-35 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18676, current rewards: -885.11991, mean: -1.09274
[32m[0907 03-54-44 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18641, current rewards: -886.51760, mean: -1.03083
[32m[0907 03-54-53 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18629, current rewards: -887.45458, mean: -0.97522
[32m[0907 03-55-02 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18597, current rewards: -900.96315, mean: -0.93850
[32m[0907 03-55-11 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18558, current rewards: -973.66576, mean: -0.96403
[32m[0907 03-55-20 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18520, current rewards: -1025.18601, mean: -0.96716
[32m[0907 03-55-29 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18484, current rewards: -1101.06530, mean: -0.99195
[32m[0907 03-55-37 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18456, current rewards: -1169.74796, mean: -1.00840
[32m[0907 03-55-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18446, current rewards: -1228.55790, mean: -1.01534
[32m[0907 03-55-56 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18441, current rewards: -1278.89227, mean: -1.01499
[32m[0907 03-56-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18436, current rewards: -1324.80692, mean: -1.01130
[32m[0907 03-56-14 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18433, current rewards: -1381.08643, mean: -1.01550
[32m[0907 03-56-23 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18433, current rewards: -1449.30938, mean: -1.02788
[32m[0907 03-56-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18438, current rewards: -1508.51716, mean: -1.03323
[32m[0907 03-56-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18454, current rewards: -1594.64411, mean: -1.05606
[32m[0907 03-56-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18472, current rewards: -1664.60589, mean: -1.06706
[32m[0907 03-57-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18495, current rewards: -1744.43324, mean: -1.08350
[32m[0907 03-57-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18503, current rewards: -1822.22491, mean: -1.09773
[32m[0907 03-57-21 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18540, current rewards: -1902.40370, mean: -1.11252
[32m[0907 03-57-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18552, current rewards: -1984.55491, mean: -1.12759
[32m[0907 03-57-40 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18611, current rewards: -2055.05638, mean: -1.13539
[32m[0907 03-57-50 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18626, current rewards: -2122.23422, mean: -1.14099
[32m[0907 03-58-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18677, current rewards: -2190.58914, mean: -1.14691
[32m[0907 03-58-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18707, current rewards: -2269.61923, mean: -1.15797
[32m[0907 03-58-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18760, current rewards: -2347.03014, mean: -1.16768
[32m[0907 03-58-31 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18819, current rewards: -2406.03224, mean: -1.16798
[32m[0907 03-58-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18840, current rewards: -2474.59033, mean: -1.17279
[32m[0907 03-58-51 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18844, current rewards: -2529.22721, mean: -1.17094
[32m[0907 03-59-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18896, current rewards: -2591.37529, mean: -1.17257
[32m[0907 03-59-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18894, current rewards: -2646.02494, mean: -1.17081
[32m[0907 03-59-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18905, current rewards: -2709.05981, mean: -1.17275
[32m[0907 03-59-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18902, current rewards: -2789.91590, mean: -1.18217
[32m[0907 03-59-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18879, current rewards: -2889.91590, mean: -1.19914
[32m[0907 03-59-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18856, current rewards: -2989.91590, mean: -1.21541
[32m[0907 03-59-55 @Agent.py:117][0m Average action selection time: 0.1884
[32m[0907 03-59-55 @Agent.py:118][0m Rollout length: 2510
[32m[0907 03-59-55 @MBExp.py:227][0m Rewards obtained: [-3069.9158972256823], Lows: [1507], Highs: [174], Total time: 42693.96201299998
[32m[0907 04-03-08 @MBExp.py:144][0m ####################################################################
[32m[0907 04-03-08 @MBExp.py:145][0m Starting training iteration 94.
[32m[0907 04-03-10 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18886, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-03-19 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18901, current rewards: -110.00000, mean: -1.83333
[32m[0907 04-03-29 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18846, current rewards: -210.00000, mean: -1.90909
[32m[0907 04-03-38 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18767, current rewards: -310.00000, mean: -1.93750
[32m[0907 04-03-48 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18779, current rewards: -410.00000, mean: -1.95238
[32m[0907 04-03-57 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18792, current rewards: -510.00000, mean: -1.96154
[32m[0907 04-04-06 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18793, current rewards: -610.00000, mean: -1.96774
[32m[0907 04-04-16 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18786, current rewards: -710.00000, mean: -1.97222
[32m[0907 04-04-25 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18785, current rewards: -810.00000, mean: -1.97561
[32m[0907 04-04-34 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18735, current rewards: -910.00000, mean: -1.97826
[32m[0907 04-04-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18700, current rewards: -1010.00000, mean: -1.98039
[32m[0907 04-04-53 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18667, current rewards: -1110.00000, mean: -1.98214
[32m[0907 04-05-02 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18631, current rewards: -1210.00000, mean: -1.98361
[32m[0907 04-05-11 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18566, current rewards: -1310.00000, mean: -1.98485
[32m[0907 04-05-20 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18510, current rewards: -1410.00000, mean: -1.98592
[32m[0907 04-05-29 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18461, current rewards: -1510.00000, mean: -1.98684
[32m[0907 04-05-38 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18417, current rewards: -1610.00000, mean: -1.98765
[32m[0907 04-05-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18379, current rewards: -1710.00000, mean: -1.98837
[32m[0907 04-05-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18347, current rewards: -1810.00000, mean: -1.98901
[32m[0907 04-06-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18317, current rewards: -1910.00000, mean: -1.98958
[32m[0907 04-06-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18290, current rewards: -2010.00000, mean: -1.99010
[32m[0907 04-06-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18263, current rewards: -2110.00000, mean: -1.99057
[32m[0907 04-06-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18239, current rewards: -2210.00000, mean: -1.99099
[32m[0907 04-06-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18220, current rewards: -2310.00000, mean: -1.99138
[32m[0907 04-06-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18203, current rewards: -2410.00000, mean: -1.99174
[32m[0907 04-06-58 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18184, current rewards: -2510.00000, mean: -1.99206
[32m[0907 04-07-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18168, current rewards: -2610.00000, mean: -1.99237
[32m[0907 04-07-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18155, current rewards: -2710.00000, mean: -1.99265
[32m[0907 04-07-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18144, current rewards: -2810.00000, mean: -1.99291
[32m[0907 04-07-33 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18130, current rewards: -2910.00000, mean: -1.99315
[32m[0907 04-07-42 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18115, current rewards: -3010.00000, mean: -1.99338
[32m[0907 04-07-51 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18117, current rewards: -3110.00000, mean: -1.99359
[32m[0907 04-08-00 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18124, current rewards: -3210.00000, mean: -1.99379
[32m[0907 04-08-09 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18131, current rewards: -3310.00000, mean: -1.99398
[32m[0907 04-08-19 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18139, current rewards: -3410.00000, mean: -1.99415
[32m[0907 04-08-28 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18162, current rewards: -3510.00000, mean: -1.99432
[32m[0907 04-08-38 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18182, current rewards: -3610.00000, mean: -1.99448
[32m[0907 04-08-47 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18201, current rewards: -3710.00000, mean: -1.99462
[32m[0907 04-08-57 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18218, current rewards: -3810.00000, mean: -1.99476
[32m[0907 04-09-06 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18235, current rewards: -3910.00000, mean: -1.99490
[32m[0907 04-09-15 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18245, current rewards: -4010.00000, mean: -1.99502
[32m[0907 04-09-25 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18248, current rewards: -4110.00000, mean: -1.99515
[32m[0907 04-09-34 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18250, current rewards: -4210.00000, mean: -1.99526
[32m[0907 04-09-43 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18253, current rewards: -4310.00000, mean: -1.99537
[32m[0907 04-09-52 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18254, current rewards: -4410.00000, mean: -1.99548
[32m[0907 04-10-01 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18255, current rewards: -4510.00000, mean: -1.99558
[32m[0907 04-10-10 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18257, current rewards: -4610.00000, mean: -1.99567
[32m[0907 04-10-20 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18259, current rewards: -4710.00000, mean: -1.99576
[32m[0907 04-10-29 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18251, current rewards: -4810.00000, mean: -1.99585
[32m[0907 04-10-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18241, current rewards: -4910.00000, mean: -1.99593
[32m[0907 04-10-45 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0907 04-10-45 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-10-45 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 43150.62563099998
[32m[0907 04-14-00 @MBExp.py:144][0m ####################################################################
[32m[0907 04-14-00 @MBExp.py:145][0m Starting training iteration 95.
[32m[0907 04-14-02 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18882, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-14-11 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18910, current rewards: -38.19598, mean: -0.63660
[32m[0907 04-14-21 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18856, current rewards: -30.65625, mean: -0.27869
[32m[0907 04-14-30 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18818, current rewards: -23.27537, mean: -0.14547
[32m[0907 04-14-40 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18789, current rewards: -12.87779, mean: -0.06132
[32m[0907 04-14-49 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18801, current rewards: -4.76390, mean: -0.01832
[32m[0907 04-14-58 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18795, current rewards: 3.34855, mean: 0.01080
[32m[0907 04-15-08 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18807, current rewards: 11.46663, mean: 0.03185
[32m[0907 04-15-17 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18813, current rewards: 19.57895, mean: 0.04775
[32m[0907 04-15-27 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18807, current rewards: -18.87656, mean: -0.04104
[32m[0907 04-15-36 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18812, current rewards: -13.68757, mean: -0.02684
[32m[0907 04-15-46 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18810, current rewards: -8.50050, mean: -0.01518
[32m[0907 04-15-55 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18788, current rewards: -3.08677, mean: -0.00506
[32m[0907 04-16-04 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18720, current rewards: 2.14186, mean: 0.00325
[32m[0907 04-16-13 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18656, current rewards: 7.36785, mean: 0.01038
[32m[0907 04-16-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18601, current rewards: 12.59579, mean: 0.01657
[32m[0907 04-16-30 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18548, current rewards: 17.28652, mean: 0.02134
[32m[0907 04-16-39 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18501, current rewards: 22.56310, mean: 0.02624
[32m[0907 04-16-48 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18464, current rewards: 27.79154, mean: 0.03054
[32m[0907 04-16-57 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18429, current rewards: 33.02277, mean: 0.03440
[32m[0907 04-17-06 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18396, current rewards: 38.24811, mean: 0.03787
[32m[0907 04-17-15 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18364, current rewards: 43.47789, mean: 0.04102
[32m[0907 04-17-24 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18341, current rewards: 44.89772, mean: 0.04045
[32m[0907 04-17-33 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18317, current rewards: 44.21165, mean: 0.03811
[32m[0907 04-17-42 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18291, current rewards: 45.57628, mean: 0.03767
[32m[0907 04-17-51 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18270, current rewards: 44.70244, mean: 0.03548
[32m[0907 04-17-59 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18250, current rewards: 46.15793, mean: 0.03524
[32m[0907 04-18-08 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18232, current rewards: 45.37960, mean: 0.03337
[32m[0907 04-18-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18214, current rewards: 44.66303, mean: 0.03168
[32m[0907 04-18-26 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18198, current rewards: 40.19866, mean: 0.02753
[32m[0907 04-18-35 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18183, current rewards: 35.47310, mean: 0.02349
[32m[0907 04-18-44 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18170, current rewards: 32.91330, mean: 0.02110
[32m[0907 04-18-53 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18157, current rewards: -30.86064, mean: -0.01917
[32m[0907 04-19-02 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18154, current rewards: -30.26332, mean: -0.01823
[32m[0907 04-19-11 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18152, current rewards: -32.47646, mean: -0.01899
[32m[0907 04-19-20 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18174, current rewards: -34.31404, mean: -0.01950
[32m[0907 04-19-30 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18207, current rewards: -34.46456, mean: -0.01904
[32m[0907 04-19-40 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18242, current rewards: -65.87982, mean: -0.03542
[32m[0907 04-19-49 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18266, current rewards: -111.37804, mean: -0.05831
[32m[0907 04-19-59 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18280, current rewards: -104.76981, mean: -0.05345
[32m[0907 04-20-08 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18295, current rewards: -98.16158, mean: -0.04884
[32m[0907 04-20-18 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18302, current rewards: -91.55334, mean: -0.04444
[32m[0907 04-20-27 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18304, current rewards: -84.94511, mean: -0.04026
[32m[0907 04-20-36 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18305, current rewards: -78.33688, mean: -0.03627
[32m[0907 04-20-45 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18307, current rewards: -71.72865, mean: -0.03246
[32m[0907 04-20-54 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18308, current rewards: -66.94333, mean: -0.02962
[32m[0907 04-21-04 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18308, current rewards: -98.59064, mean: -0.04268
[32m[0907 04-21-13 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18308, current rewards: -148.59064, mean: -0.06296
[32m[0907 04-21-22 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18307, current rewards: -198.59064, mean: -0.08240
[32m[0907 04-21-31 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18296, current rewards: -248.59064, mean: -0.10105
[32m[0907 04-21-38 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 04-21-38 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-21-38 @MBExp.py:227][0m Rewards obtained: [-288.5906351041858], Lows: [179], Highs: [236], Total time: 43608.63798899998
[32m[0907 04-24-54 @MBExp.py:144][0m ####################################################################
[32m[0907 04-24-54 @MBExp.py:145][0m Starting training iteration 96.
[32m[0907 04-24-56 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18989, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-25-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18982, current rewards: -55.79110, mean: -0.92985
[32m[0907 04-25-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18894, current rewards: -102.62267, mean: -0.93293
[32m[0907 04-25-25 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18864, current rewards: -149.44621, mean: -0.93404
[32m[0907 04-25-34 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18844, current rewards: -198.38604, mean: -0.94470
[32m[0907 04-25-43 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18838, current rewards: -244.18320, mean: -0.93917
[32m[0907 04-25-53 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18834, current rewards: -288.83028, mean: -0.93171
[32m[0907 04-26-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18828, current rewards: -334.61682, mean: -0.92949
[32m[0907 04-26-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18824, current rewards: -382.51735, mean: -0.93297
[32m[0907 04-26-21 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18819, current rewards: -429.07333, mean: -0.93277
[32m[0907 04-26-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18808, current rewards: -474.81744, mean: -0.93101
[32m[0907 04-26-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18799, current rewards: -522.71181, mean: -0.93341
[32m[0907 04-26-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18792, current rewards: -566.34539, mean: -0.92844
[32m[0907 04-26-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18737, current rewards: -617.78747, mean: -0.93604
[32m[0907 04-27-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18669, current rewards: -669.56872, mean: -0.94305
[32m[0907 04-27-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18613, current rewards: -719.50835, mean: -0.94672
[32m[0907 04-27-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18561, current rewards: -766.99119, mean: -0.94690
[32m[0907 04-27-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18513, current rewards: -815.82446, mean: -0.94863
[32m[0907 04-27-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18472, current rewards: -862.46355, mean: -0.94776
[32m[0907 04-27-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18434, current rewards: -910.24204, mean: -0.94817
[32m[0907 04-28-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18402, current rewards: -962.93918, mean: -0.95341
[32m[0907 04-28-09 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18372, current rewards: -962.20945, mean: -0.90774
[32m[0907 04-28-18 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18344, current rewards: -955.11290, mean: -0.86046
[32m[0907 04-28-27 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18320, current rewards: -948.01635, mean: -0.81726
[32m[0907 04-28-36 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18299, current rewards: -940.91980, mean: -0.77762
[32m[0907 04-28-45 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18279, current rewards: -933.82325, mean: -0.74113
[32m[0907 04-28-54 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18260, current rewards: -926.72670, mean: -0.70742
[32m[0907 04-29-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18241, current rewards: -961.88159, mean: -0.70727
[32m[0907 04-29-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18223, current rewards: -1011.88159, mean: -0.71765
[32m[0907 04-29-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18209, current rewards: -1061.88159, mean: -0.72732
[32m[0907 04-29-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18194, current rewards: -1111.88159, mean: -0.73635
[32m[0907 04-29-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18181, current rewards: -1161.88159, mean: -0.74480
[32m[0907 04-29-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18168, current rewards: -1211.88159, mean: -0.75272
[32m[0907 04-29-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18157, current rewards: -1261.88159, mean: -0.76017
[32m[0907 04-30-05 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18145, current rewards: -1311.88159, mean: -0.76718
[32m[0907 04-30-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18141, current rewards: -1361.88159, mean: -0.77380
[32m[0907 04-30-24 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18158, current rewards: -1411.88159, mean: -0.78005
[32m[0907 04-30-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18178, current rewards: -1461.88159, mean: -0.78596
[32m[0907 04-30-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18194, current rewards: -1511.88159, mean: -0.79156
[32m[0907 04-30-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18209, current rewards: -1561.88159, mean: -0.79688
[32m[0907 04-31-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18224, current rewards: -1611.88159, mean: -0.80193
[32m[0907 04-31-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18233, current rewards: -1661.88159, mean: -0.80674
[32m[0907 04-31-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18236, current rewards: -1711.88159, mean: -0.81132
[32m[0907 04-31-29 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18238, current rewards: -1761.88159, mean: -0.81569
[32m[0907 04-31-38 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18240, current rewards: -1811.88159, mean: -0.81986
[32m[0907 04-31-47 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18243, current rewards: -1861.88159, mean: -0.82384
[32m[0907 04-31-56 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18245, current rewards: -1911.88159, mean: -0.82765
[32m[0907 04-32-06 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18248, current rewards: -1961.88159, mean: -0.83131
[32m[0907 04-32-15 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18249, current rewards: -2011.88159, mean: -0.83481
[32m[0907 04-32-24 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18242, current rewards: -2061.88159, mean: -0.83816
[32m[0907 04-32-31 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0907 04-32-31 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-32-31 @MBExp.py:227][0m Rewards obtained: [-2101.8815919357744], Lows: [25], Highs: [2102], Total time: 44065.33139499998
[32m[0907 04-35-50 @MBExp.py:144][0m ####################################################################
[32m[0907 04-35-50 @MBExp.py:145][0m Starting training iteration 97.
[32m[0907 04-35-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19406, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-36-02 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18980, current rewards: -95.81596, mean: -1.59693
[32m[0907 04-36-11 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18915, current rewards: -189.36027, mean: -1.72146
[32m[0907 04-36-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18893, current rewards: -280.60407, mean: -1.75378
[32m[0907 04-36-30 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18895, current rewards: -366.14233, mean: -1.74353
[32m[0907 04-36-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18884, current rewards: -456.62200, mean: -1.75624
[32m[0907 04-36-49 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18877, current rewards: -544.93527, mean: -1.75786
[32m[0907 04-36-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18880, current rewards: -632.57768, mean: -1.75716
[32m[0907 04-37-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18892, current rewards: -720.17976, mean: -1.75654
[32m[0907 04-37-17 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18897, current rewards: -791.52068, mean: -1.72070
[32m[0907 04-37-27 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18887, current rewards: -879.63364, mean: -1.72477
[32m[0907 04-37-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18876, current rewards: -954.39466, mean: -1.70428
[32m[0907 04-37-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18852, current rewards: -1041.22653, mean: -1.70693
[32m[0907 04-37-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18787, current rewards: -1121.54607, mean: -1.69931
[32m[0907 04-38-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18718, current rewards: -1199.27453, mean: -1.68912
[32m[0907 04-38-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18658, current rewards: -1280.14443, mean: -1.68440
[32m[0907 04-38-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18607, current rewards: -1362.48899, mean: -1.68209
[32m[0907 04-38-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18554, current rewards: -1448.85183, mean: -1.68471
[32m[0907 04-38-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18515, current rewards: -1530.44310, mean: -1.68181
[32m[0907 04-38-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18478, current rewards: -1625.27983, mean: -1.69300
[32m[0907 04-38-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18445, current rewards: -1718.81057, mean: -1.70179
[32m[0907 04-39-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18412, current rewards: -1812.28141, mean: -1.70970
[32m[0907 04-39-14 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18383, current rewards: -1905.41808, mean: -1.71659
[32m[0907 04-39-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18372, current rewards: -2005.41808, mean: -1.72881
[32m[0907 04-39-32 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18350, current rewards: -2105.41808, mean: -1.74001
[32m[0907 04-39-41 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18330, current rewards: -2205.41808, mean: -1.75033
[32m[0907 04-39-50 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18306, current rewards: -2305.41808, mean: -1.75986
[32m[0907 04-39-59 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18286, current rewards: -2405.41808, mean: -1.76869
[32m[0907 04-40-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18269, current rewards: -2505.41808, mean: -1.77689
[32m[0907 04-40-17 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18253, current rewards: -2605.41808, mean: -1.78453
[32m[0907 04-40-26 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18238, current rewards: -2705.41808, mean: -1.79167
[32m[0907 04-40-35 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18222, current rewards: -2805.41808, mean: -1.79834
[32m[0907 04-40-44 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18210, current rewards: -2905.41808, mean: -1.80461
[32m[0907 04-40-53 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18198, current rewards: -3005.41808, mean: -1.81049
[32m[0907 04-41-02 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18187, current rewards: -3073.52779, mean: -1.79738
[32m[0907 04-41-11 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18183, current rewards: -3136.17706, mean: -1.78192
[32m[0907 04-41-20 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18202, current rewards: -3206.21391, mean: -1.77139
[32m[0907 04-41-30 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18221, current rewards: -3258.61023, mean: -1.75194
[32m[0907 04-41-39 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18238, current rewards: -3316.91953, mean: -1.73661
[32m[0907 04-41-48 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18251, current rewards: -3383.21742, mean: -1.72613
[32m[0907 04-41-58 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18264, current rewards: -3436.85938, mean: -1.70988
[32m[0907 04-42-07 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18277, current rewards: -3495.08088, mean: -1.69664
[32m[0907 04-42-17 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18291, current rewards: -3577.44206, mean: -1.69547
[32m[0907 04-42-26 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18297, current rewards: -3654.57319, mean: -1.69193
[32m[0907 04-42-35 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18299, current rewards: -3735.81204, mean: -1.69041
[32m[0907 04-42-44 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18301, current rewards: -3816.05695, mean: -1.68852
[32m[0907 04-42-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: -3893.55564, mean: -1.68552
[32m[0907 04-43-03 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18308, current rewards: -3968.85571, mean: -1.68172
[32m[0907 04-43-12 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18308, current rewards: -4045.85818, mean: -1.67878
[32m[0907 04-43-21 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18299, current rewards: -4121.01530, mean: -1.67521
[32m[0907 04-43-28 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 04-43-28 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-43-28 @MBExp.py:227][0m Rewards obtained: [-4181.344051275114], Lows: [2124], Highs: [26], Total time: 44523.41695699998
[32m[0907 04-46-49 @MBExp.py:144][0m ####################################################################
[32m[0907 04-46-49 @MBExp.py:145][0m Starting training iteration 98.
[32m[0907 04-46-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18961, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-47-00 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18959, current rewards: -60.00000, mean: -1.00000
[32m[0907 04-47-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18905, current rewards: -110.00000, mean: -1.00000
[32m[0907 04-47-19 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18886, current rewards: -160.00000, mean: -1.00000
[32m[0907 04-47-28 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18884, current rewards: -210.00000, mean: -1.00000
[32m[0907 04-47-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18877, current rewards: -260.00000, mean: -1.00000
[32m[0907 04-47-47 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18879, current rewards: -310.00000, mean: -1.00000
[32m[0907 04-47-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18879, current rewards: -360.00000, mean: -1.00000
[32m[0907 04-48-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18873, current rewards: -410.00000, mean: -1.00000
[32m[0907 04-48-16 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18864, current rewards: -411.04307, mean: -0.89357
[32m[0907 04-48-25 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18862, current rewards: -406.13610, mean: -0.79635
[32m[0907 04-48-35 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18859, current rewards: -403.60853, mean: -0.72073
[32m[0907 04-48-44 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18824, current rewards: -401.08096, mean: -0.65751
[32m[0907 04-48-53 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18771, current rewards: -398.55340, mean: -0.60387
[32m[0907 04-49-02 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18705, current rewards: -396.02583, mean: -0.55778
[32m[0907 04-49-11 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18649, current rewards: -393.49827, mean: -0.51776
[32m[0907 04-49-20 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18599, current rewards: -390.97070, mean: -0.48268
[32m[0907 04-49-29 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18553, current rewards: -388.44313, mean: -0.45168
[32m[0907 04-49-37 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18512, current rewards: -390.08840, mean: -0.42867
[32m[0907 04-49-46 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18475, current rewards: -440.08840, mean: -0.45843
[32m[0907 04-49-55 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18444, current rewards: -490.08840, mean: -0.48524
[32m[0907 04-50-04 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18414, current rewards: -540.08840, mean: -0.50952
[32m[0907 04-50-13 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18385, current rewards: -590.08840, mean: -0.53161
[32m[0907 04-50-22 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18359, current rewards: -640.08840, mean: -0.55180
[32m[0907 04-50-31 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18338, current rewards: -690.08840, mean: -0.57032
[32m[0907 04-50-40 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18316, current rewards: -740.08840, mean: -0.58737
[32m[0907 04-50-49 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18295, current rewards: -790.08840, mean: -0.60312
[32m[0907 04-50-58 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18275, current rewards: -840.08840, mean: -0.61771
[32m[0907 04-51-07 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18260, current rewards: -890.08840, mean: -0.63127
[32m[0907 04-51-15 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18243, current rewards: -940.08840, mean: -0.64390
[32m[0907 04-51-24 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18226, current rewards: -990.08840, mean: -0.65569
[32m[0907 04-51-33 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18212, current rewards: -1040.08840, mean: -0.66672
[32m[0907 04-51-42 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18199, current rewards: -1090.08840, mean: -0.67707
[32m[0907 04-51-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18188, current rewards: -1140.08840, mean: -0.68680
[32m[0907 04-52-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18175, current rewards: -1190.08840, mean: -0.69596
[32m[0907 04-52-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18174, current rewards: -1240.08840, mean: -0.70460
[32m[0907 04-52-18 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18189, current rewards: -1290.08840, mean: -0.71276
[32m[0907 04-52-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18209, current rewards: -1340.08840, mean: -0.72048
[32m[0907 04-52-37 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18227, current rewards: -1390.08840, mean: -0.72779
[32m[0907 04-52-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18242, current rewards: -1440.08840, mean: -0.73474
[32m[0907 04-52-56 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18257, current rewards: -1490.08840, mean: -0.74134
[32m[0907 04-53-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18272, current rewards: -1540.08840, mean: -0.74762
[32m[0907 04-53-15 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18286, current rewards: -1590.08840, mean: -0.75360
[32m[0907 04-53-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18298, current rewards: -1640.08840, mean: -0.75930
[32m[0907 04-53-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18302, current rewards: -1690.08840, mean: -0.76475
[32m[0907 04-53-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18302, current rewards: -1740.08840, mean: -0.76995
[32m[0907 04-53-52 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18304, current rewards: -1790.08840, mean: -0.77493
[32m[0907 04-54-01 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18304, current rewards: -1840.08840, mean: -0.77970
[32m[0907 04-54-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18305, current rewards: -1890.08840, mean: -0.78427
[32m[0907 04-54-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18303, current rewards: -1940.08840, mean: -0.78865
[32m[0907 04-54-27 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 04-54-27 @Agent.py:118][0m Rollout length: 2510
[32m[0907 04-54-27 @MBExp.py:227][0m Rewards obtained: [-1980.0883969572624], Lows: [0], Highs: [2011], Total time: 44981.60966399998
[32m[0907 04-57-50 @MBExp.py:144][0m ####################################################################
[32m[0907 04-57-50 @MBExp.py:145][0m Starting training iteration 99.
[32m[0907 04-57-52 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18910, current rewards: -10.00000, mean: -1.00000
[32m[0907 04-58-03 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21575, current rewards: -54.55819, mean: -0.90930
[32m[0907 04-58-13 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20440, current rewards: -133.14979, mean: -1.21045
[32m[0907 04-58-22 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20028, current rewards: -200.89872, mean: -1.25562
[32m[0907 04-58-32 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20041, current rewards: -285.34788, mean: -1.35880
[32m[0907 04-58-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19996, current rewards: -347.68618, mean: -1.33725
[32m[0907 04-58-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19904, current rewards: -419.26566, mean: -1.35247
[32m[0907 04-59-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20001, current rewards: -491.67139, mean: -1.36575
[32m[0907 04-59-12 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20044, current rewards: -568.09869, mean: -1.38561
[32m[0907 04-59-23 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20111, current rewards: -629.20570, mean: -1.36784
[32m[0907 04-59-33 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20113, current rewards: -709.39650, mean: -1.39097
[32m[0907 04-59-43 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20079, current rewards: -789.89083, mean: -1.41052
[32m[0907 04-59-53 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20137, current rewards: -854.32866, mean: -1.40054
[32m[0907 05-00-02 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.20024, current rewards: -936.35996, mean: -1.41873
[32m[0907 05-00-12 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19981, current rewards: -1019.88301, mean: -1.43645
[32m[0907 05-00-22 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19915, current rewards: -1099.96094, mean: -1.44732
[32m[0907 05-00-31 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19862, current rewards: -1147.93470, mean: -1.41720
[32m[0907 05-00-40 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19776, current rewards: -1185.87909, mean: -1.37893
[32m[0907 05-00-50 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19713, current rewards: -1220.70737, mean: -1.34144
[32m[0907 05-00-59 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19703, current rewards: -1270.88192, mean: -1.32384
[32m[0907 05-01-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19685, current rewards: -1314.73799, mean: -1.30172
[32m[0907 05-01-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19595, current rewards: -1354.86579, mean: -1.27818
[32m[0907 05-01-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19513, current rewards: -1350.97565, mean: -1.21710
[32m[0907 05-01-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19438, current rewards: -1347.09541, mean: -1.16129
[32m[0907 05-01-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19370, current rewards: -1343.21466, mean: -1.11009
[32m[0907 05-01-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19339, current rewards: -1340.07772, mean: -1.06355
[32m[0907 05-02-05 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19421, current rewards: -1362.49047, mean: -1.04007
[32m[0907 05-02-16 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19499, current rewards: -1386.34760, mean: -1.01937
[32m[0907 05-02-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19621, current rewards: -1392.80363, mean: -0.98780
[32m[0907 05-02-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.19654, current rewards: -1419.03408, mean: -0.97194
[32m[0907 05-02-48 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.19703, current rewards: -1435.65190, mean: -0.95076
[32m[0907 05-02-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.19719, current rewards: -1464.55807, mean: -0.93882
[32m[0907 05-03-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.19725, current rewards: -1519.43172, mean: -0.94375
[32m[0907 05-03-20 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.19820, current rewards: -1555.96793, mean: -0.93733
[32m[0907 05-03-31 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.19901, current rewards: -1600.65634, mean: -0.93606
[32m[0907 05-03-41 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.19914, current rewards: -1655.74114, mean: -0.94076
[32m[0907 05-03-52 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.19961, current rewards: -1695.33087, mean: -0.93665
[32m[0907 05-04-03 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.20050, current rewards: -1716.85212, mean: -0.92304
[32m[0907 05-04-16 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.20156, current rewards: -1743.84897, mean: -0.91301
[32m[0907 05-04-26 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.20180, current rewards: -1793.11087, mean: -0.91485
[32m[0907 05-04-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.20163, current rewards: -1853.42701, mean: -0.92210
[32m[0907 05-04-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.20179, current rewards: -1896.42175, mean: -0.92059
[32m[0907 05-04-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.20136, current rewards: -1891.57362, mean: -0.89648
[32m[0907 05-05-05 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.20095, current rewards: -1885.92997, mean: -0.87312
[32m[0907 05-05-14 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.20056, current rewards: -1879.93730, mean: -0.85065
[32m[0907 05-05-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.20012, current rewards: -1873.94516, mean: -0.82918
[32m[0907 05-05-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.19965, current rewards: -1867.94997, mean: -0.80864
[32m[0907 05-05-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.19920, current rewards: -1861.95661, mean: -0.78896
[32m[0907 05-05-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.19876, current rewards: -1855.97740, mean: -0.77012
[32m[0907 05-05-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.19833, current rewards: -1849.99458, mean: -0.75203
[32m[0907 05-06-06 @Agent.py:117][0m Average action selection time: 0.1980
[32m[0907 05-06-06 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-06-06 @MBExp.py:227][0m Rewards obtained: [-1845.2094647121103], Lows: [983], Highs: [97], Total time: 45477.469324999984
[32m[0907 05-09-32 @MBExp.py:144][0m ####################################################################
[32m[0907 05-09-32 @MBExp.py:145][0m Starting training iteration 100.
[32m[0907 05-09-34 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18845, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-09-44 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19444, current rewards: -91.92412, mean: -1.53207
[32m[0907 05-09-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19660, current rewards: -172.10690, mean: -1.56461
[32m[0907 05-10-04 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19744, current rewards: -258.10516, mean: -1.61316
[32m[0907 05-10-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19730, current rewards: -348.35680, mean: -1.65884
[32m[0907 05-10-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19681, current rewards: -432.30971, mean: -1.66273
[32m[0907 05-10-33 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19647, current rewards: -515.74936, mean: -1.66371
[32m[0907 05-10-43 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19616, current rewards: -603.32212, mean: -1.67589
[32m[0907 05-10-52 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19555, current rewards: -691.99327, mean: -1.68779
[32m[0907 05-11-02 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19467, current rewards: -779.95581, mean: -1.69556
[32m[0907 05-11-11 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.19372, current rewards: -855.08926, mean: -1.67665
[32m[0907 05-11-20 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.19282, current rewards: -939.36296, mean: -1.67743
[32m[0907 05-11-30 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.19221, current rewards: -1018.63794, mean: -1.66990
[32m[0907 05-11-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.19201, current rewards: -1086.54749, mean: -1.64628
[32m[0907 05-11-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.19176, current rewards: -1179.01843, mean: -1.66059
[32m[0907 05-11-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.19082, current rewards: -1279.01843, mean: -1.68292
[32m[0907 05-12-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19002, current rewards: -1379.01843, mean: -1.70249
[32m[0907 05-12-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18933, current rewards: -1479.01843, mean: -1.71979
[32m[0907 05-12-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18871, current rewards: -1579.01843, mean: -1.73519
[32m[0907 05-12-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18816, current rewards: -1679.01843, mean: -1.74898
[32m[0907 05-12-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18766, current rewards: -1779.01843, mean: -1.76140
[32m[0907 05-12-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18721, current rewards: -1879.01843, mean: -1.77266
[32m[0907 05-13-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18678, current rewards: -1979.01843, mean: -1.78290
[32m[0907 05-13-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18641, current rewards: -2079.01843, mean: -1.79226
[32m[0907 05-13-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18604, current rewards: -2179.01843, mean: -1.80084
[32m[0907 05-13-26 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18570, current rewards: -2279.01843, mean: -1.80874
[32m[0907 05-13-35 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18540, current rewards: -2379.01843, mean: -1.81604
[32m[0907 05-13-44 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18510, current rewards: -2479.01843, mean: -1.82281
[32m[0907 05-13-53 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18484, current rewards: -2579.01843, mean: -1.82909
[32m[0907 05-14-02 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18462, current rewards: -2679.01843, mean: -1.83494
[32m[0907 05-14-11 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18443, current rewards: -2779.01843, mean: -1.84041
[32m[0907 05-14-20 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18440, current rewards: -2879.01843, mean: -1.84552
[32m[0907 05-14-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18457, current rewards: -2979.01843, mean: -1.85032
[32m[0907 05-14-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18468, current rewards: -3079.01843, mean: -1.85483
[32m[0907 05-14-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18482, current rewards: -3179.01843, mean: -1.85908
[32m[0907 05-14-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18494, current rewards: -3279.01843, mean: -1.86308
[32m[0907 05-15-07 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18505, current rewards: -3379.01843, mean: -1.86686
[32m[0907 05-15-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18514, current rewards: -3479.01843, mean: -1.87044
[32m[0907 05-15-26 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18526, current rewards: -3579.01843, mean: -1.87383
[32m[0907 05-15-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18536, current rewards: -3679.01843, mean: -1.87705
[32m[0907 05-15-45 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18544, current rewards: -3779.01843, mean: -1.88011
[32m[0907 05-15-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18542, current rewards: -3879.01843, mean: -1.88302
[32m[0907 05-16-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18539, current rewards: -3979.01843, mean: -1.88579
[32m[0907 05-16-13 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18536, current rewards: -4079.01843, mean: -1.88843
[32m[0907 05-16-22 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18533, current rewards: -4179.01843, mean: -1.89096
[32m[0907 05-16-31 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18517, current rewards: -4279.01843, mean: -1.89337
[32m[0907 05-16-40 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18502, current rewards: -4379.01843, mean: -1.89568
[32m[0907 05-16-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18486, current rewards: -4479.01843, mean: -1.89789
[32m[0907 05-16-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18471, current rewards: -4579.01843, mean: -1.90001
[32m[0907 05-17-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18458, current rewards: -4679.01843, mean: -1.90204
[32m[0907 05-17-14 @Agent.py:117][0m Average action selection time: 0.1845
[32m[0907 05-17-14 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-17-14 @MBExp.py:227][0m Rewards obtained: [-4759.0184262367875], Lows: [2389], Highs: [14], Total time: 45939.510554999986
[32m[0907 05-20-44 @MBExp.py:144][0m ####################################################################
[32m[0907 05-20-44 @MBExp.py:145][0m Starting training iteration 101.
[32m[0907 05-20-46 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18982, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-20-56 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21401, current rewards: -107.00000, mean: -1.78333
[32m[0907 05-21-07 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.21277, current rewards: -204.32139, mean: -1.85747
[32m[0907 05-21-17 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.20878, current rewards: -304.32139, mean: -1.90201
[32m[0907 05-21-27 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.20736, current rewards: -404.32139, mean: -1.92534
[32m[0907 05-21-38 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.20765, current rewards: -504.32139, mean: -1.93970
[32m[0907 05-21-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.20652, current rewards: -604.32139, mean: -1.94942
[32m[0907 05-21-58 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.20520, current rewards: -704.32139, mean: -1.95645
[32m[0907 05-22-08 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.20544, current rewards: -804.32139, mean: -1.96176
[32m[0907 05-22-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.20736, current rewards: -904.32139, mean: -1.96592
[32m[0907 05-22-30 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.20897, current rewards: -1004.32139, mean: -1.96926
[32m[0907 05-22-40 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.20753, current rewards: -1100.01495, mean: -1.96431
[32m[0907 05-22-49 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.20512, current rewards: -1191.30117, mean: -1.95295
[32m[0907 05-22-58 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.20304, current rewards: -1278.06029, mean: -1.93645
[32m[0907 05-23-07 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.20125, current rewards: -1370.90377, mean: -1.93085
[32m[0907 05-23-16 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.20050, current rewards: -1465.85644, mean: -1.92876
[32m[0907 05-23-25 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.19930, current rewards: -1558.67749, mean: -1.92429
[32m[0907 05-23-34 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.19813, current rewards: -1640.49871, mean: -1.90756
[32m[0907 05-23-43 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.19706, current rewards: -1722.45735, mean: -1.89281
[32m[0907 05-23-52 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.19609, current rewards: -1804.74481, mean: -1.87994
[32m[0907 05-24-01 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.19519, current rewards: -1890.00777, mean: -1.87129
[32m[0907 05-24-10 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.19441, current rewards: -1975.29619, mean: -1.86349
[32m[0907 05-24-19 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.19371, current rewards: -2060.53442, mean: -1.85634
[32m[0907 05-24-28 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.19304, current rewards: -2145.82599, mean: -1.84985
[32m[0907 05-24-37 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.19241, current rewards: -2230.99009, mean: -1.84379
[32m[0907 05-24-46 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.19184, current rewards: -2313.94033, mean: -1.83646
[32m[0907 05-24-55 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.19131, current rewards: -2393.38880, mean: -1.82701
[32m[0907 05-25-03 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.19083, current rewards: -2493.38880, mean: -1.83337
[32m[0907 05-25-12 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.19037, current rewards: -2593.38880, mean: -1.83928
[32m[0907 05-25-21 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18996, current rewards: -2693.38880, mean: -1.84479
[32m[0907 05-25-30 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18963, current rewards: -2793.38880, mean: -1.84993
[32m[0907 05-25-40 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18946, current rewards: -2893.38880, mean: -1.85474
[32m[0907 05-25-49 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18930, current rewards: -2993.38880, mean: -1.85925
[32m[0907 05-25-58 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18920, current rewards: -3093.38880, mean: -1.86349
[32m[0907 05-26-08 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18923, current rewards: -3193.38880, mean: -1.86748
[32m[0907 05-26-17 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18922, current rewards: -3293.38880, mean: -1.87124
[32m[0907 05-26-27 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18921, current rewards: -3393.38880, mean: -1.87480
[32m[0907 05-26-36 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18920, current rewards: -3493.38880, mean: -1.87817
[32m[0907 05-26-45 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18918, current rewards: -3593.38880, mean: -1.88136
[32m[0907 05-26-55 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18919, current rewards: -3693.38880, mean: -1.88438
[32m[0907 05-27-04 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18904, current rewards: -3793.38880, mean: -1.88726
[32m[0907 05-27-13 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18892, current rewards: -3893.38880, mean: -1.88999
[32m[0907 05-27-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18879, current rewards: -3993.38880, mean: -1.89260
[32m[0907 05-27-32 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18867, current rewards: -4093.38880, mean: -1.89509
[32m[0907 05-27-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18855, current rewards: -4193.38880, mean: -1.89746
[32m[0907 05-27-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18832, current rewards: -4293.38880, mean: -1.89973
[32m[0907 05-27-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18811, current rewards: -4393.38880, mean: -1.90190
[32m[0907 05-28-08 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18791, current rewards: -4493.38880, mean: -1.90398
[32m[0907 05-28-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18770, current rewards: -4593.38880, mean: -1.90597
[32m[0907 05-28-25 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18750, current rewards: -4693.38880, mean: -1.90788
[32m[0907 05-28-33 @Agent.py:117][0m Average action selection time: 0.1874
[32m[0907 05-28-33 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-28-33 @MBExp.py:227][0m Rewards obtained: [-4773.388802195771], Lows: [2390], Highs: [13], Total time: 46408.757754999984
[32m[0907 05-32-04 @MBExp.py:144][0m ####################################################################
[32m[0907 05-32-04 @MBExp.py:145][0m Starting training iteration 102.
[32m[0907 05-32-06 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19596, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-32-16 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19078, current rewards: -107.84869, mean: -1.79748
[32m[0907 05-32-25 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19002, current rewards: -207.84869, mean: -1.88953
[32m[0907 05-32-35 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18956, current rewards: -307.84869, mean: -1.92405
[32m[0907 05-32-44 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18929, current rewards: -407.84869, mean: -1.94214
[32m[0907 05-32-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18927, current rewards: -507.84869, mean: -1.95326
[32m[0907 05-33-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18879, current rewards: -607.84869, mean: -1.96080
[32m[0907 05-33-12 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18808, current rewards: -707.84869, mean: -1.96625
[32m[0907 05-33-21 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18757, current rewards: -807.84869, mean: -1.97036
[32m[0907 05-33-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18716, current rewards: -907.84869, mean: -1.97358
[32m[0907 05-33-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18668, current rewards: -1007.84869, mean: -1.97617
[32m[0907 05-33-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18589, current rewards: -1107.84869, mean: -1.97830
[32m[0907 05-33-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18525, current rewards: -1207.84869, mean: -1.98008
[32m[0907 05-34-06 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18470, current rewards: -1307.84869, mean: -1.98159
[32m[0907 05-34-15 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18421, current rewards: -1407.84869, mean: -1.98289
[32m[0907 05-34-24 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18381, current rewards: -1507.84869, mean: -1.98401
[32m[0907 05-34-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18346, current rewards: -1607.84869, mean: -1.98500
[32m[0907 05-34-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18313, current rewards: -1707.84869, mean: -1.98587
[32m[0907 05-34-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18285, current rewards: -1807.84869, mean: -1.98665
[32m[0907 05-35-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18261, current rewards: -1907.84869, mean: -1.98734
[32m[0907 05-35-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18239, current rewards: -2007.84869, mean: -1.98797
[32m[0907 05-35-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18218, current rewards: -2107.84869, mean: -1.98854
[32m[0907 05-35-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18201, current rewards: -2207.84869, mean: -1.98905
[32m[0907 05-35-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18185, current rewards: -2307.84869, mean: -1.98952
[32m[0907 05-35-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18172, current rewards: -2407.84869, mean: -1.98996
[32m[0907 05-35-53 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18154, current rewards: -2507.84869, mean: -1.99036
[32m[0907 05-36-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18140, current rewards: -2607.84869, mean: -1.99072
[32m[0907 05-36-11 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18129, current rewards: -2707.84869, mean: -1.99107
[32m[0907 05-36-20 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18117, current rewards: -2807.84869, mean: -1.99138
[32m[0907 05-36-29 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18106, current rewards: -2907.84869, mean: -1.99168
[32m[0907 05-36-38 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18102, current rewards: -3007.84869, mean: -1.99195
[32m[0907 05-36-47 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18111, current rewards: -3107.84869, mean: -1.99221
[32m[0907 05-36-57 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18120, current rewards: -3207.84869, mean: -1.99245
[32m[0907 05-37-06 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18128, current rewards: -3307.84869, mean: -1.99268
[32m[0907 05-37-15 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18137, current rewards: -3407.84869, mean: -1.99289
[32m[0907 05-37-24 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18162, current rewards: -3507.84869, mean: -1.99310
[32m[0907 05-37-34 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18182, current rewards: -3607.84869, mean: -1.99329
[32m[0907 05-37-43 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18203, current rewards: -3707.84869, mean: -1.99347
[32m[0907 05-37-53 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18219, current rewards: -3807.84869, mean: -1.99364
[32m[0907 05-38-02 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18237, current rewards: -3907.84869, mean: -1.99380
[32m[0907 05-38-12 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18244, current rewards: -4007.84869, mean: -1.99395
[32m[0907 05-38-21 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18250, current rewards: -4107.84869, mean: -1.99410
[32m[0907 05-38-30 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18254, current rewards: -4207.84869, mean: -1.99424
[32m[0907 05-38-39 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18257, current rewards: -4307.84869, mean: -1.99437
[32m[0907 05-38-49 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18261, current rewards: -4407.84869, mean: -1.99450
[32m[0907 05-38-57 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18250, current rewards: -4507.84869, mean: -1.99462
[32m[0907 05-39-06 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18241, current rewards: -4607.84869, mean: -1.99474
[32m[0907 05-39-15 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18234, current rewards: -4707.84869, mean: -1.99485
[32m[0907 05-39-24 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18226, current rewards: -4807.84869, mean: -1.99496
[32m[0907 05-39-33 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18217, current rewards: -4907.84869, mean: -1.99506
[32m[0907 05-39-40 @Agent.py:117][0m Average action selection time: 0.1821
[32m[0907 05-39-40 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-39-41 @MBExp.py:227][0m Rewards obtained: [-4987.848687222154], Lows: [2489], Highs: [10], Total time: 46864.904011999985
[32m[0907 05-43-15 @MBExp.py:144][0m ####################################################################
[32m[0907 05-43-15 @MBExp.py:145][0m Starting training iteration 103.
[32m[0907 05-43-17 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18913, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-43-26 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18924, current rewards: -107.92217, mean: -1.79870
[32m[0907 05-43-36 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18896, current rewards: -207.92217, mean: -1.89020
[32m[0907 05-43-45 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18914, current rewards: -307.92217, mean: -1.92451
[32m[0907 05-43-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18927, current rewards: -407.92217, mean: -1.94249
[32m[0907 05-44-04 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18915, current rewards: -507.92217, mean: -1.95355
[32m[0907 05-44-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18853, current rewards: -607.92217, mean: -1.96104
[32m[0907 05-44-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18792, current rewards: -707.92217, mean: -1.96645
[32m[0907 05-44-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18746, current rewards: -807.92217, mean: -1.97054
[32m[0907 05-44-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18710, current rewards: -907.92217, mean: -1.97374
[32m[0907 05-44-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18662, current rewards: -1007.92217, mean: -1.97632
[32m[0907 05-44-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18585, current rewards: -1107.92217, mean: -1.97843
[32m[0907 05-45-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18524, current rewards: -1207.92217, mean: -1.98020
[32m[0907 05-45-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18474, current rewards: -1307.92217, mean: -1.98170
[32m[0907 05-45-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18430, current rewards: -1407.92217, mean: -1.98299
[32m[0907 05-45-35 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18389, current rewards: -1507.92217, mean: -1.98411
[32m[0907 05-45-44 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18355, current rewards: -1607.92217, mean: -1.98509
[32m[0907 05-45-53 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18327, current rewards: -1707.92217, mean: -1.98596
[32m[0907 05-46-02 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18301, current rewards: -1807.92217, mean: -1.98673
[32m[0907 05-46-11 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18278, current rewards: -1907.92217, mean: -1.98742
[32m[0907 05-46-20 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18254, current rewards: -2007.92217, mean: -1.98804
[32m[0907 05-46-29 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18232, current rewards: -2107.92217, mean: -1.98861
[32m[0907 05-46-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18214, current rewards: -2207.92217, mean: -1.98912
[32m[0907 05-46-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18199, current rewards: -2307.92217, mean: -1.98959
[32m[0907 05-46-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18184, current rewards: -2407.92217, mean: -1.99002
[32m[0907 05-47-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18170, current rewards: -2507.92217, mean: -1.99041
[32m[0907 05-47-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18158, current rewards: -2607.92217, mean: -1.99078
[32m[0907 05-47-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18146, current rewards: -2707.92217, mean: -1.99112
[32m[0907 05-47-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18135, current rewards: -2807.92217, mean: -1.99143
[32m[0907 05-47-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18126, current rewards: -2907.92217, mean: -1.99173
[32m[0907 05-47-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18126, current rewards: -3007.92217, mean: -1.99200
[32m[0907 05-47-58 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18136, current rewards: -3107.92217, mean: -1.99226
[32m[0907 05-48-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18146, current rewards: -3207.92217, mean: -1.99250
[32m[0907 05-48-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18155, current rewards: -3307.92217, mean: -1.99272
[32m[0907 05-48-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18161, current rewards: -3407.92217, mean: -1.99294
[32m[0907 05-48-35 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18182, current rewards: -3507.92217, mean: -1.99314
[32m[0907 05-48-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18204, current rewards: -3607.92217, mean: -1.99333
[32m[0907 05-48-54 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18223, current rewards: -3707.92217, mean: -1.99351
[32m[0907 05-49-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18237, current rewards: -3807.92217, mean: -1.99368
[32m[0907 05-49-13 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18252, current rewards: -3907.92217, mean: -1.99384
[32m[0907 05-49-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18262, current rewards: -4007.92217, mean: -1.99399
[32m[0907 05-49-32 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18265, current rewards: -4107.92217, mean: -1.99414
[32m[0907 05-49-41 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18268, current rewards: -4207.92217, mean: -1.99428
[32m[0907 05-49-50 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18272, current rewards: -4307.92217, mean: -1.99441
[32m[0907 05-49-59 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18274, current rewards: -4407.92217, mean: -1.99453
[32m[0907 05-50-09 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18270, current rewards: -4507.92217, mean: -1.99466
[32m[0907 05-50-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18260, current rewards: -4607.92217, mean: -1.99477
[32m[0907 05-50-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18250, current rewards: -4707.92217, mean: -1.99488
[32m[0907 05-50-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18241, current rewards: -4807.92217, mean: -1.99499
[32m[0907 05-50-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18233, current rewards: -4907.92217, mean: -1.99509
[32m[0907 05-50-51 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0907 05-50-51 @Agent.py:118][0m Rollout length: 2510
[32m[0907 05-50-52 @MBExp.py:227][0m Rewards obtained: [-4987.922165223916], Lows: [2489], Highs: [10], Total time: 47321.39826099999
[32m[0907 05-54-27 @MBExp.py:144][0m ####################################################################
[32m[0907 05-54-27 @MBExp.py:145][0m Starting training iteration 104.
[32m[0907 05-54-29 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20685, current rewards: -10.00000, mean: -1.00000
[32m[0907 05-54-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.21047, current rewards: -70.28917, mean: -1.17149
[32m[0907 05-54-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.20274, current rewards: -125.53302, mean: -1.14121
[32m[0907 05-54-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19925, current rewards: -176.85664, mean: -1.10535
[32m[0907 05-55-09 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19731, current rewards: -228.88470, mean: -1.08993
[32m[0907 05-55-18 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.19560, current rewards: -283.26392, mean: -1.08948
[32m[0907 05-55-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.19377, current rewards: -344.14747, mean: -1.11015
[32m[0907 05-55-37 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.19245, current rewards: -393.02461, mean: -1.09174
[32m[0907 05-55-46 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.19142, current rewards: -443.02461, mean: -1.08055
[32m[0907 05-55-55 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.19055, current rewards: -493.02461, mean: -1.07179
[32m[0907 05-56-04 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18940, current rewards: -543.02461, mean: -1.06475
[32m[0907 05-56-13 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18844, current rewards: -593.02461, mean: -1.05897
[32m[0907 05-56-22 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18763, current rewards: -643.02461, mean: -1.05414
[32m[0907 05-56-31 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18693, current rewards: -693.02461, mean: -1.05004
[32m[0907 05-56-40 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18633, current rewards: -743.02461, mean: -1.04651
[32m[0907 05-56-49 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18580, current rewards: -790.88544, mean: -1.04064
[32m[0907 05-56-59 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18745, current rewards: -797.20162, mean: -0.98420
[32m[0907 05-57-08 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18692, current rewards: -835.56249, mean: -0.97158
[32m[0907 05-57-17 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18645, current rewards: -873.91665, mean: -0.96035
[32m[0907 05-57-26 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18601, current rewards: -912.28232, mean: -0.95029
[32m[0907 05-57-35 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18565, current rewards: -950.65943, mean: -0.94125
[32m[0907 05-57-44 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18534, current rewards: -978.47742, mean: -0.92309
[32m[0907 05-57-53 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18502, current rewards: -1015.75137, mean: -0.91509
[32m[0907 05-58-02 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18474, current rewards: -1054.10820, mean: -0.90871
[32m[0907 05-58-11 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18446, current rewards: -1104.10820, mean: -0.91249
[32m[0907 05-58-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18421, current rewards: -1154.10820, mean: -0.91596
[32m[0907 05-58-28 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18399, current rewards: -1204.10820, mean: -0.91917
[32m[0907 05-58-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18448, current rewards: -1264.10247, mean: -0.92949
[32m[0907 05-58-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18435, current rewards: -1336.41617, mean: -0.94781
[32m[0907 05-58-57 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18446, current rewards: -1382.81149, mean: -0.94713
[32m[0907 05-59-07 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18504, current rewards: -1429.43525, mean: -0.94665
[32m[0907 05-59-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18547, current rewards: -1499.18918, mean: -0.96102
[32m[0907 05-59-27 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18613, current rewards: -1548.86798, mean: -0.96203
[32m[0907 05-59-39 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18750, current rewards: -1586.09520, mean: -0.95548
[32m[0907 05-59-50 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18828, current rewards: -1637.85264, mean: -0.95781
[32m[0907 05-59-59 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18830, current rewards: -1697.79646, mean: -0.96466
[32m[0907 06-00-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18832, current rewards: -1797.79646, mean: -0.99326
[32m[0907 06-00-18 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18834, current rewards: -1897.79646, mean: -1.02032
[32m[0907 06-00-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18837, current rewards: -1997.79646, mean: -1.04597
[32m[0907 06-00-37 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18831, current rewards: -2097.79646, mean: -1.07030
[32m[0907 06-00-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18822, current rewards: -2197.79646, mean: -1.09343
[32m[0907 06-00-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18814, current rewards: -2297.79646, mean: -1.11544
[32m[0907 06-01-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18804, current rewards: -2397.79646, mean: -1.13640
[32m[0907 06-01-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18795, current rewards: -2497.79646, mean: -1.15639
[32m[0907 06-01-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18779, current rewards: -2597.79646, mean: -1.17547
[32m[0907 06-01-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18757, current rewards: -2697.79646, mean: -1.19372
[32m[0907 06-01-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18737, current rewards: -2797.79646, mean: -1.21117
[32m[0907 06-01-49 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18717, current rewards: -2897.79646, mean: -1.22788
[32m[0907 06-01-58 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18698, current rewards: -2997.79646, mean: -1.24390
[32m[0907 06-02-07 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18680, current rewards: -3097.79646, mean: -1.25927
[32m[0907 06-02-14 @Agent.py:117][0m Average action selection time: 0.1867
[32m[0907 06-02-14 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-02-15 @MBExp.py:227][0m Rewards obtained: [-3177.79645639788], Lows: [923], Highs: [1358], Total time: 47788.934212999986
[32m[0907 06-05-54 @MBExp.py:144][0m ####################################################################
[32m[0907 06-05-54 @MBExp.py:145][0m Starting training iteration 105.
[32m[0907 06-05-55 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18965, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-06-05 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18989, current rewards: -69.00443, mean: -1.15007
[32m[0907 06-06-14 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18979, current rewards: -119.00443, mean: -1.08186
[32m[0907 06-06-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18931, current rewards: -169.00443, mean: -1.05628
[32m[0907 06-06-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18831, current rewards: -219.00443, mean: -1.04288
[32m[0907 06-06-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18747, current rewards: -269.00443, mean: -1.03463
[32m[0907 06-06-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18688, current rewards: -319.00443, mean: -1.02905
[32m[0907 06-07-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18649, current rewards: -369.00443, mean: -1.02501
[32m[0907 06-07-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18573, current rewards: -419.00443, mean: -1.02196
[32m[0907 06-07-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18494, current rewards: -469.00443, mean: -1.01957
[32m[0907 06-07-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18434, current rewards: -519.00443, mean: -1.01766
[32m[0907 06-07-37 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18382, current rewards: -569.00443, mean: -1.01608
[32m[0907 06-07-46 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18334, current rewards: -619.00443, mean: -1.01476
[32m[0907 06-07-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18288, current rewards: -669.00443, mean: -1.01364
[32m[0907 06-08-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18255, current rewards: -719.00443, mean: -1.01268
[32m[0907 06-08-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18228, current rewards: -769.00443, mean: -1.01185
[32m[0907 06-08-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18205, current rewards: -819.00443, mean: -1.01112
[32m[0907 06-08-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18184, current rewards: -869.00443, mean: -1.01047
[32m[0907 06-08-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18165, current rewards: -919.00443, mean: -1.00989
[32m[0907 06-08-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18147, current rewards: -969.00443, mean: -1.00938
[32m[0907 06-08-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18134, current rewards: -1019.00443, mean: -1.00892
[32m[0907 06-09-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18120, current rewards: -1069.00443, mean: -1.00849
[32m[0907 06-09-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18107, current rewards: -1119.00443, mean: -1.00811
[32m[0907 06-09-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18095, current rewards: -1169.00443, mean: -1.00776
[32m[0907 06-09-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18084, current rewards: -1219.00443, mean: -1.00744
[32m[0907 06-09-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18075, current rewards: -1269.00443, mean: -1.00715
[32m[0907 06-09-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18069, current rewards: -1319.00443, mean: -1.00687
[32m[0907 06-10-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18060, current rewards: -1369.00443, mean: -1.00662
[32m[0907 06-10-08 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18053, current rewards: -1419.00443, mean: -1.00639
[32m[0907 06-10-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18062, current rewards: -1469.00443, mean: -1.00617
[32m[0907 06-10-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18076, current rewards: -1519.00443, mean: -1.00596
[32m[0907 06-10-36 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18087, current rewards: -1569.00443, mean: -1.00577
[32m[0907 06-10-45 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18098, current rewards: -1619.00443, mean: -1.00559
[32m[0907 06-10-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18120, current rewards: -1669.00443, mean: -1.00542
[32m[0907 06-11-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18145, current rewards: -1719.00443, mean: -1.00527
[32m[0907 06-11-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18166, current rewards: -1769.00443, mean: -1.00512
[32m[0907 06-11-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18185, current rewards: -1819.00443, mean: -1.00497
[32m[0907 06-11-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18205, current rewards: -1869.00443, mean: -1.00484
[32m[0907 06-11-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18223, current rewards: -1919.00443, mean: -1.00471
[32m[0907 06-11-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18238, current rewards: -1935.90717, mean: -0.98771
[32m[0907 06-12-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18245, current rewards: -1932.49514, mean: -0.96144
[32m[0907 06-12-10 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18249, current rewards: -1928.96572, mean: -0.93639
[32m[0907 06-12-19 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18253, current rewards: -1925.43630, mean: -0.91253
[32m[0907 06-12-28 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18256, current rewards: -1921.90688, mean: -0.88977
[32m[0907 06-12-37 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18249, current rewards: -1918.37746, mean: -0.86804
[32m[0907 06-12-46 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18238, current rewards: -1914.84804, mean: -0.84728
[32m[0907 06-12-55 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18228, current rewards: -1911.31862, mean: -0.82741
[32m[0907 06-13-04 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18221, current rewards: -1907.78920, mean: -0.80839
[32m[0907 06-13-13 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18212, current rewards: -1904.11363, mean: -0.79009
[32m[0907 06-13-22 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18204, current rewards: -1899.41722, mean: -0.77212
[32m[0907 06-13-29 @Agent.py:117][0m Average action selection time: 0.1820
[32m[0907 06-13-29 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-13-29 @MBExp.py:227][0m Rewards obtained: [-1908.7872350994155], Lows: [13], Highs: [1925], Total time: 48244.766871999986
[32m[0907 06-17-09 @MBExp.py:144][0m ####################################################################
[32m[0907 06-17-09 @MBExp.py:145][0m Starting training iteration 106.
[32m[0907 06-17-11 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18915, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-17-21 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19118, current rewards: -104.75493, mean: -1.74592
[32m[0907 06-17-30 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19007, current rewards: -204.75493, mean: -1.86141
[32m[0907 06-17-40 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18974, current rewards: -304.75493, mean: -1.90472
[32m[0907 06-17-49 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18845, current rewards: -404.75493, mean: -1.92740
[32m[0907 06-17-58 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18770, current rewards: -504.75493, mean: -1.94137
[32m[0907 06-18-08 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18723, current rewards: -604.75493, mean: -1.95082
[32m[0907 06-18-17 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18678, current rewards: -704.75493, mean: -1.95765
[32m[0907 06-18-26 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18576, current rewards: -804.75493, mean: -1.96282
[32m[0907 06-18-35 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18497, current rewards: -904.75493, mean: -1.96686
[32m[0907 06-18-44 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18437, current rewards: -1004.75493, mean: -1.97011
[32m[0907 06-18-52 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18383, current rewards: -1104.75493, mean: -1.97278
[32m[0907 06-19-01 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18338, current rewards: -1204.75493, mean: -1.97501
[32m[0907 06-19-10 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18300, current rewards: -1304.75493, mean: -1.97690
[32m[0907 06-19-19 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18265, current rewards: -1404.75493, mean: -1.97853
[32m[0907 06-19-28 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18238, current rewards: -1504.75493, mean: -1.97994
[32m[0907 06-19-37 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18214, current rewards: -1604.75493, mean: -1.98118
[32m[0907 06-19-46 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18192, current rewards: -1704.75493, mean: -1.98227
[32m[0907 06-19-55 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18169, current rewards: -1804.75493, mean: -1.98325
[32m[0907 06-20-04 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18151, current rewards: -1904.75493, mean: -1.98412
[32m[0907 06-20-13 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18134, current rewards: -2004.75493, mean: -1.98491
[32m[0907 06-20-22 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18121, current rewards: -2104.75493, mean: -1.98562
[32m[0907 06-20-31 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18107, current rewards: -2204.75493, mean: -1.98627
[32m[0907 06-20-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18095, current rewards: -2304.75493, mean: -1.98686
[32m[0907 06-20-49 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18085, current rewards: -2404.75493, mean: -1.98740
[32m[0907 06-20-57 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18077, current rewards: -2504.75493, mean: -1.98790
[32m[0907 06-21-06 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18070, current rewards: -2604.75493, mean: -1.98836
[32m[0907 06-21-15 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18063, current rewards: -2704.75493, mean: -1.98879
[32m[0907 06-21-24 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18055, current rewards: -2804.75493, mean: -1.98919
[32m[0907 06-21-34 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18065, current rewards: -2904.75493, mean: -1.98956
[32m[0907 06-21-43 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18076, current rewards: -3004.75493, mean: -1.98990
[32m[0907 06-21-52 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18086, current rewards: -3104.75493, mean: -1.99023
[32m[0907 06-22-01 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18097, current rewards: -3204.75493, mean: -1.99053
[32m[0907 06-22-11 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18121, current rewards: -3304.75493, mean: -1.99082
[32m[0907 06-22-20 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18146, current rewards: -3404.75493, mean: -1.99108
[32m[0907 06-22-30 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18166, current rewards: -3504.75493, mean: -1.99134
[32m[0907 06-22-39 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18183, current rewards: -3604.75493, mean: -1.99158
[32m[0907 06-22-48 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18199, current rewards: -3704.75493, mean: -1.99180
[32m[0907 06-22-58 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18216, current rewards: -3804.75493, mean: -1.99202
[32m[0907 06-23-07 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18233, current rewards: -3904.75493, mean: -1.99222
[32m[0907 06-23-17 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18242, current rewards: -4004.75493, mean: -1.99242
[32m[0907 06-23-26 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18246, current rewards: -4104.75493, mean: -1.99260
[32m[0907 06-23-35 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18249, current rewards: -4204.75493, mean: -1.99277
[32m[0907 06-23-44 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18253, current rewards: -4304.75493, mean: -1.99294
[32m[0907 06-23-53 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18257, current rewards: -4404.75493, mean: -1.99310
[32m[0907 06-24-03 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18260, current rewards: -4504.75493, mean: -1.99325
[32m[0907 06-24-12 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18264, current rewards: -4604.75493, mean: -1.99340
[32m[0907 06-24-21 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18256, current rewards: -4704.75493, mean: -1.99354
[32m[0907 06-24-30 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18248, current rewards: -4804.75493, mean: -1.99367
[32m[0907 06-24-39 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18240, current rewards: -4904.75493, mean: -1.99380
[32m[0907 06-24-46 @Agent.py:117][0m Average action selection time: 0.1823
[32m[0907 06-24-46 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-24-46 @MBExp.py:227][0m Rewards obtained: [-4984.7549312988], Lows: [2487], Highs: [11], Total time: 48701.47814699999
[32m[0907 06-28-29 @MBExp.py:144][0m ####################################################################
[32m[0907 06-28-29 @MBExp.py:145][0m Starting training iteration 107.
[32m[0907 06-28-30 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18840, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-28-40 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18962, current rewards: -110.00000, mean: -1.83333
[32m[0907 06-28-49 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18985, current rewards: -210.00000, mean: -1.90909
[32m[0907 06-28-59 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18952, current rewards: -310.00000, mean: -1.93750
[32m[0907 06-29-08 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18828, current rewards: -410.00000, mean: -1.95238
[32m[0907 06-29-17 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18745, current rewards: -510.00000, mean: -1.96154
[32m[0907 06-29-27 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18688, current rewards: -610.00000, mean: -1.96774
[32m[0907 06-29-36 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18631, current rewards: -710.00000, mean: -1.97222
[32m[0907 06-29-45 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18540, current rewards: -810.00000, mean: -1.97561
[32m[0907 06-29-54 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18495, current rewards: -910.00000, mean: -1.97826
[32m[0907 06-30-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18438, current rewards: -1008.00000, mean: -1.97647
[32m[0907 06-30-12 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18386, current rewards: -1103.53181, mean: -1.97059
[32m[0907 06-30-21 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18340, current rewards: -1196.81887, mean: -1.96200
[32m[0907 06-30-30 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18305, current rewards: -1292.76172, mean: -1.95873
[32m[0907 06-30-38 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18275, current rewards: -1392.76172, mean: -1.96164
[32m[0907 06-30-47 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18245, current rewards: -1492.76172, mean: -1.96416
[32m[0907 06-30-56 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18222, current rewards: -1592.76172, mean: -1.96637
[32m[0907 06-31-05 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18202, current rewards: -1692.76172, mean: -1.96833
[32m[0907 06-31-14 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18179, current rewards: -1792.76172, mean: -1.97007
[32m[0907 06-31-23 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18163, current rewards: -1892.76172, mean: -1.97163
[32m[0907 06-31-32 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18148, current rewards: -1992.76172, mean: -1.97303
[32m[0907 06-31-41 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18133, current rewards: -2092.76172, mean: -1.97430
[32m[0907 06-31-50 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18121, current rewards: -2192.76172, mean: -1.97546
[32m[0907 06-31-59 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18108, current rewards: -2292.76172, mean: -1.97652
[32m[0907 06-32-08 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18101, current rewards: -2392.76172, mean: -1.97749
[32m[0907 06-32-17 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18092, current rewards: -2492.76172, mean: -1.97838
[32m[0907 06-32-26 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18084, current rewards: -2592.76172, mean: -1.97921
[32m[0907 06-32-35 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18075, current rewards: -2692.76172, mean: -1.97997
[32m[0907 06-32-44 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18065, current rewards: -2792.76172, mean: -1.98068
[32m[0907 06-32-53 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18080, current rewards: -2892.76172, mean: -1.98134
[32m[0907 06-33-02 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18092, current rewards: -2992.76172, mean: -1.98196
[32m[0907 06-33-11 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18102, current rewards: -3092.76172, mean: -1.98254
[32m[0907 06-33-21 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18112, current rewards: -3192.76172, mean: -1.98308
[32m[0907 06-33-30 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18135, current rewards: -3292.76172, mean: -1.98359
[32m[0907 06-33-40 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18162, current rewards: -3392.76172, mean: -1.98407
[32m[0907 06-33-49 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18179, current rewards: -3492.76172, mean: -1.98452
[32m[0907 06-33-58 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18198, current rewards: -3592.76172, mean: -1.98495
[32m[0907 06-34-08 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18216, current rewards: -3692.76172, mean: -1.98536
[32m[0907 06-34-17 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18233, current rewards: -3792.76172, mean: -1.98574
[32m[0907 06-34-27 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18249, current rewards: -3892.76172, mean: -1.98610
[32m[0907 06-34-36 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18265, current rewards: -3992.76172, mean: -1.98645
[32m[0907 06-34-46 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18275, current rewards: -4092.76172, mean: -1.98678
[32m[0907 06-34-55 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18277, current rewards: -4192.76172, mean: -1.98709
[32m[0907 06-35-04 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18280, current rewards: -4292.76172, mean: -1.98739
[32m[0907 06-35-13 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18284, current rewards: -4392.76172, mean: -1.98767
[32m[0907 06-35-22 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18287, current rewards: -4492.76172, mean: -1.98795
[32m[0907 06-35-32 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18289, current rewards: -4592.76172, mean: -1.98821
[32m[0907 06-35-41 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18290, current rewards: -4692.76172, mean: -1.98846
[32m[0907 06-35-50 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18280, current rewards: -4792.76172, mean: -1.98870
[32m[0907 06-35-59 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18270, current rewards: -4892.76172, mean: -1.98893
[32m[0907 06-36-06 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0907 06-36-06 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-36-06 @MBExp.py:227][0m Rewards obtained: [-4972.761722989587], Lows: [2478], Highs: [18], Total time: 49158.92445799999
[32m[0907 06-39-49 @MBExp.py:144][0m ####################################################################
[32m[0907 06-39-49 @MBExp.py:145][0m Starting training iteration 108.
[32m[0907 06-39-51 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19631, current rewards: 0.74851, mean: 0.07485
[32m[0907 06-40-01 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19183, current rewards: -67.56089, mean: -1.12601
[32m[0907 06-40-10 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19273, current rewards: -167.56089, mean: -1.52328
[32m[0907 06-40-20 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19154, current rewards: -254.85991, mean: -1.59287
[32m[0907 06-40-29 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19098, current rewards: -352.70088, mean: -1.67953
[32m[0907 06-40-39 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18982, current rewards: -448.50132, mean: -1.72501
[32m[0907 06-40-48 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18881, current rewards: -548.50132, mean: -1.76936
[32m[0907 06-40-57 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18762, current rewards: -642.11212, mean: -1.78364
[32m[0907 06-41-06 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18646, current rewards: -734.76734, mean: -1.79212
[32m[0907 06-41-15 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18560, current rewards: -834.76734, mean: -1.81471
[32m[0907 06-41-24 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18488, current rewards: -934.76734, mean: -1.83288
[32m[0907 06-41-33 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18434, current rewards: -1034.76734, mean: -1.84780
[32m[0907 06-41-42 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18385, current rewards: -1134.76734, mean: -1.86027
[32m[0907 06-41-50 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18344, current rewards: -1234.76734, mean: -1.87086
[32m[0907 06-41-59 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18307, current rewards: -1334.76734, mean: -1.87995
[32m[0907 06-42-08 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18278, current rewards: -1434.76734, mean: -1.88785
[32m[0907 06-42-17 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18248, current rewards: -1534.76734, mean: -1.89477
[32m[0907 06-42-26 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18222, current rewards: -1634.76734, mean: -1.90089
[32m[0907 06-42-35 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18201, current rewards: -1734.76734, mean: -1.90634
[32m[0907 06-42-44 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18182, current rewards: -1834.76734, mean: -1.91122
[32m[0907 06-42-53 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18165, current rewards: -1934.76734, mean: -1.91561
[32m[0907 06-43-02 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18150, current rewards: -2034.76734, mean: -1.91959
[32m[0907 06-43-11 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18136, current rewards: -2134.76734, mean: -1.92321
[32m[0907 06-43-20 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18123, current rewards: -2234.76734, mean: -1.92652
[32m[0907 06-43-29 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18111, current rewards: -2334.76734, mean: -1.92956
[32m[0907 06-43-38 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18099, current rewards: -2434.76734, mean: -1.93236
[32m[0907 06-43-47 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18088, current rewards: -2534.76734, mean: -1.93494
[32m[0907 06-43-55 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18079, current rewards: -2634.76734, mean: -1.93733
[32m[0907 06-44-04 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18070, current rewards: -2734.76734, mean: -1.93955
[32m[0907 06-44-14 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18077, current rewards: -2834.76734, mean: -1.94162
[32m[0907 06-44-23 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18087, current rewards: -2934.76734, mean: -1.94355
[32m[0907 06-44-32 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18098, current rewards: -3034.76734, mean: -1.94536
[32m[0907 06-44-41 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18106, current rewards: -3134.76734, mean: -1.94706
[32m[0907 06-44-51 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18133, current rewards: -3234.76734, mean: -1.94866
[32m[0907 06-45-00 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18157, current rewards: -3334.76734, mean: -1.95016
[32m[0907 06-45-10 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18175, current rewards: -3434.76734, mean: -1.95157
[32m[0907 06-45-19 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18193, current rewards: -3534.76734, mean: -1.95291
[32m[0907 06-45-28 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18210, current rewards: -3634.76734, mean: -1.95418
[32m[0907 06-45-38 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18227, current rewards: -3734.76734, mean: -1.95538
[32m[0907 06-45-47 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18243, current rewards: -3834.76734, mean: -1.95651
[32m[0907 06-45-57 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18259, current rewards: -3934.76734, mean: -1.95760
[32m[0907 06-46-06 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18275, current rewards: -4034.76734, mean: -1.95862
[32m[0907 06-46-16 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18289, current rewards: -4134.76734, mean: -1.95961
[32m[0907 06-46-25 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18292, current rewards: -4234.76734, mean: -1.96054
[32m[0907 06-46-34 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18295, current rewards: -4334.76734, mean: -1.96143
[32m[0907 06-46-43 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18299, current rewards: -4434.76734, mean: -1.96229
[32m[0907 06-46-53 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: -4534.76734, mean: -1.96310
[32m[0907 06-47-02 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18302, current rewards: -4634.76734, mean: -1.96388
[32m[0907 06-47-11 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18292, current rewards: -4734.76734, mean: -1.96463
[32m[0907 06-47-20 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18284, current rewards: -4834.76734, mean: -1.96535
[32m[0907 06-47-27 @Agent.py:117][0m Average action selection time: 0.1828
[32m[0907 06-47-27 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-47-27 @MBExp.py:227][0m Rewards obtained: [-4914.767343657824], Lows: [2458], Highs: [3], Total time: 49616.699537999986
[32m[0907 06-51-13 @MBExp.py:144][0m ####################################################################
[32m[0907 06-51-13 @MBExp.py:145][0m Starting training iteration 109.
[32m[0907 06-51-15 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19246, current rewards: -10.00000, mean: -1.00000
[32m[0907 06-51-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19029, current rewards: -77.73776, mean: -1.29563
[32m[0907 06-51-34 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19059, current rewards: -145.44340, mean: -1.32221
[32m[0907 06-51-43 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18907, current rewards: -214.22829, mean: -1.33893
[32m[0907 06-51-53 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18801, current rewards: -283.15161, mean: -1.34834
[32m[0907 06-52-02 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18728, current rewards: -350.45737, mean: -1.34791
[32m[0907 06-52-11 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18696, current rewards: -420.40724, mean: -1.35615
[32m[0907 06-52-20 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18635, current rewards: -485.21701, mean: -1.34783
[32m[0907 06-52-29 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18548, current rewards: -546.49739, mean: -1.33292
[32m[0907 06-52-38 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18500, current rewards: -613.07399, mean: -1.33277
[32m[0907 06-52-47 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18485, current rewards: -633.80388, mean: -1.24275
[32m[0907 06-52-56 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18429, current rewards: -629.02327, mean: -1.12326
[32m[0907 06-53-05 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18374, current rewards: -624.24266, mean: -1.02335
[32m[0907 06-53-14 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18333, current rewards: -619.46204, mean: -0.93858
[32m[0907 06-53-23 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18297, current rewards: -614.72647, mean: -0.86581
[32m[0907 06-53-32 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18268, current rewards: -611.84230, mean: -0.80506
[32m[0907 06-53-41 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18242, current rewards: -649.16670, mean: -0.80144
[32m[0907 06-53-50 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18216, current rewards: -699.16670, mean: -0.81298
[32m[0907 06-53-59 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18194, current rewards: -749.16670, mean: -0.82326
[32m[0907 06-54-08 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18174, current rewards: -799.16670, mean: -0.83247
[32m[0907 06-54-17 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18158, current rewards: -849.16670, mean: -0.84076
[32m[0907 06-54-26 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18142, current rewards: -899.16670, mean: -0.84827
[32m[0907 06-54-35 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18126, current rewards: -949.16670, mean: -0.85511
[32m[0907 06-54-43 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18115, current rewards: -999.16670, mean: -0.86135
[32m[0907 06-54-52 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18103, current rewards: -1049.16670, mean: -0.86708
[32m[0907 06-55-01 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18092, current rewards: -1099.16670, mean: -0.87235
[32m[0907 06-55-10 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18080, current rewards: -1149.16670, mean: -0.87723
[32m[0907 06-55-19 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18070, current rewards: -1199.16670, mean: -0.88174
[32m[0907 06-55-28 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18062, current rewards: -1249.16670, mean: -0.88593
[32m[0907 06-55-37 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18074, current rewards: -1299.16670, mean: -0.88984
[32m[0907 06-55-46 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18085, current rewards: -1349.16670, mean: -0.89349
[32m[0907 06-55-56 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18097, current rewards: -1399.16670, mean: -0.89690
[32m[0907 06-56-05 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18112, current rewards: -1449.16670, mean: -0.90010
[32m[0907 06-56-15 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18138, current rewards: -1499.16670, mean: -0.90311
[32m[0907 06-56-24 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18161, current rewards: -1549.16670, mean: -0.90595
[32m[0907 06-56-34 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18185, current rewards: -1599.16670, mean: -0.90862
[32m[0907 06-56-43 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18204, current rewards: -1649.16670, mean: -0.91114
[32m[0907 06-56-52 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18222, current rewards: -1699.16670, mean: -0.91353
[32m[0907 06-57-02 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18241, current rewards: -1749.16670, mean: -0.91579
[32m[0907 06-57-11 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18258, current rewards: -1799.16670, mean: -0.91794
[32m[0907 06-57-21 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18274, current rewards: -1849.16670, mean: -0.91998
[32m[0907 06-57-30 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18289, current rewards: -1899.16670, mean: -0.92193
[32m[0907 06-57-40 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18304, current rewards: -1949.16670, mean: -0.92378
[32m[0907 06-57-49 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18309, current rewards: -1999.16670, mean: -0.92554
[32m[0907 06-57-58 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18312, current rewards: -2049.16670, mean: -0.92722
[32m[0907 06-58-08 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18316, current rewards: -2099.16670, mean: -0.92883
[32m[0907 06-58-17 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18319, current rewards: -2149.16670, mean: -0.93038
[32m[0907 06-58-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18323, current rewards: -2199.16670, mean: -0.93185
[32m[0907 06-58-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18314, current rewards: -2249.16670, mean: -0.93326
[32m[0907 06-58-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18304, current rewards: -2299.16670, mean: -0.93462
[32m[0907 06-58-51 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0907 06-58-51 @Agent.py:118][0m Rollout length: 2510
[32m[0907 06-58-51 @MBExp.py:227][0m Rewards obtained: [-2339.166703367547], Lows: [187], Highs: [1996], Total time: 50074.970250999984
[32m[0907 07-02-39 @MBExp.py:144][0m ####################################################################
[32m[0907 07-02-39 @MBExp.py:145][0m Starting training iteration 110.
[32m[0907 07-02-40 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18812, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-02-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18952, current rewards: -60.00000, mean: -1.00000
[32m[0907 07-02-59 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18936, current rewards: -110.00000, mean: -1.00000
[32m[0907 07-03-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18784, current rewards: -160.00000, mean: -1.00000
[32m[0907 07-03-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18690, current rewards: -210.00000, mean: -1.00000
[32m[0907 07-03-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18637, current rewards: -260.00000, mean: -1.00000
[32m[0907 07-03-36 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18602, current rewards: -298.01603, mean: -0.96134
[32m[0907 07-03-45 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18570, current rewards: -348.01603, mean: -0.96671
[32m[0907 07-03-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18548, current rewards: -398.01603, mean: -0.97077
[32m[0907 07-04-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18517, current rewards: -448.01603, mean: -0.97395
[32m[0907 07-04-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18451, current rewards: -498.01603, mean: -0.97650
[32m[0907 07-04-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18395, current rewards: -548.01603, mean: -0.97860
[32m[0907 07-04-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18349, current rewards: -598.01603, mean: -0.98035
[32m[0907 07-04-40 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18310, current rewards: -648.01603, mean: -0.98184
[32m[0907 07-04-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18272, current rewards: -681.12185, mean: -0.95933
[32m[0907 07-04-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18243, current rewards: -729.00641, mean: -0.95922
[32m[0907 07-05-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18217, current rewards: -779.00641, mean: -0.96174
[32m[0907 07-05-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18198, current rewards: -829.00641, mean: -0.96396
[32m[0907 07-05-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18175, current rewards: -879.00641, mean: -0.96594
[32m[0907 07-05-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18158, current rewards: -929.00641, mean: -0.96772
[32m[0907 07-05-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18143, current rewards: -979.00641, mean: -0.96931
[32m[0907 07-05-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18129, current rewards: -1029.00641, mean: -0.97076
[32m[0907 07-06-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18117, current rewards: -1079.00641, mean: -0.97208
[32m[0907 07-06-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18105, current rewards: -1129.00641, mean: -0.97328
[32m[0907 07-06-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18091, current rewards: -1179.00641, mean: -0.97439
[32m[0907 07-06-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18084, current rewards: -1229.00641, mean: -0.97540
[32m[0907 07-06-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18074, current rewards: -1279.00641, mean: -0.97634
[32m[0907 07-06-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18066, current rewards: -1329.00641, mean: -0.97721
[32m[0907 07-06-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18062, current rewards: -1379.00641, mean: -0.97802
[32m[0907 07-07-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18076, current rewards: -1429.00641, mean: -0.97877
[32m[0907 07-07-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18086, current rewards: -1479.00641, mean: -0.97947
[32m[0907 07-07-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18096, current rewards: -1529.00641, mean: -0.98013
[32m[0907 07-07-30 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18106, current rewards: -1579.00641, mean: -0.98075
[32m[0907 07-07-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18115, current rewards: -1629.00641, mean: -0.98133
[32m[0907 07-07-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18124, current rewards: -1679.00641, mean: -0.98188
[32m[0907 07-07-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18135, current rewards: -1729.00641, mean: -0.98239
[32m[0907 07-08-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18159, current rewards: -1779.00641, mean: -0.98288
[32m[0907 07-08-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18181, current rewards: -1829.00641, mean: -0.98334
[32m[0907 07-08-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18200, current rewards: -1879.00641, mean: -0.98377
[32m[0907 07-08-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18217, current rewards: -1892.32593, mean: -0.96547
[32m[0907 07-08-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18235, current rewards: -1889.92526, mean: -0.94026
[32m[0907 07-08-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18250, current rewards: -1896.95671, mean: -0.92085
[32m[0907 07-09-04 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18265, current rewards: -1946.95671, mean: -0.92273
[32m[0907 07-09-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18273, current rewards: -1996.95671, mean: -0.92452
[32m[0907 07-09-23 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18276, current rewards: -2046.95671, mean: -0.92622
[32m[0907 07-09-32 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18278, current rewards: -2096.95671, mean: -0.92786
[32m[0907 07-09-41 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18282, current rewards: -2146.95671, mean: -0.92942
[32m[0907 07-09-51 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18286, current rewards: -2196.95671, mean: -0.93091
[32m[0907 07-10-00 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18284, current rewards: -2246.95671, mean: -0.93235
[32m[0907 07-10-09 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18276, current rewards: -2296.95671, mean: -0.93372
[32m[0907 07-10-16 @Agent.py:117][0m Average action selection time: 0.1827
[32m[0907 07-10-16 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-10-16 @MBExp.py:227][0m Rewards obtained: [-2336.9567057080358], Lows: [0], Highs: [2346], Total time: 50532.597638999985
[32m[0907 07-14-06 @MBExp.py:144][0m ####################################################################
[32m[0907 07-14-06 @MBExp.py:145][0m Starting training iteration 111.
[32m[0907 07-14-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.20748, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-14-17 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19319, current rewards: -55.75012, mean: -0.92917
[32m[0907 07-14-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18958, current rewards: -105.75012, mean: -0.96136
[32m[0907 07-14-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18797, current rewards: -155.75012, mean: -0.97344
[32m[0907 07-14-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18705, current rewards: -189.42599, mean: -0.90203
[32m[0907 07-14-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18649, current rewards: -278.20070, mean: -1.07000
[32m[0907 07-15-03 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18616, current rewards: -378.20070, mean: -1.22000
[32m[0907 07-15-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18586, current rewards: -478.20070, mean: -1.32834
[32m[0907 07-15-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18566, current rewards: -578.20070, mean: -1.41025
[32m[0907 07-15-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18507, current rewards: -678.20070, mean: -1.47435
[32m[0907 07-15-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18442, current rewards: -778.20070, mean: -1.52588
[32m[0907 07-15-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18391, current rewards: -878.20070, mean: -1.56822
[32m[0907 07-15-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18345, current rewards: -978.20070, mean: -1.60361
[32m[0907 07-16-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18305, current rewards: -1078.20070, mean: -1.63364
[32m[0907 07-16-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18273, current rewards: -1178.20070, mean: -1.65944
[32m[0907 07-16-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18246, current rewards: -1278.20070, mean: -1.68184
[32m[0907 07-16-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18222, current rewards: -1378.20070, mean: -1.70148
[32m[0907 07-16-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18203, current rewards: -1478.20070, mean: -1.71884
[32m[0907 07-16-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18182, current rewards: -1578.20070, mean: -1.73429
[32m[0907 07-17-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18164, current rewards: -1678.20070, mean: -1.74813
[32m[0907 07-17-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18149, current rewards: -1778.20070, mean: -1.76059
[32m[0907 07-17-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18138, current rewards: -1878.20070, mean: -1.77189
[32m[0907 07-17-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18124, current rewards: -1978.20070, mean: -1.78216
[32m[0907 07-17-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18109, current rewards: -2078.20070, mean: -1.79155
[32m[0907 07-17-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18100, current rewards: -2178.20070, mean: -1.80017
[32m[0907 07-17-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18091, current rewards: -2278.20070, mean: -1.80810
[32m[0907 07-18-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18085, current rewards: -2378.20070, mean: -1.81542
[32m[0907 07-18-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18076, current rewards: -2478.20070, mean: -1.82221
[32m[0907 07-18-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18076, current rewards: -2578.20070, mean: -1.82851
[32m[0907 07-18-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18087, current rewards: -2678.20070, mean: -1.83438
[32m[0907 07-18-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18099, current rewards: -2778.20070, mean: -1.83987
[32m[0907 07-18-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18112, current rewards: -2878.20070, mean: -1.84500
[32m[0907 07-18-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18124, current rewards: -2978.20070, mean: -1.84981
[32m[0907 07-19-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18132, current rewards: -3078.20070, mean: -1.85434
[32m[0907 07-19-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18141, current rewards: -3178.20070, mean: -1.85860
[32m[0907 07-19-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18155, current rewards: -3278.20070, mean: -1.86261
[32m[0907 07-19-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18176, current rewards: -3378.20070, mean: -1.86641
[32m[0907 07-19-45 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18198, current rewards: -3478.20070, mean: -1.87000
[32m[0907 07-19-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18216, current rewards: -3578.20070, mean: -1.87340
[32m[0907 07-20-04 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18236, current rewards: -3678.20070, mean: -1.87663
[32m[0907 07-20-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18255, current rewards: -3778.20070, mean: -1.87970
[32m[0907 07-20-23 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18271, current rewards: -3878.20070, mean: -1.88262
[32m[0907 07-20-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18284, current rewards: -3978.20070, mean: -1.88540
[32m[0907 07-20-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18295, current rewards: -4078.20070, mean: -1.88806
[32m[0907 07-20-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18297, current rewards: -4178.20070, mean: -1.89059
[32m[0907 07-21-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18299, current rewards: -4278.20070, mean: -1.89301
[32m[0907 07-21-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18302, current rewards: -4378.20070, mean: -1.89532
[32m[0907 07-21-18 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18305, current rewards: -4478.20070, mean: -1.89754
[32m[0907 07-21-27 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18308, current rewards: -4578.20070, mean: -1.89967
[32m[0907 07-21-36 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18300, current rewards: -4678.20070, mean: -1.90171
[32m[0907 07-21-44 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 07-21-44 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-21-44 @MBExp.py:227][0m Rewards obtained: [-4758.200695024628], Lows: [2285], Highs: [192], Total time: 50990.80275699998
[32m[0907 07-25-35 @MBExp.py:144][0m ####################################################################
[32m[0907 07-25-35 @MBExp.py:145][0m Starting training iteration 112.
[32m[0907 07-25-37 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19061, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-25-46 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.19190, current rewards: -101.85080, mean: -1.69751
[32m[0907 07-25-55 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18813, current rewards: -201.85080, mean: -1.83501
[32m[0907 07-26-05 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18713, current rewards: -301.85080, mean: -1.88657
[32m[0907 07-26-14 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18640, current rewards: -401.85080, mean: -1.91358
[32m[0907 07-26-23 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18603, current rewards: -501.85080, mean: -1.93020
[32m[0907 07-26-32 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18578, current rewards: -601.85080, mean: -1.94145
[32m[0907 07-26-42 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18557, current rewards: -701.85080, mean: -1.94959
[32m[0907 07-26-51 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18519, current rewards: -801.85080, mean: -1.95573
[32m[0907 07-27-00 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18443, current rewards: -901.85080, mean: -1.96055
[32m[0907 07-27-09 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18384, current rewards: -1001.85080, mean: -1.96441
[32m[0907 07-27-17 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18329, current rewards: -1101.85080, mean: -1.96759
[32m[0907 07-27-26 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18288, current rewards: -1201.85080, mean: -1.97025
[32m[0907 07-27-35 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18256, current rewards: -1301.85080, mean: -1.97250
[32m[0907 07-27-44 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18227, current rewards: -1401.85080, mean: -1.97444
[32m[0907 07-27-53 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18200, current rewards: -1501.85080, mean: -1.97612
[32m[0907 07-28-02 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18179, current rewards: -1601.85080, mean: -1.97759
[32m[0907 07-28-11 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18158, current rewards: -1701.85080, mean: -1.97890
[32m[0907 07-28-20 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18145, current rewards: -1801.85080, mean: -1.98006
[32m[0907 07-28-29 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18132, current rewards: -1901.85080, mean: -1.98109
[32m[0907 07-28-38 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18118, current rewards: -2001.85080, mean: -1.98203
[32m[0907 07-28-47 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18106, current rewards: -2101.85080, mean: -1.98288
[32m[0907 07-28-56 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18094, current rewards: -2201.85080, mean: -1.98365
[32m[0907 07-29-05 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18081, current rewards: -2301.85080, mean: -1.98435
[32m[0907 07-29-14 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18069, current rewards: -2401.85080, mean: -1.98500
[32m[0907 07-29-23 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18060, current rewards: -2501.85080, mean: -1.98560
[32m[0907 07-29-31 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18053, current rewards: -2601.85080, mean: -1.98615
[32m[0907 07-29-40 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18046, current rewards: -2701.85080, mean: -1.98665
[32m[0907 07-29-50 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18051, current rewards: -2801.85080, mean: -1.98713
[32m[0907 07-29-59 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18064, current rewards: -2901.85080, mean: -1.98757
[32m[0907 07-30-08 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18079, current rewards: -3001.85080, mean: -1.98798
[32m[0907 07-30-17 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18091, current rewards: -3101.85080, mean: -1.98837
[32m[0907 07-30-26 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18103, current rewards: -3201.85080, mean: -1.98873
[32m[0907 07-30-36 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18114, current rewards: -3301.85080, mean: -1.98907
[32m[0907 07-30-45 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18125, current rewards: -3401.85080, mean: -1.98939
[32m[0907 07-30-54 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18146, current rewards: -3501.85080, mean: -1.98969
[32m[0907 07-31-04 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18163, current rewards: -3601.85080, mean: -1.98997
[32m[0907 07-31-13 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18181, current rewards: -3701.85080, mean: -1.99024
[32m[0907 07-31-23 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18197, current rewards: -3801.85080, mean: -1.99050
[32m[0907 07-31-32 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18216, current rewards: -3901.85080, mean: -1.99074
[32m[0907 07-31-42 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18235, current rewards: -4001.85080, mean: -1.99097
[32m[0907 07-31-51 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18251, current rewards: -4101.85080, mean: -1.99119
[32m[0907 07-32-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18265, current rewards: -4201.85080, mean: -1.99140
[32m[0907 07-32-10 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18279, current rewards: -4301.85080, mean: -1.99160
[32m[0907 07-32-19 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18292, current rewards: -4401.85080, mean: -1.99179
[32m[0907 07-32-29 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18304, current rewards: -4501.85080, mean: -1.99197
[32m[0907 07-32-38 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18316, current rewards: -4601.85080, mean: -1.99214
[32m[0907 07-32-48 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18322, current rewards: -4701.85080, mean: -1.99231
[32m[0907 07-32-57 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18324, current rewards: -4801.85080, mean: -1.99247
[32m[0907 07-33-06 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18317, current rewards: -4901.85080, mean: -1.99262
[32m[0907 07-33-13 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0907 07-33-13 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-33-13 @MBExp.py:227][0m Rewards obtained: [-4981.850797860986], Lows: [2484], Highs: [14], Total time: 51449.42179199999
[32m[0907 07-37-06 @MBExp.py:144][0m ####################################################################
[32m[0907 07-37-06 @MBExp.py:145][0m Starting training iteration 113.
[32m[0907 07-37-08 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18919, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-37-18 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18777, current rewards: -110.00000, mean: -1.83333
[32m[0907 07-37-27 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18626, current rewards: -210.00000, mean: -1.90909
[32m[0907 07-37-36 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18569, current rewards: -310.00000, mean: -1.93750
[32m[0907 07-37-45 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18519, current rewards: -410.00000, mean: -1.95238
[32m[0907 07-37-54 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18499, current rewards: -510.00000, mean: -1.96154
[32m[0907 07-38-04 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18487, current rewards: -610.00000, mean: -1.96774
[32m[0907 07-38-13 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18482, current rewards: -710.00000, mean: -1.97222
[32m[0907 07-38-22 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18463, current rewards: -810.00000, mean: -1.97561
[32m[0907 07-38-31 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18396, current rewards: -910.00000, mean: -1.97826
[32m[0907 07-38-40 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18338, current rewards: -1010.00000, mean: -1.98039
[32m[0907 07-38-49 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18295, current rewards: -1110.00000, mean: -1.98214
[32m[0907 07-38-58 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18258, current rewards: -1210.00000, mean: -1.98361
[32m[0907 07-39-07 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18227, current rewards: -1310.00000, mean: -1.98485
[32m[0907 07-39-16 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18199, current rewards: -1410.00000, mean: -1.98592
[32m[0907 07-39-25 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18174, current rewards: -1510.00000, mean: -1.98684
[32m[0907 07-39-33 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18153, current rewards: -1610.00000, mean: -1.98765
[32m[0907 07-39-42 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18133, current rewards: -1710.00000, mean: -1.98837
[32m[0907 07-39-51 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18119, current rewards: -1810.00000, mean: -1.98901
[32m[0907 07-40-00 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18103, current rewards: -1910.00000, mean: -1.98958
[32m[0907 07-40-09 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18092, current rewards: -2010.00000, mean: -1.99010
[32m[0907 07-40-18 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18079, current rewards: -2110.00000, mean: -1.99057
[32m[0907 07-40-27 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18069, current rewards: -2210.00000, mean: -1.99099
[32m[0907 07-40-36 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18059, current rewards: -2310.00000, mean: -1.99138
[32m[0907 07-40-45 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18048, current rewards: -2410.00000, mean: -1.99174
[32m[0907 07-40-54 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18040, current rewards: -2510.00000, mean: -1.99206
[32m[0907 07-41-03 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18033, current rewards: -2610.00000, mean: -1.99237
[32m[0907 07-41-12 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18024, current rewards: -2710.00000, mean: -1.99265
[32m[0907 07-41-21 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18030, current rewards: -2810.00000, mean: -1.99291
[32m[0907 07-41-30 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18045, current rewards: -2910.00000, mean: -1.99315
[32m[0907 07-41-39 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18058, current rewards: -3010.00000, mean: -1.99338
[32m[0907 07-41-49 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18070, current rewards: -3110.00000, mean: -1.99359
[32m[0907 07-41-58 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18081, current rewards: -3210.00000, mean: -1.99379
[32m[0907 07-42-07 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18091, current rewards: -3310.00000, mean: -1.99398
[32m[0907 07-42-16 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18100, current rewards: -3410.00000, mean: -1.99415
[32m[0907 07-42-26 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18116, current rewards: -3510.00000, mean: -1.99432
[32m[0907 07-42-35 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18139, current rewards: -3610.00000, mean: -1.99448
[32m[0907 07-42-44 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18159, current rewards: -3710.00000, mean: -1.99462
[32m[0907 07-42-54 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18176, current rewards: -3810.00000, mean: -1.99476
[32m[0907 07-43-03 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18194, current rewards: -3910.00000, mean: -1.99490
[32m[0907 07-43-13 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18210, current rewards: -4010.00000, mean: -1.99502
[32m[0907 07-43-22 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18229, current rewards: -4110.00000, mean: -1.99515
[32m[0907 07-43-32 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18244, current rewards: -4210.00000, mean: -1.99526
[32m[0907 07-43-41 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18258, current rewards: -4310.00000, mean: -1.99537
[32m[0907 07-43-51 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18271, current rewards: -4410.00000, mean: -1.99548
[32m[0907 07-44-00 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18283, current rewards: -4510.00000, mean: -1.99558
[32m[0907 07-44-09 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18295, current rewards: -4610.00000, mean: -1.99567
[32m[0907 07-44-19 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18306, current rewards: -4710.00000, mean: -1.99576
[32m[0907 07-44-28 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18308, current rewards: -4810.00000, mean: -1.99585
[32m[0907 07-44-37 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18310, current rewards: -4910.00000, mean: -1.99593
[32m[0907 07-44-45 @Agent.py:117][0m Average action selection time: 0.1831
[32m[0907 07-44-45 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-44-45 @MBExp.py:227][0m Rewards obtained: [-4990], Lows: [2490], Highs: [10], Total time: 51907.948376999986
[32m[0907 07-48-39 @MBExp.py:144][0m ####################################################################
[32m[0907 07-48-39 @MBExp.py:145][0m Starting training iteration 114.
[32m[0907 07-48-41 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18815, current rewards: -10.00000, mean: -1.00000
[32m[0907 07-48-50 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18584, current rewards: -83.65604, mean: -1.39427
[32m[0907 07-49-00 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.18528, current rewards: -183.65604, mean: -1.66960
[32m[0907 07-49-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.18511, current rewards: -283.65604, mean: -1.77285
[32m[0907 07-49-18 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18496, current rewards: -383.65604, mean: -1.82693
[32m[0907 07-49-27 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18488, current rewards: -483.65604, mean: -1.86022
[32m[0907 07-49-37 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18475, current rewards: -583.65604, mean: -1.88276
[32m[0907 07-49-46 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18468, current rewards: -683.65604, mean: -1.89904
[32m[0907 07-49-55 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18405, current rewards: -783.65604, mean: -1.91136
[32m[0907 07-50-04 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18348, current rewards: -883.65604, mean: -1.92099
[32m[0907 07-50-13 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18302, current rewards: -983.65604, mean: -1.92874
[32m[0907 07-50-22 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18261, current rewards: -1083.65604, mean: -1.93510
[32m[0907 07-50-31 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18222, current rewards: -1183.65604, mean: -1.94042
[32m[0907 07-50-39 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18192, current rewards: -1283.65604, mean: -1.94493
[32m[0907 07-50-48 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18167, current rewards: -1383.65604, mean: -1.94881
[32m[0907 07-50-57 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18150, current rewards: -1483.65604, mean: -1.95218
[32m[0907 07-51-06 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18134, current rewards: -1583.65604, mean: -1.95513
[32m[0907 07-51-15 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18118, current rewards: -1683.65604, mean: -1.95774
[32m[0907 07-51-24 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18104, current rewards: -1783.65604, mean: -1.96006
[32m[0907 07-51-33 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18089, current rewards: -1883.65604, mean: -1.96214
[32m[0907 07-51-42 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18075, current rewards: -1983.65604, mean: -1.96402
[32m[0907 07-51-51 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18063, current rewards: -2083.65604, mean: -1.96571
[32m[0907 07-52-00 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18052, current rewards: -2183.65604, mean: -1.96726
[32m[0907 07-52-09 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18044, current rewards: -2283.65604, mean: -1.96867
[32m[0907 07-52-18 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18033, current rewards: -2383.65604, mean: -1.96996
[32m[0907 07-52-27 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18027, current rewards: -2483.65604, mean: -1.97116
[32m[0907 07-52-36 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18018, current rewards: -2583.65604, mean: -1.97226
[32m[0907 07-52-45 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18011, current rewards: -2683.65604, mean: -1.97328
[32m[0907 07-52-54 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18024, current rewards: -2783.65604, mean: -1.97422
[32m[0907 07-53-03 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18036, current rewards: -2883.65604, mean: -1.97511
[32m[0907 07-53-12 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18047, current rewards: -2983.65604, mean: -1.97593
[32m[0907 07-53-21 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18061, current rewards: -3083.65604, mean: -1.97670
[32m[0907 07-53-31 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18070, current rewards: -3183.65604, mean: -1.97743
[32m[0907 07-53-40 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18081, current rewards: -3283.65604, mean: -1.97811
[32m[0907 07-53-49 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18090, current rewards: -3383.65604, mean: -1.97875
[32m[0907 07-53-58 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18112, current rewards: -3483.65604, mean: -1.97935
[32m[0907 07-54-08 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18133, current rewards: -3583.65604, mean: -1.97992
[32m[0907 07-54-17 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18153, current rewards: -3683.65604, mean: -1.98046
[32m[0907 07-54-27 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18173, current rewards: -3783.65604, mean: -1.98097
[32m[0907 07-54-36 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18192, current rewards: -3883.65604, mean: -1.98146
[32m[0907 07-54-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18209, current rewards: -3983.65604, mean: -1.98192
[32m[0907 07-54-55 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18225, current rewards: -4083.65604, mean: -1.98236
[32m[0907 07-55-05 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18242, current rewards: -4183.65604, mean: -1.98278
[32m[0907 07-55-14 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18257, current rewards: -4283.65604, mean: -1.98317
[32m[0907 07-55-24 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18271, current rewards: -4383.65604, mean: -1.98355
[32m[0907 07-55-33 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18286, current rewards: -4483.65604, mean: -1.98392
[32m[0907 07-55-43 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18299, current rewards: -4583.65604, mean: -1.98427
[32m[0907 07-55-52 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18311, current rewards: -4683.65604, mean: -1.98460
[32m[0907 07-56-01 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18324, current rewards: -4783.65604, mean: -1.98492
[32m[0907 07-56-11 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18325, current rewards: -4883.65604, mean: -1.98523
[32m[0907 07-56-18 @Agent.py:117][0m Average action selection time: 0.1832
[32m[0907 07-56-18 @Agent.py:118][0m Rollout length: 2510
[32m[0907 07-56-18 @MBExp.py:227][0m Rewards obtained: [-4963.656043396035], Lows: [2477], Highs: [11], Total time: 52366.82660799999
[32m[0907 08-00-15 @MBExp.py:144][0m ####################################################################
[32m[0907 08-00-15 @MBExp.py:145][0m Starting training iteration 115.
[32m[0907 08-00-18 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.28097, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-00-28 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.20479, current rewards: -108.00000, mean: -1.80000
[32m[0907 08-00-37 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.19542, current rewards: -208.00000, mean: -1.89091
[32m[0907 08-00-46 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.19197, current rewards: -308.00000, mean: -1.92500
[32m[0907 08-00-55 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.19014, current rewards: -408.00000, mean: -1.94286
[32m[0907 08-01-05 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18896, current rewards: -508.00000, mean: -1.95385
[32m[0907 08-01-14 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18823, current rewards: -608.00000, mean: -1.96129
[32m[0907 08-01-23 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18744, current rewards: -708.00000, mean: -1.96667
[32m[0907 08-01-32 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18637, current rewards: -808.00000, mean: -1.97073
[32m[0907 08-01-41 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18553, current rewards: -908.00000, mean: -1.97391
[32m[0907 08-01-50 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18484, current rewards: -1008.00000, mean: -1.97647
[32m[0907 08-01-59 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18424, current rewards: -1108.00000, mean: -1.97857
[32m[0907 08-02-08 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18375, current rewards: -1208.00000, mean: -1.98033
[32m[0907 08-02-17 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18334, current rewards: -1308.00000, mean: -1.98182
[32m[0907 08-02-26 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18302, current rewards: -1408.00000, mean: -1.98310
[32m[0907 08-02-34 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18272, current rewards: -1508.00000, mean: -1.98421
[32m[0907 08-02-43 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18245, current rewards: -1608.00000, mean: -1.98519
[32m[0907 08-02-52 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18222, current rewards: -1708.00000, mean: -1.98605
[32m[0907 08-03-01 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18201, current rewards: -1808.00000, mean: -1.98681
[32m[0907 08-03-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.18185, current rewards: -1908.00000, mean: -1.98750
[32m[0907 08-03-19 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.18169, current rewards: -2008.00000, mean: -1.98812
[32m[0907 08-03-28 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.18153, current rewards: -2108.00000, mean: -1.98868
[32m[0907 08-03-37 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.18138, current rewards: -2208.00000, mean: -1.98919
[32m[0907 08-03-46 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.18125, current rewards: -2308.00000, mean: -1.98966
[32m[0907 08-03-55 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.18111, current rewards: -2408.00000, mean: -1.99008
[32m[0907 08-04-04 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.18101, current rewards: -2508.00000, mean: -1.99048
[32m[0907 08-04-13 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.18092, current rewards: -2608.00000, mean: -1.99084
[32m[0907 08-04-22 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.18089, current rewards: -2708.00000, mean: -1.99118
[32m[0907 08-04-31 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.18100, current rewards: -2808.00000, mean: -1.99149
[32m[0907 08-04-40 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.18112, current rewards: -2908.00000, mean: -1.99178
[32m[0907 08-04-49 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18121, current rewards: -3008.00000, mean: -1.99205
[32m[0907 08-04-59 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18131, current rewards: -3108.00000, mean: -1.99231
[32m[0907 08-05-08 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18142, current rewards: -3208.00000, mean: -1.99255
[32m[0907 08-05-17 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18151, current rewards: -3308.00000, mean: -1.99277
[32m[0907 08-05-26 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18163, current rewards: -3408.00000, mean: -1.99298
[32m[0907 08-05-36 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18188, current rewards: -3508.00000, mean: -1.99318
[32m[0907 08-05-45 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18212, current rewards: -3608.00000, mean: -1.99337
[32m[0907 08-05-55 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18231, current rewards: -3708.00000, mean: -1.99355
[32m[0907 08-06-04 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18248, current rewards: -3808.00000, mean: -1.99372
[32m[0907 08-06-14 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18267, current rewards: -3908.00000, mean: -1.99388
[32m[0907 08-06-23 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18283, current rewards: -4008.00000, mean: -1.99403
[32m[0907 08-06-33 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18299, current rewards: -4108.00000, mean: -1.99417
[32m[0907 08-06-42 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18313, current rewards: -4208.00000, mean: -1.99431
[32m[0907 08-06-52 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18328, current rewards: -4308.00000, mean: -1.99444
[32m[0907 08-07-01 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18341, current rewards: -4408.00000, mean: -1.99457
[32m[0907 08-07-11 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18353, current rewards: -4508.00000, mean: -1.99469
[32m[0907 08-07-20 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18365, current rewards: -4608.00000, mean: -1.99481
[32m[0907 08-07-30 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18375, current rewards: -4708.00000, mean: -1.99492
[32m[0907 08-07-39 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18384, current rewards: -4808.00000, mean: -1.99502
[32m[0907 08-07-48 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18386, current rewards: -4908.00000, mean: -1.99512
[32m[0907 08-07-56 @Agent.py:117][0m Average action selection time: 0.1839
[32m[0907 08-07-56 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-07-56 @MBExp.py:227][0m Rewards obtained: [-4988], Lows: [2488], Highs: [12], Total time: 52827.40805199999
[32m[0907 08-11-55 @MBExp.py:144][0m ####################################################################
[32m[0907 08-11-55 @MBExp.py:145][0m Starting training iteration 116.
[32m[0907 08-11-57 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17797, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-12-06 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17876, current rewards: -60.00000, mean: -1.00000
[32m[0907 08-12-15 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17889, current rewards: -110.00000, mean: -1.00000
[32m[0907 08-12-24 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17961, current rewards: -160.00000, mean: -1.00000
[32m[0907 08-12-33 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18078, current rewards: -210.00000, mean: -1.00000
[32m[0907 08-12-42 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18147, current rewards: -260.00000, mean: -1.00000
[32m[0907 08-12-52 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18201, current rewards: -310.00000, mean: -1.00000
[32m[0907 08-13-01 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18202, current rewards: -360.00000, mean: -1.00000
[32m[0907 08-13-10 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18164, current rewards: -410.00000, mean: -1.00000
[32m[0907 08-13-19 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18132, current rewards: -460.00000, mean: -1.00000
[32m[0907 08-13-28 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18106, current rewards: -510.00000, mean: -1.00000
[32m[0907 08-13-36 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.18080, current rewards: -560.00000, mean: -1.00000
[32m[0907 08-13-45 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.18062, current rewards: -610.00000, mean: -1.00000
[32m[0907 08-13-54 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.18046, current rewards: -660.00000, mean: -1.00000
[32m[0907 08-14-03 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.18036, current rewards: -710.00000, mean: -1.00000
[32m[0907 08-14-12 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.18031, current rewards: -760.00000, mean: -1.00000
[32m[0907 08-14-21 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.18016, current rewards: -810.00000, mean: -1.00000
[32m[0907 08-14-30 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.18009, current rewards: -860.00000, mean: -1.00000
[32m[0907 08-14-39 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.18005, current rewards: -883.43618, mean: -0.97081
[32m[0907 08-14-48 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17997, current rewards: -880.55010, mean: -0.91724
[32m[0907 08-14-57 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17992, current rewards: -877.66401, mean: -0.86897
[32m[0907 08-15-06 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17986, current rewards: -874.77793, mean: -0.82526
[32m[0907 08-15-15 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17978, current rewards: -871.89185, mean: -0.78549
[32m[0907 08-15-24 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17973, current rewards: -869.00576, mean: -0.74914
[32m[0907 08-15-33 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17966, current rewards: -866.11968, mean: -0.71580
[32m[0907 08-15-42 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17958, current rewards: -863.23359, mean: -0.68511
[32m[0907 08-15-51 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17953, current rewards: -861.40523, mean: -0.65756
[32m[0907 08-16-00 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17958, current rewards: -911.40523, mean: -0.67015
[32m[0907 08-16-09 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17975, current rewards: -961.40523, mean: -0.68185
[32m[0907 08-16-18 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17990, current rewards: -1011.40523, mean: -0.69274
[32m[0907 08-16-27 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.18003, current rewards: -1061.40523, mean: -0.70292
[32m[0907 08-16-37 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.18017, current rewards: -1111.40523, mean: -0.71244
[32m[0907 08-16-46 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.18031, current rewards: -1161.40523, mean: -0.72137
[32m[0907 08-16-55 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.18044, current rewards: -1211.40523, mean: -0.72976
[32m[0907 08-17-04 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18055, current rewards: -1261.40523, mean: -0.73766
[32m[0907 08-17-14 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18080, current rewards: -1311.40523, mean: -0.74512
[32m[0907 08-17-23 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18105, current rewards: -1361.40523, mean: -0.75216
[32m[0907 08-17-33 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18128, current rewards: -1411.40523, mean: -0.75882
[32m[0907 08-17-42 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18152, current rewards: -1461.40523, mean: -0.76513
[32m[0907 08-17-52 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18170, current rewards: -1511.40523, mean: -0.77113
[32m[0907 08-18-01 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18188, current rewards: -1561.40523, mean: -0.77682
[32m[0907 08-18-11 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18206, current rewards: -1611.40523, mean: -0.78224
[32m[0907 08-18-20 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18221, current rewards: -1661.40523, mean: -0.78740
[32m[0907 08-18-30 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18238, current rewards: -1711.40523, mean: -0.79232
[32m[0907 08-18-39 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18252, current rewards: -1761.40523, mean: -0.79702
[32m[0907 08-18-48 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18266, current rewards: -1811.40523, mean: -0.80151
[32m[0907 08-18-58 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18276, current rewards: -1861.40523, mean: -0.80580
[32m[0907 08-19-07 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18288, current rewards: -1911.40523, mean: -0.80992
[32m[0907 08-19-17 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18300, current rewards: -1961.40523, mean: -0.81386
[32m[0907 08-19-26 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18301, current rewards: -2011.40523, mean: -0.81764
[32m[0907 08-19-33 @Agent.py:117][0m Average action selection time: 0.1830
[32m[0907 08-19-33 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-19-34 @MBExp.py:227][0m Rewards obtained: [-2051.4052322005045], Lows: [0], Highs: [2077], Total time: 53285.87614699999
[32m[0907 08-23-35 @MBExp.py:144][0m ####################################################################
[32m[0907 08-23-35 @MBExp.py:145][0m Starting training iteration 117.
[32m[0907 08-23-36 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18346, current rewards: -6.85344, mean: -0.68534
[32m[0907 08-23-45 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17956, current rewards: -106.85344, mean: -1.78089
[32m[0907 08-23-54 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17869, current rewards: -206.85344, mean: -1.88049
[32m[0907 08-24-03 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17873, current rewards: -306.85344, mean: -1.91783
[32m[0907 08-24-12 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17996, current rewards: -406.85344, mean: -1.93740
[32m[0907 08-24-22 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18077, current rewards: -506.85344, mean: -1.94944
[32m[0907 08-24-31 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18133, current rewards: -606.85344, mean: -1.95759
[32m[0907 08-24-40 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18083, current rewards: -706.85344, mean: -1.96348
[32m[0907 08-24-49 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18054, current rewards: -806.85344, mean: -1.96794
[32m[0907 08-24-58 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18028, current rewards: -906.85344, mean: -1.97142
[32m[0907 08-25-07 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18011, current rewards: -1006.85344, mean: -1.97422
[32m[0907 08-25-16 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17998, current rewards: -1106.85344, mean: -1.97652
[32m[0907 08-25-24 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17984, current rewards: -1206.85344, mean: -1.97845
[32m[0907 08-25-33 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17975, current rewards: -1306.85344, mean: -1.98008
[32m[0907 08-25-42 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17965, current rewards: -1406.85344, mean: -1.98148
[32m[0907 08-25-51 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17953, current rewards: -1506.85344, mean: -1.98270
[32m[0907 08-26-00 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17945, current rewards: -1606.85344, mean: -1.98377
[32m[0907 08-26-09 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17937, current rewards: -1706.85344, mean: -1.98471
[32m[0907 08-26-18 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17931, current rewards: -1804.65382, mean: -1.98314
[32m[0907 08-26-27 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17925, current rewards: -1904.65382, mean: -1.98401
[32m[0907 08-26-36 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17920, current rewards: -2004.65382, mean: -1.98481
[32m[0907 08-26-45 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17915, current rewards: -2104.65382, mean: -1.98552
[32m[0907 08-26-54 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17912, current rewards: -2204.65382, mean: -1.98617
[32m[0907 08-27-03 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17906, current rewards: -2304.65382, mean: -1.98677
[32m[0907 08-27-12 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17903, current rewards: -2404.65382, mean: -1.98732
[32m[0907 08-27-20 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17902, current rewards: -2504.65382, mean: -1.98782
[32m[0907 08-27-29 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17898, current rewards: -2604.65382, mean: -1.98829
[32m[0907 08-27-38 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17896, current rewards: -2704.65382, mean: -1.98872
[32m[0907 08-27-47 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17896, current rewards: -2804.65382, mean: -1.98912
[32m[0907 08-27-56 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17912, current rewards: -2904.65382, mean: -1.98949
[32m[0907 08-28-06 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17929, current rewards: -3004.65382, mean: -1.98984
[32m[0907 08-28-15 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17946, current rewards: -3104.65382, mean: -1.99016
[32m[0907 08-28-24 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17959, current rewards: -3204.65382, mean: -1.99047
[32m[0907 08-28-33 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17973, current rewards: -3304.65382, mean: -1.99076
[32m[0907 08-28-43 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.17990, current rewards: -3404.65382, mean: -1.99103
[32m[0907 08-28-52 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18017, current rewards: -3504.65382, mean: -1.99128
[32m[0907 08-29-02 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18041, current rewards: -3604.65382, mean: -1.99152
[32m[0907 08-29-11 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18065, current rewards: -3704.65382, mean: -1.99175
[32m[0907 08-29-20 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18086, current rewards: -3804.65382, mean: -1.99197
[32m[0907 08-29-30 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18106, current rewards: -3904.65382, mean: -1.99217
[32m[0907 08-29-39 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18124, current rewards: -4004.65382, mean: -1.99237
[32m[0907 08-29-49 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18141, current rewards: -4104.65382, mean: -1.99255
[32m[0907 08-29-58 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18157, current rewards: -4204.65382, mean: -1.99273
[32m[0907 08-30-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18175, current rewards: -4304.65382, mean: -1.99290
[32m[0907 08-30-17 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18189, current rewards: -4404.65382, mean: -1.99306
[32m[0907 08-30-27 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18204, current rewards: -4504.65382, mean: -1.99321
[32m[0907 08-30-36 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18218, current rewards: -4604.65382, mean: -1.99336
[32m[0907 08-30-45 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18231, current rewards: -4704.65382, mean: -1.99350
[32m[0907 08-30-55 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18246, current rewards: -4804.65382, mean: -1.99363
[32m[0907 08-31-04 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18254, current rewards: -4904.65382, mean: -1.99376
[32m[0907 08-31-12 @Agent.py:117][0m Average action selection time: 0.1826
[32m[0907 08-31-12 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-31-12 @MBExp.py:227][0m Rewards obtained: [-4984.653817391183], Lows: [2489], Highs: [7], Total time: 53743.160202999985
[32m[0907 08-35-14 @MBExp.py:144][0m ####################################################################
[32m[0907 08-35-14 @MBExp.py:145][0m Starting training iteration 118.
[32m[0907 08-35-16 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.17513, current rewards: 0.80196, mean: 0.08020
[32m[0907 08-35-24 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17780, current rewards: -94.38963, mean: -1.57316
[32m[0907 08-35-33 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17797, current rewards: -194.38963, mean: -1.76718
[32m[0907 08-35-42 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17843, current rewards: -294.38963, mean: -1.83994
[32m[0907 08-35-52 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.17982, current rewards: -394.38963, mean: -1.87805
[32m[0907 08-36-01 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18073, current rewards: -494.38963, mean: -1.90150
[32m[0907 08-36-10 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18073, current rewards: -594.38963, mean: -1.91739
[32m[0907 08-36-19 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18043, current rewards: -694.38963, mean: -1.92886
[32m[0907 08-36-28 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18026, current rewards: -794.38963, mean: -1.93754
[32m[0907 08-36-37 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18009, current rewards: -894.38963, mean: -1.94433
[32m[0907 08-36-46 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.17995, current rewards: -994.38963, mean: -1.94978
[32m[0907 08-36-55 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17983, current rewards: -1094.38963, mean: -1.95427
[32m[0907 08-37-04 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17974, current rewards: -1194.38963, mean: -1.95802
[32m[0907 08-37-13 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17966, current rewards: -1294.38963, mean: -1.96120
[32m[0907 08-37-21 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17958, current rewards: -1394.38963, mean: -1.96393
[32m[0907 08-37-30 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17950, current rewards: -1494.38963, mean: -1.96630
[32m[0907 08-37-39 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17945, current rewards: -1594.38963, mean: -1.96838
[32m[0907 08-37-48 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17938, current rewards: -1694.38963, mean: -1.97022
[32m[0907 08-37-57 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17933, current rewards: -1794.38963, mean: -1.97186
[32m[0907 08-38-06 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17930, current rewards: -1894.38963, mean: -1.97332
[32m[0907 08-38-15 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17929, current rewards: -1994.38963, mean: -1.97464
[32m[0907 08-38-24 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17928, current rewards: -2094.38963, mean: -1.97584
[32m[0907 08-38-33 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17924, current rewards: -2194.38963, mean: -1.97693
[32m[0907 08-38-42 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17919, current rewards: -2294.38963, mean: -1.97792
[32m[0907 08-38-51 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17918, current rewards: -2394.38963, mean: -1.97883
[32m[0907 08-39-00 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17914, current rewards: -2494.38963, mean: -1.97967
[32m[0907 08-39-09 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17912, current rewards: -2594.38963, mean: -1.98045
[32m[0907 08-39-18 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17909, current rewards: -2694.38963, mean: -1.98117
[32m[0907 08-39-27 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17915, current rewards: -2794.38963, mean: -1.98184
[32m[0907 08-39-36 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17934, current rewards: -2894.38963, mean: -1.98246
[32m[0907 08-39-45 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17950, current rewards: -2994.38963, mean: -1.98304
[32m[0907 08-39-54 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17966, current rewards: -3094.38963, mean: -1.98358
[32m[0907 08-40-04 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17981, current rewards: -3194.38963, mean: -1.98409
[32m[0907 08-40-13 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17996, current rewards: -3294.38963, mean: -1.98457
[32m[0907 08-40-22 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18020, current rewards: -3394.38963, mean: -1.98502
[32m[0907 08-40-32 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18046, current rewards: -3494.38963, mean: -1.98545
[32m[0907 08-40-41 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18070, current rewards: -3594.38963, mean: -1.98585
[32m[0907 08-40-51 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18094, current rewards: -3694.38963, mean: -1.98623
[32m[0907 08-41-00 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18116, current rewards: -3794.38963, mean: -1.98659
[32m[0907 08-41-10 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18136, current rewards: -3894.38963, mean: -1.98693
[32m[0907 08-41-19 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18155, current rewards: -3994.38963, mean: -1.98726
[32m[0907 08-41-29 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18176, current rewards: -4094.38963, mean: -1.98757
[32m[0907 08-41-38 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18194, current rewards: -4194.38963, mean: -1.98786
[32m[0907 08-41-48 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18211, current rewards: -4294.38963, mean: -1.98814
[32m[0907 08-41-57 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18229, current rewards: -4394.38963, mean: -1.98841
[32m[0907 08-42-07 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18243, current rewards: -4494.38963, mean: -1.98867
[32m[0907 08-42-16 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18255, current rewards: -4594.38963, mean: -1.98891
[32m[0907 08-42-26 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18269, current rewards: -4694.38963, mean: -1.98915
[32m[0907 08-42-35 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18283, current rewards: -4794.38963, mean: -1.98937
[32m[0907 08-42-44 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18294, current rewards: -4894.38963, mean: -1.98959
[32m[0907 08-42-52 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 08-42-52 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-42-52 @MBExp.py:227][0m Rewards obtained: [-4974.389634752653], Lows: [2488], Highs: [0], Total time: 54201.41911499998
[32m[0907 08-46-57 @MBExp.py:144][0m ####################################################################
[32m[0907 08-46-57 @MBExp.py:145][0m Starting training iteration 119.
[32m[0907 08-46-59 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.18272, current rewards: 0.57914, mean: 0.05791
[32m[0907 08-47-08 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.18112, current rewards: -26.55119, mean: -0.44252
[32m[0907 08-47-17 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17965, current rewards: -23.83764, mean: -0.21671
[32m[0907 08-47-26 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.17954, current rewards: -21.12408, mean: -0.13203
[32m[0907 08-47-35 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.18073, current rewards: -18.41053, mean: -0.08767
[32m[0907 08-47-45 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.18155, current rewards: -15.69698, mean: -0.06037
[32m[0907 08-47-54 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.18106, current rewards: -12.98343, mean: -0.04188
[32m[0907 08-48-02 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.18077, current rewards: -10.26988, mean: -0.02853
[32m[0907 08-48-11 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.18050, current rewards: -7.55632, mean: -0.01843
[32m[0907 08-48-20 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.18030, current rewards: -8.01665, mean: -0.01743
[32m[0907 08-48-29 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.18015, current rewards: -58.01665, mean: -0.11376
[32m[0907 08-48-38 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.17997, current rewards: -108.01665, mean: -0.19289
[32m[0907 08-48-47 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.17985, current rewards: -158.01665, mean: -0.25904
[32m[0907 08-48-56 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.17976, current rewards: -208.01665, mean: -0.31518
[32m[0907 08-49-05 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.17968, current rewards: -258.01665, mean: -0.36340
[32m[0907 08-49-14 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.17963, current rewards: -308.01665, mean: -0.40529
[32m[0907 08-49-23 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.17956, current rewards: -358.01665, mean: -0.44200
[32m[0907 08-49-32 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.17947, current rewards: -408.01665, mean: -0.47444
[32m[0907 08-49-41 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.17941, current rewards: -458.01665, mean: -0.50331
[32m[0907 08-49-50 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.17934, current rewards: -508.01665, mean: -0.52918
[32m[0907 08-49-59 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.17931, current rewards: -558.01665, mean: -0.55249
[32m[0907 08-50-08 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.17926, current rewards: -608.01665, mean: -0.57360
[32m[0907 08-50-17 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.17922, current rewards: -658.01665, mean: -0.59281
[32m[0907 08-50-25 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.17918, current rewards: -708.01665, mean: -0.61036
[32m[0907 08-50-34 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.17917, current rewards: -758.01665, mean: -0.62646
[32m[0907 08-50-43 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.17915, current rewards: -808.01665, mean: -0.64128
[32m[0907 08-50-52 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.17913, current rewards: -858.01665, mean: -0.65497
[32m[0907 08-51-01 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.17912, current rewards: -908.01665, mean: -0.66766
[32m[0907 08-51-10 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.17923, current rewards: -958.01665, mean: -0.67944
[32m[0907 08-51-20 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.17941, current rewards: -1008.01665, mean: -0.69042
[32m[0907 08-51-29 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.17957, current rewards: -1058.01665, mean: -0.70067
[32m[0907 08-51-38 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.17971, current rewards: -1108.01665, mean: -0.71027
[32m[0907 08-51-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.17984, current rewards: -1158.01665, mean: -0.71926
[32m[0907 08-51-56 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.17998, current rewards: -1208.01665, mean: -0.72772
[32m[0907 08-52-06 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.18021, current rewards: -1258.01665, mean: -0.73568
[32m[0907 08-52-15 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.18048, current rewards: -1308.01665, mean: -0.74319
[32m[0907 08-52-25 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.18072, current rewards: -1358.01665, mean: -0.75029
[32m[0907 08-52-34 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.18095, current rewards: -1408.01665, mean: -0.75700
[32m[0907 08-52-44 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.18119, current rewards: -1458.01665, mean: -0.76336
[32m[0907 08-52-53 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.18139, current rewards: -1508.01665, mean: -0.76940
[32m[0907 08-53-03 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.18157, current rewards: -1558.01665, mean: -0.77513
[32m[0907 08-53-12 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.18174, current rewards: -1608.01665, mean: -0.78059
[32m[0907 08-53-22 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.18189, current rewards: -1658.01665, mean: -0.78579
[32m[0907 08-53-31 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.18205, current rewards: -1708.01665, mean: -0.79075
[32m[0907 08-53-41 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.18220, current rewards: -1758.01665, mean: -0.79548
[32m[0907 08-53-50 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.18235, current rewards: -1808.01665, mean: -0.80001
[32m[0907 08-53-59 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.18249, current rewards: -1858.01665, mean: -0.80434
[32m[0907 08-54-09 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.18261, current rewards: -1908.01665, mean: -0.80848
[32m[0907 08-54-18 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.18275, current rewards: -1958.01665, mean: -0.81246
[32m[0907 08-54-28 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.18287, current rewards: -2008.01665, mean: -0.81627
[32m[0907 08-54-35 @Agent.py:117][0m Average action selection time: 0.1829
[32m[0907 08-54-35 @Agent.py:118][0m Rollout length: 2510
[32m[0907 08-54-35 @MBExp.py:227][0m Rewards obtained: [-2048.0166460836917], Lows: [15], Highs: [2043], Total time: 54659.507023999984
[32m[0907 08-58-42 @MBExp.py:144][0m ####################################################################
[32m[0907 08-58-42 @MBExp.py:145][0m Starting training iteration 120.
[32m[0907 08-58-44 @Agent.py:82][0m Current timesteps: 10 / 2500, average time: 0.19453, current rewards: -10.00000, mean: -1.00000
[32m[0907 08-58-53 @Agent.py:82][0m Current timesteps: 60 / 2500, average time: 0.17659, current rewards: -101.68401, mean: -1.69473
[32m[0907 08-59-01 @Agent.py:82][0m Current timesteps: 110 / 2500, average time: 0.17028, current rewards: -201.68401, mean: -1.83349
[32m[0907 08-59-09 @Agent.py:82][0m Current timesteps: 160 / 2500, average time: 0.16788, current rewards: -301.68401, mean: -1.88553
[32m[0907 08-59-17 @Agent.py:82][0m Current timesteps: 210 / 2500, average time: 0.16735, current rewards: -401.68401, mean: -1.91278
[32m[0907 08-59-26 @Agent.py:82][0m Current timesteps: 260 / 2500, average time: 0.16796, current rewards: -501.68401, mean: -1.92955
[32m[0907 08-59-34 @Agent.py:82][0m Current timesteps: 310 / 2500, average time: 0.16544, current rewards: -601.68401, mean: -1.94092
[32m[0907 08-59-41 @Agent.py:82][0m Current timesteps: 360 / 2500, average time: 0.16305, current rewards: -701.68401, mean: -1.94912
[32m[0907 08-59-48 @Agent.py:82][0m Current timesteps: 410 / 2500, average time: 0.16123, current rewards: -801.68401, mean: -1.95533
[32m[0907 08-59-56 @Agent.py:82][0m Current timesteps: 460 / 2500, average time: 0.15978, current rewards: -901.68401, mean: -1.96018
[32m[0907 09-00-03 @Agent.py:82][0m Current timesteps: 510 / 2500, average time: 0.15870, current rewards: -1001.68401, mean: -1.96409
[32m[0907 09-00-11 @Agent.py:82][0m Current timesteps: 560 / 2500, average time: 0.15773, current rewards: -1101.68401, mean: -1.96729
[32m[0907 09-00-18 @Agent.py:82][0m Current timesteps: 610 / 2500, average time: 0.15696, current rewards: -1201.68401, mean: -1.96997
[32m[0907 09-00-26 @Agent.py:82][0m Current timesteps: 660 / 2500, average time: 0.15629, current rewards: -1301.68401, mean: -1.97225
[32m[0907 09-00-33 @Agent.py:82][0m Current timesteps: 710 / 2500, average time: 0.15570, current rewards: -1401.68401, mean: -1.97420
[32m[0907 09-00-40 @Agent.py:82][0m Current timesteps: 760 / 2500, average time: 0.15522, current rewards: -1501.68401, mean: -1.97590
[32m[0907 09-00-48 @Agent.py:82][0m Current timesteps: 810 / 2500, average time: 0.15478, current rewards: -1601.68401, mean: -1.97739
[32m[0907 09-00-55 @Agent.py:82][0m Current timesteps: 860 / 2500, average time: 0.15441, current rewards: -1701.68401, mean: -1.97870
[32m[0907 09-01-03 @Agent.py:82][0m Current timesteps: 910 / 2500, average time: 0.15407, current rewards: -1801.68401, mean: -1.97987
[32m[0907 09-01-10 @Agent.py:82][0m Current timesteps: 960 / 2500, average time: 0.15380, current rewards: -1901.68401, mean: -1.98092
[32m[0907 09-01-18 @Agent.py:82][0m Current timesteps: 1010 / 2500, average time: 0.15352, current rewards: -2001.68401, mean: -1.98187
[32m[0907 09-01-25 @Agent.py:82][0m Current timesteps: 1060 / 2500, average time: 0.15328, current rewards: -2101.68401, mean: -1.98272
[32m[0907 09-01-32 @Agent.py:82][0m Current timesteps: 1110 / 2500, average time: 0.15305, current rewards: -2201.68401, mean: -1.98350
[32m[0907 09-01-40 @Agent.py:82][0m Current timesteps: 1160 / 2500, average time: 0.15284, current rewards: -2301.68401, mean: -1.98421
[32m[0907 09-01-47 @Agent.py:82][0m Current timesteps: 1210 / 2500, average time: 0.15266, current rewards: -2401.68401, mean: -1.98486
[32m[0907 09-01-55 @Agent.py:82][0m Current timesteps: 1260 / 2500, average time: 0.15249, current rewards: -2501.68401, mean: -1.98546
[32m[0907 09-02-02 @Agent.py:82][0m Current timesteps: 1310 / 2500, average time: 0.15232, current rewards: -2601.68401, mean: -1.98602
[32m[0907 09-02-09 @Agent.py:82][0m Current timesteps: 1360 / 2500, average time: 0.15216, current rewards: -2701.68401, mean: -1.98653
[32m[0907 09-02-17 @Agent.py:82][0m Current timesteps: 1410 / 2500, average time: 0.15203, current rewards: -2801.68401, mean: -1.98701
[32m[0907 09-02-24 @Agent.py:82][0m Current timesteps: 1460 / 2500, average time: 0.15190, current rewards: -2901.68401, mean: -1.98745
[32m[0907 09-02-32 @Agent.py:82][0m Current timesteps: 1510 / 2500, average time: 0.15177, current rewards: -3001.68401, mean: -1.98787
[32m[0907 09-02-39 @Agent.py:82][0m Current timesteps: 1560 / 2500, average time: 0.15167, current rewards: -3101.68401, mean: -1.98826
[32m[0907 09-02-47 @Agent.py:82][0m Current timesteps: 1610 / 2500, average time: 0.15156, current rewards: -3201.68401, mean: -1.98862
[32m[0907 09-02-54 @Agent.py:82][0m Current timesteps: 1660 / 2500, average time: 0.15146, current rewards: -3301.68401, mean: -1.98897
[32m[0907 09-03-01 @Agent.py:82][0m Current timesteps: 1710 / 2500, average time: 0.15136, current rewards: -3401.68401, mean: -1.98929
[32m[0907 09-03-09 @Agent.py:82][0m Current timesteps: 1760 / 2500, average time: 0.15127, current rewards: -3501.68401, mean: -1.98959
[32m[0907 09-03-16 @Agent.py:82][0m Current timesteps: 1810 / 2500, average time: 0.15118, current rewards: -3601.68401, mean: -1.98988
[32m[0907 09-03-24 @Agent.py:82][0m Current timesteps: 1860 / 2500, average time: 0.15110, current rewards: -3701.68401, mean: -1.99015
[32m[0907 09-03-31 @Agent.py:82][0m Current timesteps: 1910 / 2500, average time: 0.15103, current rewards: -3801.68401, mean: -1.99041
[32m[0907 09-03-39 @Agent.py:82][0m Current timesteps: 1960 / 2500, average time: 0.15096, current rewards: -3901.68401, mean: -1.99066
[32m[0907 09-03-46 @Agent.py:82][0m Current timesteps: 2010 / 2500, average time: 0.15088, current rewards: -4001.68401, mean: -1.99089
[32m[0907 09-03-53 @Agent.py:82][0m Current timesteps: 2060 / 2500, average time: 0.15082, current rewards: -4101.68401, mean: -1.99111
[32m[0907 09-04-01 @Agent.py:82][0m Current timesteps: 2110 / 2500, average time: 0.15074, current rewards: -4201.68401, mean: -1.99132
[32m[0907 09-04-08 @Agent.py:82][0m Current timesteps: 2160 / 2500, average time: 0.15070, current rewards: -4301.68401, mean: -1.99152
[32m[0907 09-04-16 @Agent.py:82][0m Current timesteps: 2210 / 2500, average time: 0.15064, current rewards: -4401.68401, mean: -1.99171
[32m[0907 09-04-23 @Agent.py:82][0m Current timesteps: 2260 / 2500, average time: 0.15058, current rewards: -4501.68401, mean: -1.99190
[32m[0907 09-04-30 @Agent.py:82][0m Current timesteps: 2310 / 2500, average time: 0.15052, current rewards: -4601.68401, mean: -1.99207
[32m[0907 09-04-38 @Agent.py:82][0m Current timesteps: 2360 / 2500, average time: 0.15047, current rewards: -4701.68401, mean: -1.99224
[32m[0907 09-04-45 @Agent.py:82][0m Current timesteps: 2410 / 2500, average time: 0.15041, current rewards: -4801.68401, mean: -1.99240
[32m[0907 09-04-53 @Agent.py:82][0m Current timesteps: 2460 / 2500, average time: 0.15037, current rewards: -4901.68401, mean: -1.99255
[32m[0907 09-04-58 @Agent.py:117][0m Average action selection time: 0.1501
[32m[0907 09-04-58 @Agent.py:118][0m Rollout length: 2510
[32m[0907 09-04-58 @MBExp.py:227][0m Rewards obtained: [-4981.6840140027325], Lows: [2483], Highs: [16], Total time: 55035.58982099999
